{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84efbd7",
   "metadata": {
    "papermill": {
     "duration": 0.008953,
     "end_time": "2025-02-25T04:58:47.955275",
     "exception": false,
     "start_time": "2025-02-25T04:58:47.946322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a1fb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:58:47.971546Z",
     "iopub.status.busy": "2025-02-25T04:58:47.971263Z",
     "iopub.status.idle": "2025-02-25T04:59:18.975996Z",
     "shell.execute_reply": "2025-02-25T04:59:18.974678Z"
    },
    "papermill": {
     "duration": 31.015045,
     "end_time": "2025-02-25T04:59:18.977966",
     "exception": false,
     "start_time": "2025-02-25T04:58:47.962921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aif360\r\n",
      "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.2.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.7.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16->aif360) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16->aif360) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16->aif360) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16->aif360) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16->aif360) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16->aif360) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2025.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.5.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16->aif360) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16->aif360) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16->aif360) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16->aif360) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16->aif360) (2024.2.0)\r\n",
      "Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: aif360\r\n",
      "Successfully installed aif360-0.6.1\r\n",
      "Collecting fairlearn\r\n",
      "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.2.2)\r\n",
      "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->fairlearn) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->fairlearn) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->fairlearn) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->fairlearn) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->fairlearn) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->fairlearn) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2025.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->fairlearn) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->fairlearn) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->fairlearn) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24.4->fairlearn) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24.4->fairlearn) (2024.2.0)\r\n",
      "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: fairlearn\r\n",
      "Successfully installed fairlearn-0.12.0\r\n",
      "Collecting BlackBoxAuditing\r\n",
      "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from BlackBoxAuditing) (3.4.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from BlackBoxAuditing) (3.7.5)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from BlackBoxAuditing) (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from BlackBoxAuditing) (1.26.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->BlackBoxAuditing) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->BlackBoxAuditing) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->BlackBoxAuditing) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->BlackBoxAuditing) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->BlackBoxAuditing) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->BlackBoxAuditing) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->BlackBoxAuditing) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BlackBoxAuditing) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->BlackBoxAuditing) (2025.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->BlackBoxAuditing) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->BlackBoxAuditing) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->BlackBoxAuditing) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->BlackBoxAuditing) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->BlackBoxAuditing) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->BlackBoxAuditing) (2024.2.0)\r\n",
      "Building wheels for collected packages: BlackBoxAuditing\r\n",
      "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394756 sha256=b2801dc906ee6707f5143d55f207ae865061fc839a8d3039da8fc8e0e7ce59a0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/4f/b1/80e1b0790df07536470758fe0a4f9ff8fa942fd9fe30bbb192\r\n",
      "Successfully built BlackBoxAuditing\r\n",
      "Installing collected packages: BlackBoxAuditing\r\n",
      "Successfully installed BlackBoxAuditing-0.1.54\r\n",
      "Collecting adversarial-robustness-toolbox\r\n",
      "  Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.13.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.2.2)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (75.1.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2.4.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.5.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\r\n",
      "Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\r\n",
      "Successfully installed adversarial-robustness-toolbox-1.19.1\r\n",
      "Collecting scikeras\r\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\r\n",
      "Collecting scikit-learn>=1.4.2 (from scikeras)\r\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\r\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->keras>=3.2.0->scikeras) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->keras>=3.2.0->scikeras) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->keras>=3.2.0->scikeras) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->keras>=3.2.0->scikeras) (2.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->keras>=3.2.0->scikeras) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->keras>=3.2.0->scikeras) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\r\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\r\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, scikeras\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed scikeras-0.13.0 scikit-learn-1.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install aif360\n",
    "!pip install fairlearn\n",
    "!pip install BlackBoxAuditing\n",
    "!pip install adversarial-robustness-toolbox \n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa9f50",
   "metadata": {
    "papermill": {
     "duration": 0.009877,
     "end_time": "2025-02-25T04:59:18.998553",
     "exception": false,
     "start_time": "2025-02-25T04:59:18.988676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feef30cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:19.020537Z",
     "iopub.status.busy": "2025-02-25T04:59:19.020208Z",
     "iopub.status.idle": "2025-02-25T04:59:20.775405Z",
     "shell.execute_reply": "2025-02-25T04:59:20.774407Z"
    },
    "papermill": {
     "duration": 1.768087,
     "end_time": "2025-02-25T04:59:20.776990",
     "exception": false,
     "start_time": "2025-02-25T04:59:19.008903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>video_x</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>ecg</th>\n",
       "      <th>bvp</th>\n",
       "      <th>gsr</th>\n",
       "      <th>rsp</th>\n",
       "      <th>skt</th>\n",
       "      <th>emg_zygo</th>\n",
       "      <th>emg_coru</th>\n",
       "      <th>emg_trap</th>\n",
       "      <th>video_y</th>\n",
       "      <th>SUBJECT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>video_name</th>\n",
       "      <th>vid_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1061504</td>\n",
       "      <td>-1276.0</td>\n",
       "      <td>6252.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>0.76062</td>\n",
       "      <td>35.053549</td>\n",
       "      <td>4.384464</td>\n",
       "      <td>27.174558</td>\n",
       "      <td>28.863552</td>\n",
       "      <td>7.86300</td>\n",
       "      <td>6.13825</td>\n",
       "      <td>5.31675</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>scary</td>\n",
       "      <td>Mama (2008)</td>\n",
       "      <td>scary-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061554</td>\n",
       "      <td>-1276.0</td>\n",
       "      <td>6252.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>0.79018</td>\n",
       "      <td>35.005141</td>\n",
       "      <td>4.360800</td>\n",
       "      <td>27.193884</td>\n",
       "      <td>28.849530</td>\n",
       "      <td>7.94525</td>\n",
       "      <td>5.76850</td>\n",
       "      <td>5.15250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>scary</td>\n",
       "      <td>Mama (2008)</td>\n",
       "      <td>scary-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1061604</td>\n",
       "      <td>-1276.0</td>\n",
       "      <td>6268.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>0.80990</td>\n",
       "      <td>35.809029</td>\n",
       "      <td>4.380504</td>\n",
       "      <td>27.213270</td>\n",
       "      <td>28.860030</td>\n",
       "      <td>8.06850</td>\n",
       "      <td>5.72750</td>\n",
       "      <td>5.02950</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>scary</td>\n",
       "      <td>Mama (2008)</td>\n",
       "      <td>scary-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1061654</td>\n",
       "      <td>-1276.0</td>\n",
       "      <td>6268.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>0.83946</td>\n",
       "      <td>37.368456</td>\n",
       "      <td>4.384464</td>\n",
       "      <td>27.281031</td>\n",
       "      <td>28.863552</td>\n",
       "      <td>7.37025</td>\n",
       "      <td>6.09725</td>\n",
       "      <td>5.31675</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>scary</td>\n",
       "      <td>Mama (2008)</td>\n",
       "      <td>scary-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1061704</td>\n",
       "      <td>-1276.0</td>\n",
       "      <td>6288.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>0.79018</td>\n",
       "      <td>37.145698</td>\n",
       "      <td>4.356864</td>\n",
       "      <td>27.271309</td>\n",
       "      <td>28.863552</td>\n",
       "      <td>7.65775</td>\n",
       "      <td>5.89175</td>\n",
       "      <td>5.11150</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>scary</td>\n",
       "      <td>Mama (2008)</td>\n",
       "      <td>scary-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196278</th>\n",
       "      <td>2231442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.05632</td>\n",
       "      <td>37.949645</td>\n",
       "      <td>37.403472</td>\n",
       "      <td>46.155954</td>\n",
       "      <td>29.852173</td>\n",
       "      <td>5.39900</td>\n",
       "      <td>7.53450</td>\n",
       "      <td>5.89175</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>scary</td>\n",
       "      <td>Shutter (2004)</td>\n",
       "      <td>scary-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196279</th>\n",
       "      <td>2231492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.81318</td>\n",
       "      <td>37.542807</td>\n",
       "      <td>37.419240</td>\n",
       "      <td>46.223715</td>\n",
       "      <td>29.852173</td>\n",
       "      <td>5.64550</td>\n",
       "      <td>7.98625</td>\n",
       "      <td>5.85075</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>scary</td>\n",
       "      <td>Shutter (2004)</td>\n",
       "      <td>scary-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196280</th>\n",
       "      <td>2231542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.82632</td>\n",
       "      <td>36.961677</td>\n",
       "      <td>37.320672</td>\n",
       "      <td>46.301140</td>\n",
       "      <td>29.845152</td>\n",
       "      <td>5.56325</td>\n",
       "      <td>7.41125</td>\n",
       "      <td>5.72750</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>scary</td>\n",
       "      <td>Shutter (2004)</td>\n",
       "      <td>scary-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196281</th>\n",
       "      <td>2231592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.83290</td>\n",
       "      <td>36.516101</td>\n",
       "      <td>37.407408</td>\n",
       "      <td>46.397951</td>\n",
       "      <td>29.862694</td>\n",
       "      <td>5.76850</td>\n",
       "      <td>7.57550</td>\n",
       "      <td>5.80975</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>scary</td>\n",
       "      <td>Shutter (2004)</td>\n",
       "      <td>scary-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196282</th>\n",
       "      <td>2231642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.80990</td>\n",
       "      <td>36.361149</td>\n",
       "      <td>37.450776</td>\n",
       "      <td>46.455990</td>\n",
       "      <td>29.852173</td>\n",
       "      <td>5.56325</td>\n",
       "      <td>7.86300</td>\n",
       "      <td>5.97400</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>scary</td>\n",
       "      <td>Shutter (2004)</td>\n",
       "      <td>scary-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196283 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  valence  arousal  video_x                  Emotion      ecg  \\\n",
       "0       1061504  -1276.0   6252.0      8.0  Frustrated or Impatient  0.76062   \n",
       "1       1061554  -1276.0   6252.0      8.0  Frustrated or Impatient  0.79018   \n",
       "2       1061604  -1276.0   6268.0      8.0  Frustrated or Impatient  0.80990   \n",
       "3       1061654  -1276.0   6268.0      8.0  Frustrated or Impatient  0.83946   \n",
       "4       1061704  -1276.0   6288.0      8.0  Frustrated or Impatient  0.79018   \n",
       "...         ...      ...      ...      ...                      ...      ...   \n",
       "196278  2231442      0.0      0.0      7.0                  Neutral  1.05632   \n",
       "196279  2231492      0.0      0.0      7.0                  Neutral  0.81318   \n",
       "196280  2231542      0.0      0.0      7.0                  Neutral  0.82632   \n",
       "196281  2231592      0.0      0.0      7.0                  Neutral  0.83290   \n",
       "196282  2231642      0.0      0.0      7.0                  Neutral  0.80990   \n",
       "\n",
       "              bvp        gsr        rsp        skt  emg_zygo  emg_coru  \\\n",
       "0       35.053549   4.384464  27.174558  28.863552   7.86300   6.13825   \n",
       "1       35.005141   4.360800  27.193884  28.849530   7.94525   5.76850   \n",
       "2       35.809029   4.380504  27.213270  28.860030   8.06850   5.72750   \n",
       "3       37.368456   4.384464  27.281031  28.863552   7.37025   6.09725   \n",
       "4       37.145698   4.356864  27.271309  28.863552   7.65775   5.89175   \n",
       "...           ...        ...        ...        ...       ...       ...   \n",
       "196278  37.949645  37.403472  46.155954  29.852173   5.39900   7.53450   \n",
       "196279  37.542807  37.419240  46.223715  29.852173   5.64550   7.98625   \n",
       "196280  36.961677  37.320672  46.301140  29.845152   5.56325   7.41125   \n",
       "196281  36.516101  37.407408  46.397951  29.862694   5.76850   7.57550   \n",
       "196282  36.361149  37.450776  46.455990  29.852173   5.56325   7.86300   \n",
       "\n",
       "        emg_trap  video_y  SUBJECT    AGE GENDER EMOTION      video_name  \\\n",
       "0        5.31675      8.0        1  30-34      F   scary     Mama (2008)   \n",
       "1        5.15250      8.0        1  30-34      F   scary     Mama (2008)   \n",
       "2        5.02950      8.0        1  30-34      F   scary     Mama (2008)   \n",
       "3        5.31675      8.0        1  30-34      F   scary     Mama (2008)   \n",
       "4        5.11150      8.0        1  30-34      F   scary     Mama (2008)   \n",
       "...          ...      ...      ...    ...    ...     ...             ...   \n",
       "196278   5.89175      7.0       29  25-29      M   scary  Shutter (2004)   \n",
       "196279   5.85075      7.0       29  25-29      M   scary  Shutter (2004)   \n",
       "196280   5.72750      7.0       29  25-29      M   scary  Shutter (2004)   \n",
       "196281   5.80975     12.0       29  25-29      M   scary  Shutter (2004)   \n",
       "196282   5.97400     12.0       29  25-29      M   scary  Shutter (2004)   \n",
       "\n",
       "       vid_emotion  \n",
       "0          scary-2  \n",
       "1          scary-2  \n",
       "2          scary-2  \n",
       "3          scary-2  \n",
       "4          scary-2  \n",
       "...            ...  \n",
       "196278     scary-1  \n",
       "196279     scary-1  \n",
       "196280     scary-1  \n",
       "196281     scary-1  \n",
       "196282     scary-1  \n",
       "\n",
       "[196283 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('/kaggle/input/case-combined/merged_subjects_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60627f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:20.801796Z",
     "iopub.status.busy": "2025-02-25T04:59:20.801513Z",
     "iopub.status.idle": "2025-02-25T04:59:20.819443Z",
     "shell.execute_reply": "2025-02-25T04:59:20.818620Z"
    },
    "papermill": {
     "duration": 0.031563,
     "end_time": "2025-02-25T04:59:20.820775",
     "exception": false,
     "start_time": "2025-02-25T04:59:20.789212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Frustrated or Impatient', 'Tensed or Annoyed',\n",
       "       'Distressed or Defiant', 'Neutral', 'Confident or Attentive',\n",
       "       'Passionate or Amused', 'Pleased or Glad', 'Delighted or Happy',\n",
       "       'Worried or Apathetic', 'Frustrated or Discontented',\n",
       "       'Aroused or Astonished', 'Miserable or Sad', 'Anxious or Dejected',\n",
       "       'Tired or Bored', 'Polite or Sleepy', 'Excited or Adventurous'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed583ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:20.843998Z",
     "iopub.status.busy": "2025-02-25T04:59:20.843672Z",
     "iopub.status.idle": "2025-02-25T04:59:20.911605Z",
     "shell.execute_reply": "2025-02-25T04:59:20.910866Z"
    },
    "papermill": {
     "duration": 0.081451,
     "end_time": "2025-02-25T04:59:20.913329",
     "exception": false,
     "start_time": "2025-02-25T04:59:20.831878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define positive and negative emotions\n",
    "positive_emotions = [\n",
    "    'Confident or Attentive', 'Passionate or Amused', 'Pleased or Glad', \n",
    "    'Delighted or Happy', 'Excited or Adventurous', 'Polite or Sleepy', \n",
    "    'Neutral', 'Aroused or Astonished'\n",
    "]\n",
    "\n",
    "# Add a new column 'Emotion_Type' to classify emotions as Positive or Negative\n",
    "data['Emotion_Type'] = data['Emotion'].apply(\n",
    "    lambda x: 'Positive' if x in positive_emotions else 'Negative'\n",
    ")\n",
    "# Define the columns to retain\n",
    "columns_to_keep = [\n",
    "    'ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_coru', 'emg_trap', 'emg_zygo',  # 8 physio features\n",
    "    'Emotion', 'AGE', 'GENDER', 'Emotion_Type'  # Other required columns\n",
    "]\n",
    "\n",
    "# Create a new DataFrame retaining only the specified columns\n",
    "data = data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bd0335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:20.936622Z",
     "iopub.status.busy": "2025-02-25T04:59:20.936310Z",
     "iopub.status.idle": "2025-02-25T04:59:20.953018Z",
     "shell.execute_reply": "2025-02-25T04:59:20.952179Z"
    },
    "papermill": {
     "duration": 0.029631,
     "end_time": "2025-02-25T04:59:20.954458",
     "exception": false,
     "start_time": "2025-02-25T04:59:20.924827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg</th>\n",
       "      <th>bvp</th>\n",
       "      <th>gsr</th>\n",
       "      <th>rsp</th>\n",
       "      <th>skt</th>\n",
       "      <th>emg_coru</th>\n",
       "      <th>emg_trap</th>\n",
       "      <th>emg_zygo</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>Emotion_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.76062</td>\n",
       "      <td>35.053549</td>\n",
       "      <td>4.384464</td>\n",
       "      <td>27.174558</td>\n",
       "      <td>28.863552</td>\n",
       "      <td>6.13825</td>\n",
       "      <td>5.31675</td>\n",
       "      <td>7.86300</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79018</td>\n",
       "      <td>35.005141</td>\n",
       "      <td>4.360800</td>\n",
       "      <td>27.193884</td>\n",
       "      <td>28.849530</td>\n",
       "      <td>5.76850</td>\n",
       "      <td>5.15250</td>\n",
       "      <td>7.94525</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80990</td>\n",
       "      <td>35.809029</td>\n",
       "      <td>4.380504</td>\n",
       "      <td>27.213270</td>\n",
       "      <td>28.860030</td>\n",
       "      <td>5.72750</td>\n",
       "      <td>5.02950</td>\n",
       "      <td>8.06850</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.83946</td>\n",
       "      <td>37.368456</td>\n",
       "      <td>4.384464</td>\n",
       "      <td>27.281031</td>\n",
       "      <td>28.863552</td>\n",
       "      <td>6.09725</td>\n",
       "      <td>5.31675</td>\n",
       "      <td>7.37025</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.79018</td>\n",
       "      <td>37.145698</td>\n",
       "      <td>4.356864</td>\n",
       "      <td>27.271309</td>\n",
       "      <td>28.863552</td>\n",
       "      <td>5.89175</td>\n",
       "      <td>5.11150</td>\n",
       "      <td>7.65775</td>\n",
       "      <td>Frustrated or Impatient</td>\n",
       "      <td>30-34</td>\n",
       "      <td>F</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196278</th>\n",
       "      <td>1.05632</td>\n",
       "      <td>37.949645</td>\n",
       "      <td>37.403472</td>\n",
       "      <td>46.155954</td>\n",
       "      <td>29.852173</td>\n",
       "      <td>7.53450</td>\n",
       "      <td>5.89175</td>\n",
       "      <td>5.39900</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196279</th>\n",
       "      <td>0.81318</td>\n",
       "      <td>37.542807</td>\n",
       "      <td>37.419240</td>\n",
       "      <td>46.223715</td>\n",
       "      <td>29.852173</td>\n",
       "      <td>7.98625</td>\n",
       "      <td>5.85075</td>\n",
       "      <td>5.64550</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196280</th>\n",
       "      <td>0.82632</td>\n",
       "      <td>36.961677</td>\n",
       "      <td>37.320672</td>\n",
       "      <td>46.301140</td>\n",
       "      <td>29.845152</td>\n",
       "      <td>7.41125</td>\n",
       "      <td>5.72750</td>\n",
       "      <td>5.56325</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196281</th>\n",
       "      <td>0.83290</td>\n",
       "      <td>36.516101</td>\n",
       "      <td>37.407408</td>\n",
       "      <td>46.397951</td>\n",
       "      <td>29.862694</td>\n",
       "      <td>7.57550</td>\n",
       "      <td>5.80975</td>\n",
       "      <td>5.76850</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196282</th>\n",
       "      <td>0.80990</td>\n",
       "      <td>36.361149</td>\n",
       "      <td>37.450776</td>\n",
       "      <td>46.455990</td>\n",
       "      <td>29.852173</td>\n",
       "      <td>7.86300</td>\n",
       "      <td>5.97400</td>\n",
       "      <td>5.56325</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>25-29</td>\n",
       "      <td>M</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196283 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
       "0       0.76062  35.053549   4.384464  27.174558  28.863552   6.13825   \n",
       "1       0.79018  35.005141   4.360800  27.193884  28.849530   5.76850   \n",
       "2       0.80990  35.809029   4.380504  27.213270  28.860030   5.72750   \n",
       "3       0.83946  37.368456   4.384464  27.281031  28.863552   6.09725   \n",
       "4       0.79018  37.145698   4.356864  27.271309  28.863552   5.89175   \n",
       "...         ...        ...        ...        ...        ...       ...   \n",
       "196278  1.05632  37.949645  37.403472  46.155954  29.852173   7.53450   \n",
       "196279  0.81318  37.542807  37.419240  46.223715  29.852173   7.98625   \n",
       "196280  0.82632  36.961677  37.320672  46.301140  29.845152   7.41125   \n",
       "196281  0.83290  36.516101  37.407408  46.397951  29.862694   7.57550   \n",
       "196282  0.80990  36.361149  37.450776  46.455990  29.852173   7.86300   \n",
       "\n",
       "        emg_trap  emg_zygo                  Emotion    AGE GENDER Emotion_Type  \n",
       "0        5.31675   7.86300  Frustrated or Impatient  30-34      F     Negative  \n",
       "1        5.15250   7.94525  Frustrated or Impatient  30-34      F     Negative  \n",
       "2        5.02950   8.06850  Frustrated or Impatient  30-34      F     Negative  \n",
       "3        5.31675   7.37025  Frustrated or Impatient  30-34      F     Negative  \n",
       "4        5.11150   7.65775  Frustrated or Impatient  30-34      F     Negative  \n",
       "...          ...       ...                      ...    ...    ...          ...  \n",
       "196278   5.89175   5.39900                  Neutral  25-29      M     Positive  \n",
       "196279   5.85075   5.64550                  Neutral  25-29      M     Positive  \n",
       "196280   5.72750   5.56325                  Neutral  25-29      M     Positive  \n",
       "196281   5.80975   5.76850                  Neutral  25-29      M     Positive  \n",
       "196282   5.97400   5.56325                  Neutral  25-29      M     Positive  \n",
       "\n",
       "[196283 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf1cb9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:20.978709Z",
     "iopub.status.busy": "2025-02-25T04:59:20.978253Z",
     "iopub.status.idle": "2025-02-25T04:59:23.601694Z",
     "shell.execute_reply": "2025-02-25T04:59:23.600755Z"
    },
    "papermill": {
     "duration": 2.637421,
     "end_time": "2025-02-25T04:59:23.603315",
     "exception": false,
     "start_time": "2025-02-25T04:59:20.965894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender and Age Distribution (Heatmap Data):\n",
      "AGE     20-24  25-29  30-34  35-39\n",
      "GENDER                            \n",
      "F       47654  32822  13625      0\n",
      "M       20440  61304   6812  13626\n",
      "Total Instances: 196283\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion Type Counts and Percentages:\n",
      "Emotion\n",
      "Neutral                       108843\n",
      "Confident or Attentive         18418\n",
      "Passionate or Amused           17212\n",
      "Frustrated or Impatient        16325\n",
      "Distressed or Defiant          11175\n",
      "Worried or Apathetic            6601\n",
      "Tensed or Annoyed               4845\n",
      "Delighted or Happy              4296\n",
      "Pleased or Glad                 2963\n",
      "Frustrated or Discontented      1823\n",
      "Tired or Bored                  1195\n",
      "Aroused or Astonished           1152\n",
      "Polite or Sleepy                 982\n",
      "Miserable or Sad                 247\n",
      "Anxious or Dejected              157\n",
      "Excited or Adventurous            49\n",
      "Name: count, dtype: int64\n",
      "Emotion\n",
      "Neutral                       55.452077\n",
      "Confident or Attentive         9.383390\n",
      "Passionate or Amused           8.768971\n",
      "Frustrated or Impatient        8.317073\n",
      "Distressed or Defiant          5.693310\n",
      "Worried or Apathetic           3.363001\n",
      "Tensed or Annoyed              2.468375\n",
      "Delighted or Happy             2.188677\n",
      "Pleased or Glad                1.509555\n",
      "Frustrated or Discontented     0.928761\n",
      "Tired or Bored                 0.608815\n",
      "Aroused or Astonished          0.586908\n",
      "Polite or Sleepy               0.500298\n",
      "Miserable or Sad               0.125839\n",
      "Anxious or Dejected            0.079987\n",
      "Excited or Adventurous         0.024964\n",
      "Name: count, dtype: float64\n",
      "Total Instances: 196283\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Instances with 'Neutral': 108843\n",
      "\n",
      "Emotion Type Counts (Excluding Neutral):\n",
      "Emotion\n",
      "Confident or Attentive        18418\n",
      "Passionate or Amused          17212\n",
      "Frustrated or Impatient       16325\n",
      "Distressed or Defiant         11175\n",
      "Worried or Apathetic           6601\n",
      "Tensed or Annoyed              4845\n",
      "Delighted or Happy             4296\n",
      "Pleased or Glad                2963\n",
      "Frustrated or Discontented     1823\n",
      "Tired or Bored                 1195\n",
      "Aroused or Astonished          1152\n",
      "Polite or Sleepy                982\n",
      "Miserable or Sad                247\n",
      "Anxious or Dejected             157\n",
      "Excited or Adventurous           49\n",
      "Name: count, dtype: int64\n",
      "Total Instances (Excluding Neutral): 87440\n",
      "Emotion Type Percentages (Excluding Neutral):\n",
      "Emotion\n",
      "Confident or Attentive        21.063586\n",
      "Passionate or Amused          19.684355\n",
      "Frustrated or Impatient       18.669945\n",
      "Distressed or Defiant         12.780192\n",
      "Worried or Apathetic           7.549177\n",
      "Tensed or Annoyed              5.540942\n",
      "Delighted or Happy             4.913083\n",
      "Pleased or Glad                3.388609\n",
      "Frustrated or Discontented     2.084858\n",
      "Tired or Bored                 1.366651\n",
      "Aroused or Astonished          1.317475\n",
      "Polite or Sleepy               1.123056\n",
      "Miserable or Sad               0.282479\n",
      "Anxious or Dejected            0.179552\n",
      "Excited or Adventurous         0.056038\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age Group Distribution:\n",
      "AGE\n",
      "25-29    94126\n",
      "20-24    68094\n",
      "30-34    20437\n",
      "35-39    13626\n",
      "Name: count, dtype: int64\n",
      "Total Instances in Age Groups: 196283\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender Distribution:\n",
      "GENDER\n",
      "M    102182\n",
      "F     94101\n",
      "Name: count, dtype: int64\n",
      "Total Instances in Gender Classes: 196283\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame (replace with your dataset)\n",
    "# data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# 1. Heatmap for Gender and Age Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Grouping data by Gender and Age and calculating the count\n",
    "heatmap_data = data.groupby(['GENDER', 'AGE']).size().unstack(fill_value=0)\n",
    "\n",
    "# Print the heatmap data and total count\n",
    "print(\"Gender and Age Distribution (Heatmap Data):\")\n",
    "print(heatmap_data)\n",
    "print(f\"Total Instances: {heatmap_data.sum().sum()}\")  # Total instances in the heatmap data\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(\n",
    "    heatmap_data, annot=True, cmap='coolwarm', fmt='d', linewidths=1, cbar=False,\n",
    "    annot_kws={\"size\": 20}  # Adjust text size\n",
    ")\n",
    "plt.title('Heatmap of Instance Counts by Gender and Age Group', fontsize=16)\n",
    "plt.xlabel('Age Group', fontsize=18)\n",
    "plt.ylabel('Gender', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# 2. Donut Chart for Emotion_Type Distribution (with threshold)\n",
    "percentage_threshold = 2.2  # Set the percentage threshold (e.g., 5%)\n",
    "emotion_type_counts = data['Emotion'].value_counts()\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = emotion_type_counts.sum()\n",
    "emotion_type_percentages = (emotion_type_counts / total_count) * 100\n",
    "\n",
    "# Print the emotion type counts, percentages, and total instances\n",
    "print(\"\\nEmotion Type Counts and Percentages:\")\n",
    "print(emotion_type_counts)\n",
    "print(emotion_type_percentages)\n",
    "print(f\"Total Instances: {total_count}\")  # Total instances in emotion type data\n",
    "\n",
    "# Group smaller categories\n",
    "emotion_type_counts_filtered = emotion_type_counts[emotion_type_percentages >= percentage_threshold]\n",
    "others_count = emotion_type_counts[emotion_type_percentages < percentage_threshold].sum()\n",
    "if others_count > 0:\n",
    "    emotion_type_counts_filtered[\"Others\"] = others_count\n",
    "\n",
    "# Plot the initial donut chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    emotion_type_counts_filtered, labels=emotion_type_counts_filtered.index, autopct='%1.1f%%', \n",
    "    startangle=90, textprops={'fontsize': 14}, wedgeprops={'width': 0.3}\n",
    ")\n",
    "plt.title(f'Distribution of Emotion Types (Below {percentage_threshold}% Grouped as Others)', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 3. Remove 'Neutral' instances and plot donut chart again\n",
    "# Print the count of 'Neutral' instances before excluding\n",
    "neutral_count = data[data['Emotion'] == 'Neutral'].shape[0]\n",
    "print(f\"\\nNumber of Instances with 'Neutral': {neutral_count}\")\n",
    "\n",
    "# Remove 'Neutral' instances\n",
    "data_no_neutral = data[data['Emotion'] != 'Neutral']\n",
    "\n",
    "# Recalculate emotion type counts and percentages for non-neutral instances\n",
    "emotion_type_counts_no_neutral = data_no_neutral['Emotion'].value_counts()\n",
    "\n",
    "# Print the filtered emotion type counts and total instances\n",
    "print(\"\\nEmotion Type Counts (Excluding Neutral):\")\n",
    "print(emotion_type_counts_no_neutral)\n",
    "print(f\"Total Instances (Excluding Neutral): {emotion_type_counts_no_neutral.sum()}\")  # Total instances excluding 'Neutral'\n",
    "\n",
    "# Calculate percentages for non-neutral instances\n",
    "emotion_type_percentages_no_neutral = (emotion_type_counts_no_neutral / emotion_type_counts_no_neutral.sum()) * 100\n",
    "print(\"Emotion Type Percentages (Excluding Neutral):\")\n",
    "print(emotion_type_percentages_no_neutral)\n",
    "\n",
    "# Plot the donut chart again without Neutral instances\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    emotion_type_counts_no_neutral, labels=emotion_type_counts_no_neutral.index, autopct='%1.1f%%', \n",
    "    startangle=90, textprops={'fontsize': 14}, wedgeprops={'width': 0.3}\n",
    ")\n",
    "plt.title('Distribution of Emotion Types (Excluding Neutral)', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 4. Bar Plot for Age Group Distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Count the instances for each age group\n",
    "age_counts = data['AGE'].value_counts()\n",
    "\n",
    "# Print the age group distribution and total instances\n",
    "print(\"\\nAge Group Distribution:\")\n",
    "print(age_counts)\n",
    "print(f\"Total Instances in Age Groups: {age_counts.sum()}\")  # Total instances in age groups\n",
    "\n",
    "# Create the bar plot\n",
    "sns.barplot(\n",
    "    x=age_counts.index,\n",
    "    y=age_counts.values,\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Number of Instances in Each Age Group', fontsize=16)\n",
    "plt.xlabel('Age Group', fontsize=14)\n",
    "plt.ylabel('Number of Instances', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 5. Bar Plot for Gender Distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Count the instances for each gender\n",
    "gender_counts = data['GENDER'].value_counts()\n",
    "\n",
    "# Print the gender distribution and total instances\n",
    "print(\"\\nGender Distribution:\")\n",
    "print(gender_counts)\n",
    "print(f\"Total Instances in Gender Classes: {gender_counts.sum()}\")  # Total instances in gender classes\n",
    "\n",
    "# Create the bar plot\n",
    "sns.barplot(\n",
    "    x=gender_counts.index,\n",
    "    y=gender_counts.values,\n",
    "    palette='cool'\n",
    ")\n",
    "plt.title('Number of Instances in Each Gender Class', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Number of Instances', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd9fd93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:23.643825Z",
     "iopub.status.busy": "2025-02-25T04:59:23.643364Z",
     "iopub.status.idle": "2025-02-25T04:59:26.476294Z",
     "shell.execute_reply": "2025-02-25T04:59:26.475333Z"
    },
    "papermill": {
     "duration": 2.853862,
     "end_time": "2025-02-25T04:59:26.477838",
     "exception": false,
     "start_time": "2025-02-25T04:59:23.623976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      "ecg             1\n",
      "bvp             1\n",
      "gsr             1\n",
      "rsp             1\n",
      "skt             1\n",
      "emg_coru        1\n",
      "emg_trap        1\n",
      "emg_zygo        1\n",
      "Emotion         0\n",
      "AGE             0\n",
      "GENDER          0\n",
      "Emotion_Type    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "ecg             1\n",
      "bvp             1\n",
      "gsr             1\n",
      "rsp             1\n",
      "skt             1\n",
      "emg_coru        1\n",
      "emg_trap        1\n",
      "emg_zygo        1\n",
      "Emotion         0\n",
      "AGE             0\n",
      "GENDER          0\n",
      "Emotion_Type    0\n",
      "dtype: int64\n",
      "Target size per class: 2963\n",
      "\n",
      "Old Emotion Class Distribution:\n",
      "Emotion\n",
      "Confident or Attentive        18418\n",
      "Passionate or Amused          17212\n",
      "Frustrated or Impatient       16325\n",
      "Distressed or Defiant         11175\n",
      "Worried or Apathetic           6601\n",
      "Tensed or Annoyed              4845\n",
      "Delighted or Happy             4296\n",
      "Pleased or Glad                2963\n",
      "Frustrated or Discontented     1823\n",
      "Tired or Bored                 1195\n",
      "Aroused or Astonished          1152\n",
      "Polite or Sleepy                982\n",
      "Miserable or Sad                247\n",
      "Anxious or Dejected             157\n",
      "Excited or Adventurous           49\n",
      "Name: count, dtype: int64\n",
      "Total Instances before balancing: 87440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Emotion Class Distribution:\n",
      "Counter({'Confident or Attentive': 18418, 'Passionate or Amused': 17212, 'Frustrated or Impatient': 16325, 'Distressed or Defiant': 11175, 'Worried or Apathetic': 6601, 'Tensed or Annoyed': 4845, 'Delighted or Happy': 4296, 'Tired or Bored': 3154, 'Pleased or Glad': 2963, 'Anxious or Dejected': 2962, 'Excited or Adventurous': 2959, 'Aroused or Astonished': 2958, 'Polite or Sleepy': 2948, 'Miserable or Sad': 2939, 'Frustrated or Discontented': 2809})\n",
      "Total Instances after balancing: 102564\n",
      "       ecg        bvp       gsr        rsp        skt  emg_coru  emg_trap  \\\n",
      "0  0.76062  35.053549  4.384464  27.174558  28.863552   6.13825   5.31675   \n",
      "1  0.79018  35.005141  4.360800  27.193884  28.849530   5.76850   5.15250   \n",
      "2  0.80990  35.809029  4.380504  27.213270  28.860030   5.72750   5.02950   \n",
      "3  0.83946  37.368456  4.384464  27.281031  28.863552   6.09725   5.31675   \n",
      "4  0.79018  37.145698  4.356864  27.271309  28.863552   5.89175   5.11150   \n",
      "\n",
      "   emg_zygo    AGE GENDER                  Emotion  \n",
      "0   7.86300  30-34      F  Frustrated or Impatient  \n",
      "1   7.94525  30-34      F  Frustrated or Impatient  \n",
      "2   8.06850  30-34      F  Frustrated or Impatient  \n",
      "3   7.37025  30-34      F  Frustrated or Impatient  \n",
      "4   7.65775  30-34      F  Frustrated or Impatient  \n",
      "\n",
      "Heatmap Information:\n",
      "AGE     20-24  25-29  30-34  35-39\n",
      "GENDER                            \n",
      "F       29002  17963   8358      0\n",
      "M        9520  26858   4051   6728\n",
      "Total Instances in Heatmap: 102480\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAI5CAYAAAC4tUveAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAChpUlEQVR4nOzdd3gU1eLG8Xc3vfdCCJDQey8K0pGidARBRLBXrr1ff6Bexa7Xfu29AHZREZUqNor0TqiBAIGEkF7O748lm4TdNDIKwe/nefKw7JyZObs7OzvvnJlzbMYYIwAAAACAZeynugIAAAAAcKYhaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNo4W+TkJAgm82mt956q8Jyffr0kc1m0/Tp0/+WesF6xhg9/vjjat26tfz8/GSz2WSz2Sqdb8eOHc6yO3bs+OsrimpLTU3VjBkz1KdPH8XGxsrb21vBwcFq3bq1rrzySv3000+nuoq1wpQpU6q0P/w7FRQU6L333tPYsWOVkJCgwMBA+fj4KDY2Vv369dP//d//ae3atae6mpUq3o8kJCSc6qqclhYsWCCbzaY+ffqc9DLy8vIUFRUlm82m2NhYFRQUWFfBv9GCBQt05ZVXqmXLlgoLC5OXl5ciIiLUtWtX3XDDDfrhhx9kjDnV1UQt5nmqKwCcroqDATvZ6nvppZd0xx13KCQkREOGDFFwcPCprlKVJSQkaOfOnUpKSuJA7QTvvvuurrvuOh07dkw+Pj7q2rWr6tatq+zsbG3cuFGvvfaaXnvtNY0dO1YzZ8481dWttn/yd37lypUaO3astm3bJpvNppYtW6pDhw7y8/PToUOHtGzZMs2fP18PPvigbrrpJj399NOnuso4hb744gsdOnRIkpSSkqI5c+ZoxIgRp7hWVXfo0CFNnDhR33//vSSpbt266tGjh0JCQpSenq61a9fqhRde0AsvvKAOHTpoxYoVp7jGqK0IWgAsV3yQPWvWLJ177rmnuDawwssvv6xrr71WNptNd955p+655x6XAL1+/XpNnz5dW7ZsOUW1xMlYvny5evXqpaysLA0dOlRPPfWUmjRpUqZMUVGRfvzxR82YMUMbNmw4RTXF6eL111+X5Agoe/fu1euvv15rglZaWprOOeccbdq0Sc2bN9eLL76ovn37upRbu3atnn76aX300UenoJY4UxC0AFhu165dkuRysIbaaePGjfrXv/4lSXryySd18803uy3XsmVLzZw5U4sWLfo7q4cayM/P19ixY5WVlaULLrhAH3/8sex217sK7Ha7zj33XJ177rn6448/TkFNcbrYvXu35s2bJw8PD82cOVPnnHOOvvnmG+3bt0916tQ51dWr1NSpU7Vp0yY1bNhQS5cuVVhYmNtyrVu31uuvv66rr776b64hziTco4VaZ/Pmzbr66qvVqFEj+fr6KiQkRL169dJ7773ntvzOnTv16KOPql+/fqpfv758fHwUGhqqc845R//73/9UVFRUpvz06dPL3E9UfM/QifcOvfXWW7LZbJoyZYrS09N1yy23KCEhQb6+vmrSpIkeffRR57L37t2rq6++WvXq1ZOPj4+aNWum5557zpL6SmXvSSgoKNBjjz2mVq1ayc/PT5GRkRo3bpw2btx4Mm+3Dh8+rHvuuUetWrWSv7+/goKC1KlTJz322GPKzs4uU7b4/rqkpCRJUmJiovN9q+k9d8XLXrBggf7880+NHj1akZGR8vHxUcuWLfXkk0+6veQrNzdXjz/+uDp16qSgoCB5e3srNjZWXbp00R133KHDhw9LKvk8d+7c6VL34vUW+/TTT3XFFVeodevWCgsLk6+vrxITE3XZZZdp06ZNbutf+p6cpKQkTZo0SbGxsfLx8VGjRo3073//W7m5ueW+/uXLl2vy5MlKTEyUr6+vwsPD1a5dO91+++3OOpeWnJysW265RS1atHB+bl26dNHzzz9f7fspHn30UeXn56tdu3a66aabKi3fq1cvl+f27NmjqVOnqkmTJs7vbY8ePfS///1PhYWFLuWLv4flbTfl3WdS+vn8/Hw9+uijzu9CRESERo8e7dIiU9XvvORopR0wYIAiIiKc93O0bNlSV155pVavXl3pe+POqlWrNHr0aEVFRcnPz09t27bVf//7X5f3ZfLkybLZbJoxY0a5y5o5c6ZsNpu6du1apXW///77SkpKko+Pj1588UW3IetEXbp0cft8dna2nnzySZ111lkKDQ2Vr6+vmjVrpjvuuEOpqaku5UvvQzMzM3X33XercePGzvvCJk+erL1795Zbj6+//lq9e/dWUFCQQkJC1LNnT33xxReV1v/IkSOaNm2a2rdvr6CgIPn7+6tNmzb6z3/+o6ysLJfypbfFXbt26fLLL1e9evXk5eWlKVOmVLo+Sfrhhx80depUtW/f3rnfio+P14UXXlhucC293oMHD+r6669XvXr15O3trXr16mnq1KlKS0srd53vvPOOunTpIn9/f4WHh2vw4MFavHhxlepbkTfeeENFRUUaMmSIunfvrn79+qmwsFBvv/12hfPt3LlTU6ZMUWxsrPN3ctq0acrJySmzf3dn9uzZGjx4sKKiouTt7a26devq4osv1vr166tV923btumDDz6QJD399NPlhqzS3H2XStd38eLFGjZsmKKiomS328vcd3kq9ntZWVm655571LhxY/n6+iouLk6XX355hd8l/IUM8Ddp0KCBkWTefPPNCsv17t3bSDLTpk1zmTZz5kzj6+trJJnmzZubUaNGmX79+pmAgAAjyVx66aUu8zz44INGkklMTDT9+/c348ePN7179zbe3t5Gkhk9erQpKipylv/ss8/M5MmTjSQjyUyePLnM38GDB40xxrz55ptGkhkxYoRp0aKFiY6ONmPGjDEDBw40fn5+RpK54YYbzNatW01sbKypV6+eGTdunOnbt6/x8PAwkswjjzxS4/oaY0xSUpKRZBo0aGBGjx5tvLy8zIABA8z48eNNw4YNjSQTGBholi5dWoVPqsS2bducn1tUVJQZM2aMGT58uAkKCjKSTMeOHc3hw4ed5WfMmGEmT57s/DzGjBnjfN8+++yzStdX/DokmaSkpDLTireLu+66y3h7e5sWLVo435vi9/PGG28sM09hYaHp37+/kWSCg4PNkCFDzIQJE8yAAQOcr2vlypXGGGMWL15cbt0nT55sNmzY4Fyuh4eH8ff3N507dzajR482w4cPd77PAQEB5ueff3Z5bcXb1I033miCg4NNgwYNzLhx48yAAQOc28vIkSPdvi+PPfaYsdvtRpJp2rSpGTdunBk2bJhp0aKF2+/UwoULTVhYmJFkEhISzPDhw82gQYOczw0cONDk5eVV+nkYY0xRUZGJiIgwksyTTz5ZpXlO9Pvvv5vw8HAjydSvX99ceOGFZvDgwc7v8qBBg0xubm6ZeaZNm1bufsAYY+bPn28kmd69e7t9vnv37mbAgAHG39/fDB482IwZM8bUq1fPSDKhoaFltq+qfufvv/9+I8l4enqaXr16mQkTJpjzzjvPtG7d2thsNvP0009X+T0pXt+1115rfH19TUJCgrnwwgvNwIEDnd/1Cy64oMx3ffny5c73sKCgwO1ye/XqZSSZt99+u0r1GDlypJFkhg8fXuW6u7N3717Tpk0bI8mEh4ebAQMGmFGjRjm/ZwkJCWbHjh1l5ineh44cOdK0bdvWhIaGmmHDhpkRI0aY6Oho5z4tLS3NZX1PPfWU8/Pq2rWrmTBhguncubORZG655RbnvCdat26dczuoU6eOGTx4sBk2bJiJiYkxkkz79u1d1le8LV500UUmPDzcxMbGmjFjxpjRo0ebW2+9tUrvT6NGjYy3t7fp0KGDGT58uBk9erRp2bKlc3uaPXu2yzzF673ssstMfHy8iYmJMaNHjzbnnXeeCQkJMZJMly5d3H6X//WvfxlJxm63m169epnx48ebli1bGrvdbm688Ua3352qKCoqcn6mn376qTHGmPfff9+5byrPunXrTGRkpJFk4uLizLhx48z5559vAgICzDnnnGO6d+9uJJn58+eXmS8/P9+MGzfOSDI+Pj6me/fuZuzYsaZdu3ZGkvHz8zPffvttlev/zDPPGEkmLCzMFBYWVvv1Fyv+PbruuuuM3W43LVu2NOPHjzcDBw40H3zwgTHm1Oz3zj77bHPWWWcZf39/c95555mxY8eaOnXqGEkmNjbWbN68+aRfM04OQQt/m5oGrdWrVxsfHx/j6+trPvnkkzLTduzY4fyRP/EA4/fffzdr1qxxWc/evXudO+uZM2e6TC/+ES9P8UGCJDNs2DCTmZnpnLZ8+XLj6enp3AFfc801Jj8/3zn9888/dx78l57vZOtbOqBERkaaVatWOacVFBSYqVOnOg88cnJyyn1NJ+rWrZvzIOzYsWPO5w8cOGA6duzoPPg4UfFnfWJYqkxVgpYk8/LLL5eZ9uOPPxqbzWY8PDzM7t27nc8vXLjQSDIdOnQwR48edVnfH3/8YQ4dOlTtun/00Udl3g9jHAcgL7zwgpFkWrVq5RKGSx/I33vvvWUOlNesWeMMeCeG4S+++MJIMr6+vubjjz92qcu6devM+vXrnf/ft2+fiYiIMDabzbz44otlDiYOHTpk+vXrZySZ+++/v9zXV9q2bduc9V60aFGV5iktJyfH+Z5ec801ZQ4Kt23bZhISEowkc88995SZr6YHHMWf+759+5zTsrOzzaBBg4wkc9VVV7kss6LvfE5OjvHz8zOBgYFm48aNLtN37NhRJoxXpvT2cN1115XZP6xdu9ZERUW53dZ79OhR5iC3tDVr1jhPilT1e14cOh588MEq1/1ERUVFznpdfvnlZb5r+fn55tZbbzWSTN++fcvMV3ofOmjQIJOenu6cdvjwYdO+fXsjyTz88MNl5lu1apXx8PAwdrvdzJo1q8y09957z9hsNrdBKysryzRq1MhIMv/+97/LHORmZmaaCRMmuD1hV7wtSjIXX3xxtfahxT777LMyJ6VKP+/p6WkiIiJMVlZWueudMmVKmfXu2rXL1K1b10hyHtgX+/rrr50nfU78zj788MPOZZ5M0Pr++++NJBMdHe38LmdnZ5vQ0NAK9xHFvxfjx48v8zr27NljmjVr5qzTiUHrnnvuMZJMt27dzPbt28tMmzVrlvHw8DBhYWHmyJEjVar/pEmTjCTTv3//qr9oN0r/Hr3wwgsu00/lfq9x48Zm586dzmnZ2dlmzJgxRpI566yzTv5F46QQtPC3Kd7pVPXvxB3NhRdeaCSZJ554wu3yf//9dyPJdOrUqcp1mjt3rpFkxo4d6zKtqkErMDDQpKSkuEwfPny480xWdna2y/TiYLhw4cIa17d0QHnmmWdc5svJyXH+KL///vtVWtfixYuNJOPv72/279/vMn3ZsmXOM6alw40xf23QGj16tNt5Bw8ebCSZd955x/nczJkzjSTzr3/9q8p1ONm6Fzv77LONJLNu3boyzxcfWHfq1MklhBljzDXXXGMkmQceeKDM88UHm1VtTbrzzjuN5GhNdWfPnj3Gy8vLREVFua3HiX799VfnZ+IuYFTm3XffdZ7FdneAOnv2bCPJBAUFlfme1PSAw2azmT///LPc19OwYUOXaRV95w8cOGAkmbZt21bwaquueHuoU6eO2/3Dc889ZySZJk2alHm+eJt2d6B49dVXG0nm7rvvrnI9iltTTwx0xT766COXFr7SrXzGGPPtt98aydEaVDowFissLDStW7c2ksqcRCrehwYEBJjk5GS365Zk+vXrV+b5K664wkgyF154ods6jxgxwm3Qeumll4wkM3ToULfzZWRkmOjoaOPp6VkmFBVvi+Hh4W5b12qqOODNmTOnzPPF642Pj3c5IWeMMY888oiRHC1epQ0YMMBIMnfeeafb9RXvU04maBX/Dp/YknfdddcZydEafKJFixY5fytTU1NdphcHwxODVmpqqvHz8zO+vr5mz549butTvN7nnnuuSvUfMmSIM/C58+eff7rd3hcvXlymXPHv0YnbZrFTtd+TZD7//HOX+VJSUoy/v7+R5PaKC/x16AwDf7sePXqocePG5U7/7rvvlJKSUua5oqIiffvtt5KkCy+80O18nTt3VmBgoFauXKmcnBz5+vo6p+Xm5ur777/XH3/8oQMHDig3N1fGGGVkZEhSuffVVEWnTp0UHR3t8nxxRxB9+/YtU5fS09esWaPk5GSXaTWp7+TJk12e8/Hx0YUXXqinnnpKCxYs0EUXXVTp6yq+Vn7w4MGKiYlxmd6pUye1a9dOq1at0sKFCzVx4sRKl2mFYcOGuX2+RYsW+u6778pch96xY0d5eHjojTfeUNOmTTV69GjLbtbeunWrvvvuO23dulUZGRnO6+2Lt91NmzapZcuWLvMNHTrU7ZhiLVq0kKQy9d+/f7/+/PNP2e12XX755VWq15w5cySV/z2pW7eumjRpovXr12vLli1q2rRplZZ7soq3o/Hjx8vHx8dl+ujRoxUWFqYjR45o+fLl6tGjhyXrrV+/vtq1a+fyvLv3uSqioqKUkJCg1atX69Zbb9Xll1/u9vOtrnHjxrndP0yePFlTp07Vli1blJycrLi4OEnSqFGjVK9ePf3444/auHGjmjdvLklKT0/Xe++9Jw8PD1177bU1rlexP/74w+29N9OnT1dkZKSkkm1uzJgx8vR0Payw2+3q1auX1q5dq6VLl6p169Zlpnfu3Nnt97K8z6p4m7r44ovd1nny5Mlu79Wq7LsRGBiozp0765tvvtEff/yhgQMHlpk+YMAAhYSEuJ23KpKTkzVnzhxt3LhR6enpznsl161bJ8mxzzjvvPNc5uvfv7/8/f1dnnf3/hQUFGjJkiWSyn9/LrnkEv3555/Vrn9qaqo+//xzSdJll11WZtpll12mF198UbNmzdJzzz2noKAg57SFCxdKcvyWhIeHuyz3/PPPV2hoqMv9ZvPnz1d2drb69++vunXruq1Tnz599OKLL2rp0qW64YYbqv2aTrR7926323ufPn10zjnnuDx/wQUXuF3OqdrvhYaGavjw4S7PR0dHa/Dgwfr000+1YMECde/e3ZL1oXIELfztrrjiigpvIO7Tp49L0EpNTdXRo0clSfXq1at0Hampqc4d86+//qoLL7zQ2ROeO8XLPhn169d3+3xgYGCF04t/iHJycso8X5P6hoaGKjQ01O20xMRESY6bc6ui+Me7eD53GjVqpFWrVv2tN9mW934WdzVe+v1s1KiRnn76ad1+++264YYbdMMNN6hBgwY6++yzNXToUI0dO1be3t7VWn9hYaFuuOEG/e9//6twvKXyPqPq1L94G6hTp06VD/C2b98uSerZs2elZQ8ePFhp0IqKinI+PnDggJo1a1alehSrbDuy2WxKTEzUkSNHLN2OKnufK+p4pDzvvPOOLrjgAj311FN66qmnFB4erm7duuncc8/VpEmTnMGjOsp7X4KCghQREaHU1FTt2bPHGbQ8PT113XXX6e6779bzzz+v559/XpL09ttvKzMz0xnEqioyMlK7d+/WwYMH3U5/4okn9MQTTzj/7+np6XITf/E2d9999+m+++6rcH3u1lOd74RUsg8r770r7/niek6aNEmTJk2qdj1rMq7e/fffr4ceekj5+fnllrFin5Gamur8f3Xfn8q89957ys3NVbdu3VxOMnTq1Elt27bV6tWr9dFHH+nKK690Tiv+vCp6/xo0aOAStIo/rx9//LHSAe/L235PVPwdLa/80KFDy+zXBwwYoB9//LHc5ZX3mk7Vfi8hIaHc96q6xwCwBkELtULpnvbctdicqPgMUlZWlkaOHKmUlBRdeumluvbaa9W4cWMFBwfLw8NDmzdvVrNmzWo0QGllvXRVpRevYn9HfWsy7+mgOu+n5OjKd9y4cfryyy+1ZMkSLVmyRB999JE++ugjTZs2TYsXL65WK9d///tfvfzyy4qNjdVTTz2l7t27KyYmxtkqcdFFF+nDDz8s932ubv2rq/i7csEFFyggIKDCshEREZUuLyEhQeHh4Tp8+LD++OOPKgW4v4O73jdL+yve5549e2rHjh2aM2eOFi5cqKVLl2ru3Ln69ttvNW3aNH322Wfq37+/5es9cVu68sor9cADD+idd97RjBkzFBgYqBdffFGSqn1Wv2PHjtq9e7eWLVt20vUr/izOOeccNWrUqMKyrVq1cnnur/5OFCuuZ3mt9KU1aNDA5Tk/P7+TWu+nn36q6dOnKzAwUM8//7z69eunuLg4+fn5yWaz6Z577tGMGTNO2T6jqorHztqzZ4/b1p3i8PL666+XCVrFKgpL7qYVf16NGzeutMWnuGW3Mh07dtS7776rFStWqKioqMbv7cluEyersv1eVdT2Y4DahqCFWiEyMlJ+fn7Kzs7WE088UeUzx4sWLVJKSoo6duyoN954w2X66Tawak3rm5aWprS0NLetWsVdVMfHx1epLsUtgsVnFd0pnlbeZR2ni5iYGF155ZXOH/+NGzfqsssu0y+//KK77rqr0m6JSysejPl///uf20s0rNymis9k79u3T+np6VVq1apXr562bNmiO++8U507d65xHex2u4YNG6a3335b77zzjm655ZZqzV+V7ah4OIDS21FxS2Px5bInctel/d/Bz89PF1xwgfOSoYMHD+rf//63XnnlFV122WXVrlfxaz9RRkaGs0v0E7+zERERmjhxol577TW98847atq0qfNS1X79+lVr/cOHD9cXX3yhuXPn6tChQyfVKlfcgjZixAjddttt1Z6/uurWratt27Zpx44dboNb6e74S6tXr542btyoyy+/vNxLvv4KxfuMhx56SFdddZXLdCv3GREREfLx8VFubm6135+K/PHHH1qzZo0kR2tNRa0wv/32m9atW+dcd/H3uqL1uvveFG9XzZo1K9Nlek0MHTpUt956q44cOaJvvvlGQ4cOtWS5JzpV+72K3uPqHgPAGqfHaRKgEh4eHjr33HMllfxoVUXxGEnlXXpR3thbkuTl5SVJ1R5zqCZqUt9i7777rstzeXl5+vjjjyXJZfyN8hSXc3fPnCStXLnSef+Qu3GTTmfNmzfXnXfeKUku9yoU/9CV97kXf0buznivW7fupO59KE9sbKzatWunoqIit8HbnSFDhkiq3vekMnfeeae8vLy0atUqPfPMM5WWLz1WT/F29PHHH7tcAiZJn332mY4cOeIcn61Y8cHHiWNeFSu+38ZKJ/Odj4qK0mOPPSbJcannkSNHqrXOWbNmub2Msfh73LhxY7cnMooHkH7hhReclw9ef/311Vq35LiPp0GDBsrJydH1119/Ume7i7e5WbNm/S1ny3v37i3JMQaYO++8847b5/+K70ZVVLTPOHDggObNm2fZujw9PZ2tP+W9P+5+Iyrz2muvSXLc32YcHam5/Rs3bpykktYvqWRcve+++87t9+Pbb791+3z//v3l7e2tBQsW6MCBA9WuszuNGzd23qN3yy23KD093ZLlnuhU7ffS0tL01VdfuTx/8OBBfffdd2Xqhr8HQQu1xrRp0+Tt7a3bb79db7/9ttsm9LVr1+rTTz91/r/4ZuEff/zRZWDDV155xRk+3Ck+61N8o/LfoSb1Lfbggw9q7dq1zv8XFRXpzjvv1J49e1SvXj2NGTOmSnU555xz1K1bN2VnZ+vqq68uM5DnoUOHdPXVV0ty3OxbnXtC/k4//fSTvvnmG5f7Iowx+vrrryW5HvxU9rkXf0YvvPBCmW1w3759uuSSSywP5tOmTZMk3Xvvvfrkk09cpq9fv77Mj/Ltt9+u0NBQPfXUU3ryySeVl5fnMk9SUlKVQnuxFi1a6KmnnpLkODi555573J5x3bx5syZMmOAMAZI0duxY1a9f3zmAcun3JykpSbfeeqskxyWepTuF6Nevn+x2u+bOneu8mV5yfHbPPvus2/eipir67Hfu3KnXXnvN7X00xQc2YWFhzvtmqio5OVm33XZbmfueNmzYoAceeECSdPPNN7udr02bNurXr582bNigL7/8UsHBwbrkkkuqtW7JcWJh1qxZ8vX11cyZMzVq1Cht3brVbdmlS5e6DVIjRoxQly5d9Pvvv+vSSy91e//LkSNH9PLLL1vy/Zg6dao8PDw0c+ZMffbZZ2WmffTRR84OG0501VVXqUGDBpo1a5buvPNOt9vw/v379eqrr9a4jqUV7zNeeeWVMt/H9PR0TZ482fKD/eJBxZ977jktXbq0zLTHHntMK1asqNbysrKy9NFHH0mq/NL94m3wvffec+53e/XqpXbt2ikjI0NTp04t8x4kJyc79wEniomJ0dSpU5WZmalhw4Y5W9RKy83N1ZdffqmNGzdW+fW88MILaty4sbZs2aLu3buX2b+UtmPHjpO+n+lU7vduvfXWMvXOzc3V9ddfr8zMTHXt2tWyjjdQRX9fB4f4p7NqwOLiLkrj4+PNwIEDzcSJE82QIUNMfHy82y5/i7v69fb2NgMHDjTjx483zZs3Nzabzdx7771uuwE2xpjbbrvNSI5xqcaNG2cuv/xyc/nllzvHXSrumthdd7bGVN5Na3H3zie+HydT3+Ju0evXr29GjRplvLy8zLnnnmvGjx/vHDcmICDApYvaypQesDg6OtpccMEFZsSIESY4ONhIrgMWF/sru3c/cZyVYu7e76efftpIjvHK+vTpYy666KIyg6iGhIQ4Bywu9vzzzzu7Ih49erTzcy/u2vzXX391DijbuHFjM27cODN48GDj5+dnWrVqZUaNGuX2cy3v8y5W0fb00EMPOccGat68ubnwwgvN8OHDnQOeuhuwuHhw0OjoaNOvXz8zceJEM3ToUOf20K1bN7f1qMgbb7zhHO/L19fXOWjvqFGjnIMny03XyaUH7mzQoIG58MILzXnnnVfhwJ3GGOfAqh4eHqZPnz5m9OjRplGjRsbLy8vcddddFXZzXFHX1cX1PFFF3/mVK1caScbLy8t06dLFjBs3zowbN8506NDB2Z38a6+9VuX3snh7uOaaa4yvr69JTEw048ePN4MGDXJuX6NGjaqwC/7i8fgkmalTp1Z53e788ccfJjEx0flaWrdubUaNGmUuvvhiM2zYsDLDcwwbNsxkZGSUmX/v3r3ObsMDAgJM9+7dzfjx483o0aNN+/btnYOKl+7KurJ9aOmB2E/02GOPOevTrVs3c9FFF5kuXboYSebmm28ud761a9c6xzAKDQ01vXr1MhdddJEZOXKkadmypbHZbCYmJqbMPJXtyyuzfft25zhTdevWdQ78HhISYurUqWMuu+wyt8s/2a6+jTHm+uuvN5Jj+I0+ffqYCRMmmFatWp3UgMVvvfWWkRwD3pY3UHax/Px85+DPpQdhXrNmjXMfULduXTNu3DgzdOhQExAQYHr06OEcFuPErsfz8/PNRRdd5HwtHTp0MGPGjDEXXnih6dGjh3N/VJ1Bi41xdHdePJh98fHE0KFDzcUXX2zGjBlj2rZt69zntmnTxmVsy8p+j4w5Nfu9s88+23Tr1s34+/uboUOHmnHjxpm4uDjnb8HJDNGBmiFo4W9jRdAyxvHje/PNN5vWrVubgIAA4+vraxo0aGD69OljHnnkEbN169Yy5fPy8szjjz9u2rRpY/z9/U14eLgZOHCg+f777yv8Ic/OzjZ33HGHady4sfPAp3QA+KuC1snUt/Tz+fn55qGHHjLNmzc3Pj4+Jjw83IwZM8ZlXKeqSk1NNXfffbdp0aKF8fX1Nf7+/qZDhw7mkUcecRlgs9jpErS2bt1qpk+fbvr372/q169vfH19TVhYmGnbtq256667XMb/MsYx5s+MGTNMq1atnD+IJ6539erVZvjw4aZOnTrG19fXNGnSxNxxxx3m6NGj5X6uNQlaxhjzyy+/mAkTJpi6desaLy8vEx4ebtq1a2fuuOOOMoNTFktJSTH33Xef6dixowkKCjLe3t4mPj7edO/e3UybNs2sXr3a7Xoqc/DgQfOf//zH9OzZ00RFRRlPT08TGBhoWrduba666qpyx4XbtWuXuf76603Dhg2Nt7e3CQoKMmeffbZ56aWX3I69ZIxjINwnn3zStGjRwnh7e5vw8HAzbNgws3z58krHkzmZoFXRd/7o0aPmmWeeMaNGjTJNmjQxgYGBJiAgwDRt2tRccsklZtmyZVV+D40puz2sWLHCDBs2zERERBgfHx/TqlUr89RTT5X7vhTLyMgwHh4exmazWXIAlZeXZ95++20zevRoU79+fePn52e8vb1NdHS06dWrl7n77rvdDqZeLCcnx7z88sumb9++JiIiwnh6epro6GjTvn17c/3115u5c+eWKV+ToGWMYzDvc845xwQEBJjAwEDTvXt3M3v27ErnO3r0qHnsscfM2WefbUJDQ42Xl5epU6eO6dKli7n99ttdBg2vadAqfi0TJ0409evXNz4+PqZBgwbmmmuuMfv37y93+TUJWsY4Tox06tTJ+Pr6mpCQEDNgwAAzf/78Kn1HSuvZs6eRZG677bYqlb/pppuMJDNkyJAyzyclJZlJkyaZ6Oho4+3tbRo1amTuuecek5WVZRo2bGgkmU2bNrld5jfffGNGjx7t3P+FhoaaFi1amPHjx5sPPvjA7ThjVfHDDz+Yyy67zDRr1swEBwcbT09PExYWZjp27GiuvvpqM2/evDKDvherStAy5tTs944dO2Zuv/12k5iYaLy9vU1MTIyZMmWK2bVr10m9R6gZmzF0PwLUdjt27FBiYqIaNGhwUjc6A6h9XnvtNV155ZUaOHCg5s6de6qrA5yUpKQkNW7cWEFBQTp8+PBp08tibbJgwQL17dtXvXv3do7hhdMDWzMAALVMZmamZsyYIUnl3uMCnC4yMzPLvfdx4sSJKioq0uTJkwlZOOPQvTsAALXE448/rrVr12rJkiXavn27Bg8erIEDB57qagEVOnjwoFq3bq1GjRqpadOmCg4O1q5du7RixQrl5uaqXbt2evDBB091NQHLEbQAAKgligdLjoyM1JQpU5y9QQKns8jISN1222366aef9McffygtLU3+/v5q27atxowZo6lTp8rf3/9UVxOwHPdoAQAAAIDFuBgWAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRvfu1TDHq9mprgJwSpyfv8n5OPOXz09dRYBTKODskc7Hr/5w6uoBnEpXDih5fM6whaeuIsApsuSr3lUuS4sWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDHPU10BnHohnVoranBvhffoqMAWjeUdFS6Tn6+c5AM68ssK7X7zEx35eXmVluWXEK+EGyYpqn93+TWoK9ltyk0+oEM/LtWOl97XsfVbq7Qcm4eH6l0+VnUnDFNAs4byDPRXTvIBHfppqXY8/26Vl+MVEabEGyYpZsQAR30kZe/cq5QvflDSc+8o/3BaBZWwKbxHJ0UN6qmwszsooFlDeYeHqDAnTzm7knV4yTLtfOUjZazZVKW64PR2+Ogxrd2+W+u279a6pN1an7RHaceyJEnDenTS/VeOq3D+5IOHNfT2R6u1zjoRYZrz5F3lTl/05wZ9tWSZ1mzbpSMZmQrw9VF8dIQGdGmjsf3Olp+Pd5XXtS/1iD5f9IeWrNqofalpysrOVVhwgOpEhqlL80Y6t2tbNY6PdZlve3KKfl+/TeuTdmvrnv06fPSY0jKyZLfbFBESpJaJ8RpyVnv17tBSNputWq8ftVdhQZ7W/faFNq/8Tgf3blJOVprsdi8FhkYrrmFHte0xVnUbdnQ7b+r+bdq58Rft37VGh5I3KysjVdnHjshm91BAUIRiG7RRi85D1aht/wq3qW/fuUvrfvusSvW98oEfFRIR/5e8HuDvEBPlo7HD6ursLhGKjvRRfn6R9u7P1k+LD+rTb5KVm1t0qqsIN2zGGHOqK1FbzPFqdqqrYLmzfnpPET27VFpuz7ufafXV98nk55dbpt4V49TqmfvkUc7BX2Funjbc8Yh2vvh+hevyighT169eUWiXtu6Xk5OrdTc+oN1vzK5wOaFd26rT7BfkWyfa7fSc5ANadsF1Sv9jjdvp/bbNl1/9uArXYQoLtf2pN7TxnicqLFfbnZ9fEiYzf/n81FXkL9Rxyp3lTvurgtZZrZvoxduucHk+MztX9/7vQy36c0O589aLidDTN05Ww7iYStfz0byf9dzs75Sdm1dumQnn9tDtE4e7PH/v/z7St7+srHQdnZo11ONTL1ZoYEClZWurgLNHOh+/+sOpq8eplp66V5++dLVS922psFyH3pPUb+y9LmFpzlu3acMfX1W6nvgmXTXiimflFxjmdrpVQaumr+ef5soBJY/PGbbw1FXkH6RHlwjdd2tzBQa4bx/ZtSdLtz+wRnv35fzNNftnWvJV7yqXpUXrH644hOTsTdG+T77T4SXLlL17n2wedoWd1V6JN10mv/hYxU8aJZunp/685Da3y6kz7jy1felBSVJ+2lFtf/pNpS74VUW5eQpu30KNbr1CAU0S1OrpfyvvwGHtm/2t+wrZ7eo8+3lnyNr36Vztfn2W8o6kKaxrOzW++1r5xESqzYsPKGfvAR2cu8j964qPVefPXpZPdISK8vOV9MxbSpkzX5IUc35fJd40Rb5x0ery2cta0m20cvamuCzDJ87x3mRu2aF9n32vI0tXKGffAXn4+Sqidzcl3jhZ3uGhanT7lTKFhdp039NVf+NxWouNCFVCnSj9urbiA6/SosJCNPM/N1da7s2v5+vbX/+U5AhwJzLG6M4X39PSNZslSS0S6mriwJ5KiItSVnauFq/aqI9/WKrdKama+uSbem/6VIUFlR9uXvvyR7346feSpAaxkRrVu6taJdZToJ+v0jKztGnnXs1fvk52u/uDR0+7Xa0b1lP7JglqHB+riJAghQUHKCMzW0n7DurTBb9p6579Wr5pu2565i29cc+1stu5Kv1MVViYXyaURNVtpk79LlV4TKLycjK1d9tyLfvxTeXnZWnlwncVGBqtbgOvKrMMu91TdRLaKa5hR0XFNVVAcKT8gsKVm3VUqfu3a/XPH+tQ8mbt2fK7Pnv5Wk245QPZKtimAkOiNeaG1yusd2Co+xMSVrwe4K/UpGGg7r+zhXx9PJSVVaB3Z+/WitVp8vGxa0DPKA0fHKf68f56/P/a6PJbVig7u/BUVxml0KJVDWdii1bnz1/W3ve+0L5P50pFrs3OXhFh6r7wQwU2S5Qk/dJ3og4vWVamjN3PV/22/CifmEgVZGTq554X6ti6sgeonkEBOnvhhwpu00w5+w9qQfOBKszMcllf/JQxavfqw5KkHS+9r3X/eqDMdP9G9XXOb5/KKyRImVt2aGGb82QKXXcq7d58VPEXj5QkLR9/o/Z/8l2Z6XUuGKKOHz4jSdr9zqdaffndLsvovuhDbX7wBR2at8RlmiT5N6yn7os/doa5Ba0GKztpj9uytd0/oUXrpc++V6vEemqVGK+IkKAyLVRVadGqisKiIp13ywwdTDuqAF8fzXv2Pvl6e5Up88Mfq3XHC45W37NaNdF/b54iL8+y58R+W7dFNzz5hgqLijSu/9m6a9JIt+v7bf1WXfvYq5KkoT066r5LL5CXp4fbsvkFBS7rkaSCwkJ5erifp/g13fnC+/pp+VpJ0tM3TlbvDi3LLV+b0aIlbVrxnb56/UZJUlxiB42/5X3Z7WW3j/271uqDJ8arqDBfPn7Buv7RX2T3KNm2igoLyvz/REVFhfrq9Zu05U/HCYKRV7+oxm37u5QrbtEKDq+rqx786ZS9nn8aWrT+Xs/PaKf2rUNVUFCk6+9apXWbjpaZPmFUvK6/rJEk6Y0PduiND3eeimr+o1SnRYvTjv9wy0Ze42hdchOyJCk/9Yg23PGI8/+xYwa5lIke0ls+MZGSpKTn3nEJWZJUkJGp9bfNkCT5xkYpfvIot+trePNlkqS81CPacOdjLtOztu3Stkf/J0kKaJKgmJHnupTxiYlU3QnDJEkH5i52CVmStG/2tzowd7EkKX7iCGf9S1vaa0K5IUuSsrbv1paHXpAk2b28FDtiQLllcfq7dtRA9WrfQhEhQX/ZOn5bt0UH0xw/kv27tHEJWZL05ZKS+yHvmjTSbfjp1qqJBnZrJ0n6dMHvSj/metKiqKhIM952XFbVtF4d/d9l5YcsSW7XI6nCkCVJHna7LhnSy/n/FZuSKiyP2i05qeQy0m6DrnIJJZIUW7+1GrXuI0nKzT6q1P3bykyvLKTY7R7qMuBy5//3bF1WQemaseL1AH+VFk2C1L51qCTp63n7XUKWJH30+R4l7cqUJI0dXlceHv/sS1tPNwQtVCp1wW/OxwEN67tMD+nU2vm4vEv5JOnwwt9VmO24frjOaNfAFtAkQUEtG0uS9s3+TkXZ7q813vNOyTX57sJN9LB+sh0/ONzz9ifl1mfPO59KcnS8ET2sX7nlKlL6vfF3894Apc35eYXzsbvLBiVpw/FW0XoxEaof63oCoFj3Nk0lOVqcFq5c7zL9l7VbtCvlkCRpyvl9Kg1MNRHg5+N8nJdf8JetB6deYUHJfbohEfXKLRcSWTKtsLD8e3vL4+1TcjlsYUH59xbW1N/1eoCT0fOskt+Ab37Y77aMMdLc+Y7bH4ICvdSxbejfUTVUEUELlbKX6tzCFLq2fHlHhDof5x4/sHPHFBYq/3C6JCn0rA7OMFQsrNSBZ+qi38tdTm7KIR07ftY8rLtrL1DhpZZzeNEf5S6n9LRwN8upirLvDddFo3yZ2bmav2KdJCkuMkwdj1+Oe6L045fURgRX3LIWERzofLxis2sr0g9/rJYk2Ww29WzXomT5x7K0a/8ht61gJ2vur6ucjxPqRFm2XJx+wmNKttv01N3llks/dHyazaawqIRqr2fj8jml1tmw2vNX1d/1eoCT0bZlsCQpK7tQm7ZmlFtu5Zp05+M2LYL/8nqh6v65FxmjysJ7lfRKeGyj6yUTBaUO2DwruezK8/jBoYePt/wbN1Dmpu3OaUEtGjkfl37enWObtiuwWaL86tWRh7+fCrOyndMCWzhaxfLTjlYY/HL3H1R+eoa8QoIU2LxRueUqElHmvam4zvhn+2HZauXkOc6En9+9Y7k9l/n5+CgjK1vHymnRLVZ6+nY3nbms2bZLkiPUBfj56NtfVurNOQu0dU/JWdHizjHGD+ghb6/q/RwcycjUrpRD+nzh787LHUODAnTe2R2qtRzULs07n68lXz2jvJxj+v37V5XYqrfL5XYpu9dr+7oFkqQWnYfKxy/QzZJcZR07rLQDO7V66Syt/dVxxYFfYJhadBlW4XzZmUf00dMX69C+LcrPzZSvf6ii6jZTw9Z91ab7GHl5+52S1wPUVIN6/pKkvfuy5eY8t9OuPSXHYQnH58HpgaCFitlsanRHSQ9LyW56CywdviJ6ddHR42ftTxTcoaU8S/WO5levTplA5Vu3ZAyf7D2uB46l5ezZ56ie3S7f+Fhlljqj71s35ngZ983sZZaze5+8QoLk62b8oMrY/XyVMHWyJEeX8ylf/ljtZeCfo/Rlg+f3KL8FNTEuSqu37lJS8gEdOXpMYcHuD+pK3wu1/4Tx4IqKirRj30FJUmigvx5//0t9OO9nl2Xs3H9Iz3z8jeYvX6dnb75UQQHlH5BK0pUz/qfl5ZwECQ0K0JNTJ1W6DNRu/oHhOm/yY/r6zVu1d/sKvffYBerUd7LCohOUn5ulvdtWaNlPb6iwIF8x9Vqpz+jyx4mTpI+emaQ9W9xfweAXGKYRVz4vX/+Kz9Dn52Zpz9aSKxQyjx5U5tGD2rFhiX6f94qGXf5MuWNgWf16AKt4e9kUFuK4auZAam6FZTMyC5SVXSh/Pw9FR/r+HdVDFRG0UKHEG6corKvjpvt9n851G6IOfrdIRfn5snt5KfHGS7Xn3S+Un3qkbCGbTc0eKNv1tecJXVKX/n/hscwK61WYWdKC5RFY9uxN8XIK3PRqeKKC4y1hnicx9k+LGbfJ//ggyDtfel+5+w5Uexn4Z9iXekTLjwejdo0bqL6bzleK9W7fUqu37lJhUZFe+HSu/j1ljEuZXfsP6ctSvX9m5ZT9ET6WnaOi4x3Kbt2zX+uS9igyNEg3jTtf57RrJm8vL61L2q1nZ36rNdt2adXWnZr+xiw9OfWSk3p9E87toSuG96+wm3mcORq37a9Jd36iZT++qTW/zNa375Qdg84/KFI9ht6otj3GVdiaVJGOfSbprCHXyT8wvPxCNpvqJLZXo9Z9FVOvpfyDI1WYn6uDyZu1Zuls7d+5WsfSUjT7ucs1/pb3FVPPfW+Yf8frAarL36/kEL0qXbbn5DiClp8vdwWdTmpN0LLb7apTp4727t3rMm3Dhg3Kz89X27buB7jFyQnv2UXNH75VkuO+qLU3THdbLmfPfu165SMlXD9JfvGx6r7wQ228+3HHOFp5+Qpu30JN7puq6EE9VZib5xzQ2MOv7FkXu2/JDfVFeRXfbFxUauDVE5fjcXw5lS2j9HLspW7mr4q4CcOUcP0kSVLG+q3a9H/PVGt+/LN8s3SlikfSqKg1S5Iu6HeWPv5xqQ4cOapPF/yunNx8XXJebyXWiVJmTq6WrNqkZ2d+o+zcfHl6eKigsFC5eWU7oCg9MHFufoF8vb30yp1Xl7l/qlOzhvrfnVdpyoMvaPPufZq/fJ3WbNulNo3K79Rl+hVjlZ2bJ2OMMrJytH7HHs3+6Vd9/MNS7TlwWP932Zi/tNdGnB4KC/K0/rcvtHX1j4478U+QlXFI63//UiER8W67ZS9t8MUPKz8vWzJGudkZ2r9rrVYt/lArF76vtEN7NGjifxQQ7P7ERN8xd7tt7Ypr2EFte4zTkq+e0W9zX1Z+Xpa+f//fuvjOT9xesmvl6wGs4u1dEpgKCiq4bvC4/ONlfLz/uo6PUH21JmhJUnlDfvXr108HDx5UQUHNe7vKzc1Vbm7Zs8M+Pj7y8anegXhtF9iysTrNfl52Ly8VZudoxfgblXfwcLnlN9zxqPwT6yn6vD4KbJaozp++6FImbdkapS9bowbXXCTJ0eV7aUWlzsrbvb3KhKkTle6EovCEe1kKc3LlGeAvu5uus8tbTlF2xc3ypYX36qq2rzwkydEN/YoLp5apO3CiOUsdlw16e3pq0PEW4vIE+fvpqRsn619PvanDR4/pm19W6ptfVrqUm3rBYL03d7GOZGTK37fs/snbq+y2P6p3V7edVPh6e+n6MYN04zNvSZK+/31VhUGrblTZ1oWOzRI1tu9ZuuOF97V41QZNuv85vfnv6xQTHlrha0TtlZebpU9fuFJ7ti2Tze6hLudeodZnjVZoZD0V5Odp345V+uXbF7R323J9/sr16jPqTnXuf2m5ywuNLNvTX3zjzmrfc4K+fO1GbV87X+89doEuuvUjBYW5Xt5d0SWFNptNPYffrH07VmnXpl+UsnudkrevUN1GZXv7tPr1AFbJyysJV56elbdSeR0vk5tHx1ynkzOmfdGqcZdnzJihkJCQMn8zZsywZNm1hV9CvLp984a8w0NVVFCglRNvcRmk+ERFefn6Y+Q1Wn31vUr/c71MqXG5clMOacvDL+mXPhdJpc4m5h9JL7OM0sHLo5JL+TxK3QdSeELvacXL8Qyo/IZQT3/HcgoquVSxWEin1ur82Uvy8PVRQUam/hh+FZ1goEJrt+923i/Vu0OLKt3D1DIhXh8+cKMu7N+9TO+CktQqMV7/vWmKLh3a13nJYPAJyww4IXid1apJuevq2rKxPD0cPwXrTmLAbR9vL02/Yqx8vb20/3C6/jvT9T5OnDmWznlOe7Y5fg8GTXxIvUferojYRvLw9JaPX6ASWvTQhTe+o3pNu0nGaOFnj+nAno3VWoenl48GT3pYnt5+yjiyTws/f/yk69vunAudj3dvce2F9u94PcDJyMouaTzw86u8lcrX11EmO6fy1i/8fWpVi9bf4e6779Ytt9xS5rl/UmuWT51odfvuTfnWjZEpKtLqK+9RyldV7OTBGO1+Y7Z2vzFbHoEB8omJUGFWjnL3H3RejhHQuIGzeMaGsj0Y5uwt6bzCLz7G9T6vUnzj6zhWWVTk0ulFzt4U+cZGVamDC996juVUpeOMwJaN1fXr1+QVHKjCnFwtG3Od0n5fXel8+Gf7+ueSAYjPL2fsLHeiQoN156QRunPSCB1Ky1BmTo7CgwMVdPzkQMrhNOUeH7OqYVxMmXm9vTwVFhSgI8dPOsSUGoLhRD7eXgoNDNCh9AylHa3aCYcThQUFqH2TBP26bosWrFin/ILCCgdHRu1kjHH2BhgWnaDWZ7kfeN7u4alzht6oD5+6SMYUad2vnyr6gnuqtS7/wHDVbdhROzf+rK2rf1RhYb48PCq/SuFEEbGNnY+PpZftZOnvfD1AdeXlG6UdzVdosJeiIyo+Dg0K8JT/8TB24FDFPdbi73XGtGhZxcfHR8HBwWX+/ilByysiTN2+fUMBxy8dWnfTg9r73hcntazCY5nK2rbL0UFEcWuj3a7g4+P5ZG7b5RKkSgevgGYVj5sSeHx69u59Zbp2l6RjG7Y6Xk9osHwq6HTAJzZKXsfvJ3HXbX1p/g3rqdu3b8o7MkxF+flaedHNSp3/a4XzAPkFhfr+N8cYU+HBgc5BhqsrMjRIDWKjnCFLkjbsKLlftXXDeJd5GtUtCV9FRRWf4Sw8Pt3D4+R/Eoo7wsjJy1daFVuIUbtkHT2knMw0SVJ0OR1LFIupXzKQfWrKybX6+weGSZIK8rKVfaz8E28VKmcYBenvfz1Ade3Y5diX1q3jp4p2z/XjS67g2bHbujESUXMELUhyjG/V7ZvXFHT8EqMNdz+hnS99YOk6Ivp0k3ek44dz36xvXKYfKXXmP6JX13KX4xMTqcDjg70eWbrCZfrhUsspPQbYiUpPO+xmOcV868ao23dvyTcuWqawUKsuu6vqrXz4R1uyaqPSjl/aOvis9vL0sK6VZ94fa5yPB3Zzve+rQ6kBkfceKP/+ymPZOc46RoWd/ECXB44cdT72/4ecnPqnKT3IfFElA7QXFZZ0RmS3n9zFMxnpJT25evuc3NhAqfu2Oh8HhkSXmfZ3vx6gulavd+xX/f081Kxx+R0NdWgT4ny8ZsPRcsvh70fQgux+vury5SsK6eg4Y7fl4Ze0/YlXLV9P0/+bKkkqysvTrtdnuUzP3LJDGesdP4p1Lhgsu5/7sSDiLym5vGP/Fz+4TD/w1U8yx3804ye7do1dspzRkiRTWKgDX/3ktox3VLi6ffeW/BMdLQZrrp+m5I++LneZQGlfLy0J/cOqcdlgZbbvTdG83x0tZd1aNVaDWNeOLvp3buN8/FM5Y9tJ0vzl65z3uHZsmlhuuYqkHE7T6m07JUl1IhwDJOPM4+cfKm9fxz2D+5JWqqiw/A6oSt8PFRLh2uJamYwj+7UvydEJTHB4Xed6q2v1zx87H8c3Lnvi7e98PcDJWPzrIefj8wa4vx3CZpMG9XVcwZBxLF8rVqf9HVVDFRG0/uFsXl7qPPt5hR8/CEx69m1tnvZMtZfjFR5afi9/drtaPft/znVsffQVZe9wf9P99qffkCR5R4SpxSO3u0z3b1hPje68WpIjmKV8Ps+lTG7KIe398CtJUvSgnoodPcilTOyYwYoe1FOStOf9L5SbcsiljGdIkLp+87oCmzsuU1x368Pa7SYgAu6kH8vSklWOm+Ybx8eqWYO4Ks974ISOYkrbn5qmm599WwWFRfL29NQdE0e4Lde0Xh31aNtMkjT31z/12/qtLmUOpWXoxU/nSpK8PD00vGfnMtN37j+o393MV1pGVrbuefkj5Rc4Tm4MraT7etReNrtdDVv3kSQdSz+gX7972W25nKx0Lfr8Cef/G7Xp43x8OCVJuzb9UuF6crMzNOfNW1VY4GhFatnNdRtPTvpTx9LLH7vQGKMlXz2tnRuXSpKi6jZ36XHQitcD/JU2bMnQn2vTJElDz41Vq2auVx2MHxmvxPqOS7dnfblXhYXWdA4Ha9Sq9u+UlBR5VHDpTUXTJEd3r1Z0AX8m6fDek4oa6Agch376RbvfnK3ACnooM3n5ytyyw+X5iD7d1Oq/92nfzG+Uuuh3Ze/eJw9fHwW1aab6V4xTSHvH9e8Hvl2orTPc/5hJ0p53PlO9KWMU3qOTEq67WD4xkdr1+izlp6UrtEtbNbnnOnmFBMkUFmrdzQ85W65OtOm+pxU1sKd8oiPU4b0ntf3p1jrwzQJJUvR5fdTwZkf3vLkHUrXZzRhYdm8vRyvf8Xrv/eBLHfpxaYXvTWFmdrkBEqe/lZuTtDsl1fn/0vcZ7T6Qqi8Xl+1588RQcqK5v61yho/qtmY99NZnOpJxTP07t1HLxHgF+fvqSEamfl+/VZ/M/1XHsnNlt9n070tHKzEuutzl3HbRMK3euksZWdm66ek3ddHAc9SjbXP5entp7fbdenPOfKUcdoS6a0cPVHRYSJn5Dx45qmsee1VN69VRn46t1CKhriJDguThYVdqeob+3LJTXyz6Q4fSMyQ5AuWU8/tU67Widjl7yHXauvpHFeRla+k3zyll91q16jZKIZH1VJifq+Qdq7T8p7eVcSRZklS/2dlKaHGOc/5j6Qc089kpiqrbXI3bDVBs/VbyD46U3e6pzKMHlbx9hdYs/USZRx09dUbGNVW3gVe51CNp/WL9/v0rSmzZUw2a91BEnUby8QtWYUGeDu7dpLW/fKJ9Oxytvp7efho48UG3Y2jV9PUAf7X/vrpNLz3WXr4+Hnr6gTZ6Z9YurVyTJm9vDw3oFaURgx0n8XbtydKHn3MMcrqxGav6Rf+L2e01b3yz2WwqrOQ67IrM8WpW4zqcbs7P31St8lk79mh+E9cBG2NHD1Knj58tdz5TVKQ9b3+qtTdMr3QgYa+IMHX96hWFdnE/AHVhTq7W3fiAdr8xu8LlhHZtq06zX5BvHfcHojn7Dmj5Bde77TnQr0Fd9dvq/nLC8qQu/E2/DrikWvPUFqW3k8xfPj91FfkLTXt1pr4qdX9fZVa89WiF0y954Hmt3b5bHna7vn3qHkWGVn0g3389/aazNcydkAB/3XXJSA1yc2/WiVZuTtIdz7+n1KPH3E632Wy6fGhfXTfGteV32YZtuurRV6pU53PaNdf9l49VWPDJXeJVGwScPdL5+FXXq5b/MXZuXKqv37yl0g4q6jc9S8OvfFa+/iUBftfm3zTzv1XbTzZs3UeDL54h/6Bwl2k/z3lOv3zzfKXLCAqL09BLn3BpzSqtJq/nn+jKASWPzxm28NRV5B+kR5cI3XdrcwUGuG8f2bUnS7c/sEZ799Hj4N9hyVe9q1y21rRoTZs27VRXARU4vGSZNtzxqCL6nqXAZg3lHRMhFRnlJB9Q6sLftOftT6rcFXp+6hEt7Tle9a4Yp7rjhyqweSN5BPg5ljX/FyU9946OVXI5kySl/b5aizoMV+LUSxQzor/8Gziuq8/asUcpX/6opGffVv7htJq8bMCtXfsPae323ZIc91BVJ2RJ0mVD+yohNkorNycp5XC60o5lKcjfV/HREerToaVG9u7q7OWvMh2aJmrWw7foo3lLtWDFOiUfOqz8gkJFhgarU/OGGj+gu5o3qOt23nZNEvTCbZfrt3VbtX7HHh04nK7DRzOUk5evAF9fxUWFqU2j+hp8Vnu1b5JQrdeI2qtB8+667L5vteaX2Upat0iH9m1VbnaG7HYPBQRHKrZBG7XoPFSN2vZ3aUWq26ijLrjhde3cuFT7d63VsbQUZR49pIK8HHn7BSokoq7qJLRXi87nVxiOWp81WgFBEUpO+lMH925S1rFU5WSmyWb3lF9AmGLqt1Sj1n3VossweXpVfM9gTV4P8Hf4+Y9UTZ66TGOHx6t753BFRfqooKBIe/Zla/6SQ/pkzl7l5jJ+1umo1rRonQ7OxBYtoCr+CS1aQGVo0QJo0QKq06JFZxgAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABarUdCy2+3y9PTU1q1braoPAAAAANR6njWZ2c/PT15eXmrcuLFV9QEAAACAWq9GLVrx8fHKz8+3qi4AAAAAcEaoUdA6//zzlZOTo4ULF1pVHwAAAACo9WoUtO6++25FRUXp2muv1b59+6yqEwAAAADUajW6R2vDhg166KGHdPPNN6tly5aaNGmSevTooejoaHl4eJQ7X69evWqyWgAAAAA4rdUoaPXp00c2m835/xdeeEEvvPBChfPYbDYVFBTUZLUAAAAAcFqrUdCSJGPMX1oeAAAAAGqbGgWtoqIiq+oBAAAAAGeMGnWGAQAAAABwRdACAAAAAIvV+B6tYkVFRVq+fLl27typrKwsXXLJJVYtGgAAAABqFUtatJ577jnVqVNHZ511li688EJdeumlZaYfOXJErVu3VvPmzZWSkmLFKgEAAADgtFXjoHX99dfrpptu0sGDBxUUFFSmu/diYWFh6tixo7Zs2aJZs2bVdJUAAAAAcFqrUdD67rvv9NJLLykwMFCfffaZ0tLSFBUV5bbsRRddJGOMfvjhh5qsEgAAAABOezUKWi+//LJsNpseeOABjRgxosKyZ599tiRpzZo1NVklAAAAAJz2ahS0fvvtN0nSZZddVmnZkJAQBQcHa//+/TVZJQAAAACc9moUtA4fPqyQkBAFBQVVbWV2O4McAwAAADjj1ShoBQcH6+jRo8rPz6+07OHDh5Wenq7IyMiarBIAAAAATns1Clpt2rSRMcZ5CWFFPvzwQxlj1Llz55qsEgAAAABOezUKWhdccIGMMZo+fXqFlwSuWrVK//73v2Wz2TRhwoSarBIAAAAATns1ClpXXnmlWrZsqfnz5+vcc8/V119/rcLCQknSli1bNG/ePP3rX/9S9+7dlZ6errPOOktjx461pOIAAAAAcLryrMnMXl5emjNnjgYPHqz58+drwYIFzmnNmzd3PjbGqE2bNvrkk0/cDmgMAAAAAGeSGrVoSVKDBg20fPly3X///apfv76MMWX+4uLiNH36dC1dulSxsbFW1BkAAAAATms1atEq5u/vr/vuu0/33XefkpOTlZycrMLCQsXGxqpBgwZWrAIAAAAAag1LglZpcXFxiouLs3qxAAAAAFBr1PjSQQAAAABAWVVu0dq1a5dlK61fv75lywIAAACA002Vg1ZiYqIlK7TZbCooKLBkWQAAAABwOqpy0DLGWLJCq5YDAAAAAKerKgetpKQkt8///vvvuvrqq2Wz2XTNNdeoX79+io+PlyTt3btXP/30k15++WUZY/S///1PXbp0sabmAAAAAHCaqnLQctdN+7Zt23TVVVepXr16mjdvnmJiYspMb9asmfr166d//etfGjBggK688kqtWLGi5rUGAAAAgNNYjXodfOihh3T06FG9+uqrLiGrtOjoaL366qtKT0/Xf/7zn5qsEgAAAABOezUKWvPmzVNgYKC6detWadlu3bopMDBQ8+bNq8kqAQAAAOC0V6OgdfDgQRUWFla5fFFRkQ4ePFiTVQIAAADAaa9GQSs6OlrZ2dn66aefKi37008/KSsrS1FRUTVZJQAAAACc9moUtIYMGSJjjC6//HJt3ry53HJbtmzRFVdcIZvNpiFDhtRklQAAAABw2qtyr4PuTJs2TbNnz9auXbvUrl07jR07Vv369VPdunUlObp3nz9/vmbNmqWcnByFhYXp//7v/yypOAAAAACcrmoUtOLi4jRv3jyNGjVKu3fv1vvvv6/333/fpZwxRvHx8frss8+cIQwAAAAAzlQ1unRQkjp27Kh169bpkUceUfv27eXh4SFjjIwxstvtat++vR555BGtW7dOnTp1sqLOAAAAAHBaq1GLVrHAwEDdcccduuOOO5Sfn6/Dhw9LksLDw+Xl5WXFKgAAAACg1rAkaJXm5eVV4eDFAAAAAHCmsxljzKmuBAAAAACcSSxr0UpOTtaaNWt0+PBh5efnV1j2kksusWq1AAAAAHDaqXGL1po1azR16lQtXry4aiu02VRQUFCTVQIAAADAaa1GLVqbNm1Sz549lZGRIWOMvL29FRUVJU9Py2/9Oi3M/KXoVFcBOCXGnV3SQemK/uecwpoAp07HH5c4H1/9yOFTWBPg1PnfXeHOxzNmFp7CmgCnxt3jPKpctkaJaPr06Tp69Kji4uL08ssva8iQIfLwqPrKAQAAAOBMVKOgNX/+fNlsNr3zzjvq16+fVXUCAAAAgFqtRgMWp6eny8fHR3369LGoOgAAAABQ+9UoaNWpU0ceHh6y22u0GAAAAAA4o9QoIQ0bNkxZWVlauXKlVfUBAAAAgFqvRkHr3nvvVWRkpG666Sbl5uZaVScAAAAAqNVq1BlGTk6O3nzzTU2aNEkdO3bUbbfdpq5duyooKKjC+erXr1+T1QIAAADAaa1GQSsxMdH5OC0tTVdccUWl8zBgMQAAAIAzXY2CljHmb5kHAAAAAGqTGgWtpKQkq+oBAAAAAGeMGgWtBg0aWFUPAAAAADhjMAAWAAAAAFisRi1aJzp48KB27typrKws9erVy8pFAwAAAECtYUmL1pdffqmOHTsqNjZW3bp1U79+/cpMP3LkiAYPHqzBgwcrPT3dilUCAAAAwGmrxkHrkUce0ahRo/Tnn3/KGOP8Ky0sLEx+fn6aN2+eZs+eXdNVAgAAAMBprUZB69dff9W9994rT09PPf300zp06JBiYmLclr344otljNG8efNqskoAAAAAOO3V6B6t//73v5Kku+++WzfeeGOFZXv37i1JWrlyZU1WCQAAAACnvRq1aP3888+SpBtuuKHSspGRkQoICFBycnJNVgkAAAAAp70aBa0DBw4oKChIkZGRVSrv4+OjvLy8mqwSAAAAAE57NQpaAQEBysrKUmFhYaVljx07prS0NIWHh9dklQAAAABw2qtR0GrWrJkKCwu1evXqSst+/vnnKioqUvv27WuySgAAAAA47dUoaA0fPlzGGM2YMaPCcnv27NFdd90lm82mMWPG1GSVAAAAAHDaq1HQuuGGG1S3bl198sknuuSSS7R27VrntPz8fG3ZskVPPfWUOnXqpOTkZDVt2lSTJ0+ucaUBAAAA4HRWo+7dAwMD9dVXX2nQoEF677339P777zun+fr6Oh8bYxQXF6fPP/9cXl5eNVklAAAAAJz2atSiJUnt27fXqlWrdOmll8rHx0fGmDJ/Xl5emjJlipYtW6ZmzZpZUWcAAAAAOK3VqEWrWGxsrF5//XW9+OKLWr58uZKTk1VYWKjY2Fh16dJF/v7+VqwGAAAAAGoFS4JWMR8fH3Xv3t3KRQIAAABArWNp0Pr1118rHJD4rLPOkre3t5WrBAAAAIDTTrWD1n//+199/PHHOvvss/Xkk0+WmTZq1CgdOHCg3Hn/85//6O67765+LQEAAACgFqlWZxgZGRmaNm2a/vjjD11xxRVuy5zYGUbpv0cffVTZ2dmWVBwAAAAATlfVClpfffWVjh49qmHDhqlFixZuy9hsNiUlJbn8nX/++crIyNAnn3xiScUBAAAA4HRVraD13XffyWazadKkSRWWa9Cggcvf9ddfL2OMvv/++xpVGAAAAABOd9UKWitXrpQk9ezZs9or6tGjhyRpxYoV1Z4XAAAAAGqTagWtvXv3ysfHR5GRkW6nG2PKnTcoKEjBwcHat29f9WoIAAAAALVMtXodPHbsmEJCQsqd/vPPP6ugoKDc6V5eXjp69Gh1VgkAAAAAtU61glZwcLDS09PLnd6oUaMK509LS6swqAEAAADAmaBalw7GxMSosLBQGzZsqPaK1q9fr8LCQsXExFR7XgAAAACoTaoVtM466yxJ0ueff17tFX322WdllgEAAAAAZ6pqBa1hw4bJGKOnn35aKSkpVZ5v3759euaZZ2Sz2TRs2LBqVxIAAAAAapNqBa0RI0aoadOmSk1N1ZAhQ7Rz585K59m5c6fOO+88paamqlmzZho5cuTJ1hUAAAAAaoVqBS2bzaa3335bXl5eWrVqldq0aaMbbrhBc+fOVUpKivLz85Wfn6+UlBTNnTtX119/vdq0aaNVq1bJx8dHb7311l/0MgAAAADg9FGtXgclqVu3bvroo480adIkHTt2TC+99JJeeumlcssbYxQQEKD33ntPXbt2rVFlAQAAAKA2qFaLVrGRI0dq2bJlGj16tCRHmHL3J0ljxozRsmXLNGLECOtqDQAAAACnsWq3aBVr1qyZZs+erf3792v+/Plav369UlNTJUkRERFq2bKl+vbtq9jYWMsqCwAAAAC1wUkHrWKxsbGaMGGCFXUBAAAAgDPCSV06CAAAAAAoH0ELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIt5nuoKoHbJz8vVisWfaP2yedq/Z5Nys47JPyhUsfWbq333EWp71vnlzpu04Xe98ejkKq2n74jr1W/UDW6nHUs/pI1/ztf2Db9p/66NSk/dp8KCfPkFhii2XnO17Hyu2ncfLi9v3yqtK+3QXv0y7z1tXrVQ6Yf3y9PLW+HR9dS6y2B17X+RvH38qrQc1G7+TZspuNvZCmzdVr4NEuQZEipTWKD81FRlrl2tQ9/OUeba1dVaZlDHzgofMFABrdvKKzxCKixUftoRZW/fqowVy3V43lwV5WSXO39wl24KHzREAc1ayis8XLLbVJCWpqwtm3Xkp3k6snC+ZIzbeb1jYtX6g9lVqmfq3G+087GHKyzjm5CoyGEjFdS2vbxjYmXz9lZh5jHl7Nih9F+W6NCcL1WUXf5rwZlvdB8/DTqrZH/55AdHtXlXQYXztGropZ7tfZQQ66lAf5uOZRnt2F+gxX/mat32/ArnnXx+gLq38alS3e55KU2p6UVupwX525RQx1MJcZ5KiPVQQh1PBfo7zkMvXZOrt+dkVmkd+OcK9pfaJdrUqI5NIf6St5eUlSulZ0o7Dxht2G106GhJ+RB/6bqhHtVaR1qm0UtzXLfhEH+pcZxN9aNtig6Rgvwkm82x/v1HpPW7jDbuMeX9VJTh7Sm1a2hTkzibooIlHy+poMjxOnYfMlqxtezrQOUIWqiyg/uS9MF/r9eh/Ullns9IO6iMtIPasnqxVi75TONv+K98fAP+kjosWzBTX73zgIqKCl2mHUs/pK3pS7R17RL9/O0bGn/DfxVbr1mFy9u4cr5mv3KHcrOPOZ/Lz8vW3qR07U1aq2WLZmvSzS8rIqaB5a8Fp48mTz+voLbt3Uzxlke8v3zj6yli8PlK/f5b7XryUZmCig8ePQKD1OCOuxXao5ebaYHyja+nsF59lbl+rbK3bXUpY/PyUsI9/6ewXn1daxQdI+/oGIX26KnIEX9q+7/vUmHmMZdyVooZP1Fxl10pm0fZnwx7aJi82ocpqH0HRY8ep2333en29eDMFx/toQFdqnZyS5Jski4e4q9z2pWdJyzYprBgb3Vo6q3Ff+bo/e+yVIXjwxp54l9hf/EacCbr1NimPm1s8vaylXk+2N/xVy/KJh+vIv3wZ8225MMZrs/1am1T9xY22Ww2l2nF629a16bkVKPPfinS0azylx8TKo3pYVdIQNlleXhI0aFSdKhNHRoaLVxr9OvGv/pbeeYgaKFKjh1N1duPX670w/skSa26DFaHHiMUFBatjCMHtPLnL7Tuj++0de3PmvnSrZp088sVLm/U5Q+pbmLrcqcHBEeUW4+iokJ5eHqpWbs+aty6h6LiGsrbN0CHD+zW8oWztHXtz0pN2am3HrtM197/iULCY90uK3nnes186Rbl5+XI29dfvc6/SoktuqogL1drfvtGyxbOUur+HXr36Wt07bTZ8vH7a8IjTj2viEhJUt6hg0pbOF/H1qxS3oEUye6hwJatFD12vLyjohUxcIhsHp7a8fD95S7LHhCgxo89rYBmzSVJaYsX6siiBcpN3isVFcorKkZB7dortGfvcpcRf8NNzpCVf+SwUj7+QFlbNskUFMovsaFixk+UT2wdBbVtr4R/369td99a4etLfv0VpS1dXO70wmNufsGPC+s7QHWvvFaSVJSXp4NffqqM5ctUkJ4un7i6ihoxSoFt2sk7JkaNH3lS66dM/MuDH04vNkkXDw6Qh4dNRzOLFBxQ+V0JI3r7OUPWrv0Fmvtbjg4eKVRUmIcGdfNV/VhP9Wzvq2NZRp8vqril9EhGkZ79uPxtuLhMVaSmF2p/apFaNfSqUnn8s3VvYVPvNo7tPfWo0Z9JRvsOG+XmS37eUkyYTc3q2lxakzKypVe/cz1h7G75rRo4lr9mh2u4CfCVbDab8vKNNu812nFAOpxhVFgkRQTZ1LmJTXERjr8Jve16Y16R8t2cJ/Txksb1tCvQzxGydh0wWrHNKC3TyN9bSoi1qVMjmzw8bOrb1qb0zCJt2E3YqgqCFqpkwRcvOkOWy2V9DVqqWfs++vGzhlrwxYvavGqh1v4xV627DCp3eWGR8YqJb1rtenj7+KnneVeox+BLFRAcXmZaXIOWat1lkL798FEtnfuWMjMO66fPntOoyx9yu6xv3n9Y+Xk5snt4avJtr6l+4w7OaQ1bnqWImAaaO/MJpe7foZ+/e7PcSxlR++Xu3ukII4sXSEVlD8iyNqxT6ry5avbsS/KtV1/h/c/Voa8+17E1q9wuq94NNyugWXMV5eUq6YH/U/ovP5ctsHmT0n9epD0vPivZXS8d8QwLU+SQoZKkgqNHtfGay5V/6KBzeuba1Tr84/dq8cpb8qkTp5Cu3eTftJmyNm8q9/XlpR5Uzo6kcqdXJHbiJc7H26ffq6O//eL8f9amDToy/wclTvuPwnr1kVd4hCLOG6YDsz48qXWhdurX2UeJcZ7ad6hQf27O05DuFV9uHR1m18CujpC1Y1+Bnnj/qPPgb+f+Qq3akqfbJgYroY6nBnbz1c+rc3UwrfygVFhklHyo8oPW8ny9JFs79hVox74CZWQZRYTY9fC1oSe9PPwzNIiWM2St2VGkb/4wKjohe+w8YPT7JiP7CeceiowqvQTPZpPqRzmCT+7xIHWi7Dzpp1VFWrnNKO+EALX/iNH63UbDu9nUsr5d4UE2dW1q08/rXZfTrqHNGbI27C7S57+ULbNtv9HOA0Zjz3H8ZvVoaSNoVRGdYaBSRUWFWrX0K0lSaESc+oy41m25viOuU0hEHUnS4jmv/iV16T5oigaOu9UlZJV27tibFRQaJUlav2yeiopcf6D3bF+tnZuXS5I69RxTJmQ51zX4UkXFNZIk/TLvXRUWVHy/AGqvbffeqbSFP7mErGKFR9O15+Xnnf8P7dXHbbmA1m0VMXCwJCn5jddcQ9aJ3FwCG9C8pWwejh+z1LnflAlZztmysnTgk5kl87Qsv3W4Juz+/vJLbChJytq8qUzIKm3/u2+Wqkurv6QuOD2FBds1vKe/JOn9uZkqqELDUf8uvvLwcBzUfTQv0+UMe36B43lJ8vCwVeuSxJPx1ZJsrdmWr4wsDhxRdYM7OQ6hU44YzXETskor56elQgnRjvsHJWnjHqMCN+cSFqw2+m2Ta8gqZoz0/QqjgkJH5ZrHu15iKEnxESXPuwtikrQ12RHeJCkqxCZvmmqqhKCFSqXu36mcbMdlGY1adZfdzVl4SbLbPdS4VXdJUvKOdTpycM/fVsfSPD29Vb9xR0lSTnaGso+luZTZsOJH5+MOPUe5XY7dblf77iMcy8k6qqSNv1tfWdQax/5c4XzsE1fXbZmokaMlSQXHMnTw809Oaj02r5JLlnL3JZdbLjd5r9t5rGTzrH5d7H9RXXB6umigv3x9bFq6Jldbdld872Kxdk28JUn7DhUqKdl9S1RScqH2pxaWKQ+cLhrGSuFBjnDy68aqdTRRXW0SSsKPu8sGqyo7TzqY7ngcGui+jEepNJBWwZXfR0pN8yBBVAlvEyqVlZnmfBwY4v7eqWIBwZHOxzs2L/urqlSpgoI852PbiW32krM1y9vHX3EJ5Z+BT2jeuWSeLSvKLYczX+kwY9ycnrR5eiq0e09JUsbyZTL5x7dBu11eUdGOnvq8Kj9gzNm9y/nYp05cueVKh73S81ip8Gi6Co6mnxZ1wemnU3NvtW3srWPZRZr9UwV32ZcSGWJXWJBjn7x5d8VXCWze5ZgeFmxXRAiHKzh9FLcMGWO0dV9JCPL1lsICHf/WhLen1KSuYx1px4x2u17YUC3Foai8QJiaUTKhvDAmOV6bJGXlGmXnlV8OJWpNw9+uXdb8eNevX9+S5fyTePv4Ox/nZFV8k3tudskNyQf3biu33A+fPKP0I/t1LP2QvLz9FBpZV4nNu6hrv/GKjE2sUX0LC/K1e9ufkqTA4Ej5B4a6lDm4b7skKTy6vjw8yv8aRNVpWDJP8vYa1Qu1W2DbkstLc3btdJnu16ix7D6Orqazk7bJ7u+vuClXKHzgEHkGBUlydCZxbM0q7X//HR1btdLtenKStuvY2tUKbN1WEYOG6MCsD5WfmlqmjN3PT9Gjx0lytCZlLKu4tTV65AWKnThZ3lFRMnn5yjt0UMfWrNKhOV8qe8vmCuc99NUXip14iaP7+y7ddPSP31zKxF48RZJkCgp06JuvKlwezgx+PjZdOMDx2/Dp/GxlZlftjHudyJIrIlJSK76vav/hkul1IjzK7Z490NeuWy8KUlyUh3y8bMrKMdpzoFCrt+bp59W5bm/+B2oi7vildmmZUl6B1LK+TWc3tyk6tKQVqrhzjOVbHJ1TVEezeJu8PR3LWruzZs1l/j5SRHBxndyXWbXdqEsTI7vd0YvhF7+6rrNRHSk2zFGnldu4zLaqak3QSkhIcNt9ZXXYbDYVVNItM1xFxNSXh4eXCgvzK22l2rGpZHra8c4z3Nm1teQgs7AgX/t3HdX+XRv067z31Gf4teo78vqT/ryXLZiprIwjkqRWbjrkyM/LdU4PDo+pcFl+ASHy9vFXXm6WjlbwenCGs9kUO+Fi53+PLPjJpYhvg4RSxe1q/tLr8o2vV6aM3dtbwZ26KKhDJyW//j+lfPS+29XtfHyGGs94Uj5xcWr+8hvHex3cLFNYKL+ERMVcOFE+cXHKTzuipIcfqLS7ef+mpYY58PaRX2Cg/BISFTVspA5+9bn2vPBfmXz3rQv7P3hHfk2aKaRrNzV84GEd/PxTZaxcroL0NPnUiVPksFEKat9BprBAu597Wrm0aP0jjOnrp5BAu7buztfPq3OrPF9xa5ZUeU+AR46WTA8LLr9Fy9fHpqb1S1qcQwJtCgm0q1VDLw0+y0+vfHFM2/fy2w/rRDjOnSk7VxrQ3qYuTV23z4hgm/q3s6lZXaOZi4uUW43bvEtfNljToNWtmU0e9uKOLtwvKzVDmrvCaFBHqWV9u/x9jP7cbpR2zMjPR0qIsalTY8cytu8z+mUDQauqak3QkhxNtPj7efv4K7FFN21du0Qpuzdp9a9z3A5MvPrXOUrZU3J2PC/bdZDHoNAotex0ruo36ajw6Hqy2z2UlrpPm1ct0J8/f6nCwnzN/+IFFRbm69wLbq52XQ8f2K0fPvmvo96+/uo19CqXMnk5JfUq3VpXHi8fP+XlZik3t2qXxuDME33BhQpo0VKSdGTRAmVvce3hzzMo2Pk4ZvxE2X18lP77r9r31mvK3r5NHv4BCu3ZW3FXXiPPwCDVvfJa5ezaqfSlS1yWlbtntzZef4Wiho1SzPiJir92apnpRfn5Svn4Ax34dJbbzjKKFWRkKG3JIh1btVK5e3erKC9PXuERCu7cVRFDhsrD319Rw0bKw89fO2Y84HYZRTk52nbvHYoYOFgxF01SzLgJihk3oUyZI4sWKOWj95S1aWP5byLOGI3jPdWjnY8KC43en1u9/aKvd8kBZG4llx6VPjD18XZz4s1I2/cWaPXWPO3aX6ijWUXy8rCpbpSHerRz9IQYFmzXjRcG6Yn3j2p3ysn3TAgU8/WS7MeDS1SIFBdhV0a20fxVRtv2GRUUSXXCpL5t7aobaVN8pE3nd7Hr06VVa9YK9pfqO/rz0p5Dpsx9UdUVFy51aeqo69EsR5ft5flzu1HKEaOzWtjVPN6mhJiy37kjGUZLNxZpzY6/5p60M1WtClo2m00JCQmaMmWKevVyHQgUf51+I6/X9g2/qqiwQJ++ercOH9il9j1GKCgkShnpB/Xnz19owRcvycPTy9k7X35+Tpll1G3YWrc+8aM8PMveLB+X0EotOw1Q5z7j9PbjVygnO0OL57yq1l2HqE795lWuY15utj587l/OjjvOn/hvBYdFu5QryC85+3piXdzx9HRcbF2QV/WztjhzBLZtr7pXXCPJMabV7v8+4bac3bekS2u7j4+OLvtd2+69w9ndVEF6mg59/YWydySp6VPPyebhobgrrnYbtCQp5OweCu9/rjz8XU8G2L28FNqnnwrS05Ty8Qdu589PPaQ1F46UyS273WZri47+/qsOfvGpGj/+jHxiYhU+YKCOLPix3F4SA5q3UPiAgeXepxXcqYsK0tOUs2e3ijJdT7DgzOFhd4yZZbfZNPeP7Gp3q+5Z6qijoKJu2iRnT2mS3PZwNvPHLGXnui5je3KBFq/K1Yhefjqvu598vW2aNCRAD79VSX/aQBV4eZZ+bFNegdEHC4rKDCi8+5D0wcIiXdLP7hhLK96muHAp+XDly2/VoGQA4pp0guHvI43qbpeH3SZjjL7+vchtz4XFvD2ltok2JbgeNkly3LvVuoFNqUeN9qa6LwNXtSZoDRkyRN9//72SkpI0ffp0NWzYUJdeeqkmT56sunXd9wB2MnJzc5V7woGJj4+PfI7fe/FPVa9xew2fPF1fvj1dhYX5+vHTZ/Xjp8+WKePl7atB427T1+/9R5Lk41t2gN/KWo/iG7bV+ZP+rU9euVPGGP32w/saedmDVapfYWGBPn7hJu3f7Tij3rXfeHUspzdBT6+Sz7IqXbYXd6zh6f3P3gb+iXwbJKrh/Q/L5umpotxcJd1/nwrS0tyWLcore3p+76svue3TN3PtaqUtWaSw3n3l1yBRfg0bKXt72fsZ615zg2LGjpckpS1ZpJSPP1D29q0yhUXybdBAUSMvUOSQ81X3quvk37ylkh78P5d1mYICqYJLCnP37tGOGQ+o2TMvSpKiRl3gNmiF9uqjhLvvk93bR1nbtmrf26/r2Oo/VZiVJe/oGIX16ac6F09R1LCRCmzbTltvv8nlnjKcOYZ091OdSA+lphfq658rHkjYndKbpKe94svDPT1KprvrvtpdyCrti0XZSozzVIsELzWI9VSjup7axiWEqKETw8qq7aZMyCpdbuHaIo3r6bgvsUU9m5IPVx6cWjewHZ/fnPRYVd6ejgGIg493Dz9/tdHOA+WXD/CVJvS2KyrEERznry7Sxt1GR7Mkby+pXqTUq7VdDaJtuqiPXV//fvJ1+6epNd34zJkzR7t27dLDDz+sJk2aaNu2bbrvvvuUkJCgIUOGaNasWcrLq3kXKDNmzFBISEiZvxkzZljwCmq/Tr3G6Or7PlKLTgPKhCa7h6ead+ina6d/orjEkvF8/AJCqr2ONt3Ok4+fo1ubHZv+qNI8xhh9+to92rx6kSSpddfBOv/i+8ot710qAOZV4XLA/FzHwYRPFS4zxJnDO7aOGj/2lDyDg2UKC5T0n2nlDlIsSUXZJdtS/pEjyt66pdyyR5eVdCjh36xsq21wt7OdISv1uznaPu0eZa5fq6KcHJn8PGVv3aJdT8zQvuNjV4X16qOo4e5PKlQmc81qZR8fyDiwdVvHCJmleIaFqcEd98ju7aPspO3a/K9rlP7zYhVmZEiFhcrbl6yUD9/Ttn/fKVNUJL8GiYq/ofqX/KJ2iAm3a/BZjjGtPpqXpbyTGFowJ6/k4Mynkp7ZfEpdcJCbd3IHdYtWllxZ0bR+rTm3jNPYiaE/KaX8bXNHimNAbUmqE175fed1wqXIYEe5LcmmWvd1FfOwS2N62J3r+3VjkX7bVPH359wOjpBljNGsxUX6daNRWqZjYOWcPGlLsvTOT0U6lG7k6WHTeV1s8ufcc5XUqr1OnTp1dNddd+muu+7Szz//rDfeeEOzZs3S3Llz9f333yssLEwXXXSRpkyZoo4dO57UOu6++27dcsstZZ77p7dmlRaX0EoXTX1OhYUFOpZ2UIWF+QoKjZHX8daeP5d+6SwbHde42sv38PBUZGyC9iat1dEjFZx+KeXrdx/Q6l8cPZ01adtTF1z1mOxuunQv5uXtI//AUGUdS9PRwykVLjs7M90ZxoLD61TxVaC284qIUJPHn5F3ZJRMUZF2Pv5IuZf4Fcs7ULIt5R+qeNvNO1Ay3TMkrMy0yPOGSXJ0IZ/8ZvkDf+9//11Fj7lQHv7+ihh8/kmP25Wzc4f8EhJl9/GRZ3CICtLTnNPC+g6Qh5/jBMP+D95VUU6O22VkrFyujJXLFdypi0J79JRHYJAKj7k5xYtabUAXX3l52nTwSKG8vWzq3MI1KcWV6lWwWQMvBQc49sWrt+YpL79sBxilO8Zwp3QHGKU7xqiOfakl84UG1ppzyziNFRZJmTlGAb7F9z5VXDY7Vwr0U5WCSZsGpTrBOInLBm02adTZduf9VX9uL9L81RUvx9dLanb8wrAdKdKucm77zS+Qlm4wGn6Wo0fElvVtWraFVq3K1KqgVVqPHj3Uo0cPPffcc/r444/15ptvasmSJXr++ef1wgsvqHXr1rr88ss1ceJERURUPPZTaVwmWDUeHp4KiXANHsk71jkf123Y5iSXXvXeBufOfEK///SRJCmhWWdNuOHZKt13FRXXSDs3L9fhA7tUWFhQbhfvxd3AO+Zp6LYMziwewSFq/NgzzrGhdj//jA7P+67S+XKOtwxJksoZ1LtY6bHdTGHZ61B86zeQJBWkHVH+oUPlLsPk5ylnR5ICWrZyznNSKrirufRys9x0AFJa1uZNCu7URTYPD/nE11PWxvUnXyecljyPdzcdFeahK0dUMNjOcUN7lNy3eM9LaUpNL9K+Uvd0xURU/D2JDS+Zvq+SruDLxV37+AscOuq43E6SKrkC1nmhQCW3JMpuk1rUdxTOzDHatr/69RrezeYcf2v9riJ9u6zy7T88qKRzj/1HKi6/r9T04p4XUbFaf3rH399fl156qRYtWqQtW7bo7rvvVt26dbVmzRrdfPPNevTRR091Ff8xiooKtX75PElSSHgd1W/SoZI5XBUWFih1/w5JUlBYVIVlF3z5kpZ887okqW5iG11808vy8vat0noaNO0kyXHpYOlweKIdG0u6q2/Q5ORaSVF72AMC1OTRp+SX4BjLbe+rL+nQF59Wad68AynKTXH8MvrExFZYtvQAvyf2GlgcvGweFR+ESo5BkkvPczKKu6Uvyst1Dk58Yl2qUh9bqV4OalIfnNkOpRc5W7Wa1qv4pFiT49OPHC0qdwytypQetyvt2MktAzjR7oOlBvgNKL+ct2dJS1ZGJbc0Nqoj+fs4As+6XdXv2W9IZ5ta1ncc1m/Za/Tlb1VbQOkAWMHFQJJKBj4+cT6Ur9a2aLnTqFEjXXbZZSosLNQzzzyj/HLGhcFfY/miT5Se6hhrqnOfcbJXclbfnbW/fevsNTCxWZdyy/3y/TvOzjhi4pvqkltfkY9fBXu7E7To2F+Lvn5FkrRy8Weq16idS5mioiL9ufQLSZKvf7ASm3et8vJR+9h8fNT4ocedY07te+/tcse5Kk/a4gWKuWC8PAIDFdSxszJWuB93LrRnb+fjY2tXl5mWt3+f/BIbyjMkVL71G7gdHFmSPIKC5Hs8EObtT65WPYsFtGojv0RHS+2xNWtczv7n7S8ZOy6wTbuyrXYnCGzj+A6ZoiLlpTDm3Jno7TmZentOxb1KDj3HT8POcbRkPfnBUW3e5dr5xKoteerT0Vd1Ij2UGOehpGTXYJ4Y5+EMSau2nPz91z3bl5x827ybjjBgjY17jM5p5XjcNN6mTXvdp45mdUt6ECwdztxpk1CSYqrb22D/dja1b+iYPynF6LNfiqoc1NIzHfe622w21Yu0SSp/xvpRJc13aXQwWyW1vkVLkrKysvTWW2+pV69eatq0qR5//HHl5eWpdevW6t+//6mu3hnj6JHy72favv5XffuBo9OQiNgE9Rh8aZnp2ZnpStrwe4XL37N9tbPHQpvNpi79Jrgtt2Lxp/r2w0ec65py++vyDwyt6suQ5OjhsLhVa/niT8oMoFxs6Xdv6mCyoze4s8+dVKVLElE72Tw91ej+hxXYpq0k6cAnM7WvgvujynPgk1kqOt5rafy1N8jupmv28AEDFdTe0Tqa/uvPyj9Y9n6utFI9/8Vf968yLUUlFbap3g03ye7tfXw5S12KhPToWWFdfeLqKuHeac7/H/rSteUu/delMsd7M4ydeIm8IiPdLivi/OEKaN5CkpS5YZ0Kj9KNNsr34x85zg4Cxp8bUKa7bMnRffb4cx0nzgoLjX5c5npvYGKch4IDKr5ma0RPP7VMdOy3d6cUaNseghascTBd2rbPsQ23rGdTAzddogf4Sr3alPQguLqC8OTr7WjRkqQDaUYH0qpel3Na2dS1meNwfs8ho0+WFKmwGo232XlydtceF2Erc59YacH+UvcWjmnGGOfrR8VqdYvWkiVL9MYbb2j27NnKzMyUMUZhYWGaMGGCLr30UnXq1OlUV/GM8ty9w5XQrIuateul6LpN5OHlrfTUZK1f/oNW//K1jCmSX0CILrzuaWfnGMVyso7pjUcnK6ZeM7Xo2F9xCa0UFBIlu91eMmDx0i+d3a33GHyp6ia0cqnD+uU/6Is3/0/GGPn4Ber8i+5RZsZhZWaUPzhFWFS8267lz5t4j157aKLy83L09hNXqNfQq9WweVfl5+dqzW/faNmCmZLcB0ecWRLuna7gLt0kSUdXLNOhb792tha5YwoKlLtnt8vz+QdSlPzWa4q/+nr5NWys5i+8qv0fve8YsDjAX6Hn9FbU8JGSpMJjx7TnxedclnF47jeKHjNWfg0SFdylm5q/9JoOfPaJsrdtPd6zX4Iih49UYCvHPZD5h1OVMutjl+U0emCGcvbsVtqSRcrauF55Bw/K5OfJKyKyzIDFknRk/o9KW7LIZRm5u3cpde43ihwyVN5R0Wr+8ps68OlMHVuzSkXO7t37K3zAQMf7Ulig5NdfqeTdxj/dgSNF+v63HA05208JdTx1x8XBmvtrjg6mFSoq1EODzvJV/VjH4cn3v+XowBHXo8ZWDb01+Cxfrduerw078pV8qFDZuUaeHlJ8lKe6t/VRw7qOZeTmGb37bfmn3xvFeyo6rOS8c6BfyePoULvOblO2049f1tS8h2PUfj+sLFJchF1+3jaNPceuP7YcH7C4UIoLt+nsFjZn9+qL1hodq+DSwZb1bM7hDKrTmtWpsU09Wzm216NZRj+tKlJIJRf3HM5wvexv4ZoiTehtl91u0/ldbWoQI0f37tmOyx/rR9nUpanNeWnjqiT3XdrDlc2Y2nWnaHJyst566y299dZb2rZtm4wxstvtGjBggC699FKNGjVK3t6V9Bl7kmb+8s++vvvBqztV2B16dN3GuuDqx90OMnzk4F49dfuAStdht3uo9/Br1XfEdc7m9tI+ffVurfz582rV+7I731ZiC/eX/W1cOV+zX7lDudnuh16PiE3QpJtfVkRMDTobOAOMO7vkwGNF/3NOYU3+Gh1/rLhHwRPl7t+ndRPHljs97vKrFTN+YplOL0rLP3JY2//vbmWud39/oHd0jBo++Ij8GzepuB7Jydo+/R5lb9vqMq2qr+ngF59pz0vPypRzqbXNy0sN7rxX4X0r/v4WZmdp11OP68hP86q03tqo9Ht69SNVGHn0H6gqlw5Kji6PLh4SoHPald/51JJVOXrv2yy3FzKVXk9FUtML9fqXmRWOnzX5/AB1b1P1TrD+6Z/9/+4Kdz6eMfOffT9mfKSjl79AP/etQMYYLd1gtGhtxYfal/S3q26ETUVFRs9/XaRM9x28urioj2Nsq+p48etCpbs5lGtZ36YhnWzy9qp4eet3Femr3427YSL/Me4eV/VbY2pNi9bMmTP15ptv6ocfflBRUZGMMWrUqJGmTJmiyZMnKz4+/lRX8Yw34tIHtG3dUu3ZvloZaQeVl5ulgKBwxdRrqtZdBqvd2cPKvbwuKCxKF17/jHZv/VN7k9bo6JEUZWUcUUF+nnz8AxUZm6jE5l3UqddYhUVZNwB1ZZp36KsbHvxcv8x7V5tWLdTRwyny8PRSREx9teoySN36T5S3T+U/5kBpya//T+m/LFHksFEKbNNWXhERKsrLU+6e3Upf+rMOfD5bRZnln2HPO5CijdddofC+AxTaq4/8mzSVZ2ioJJsKM44qe/s2pf28WIfnfVdul+vb/n2nAlq2kn/zlvKOiZVnSIg8fP1UmJWp3ORkHVu7SqnfzqnwvitJMvn52vGf6Tr09ReKGHSeAlq0kldkpOxe3irMylTO7l3KWLFMh77+0qVjD6A8RtK732Zq5aY89WzvowZ1PBXoZ9OxbKOd+wq06M9crdte/n3WS1fn6mhmkRrW9VR8lIeC/O0K8LOpqEg6ll2kXSmFWr01T7+vy3MZYBawyp5D0mtzi9SpiU1N42wKCXB0GHEsR9p10Gj5FqOUtIqXERYo1Y1whJukFFU5ZFlt/S6j3QeN2je0KSHGpoggx2DFhYWOjjz2phqt2WHK7f4d7tWaFi273S6bzSZ/f3+NHTtWl156qXr2rPgeBKv901u08M91prdoAVVBixZAixZwRrZoFfP399eCBQu0YMGCas9rs9m0bds26ysFAAAAAKXUqqBljNHBgwd18ODJtVu6u+cHAAAAAKxWa4LWtGnTKi8EAAAAAKcBghYAAAAAWOyMGLAYAAAAAE4nBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYjZjjDnVlQAAAACAMwktWjjt5ebmavr06crNzT3VVQFOGb4HAN8DgO9A7UKLFk57R48eVUhIiNLT0xUcHHyqqwOcEnwPAL4HAN+B2oUWLQAAAACwGEELAAAAACxG0AIAAAAAixG0cNrz8fHRtGnT5OPjc6qrApwyfA8AvgcA34Hahc4wAAAAAMBitGgBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNooVKpqal68803dfHFF6tly5YKCAiQj4+P4uPjNXLkSH322WeVLiMjI0PTp09XmzZtFBgYqJCQEHXp0kVPPvmk8vLyTnn93HnkkUdks9mcf/jnqsk29tZbb5XZjsr7++GHH066fnv37tWLL76osWPHqnHjxvLz85Ofn58SExM1YcIE/fTTT1Vazpdffqlhw4YpNjZW3t7eqlOnjkaMGKFvv/32pOuGM8eKFSt0//33a/jw4WrevLkiIiLk5eWliIgI9ejRQw899JAOHz5c4TJSUlJ06623qlmzZvLz81N4eLh69uyp1157TTXtm2vhwoW69957NWjQIDVp0kRhYWHy8vJSdHS0+vbtq2effVbZ2dnVXu6QIUOc39M+ffrUqI6o/WryPZg+fXqVfg+2bt160vX76quvdNttt6lv375q1KiRgoOD5e3trbi4OA0ZMkRvvvmmCgoKKlxGbm6unnvuOZ1zzjkKCwuTr6+vEhISdMUVV2j9+vUnXbd/JANUwtPT00hy/vn6+pqAgIAyzw0ZMsRkZma6nX/Hjh0mISHBWdbf39/4+Pg4/9+hQwdz+PDhU1Y/dzZu3Gh8fX3LLAP/XDXZxt58800jydjtdhMTE1Pu36JFi06qbrt27TI2m61MXfz9/Y2fn1+Z5y677DJTUFDgdhkFBQVm4sSJzrI2m82EhYUZDw8P53NTp049qfrhzHH99de7fA+CgoLKPBcZGWmWLl3qdv5ly5aZiIgIZ9nAwMAy361BgwaZ3Nzck67f+eefX6YuAQEBLt/TxMREs2nTpiovs/j7W/zXu3fvk64fzgw1+R5MmzbNSDJeXl4V/h4kJSWddP1atWpVpi5BQUEuxzMdO3Y0+/fvdzv/vn37TIf/b+/eo6Iq1z+AfwdmGC6DcktJDUXMBDHMexpZVGJ2SC2vmXoyUczMOqV5/VmurDTMjnnMNI9pmkqZpnUKxSLL0CTzxvKCOipeIEBA7gzD8/uDNTtGZmAGBkn9ftaatTb7vexnZr2bPe+87373ffcpeTUajXh7eyt/a7Va2bBhQ53ju93w2yPVCoD06NFDli9fLmfOnFH26/V6ef7555WT79lnn61W1mAwSKdOnQSA3HnnnbJr1y4RETEajbJp0ybln9OAAQMaJT5LjEaj9O7dWwDI/fffz44W1auNmb6otW7dukFi0+v1AkAeeeQRWbt2rVy6dElEKttxSkqKDBw4UIlvzpw5FuuYMWOGkmfq1KmSlZUlIiIFBQUSGxurfBn+97//3SDvgW4Oa9eulffee0+SkpIkJydH2Z+fny9r166VO+64QwBIs2bNJDc316xsbm6u+Pv7CwDp0KGDHDhwQERESktLZdmyZaLRaASATJo0qc7xLVmyRJYuXSoHDx6Ua9euKfuzsrJk6dKlyo8PISEhYjQaa63vypUr4u3tLV5eXhIcHMyOFolI/c4DU0erIdvRvHnzZOXKlZKSkiJFRUXK/kuXLsmbb74pTk5Oyg8b16uoqFC+/7i5ucmqVaukuLhYREQuX74sY8aMUTpfycnJDfYebiX89ki1+uGHH2pMnzhxovIl7cKFC2Zpn3zyiZJm6dedzz//XElPSEi44fFZ8sEHHwgAGTVqlPJPkR2t21t92lhDd7Ryc3Pl999/t5peUVEh/fv3V0YQTBdNk8zMTGWEedCgQRbreP311wWAeHl5SV5enkPjp1tHfHy8ch6sX7/eLG3OnDnKl7ezZ89WK/v2228LAHF2drZrxMkeH3/8sRLfL7/8Umv+wYMHCwBZtWqV9O3blx0tsklN58GN6GjVZubMmUp8aWlpZmk7duxQ0j744AOL5Xv16iUAJCIi4kaEe9PjPVpUq4cffrjG9Oeff17ZTk5ONktbu3atUsf9999freyIESMQGBgIAFi3bt0Nj+96er0es2fPhq+vL5YsWVKneOjW48g25mhNmzZFly5drKarVCqMGzcOAFBQUIDjx4+bpe/evRulpaUAgGnTplmsY/r06QCA3NxcbNu2zQFR062oV69eyvbFixfN0kz/36v+z69qypQp0Ol0MBqN2LBhww2P73pxcXHYunUr+vbta3Z+E9XGnnbWGKrGd+nSJbO0b7/9FgDg4eGBF154wWJ503Xihx9+wIULFxooylsHO1pUb66ursq20WhUtouKirB3714AlTcTW6JSqdC/f38AwM6dO29ofJZER0ejsLAQ77//Pu64444GiYduPfa0scZQU3znz59XtkNCQiyW9/HxQbNmzQA03HlKN7+ff/5Z2Q4KClK2T548qXwhs3Yt0Ol0CA8PB9BwbcxafNfLzs7GlClToNVqsXLlSi6GRHaxtZ01FlN8KpUKbdu2NUszXQ/atWsHjUZjsXxwcLCyzetB7djRonpLTExUtjt16qRsHz9+HBUVFQCA0NBQq+VNaenp6bWuWOXI+K63atUq7N69G48++ijGjBnj8Djo1mVLG8vMzETXrl2h0+ng5uaGtm3b4tlnnzUr29Dxubi4oH379lbz1dRJNKUdPXrUobHRza20tBTnzp3DsmXLMHr0aACVX9KioqKUPMeOHVO2bbkWOHJVs+LiYqSmpuLtt9/Gq6++CgB48MEH0a1bN6tlXnrpJfz555+YO3dujecLkYkt50FVKSkpCA0Nhbu7O3Q6He655x5ER0fjjz/+aJD4CgoKcOzYMUyfPh2LFy8GAIwePdrqD8q2XAsAXg9s0thzF+nmlpOTI3feeacAkPDwcLO07du3K3N9Dx8+bLWObdu2KfmOHj16w+Kr6uLFi9K0aVNxc3MzW+yA92hRbWprY9evWubt7S0uLi5m+5577jkxGAwNEt/Zs2fF3d1dAMjo0aOrpW/evFmJIzEx0WIdV65cMVtNi6jqyrFVX3369JHz58+b5V26dKmSXtM9fqb7YwFIfn5+nWOr2l6vf0VFRUl2drbVsqbrVmhoqJSVlSn7eY8WWWLPeSBi/p3CyclJfHx8zFbeVKlUMnv2bIfElpSUZDE2Z2dnGTdunNlCGSaTJk0SoHIlxevv5zXZuHGjUteQIUMcEuutjCNaVGcVFRUYPXo0rly5AldXVyxbtswsPT8/X9l2d3e3Wk/VtKplGjq+qiZOnIi8vDy88cYb1YbSiayxpY21aNEC8+bNw+HDh1FSUoKrV68q02offfRRAMCaNWvwyiuvODy+4uJiDB06FEVFRfDz88O7775bLU9ERAS0Wi0AYMGCBRbrqbr/2rVrDo+Tbj7+/v5o3rw5PDw8lH0PP/wwPvjgAwQEBJjlvdHXAmdnZzRv3hzNmzc3mzY7dOhQLFq0CD4+PhbL5eXlISYmBk5OTli1apXVqVNEJvacBwBw9913Y9GiRTh58iRKSkqQnZ2NwsJCxMfHo2vXrhARLFiwQBl1qg8XFxflPHBxcVH2T5w4EfPmzYObm1u1MgMGDAAAlJSUWIzBaDSaXUd4PbBBY/f06Ob14osvKr9qrF69ulr6hg0blPTU1FSr9ezcubPGlQkbKj6Tzz77TABI586dq40qcESLamJrG7PGaDQqy687OTnJqVOnHBabwWCQQYMGKUvxxsfHW807bdo05X2MGjVKjh8/LmVlZXL+/Hl5/fXXRaVSKctvu7q6OixGujVkZGRIbGyseHt7i0qlkrlz55qlL1iwQGlfNY3crly5Usl3+fJlh8RWUVEhaWlpMnv2bHF1dRWNRiMff/yxxbymRzW8+OKL1dI4okW1qe08qE1xcbF0795dWSH2+qXh68NoNEpqaqpMnjxZnJycRKfTyddff10tX0VFhfTs2VMAiFqtlgULFsjly5elrKxMDh06pDyrznQ96N+/v8NivFXx2yPVyauvvqpcEJcsWWIxT32nDnbr1s3ig/wGDx7skPhERNLT08XX11ecnZ2V57pUxY4WWWNrG6tNamqqUs/ixYvN0qw9zPKll16qsc7y8nIZNmyYcrH84osvasxvMBhkxIgRVqdb9erVS2JiYgSofB4ekSX79+9XntGzY8cOZX99pw7W9Ty43pYtW5QfNQ4dOmSWtmvXLgEgrVq1MnsGlwk7WmQra+eBLUztEIBs2bJF2X/hwgWr58F7771n1zEWL16sdOYs/aBx6dIlCQsLs3o9mDx5snTr1k0AyMiRI+069u2IUwfJblVvpoyNjcXLL79sMV+LFi2U7euXEK2qalrVMpmZmcjIyKj2qm3BDFvjA4AZM2YgOzsbEyZMQIcOHVBQUGD2KisrU/Ja2ke3J3vaWG3atWsHPz8/AMDZs2fN0iy1/4yMDOTl5Vmtz2g04tlnn0VcXBycnZ2xfv16DBkypMYY1Go1Nm7ciG+//RbDhw9Hhw4d0Lp1a4SHh2Pp0qXYs2cPioqKAICLA5BVPXr0wAMPPAAAWLlypbLf3mtBkyZNoNPplP11OQ8seeqppxAQEICKigqsXr3aLC06OhoAsGjRIqhUqmrXAtMCAEajsdo+oqqsnQe2qPoYnKrXA6PRaPU8KCgosOsYL7zwArRaLQoKCrBx48Zq6S1atMD+/fuxYsUKREZGIigoCEFBQYiKisL27duxbNky/PnnnwB4PbBJY/f06Oby2muvKb9qLFq0qMa8hYWFyq86NeU13Xzp7+9/Q+MT+etXSnteU6dOrXecdPOyt43Zws/PT/mlsD7Ky8tl+PDhyg3PGzdudEh8IiIhISECQGbOnOmwOunWM3LkSAEgwcHByr4TJ04o50xcXJzVso8//rgygtpQ7r//fgEgjz/+uNl+e68DAGTr1q0NFifd3CydB7YoKChQ2pe9I1X2MC3gNGnSJLvLZmRkKDHWNCWdKnFEi2z22muvITY2FkDlr37WHm5q4u7ujj59+gAAvv/+e4t5RATx8fEAgH79+t3Q+Ijs1RBt7MyZM8jKygIAiw9ytZXRaMQzzzyDzZs3KyNZI0aMqHd8APDHH38oS27z0QdUE9Ov8J6ensq+9u3bKwsDWLsWFBYWKs/3qe+1wBoRgV6vrxYfkaNZOg9ssW/fPmW7PteDmuTn5yMzMxNA3c4D0wPFW7ZsiYiICIfGdktq7J4e3Ryq3o8SGxtrc7lPPvlEWbJ037591dKrLi2dkJBww+OrDe/RIpO6tLGKiopa0wcPHqzcN3LixIk6xVZ1JEutVsumTZvqVI8lhYWFys3RXMr39lVeXl5re05ISBCVSiUAZPr06WZpc+bMEQDi7u4uer2+WtmFCxcqI7EnT560Oz5bHo+wevVq5Rxevny5XfXzHi0Sqd95UFu5kpIS5X+th4eH5OTk2B2fLefB3LlzlfPgf//7n131nz59Wry9vQWALFu2zO74bkf89ki1qroi2fvvv29XWYPBIJ06dRIA0rJlS6UzZTQaJS4uTpo0aWJxGseNiq827GiRSN3bmF6vl+7du8uKFSvkzJkzyoXWaDRKUlKSREZGKvXWZQqHSOWF37SQhVqtrnFqljX79u2TBQsWSEpKipSWloqISGlpqXz33Xdy3333CQC56667JCMjo04x0s1Pr9dLWFhYtbYsUnmj/jvvvCMeHh4CQHx8fOTKlStm5XNzc8Xf318ASEhIiCQnJ4tIZTtbvny58my5up4HP/74o4SHh8u6deskLS3NLO3UqVPy+uuvK88rCgoKsvgMoZqwo0Ui9TsPEhMT5ZFHHqnWRsvKyiQhIUFZcRCALFy4sE7xffrppxIVFSVbtmwx+39tNBrl8OHDEh0drRyjT58+Fjt/a9eulZUrV0paWpoYjUYRqTx/P/nkE2nWrJkAlasN1tZxpEr89kg1On/+vHJSOjk5WV31pqbVb/R6vbRp00apx93dXVxdXZW/77vvPrl69WqjxVcTdrSoPm1Mr9eb3dOh1WrFz8+v2kMu6/PA4p9++kmpR6PR1BqfpdGurVu3KnWoVCrx8fERZ2dnZV9oaKjFUQi6fVzfll1cXMTPz0/5Uml6BQYGysGDBy3WkZycLL6+vkpeT09PZZloANKvXz8pKSmpU3w//vijWRyurq7i5+cnbm5uZvvDwsLq1JbZ0SKR+p0H17dRNzc38fPzMzsHnJycZNasWXWOb82aNWbH8PDwED8/P+WHDNMrIiLC6oO7p06danZN8fLyUkboTDMbrD3MmKpTV59MSPSXiooKs+2MjIwa81ta/aZNmzY4cuQIYmNj8dVXX0Gv10Oj0aBjx44YOXIkpkyZYvYwvRsdH1FN6tPGmjdvjg8//BBJSUk4dOgQMjMzkZOTA1dXVwQGBqJ3794YN26cci9jfeMzGAy1xldcXFxtX9euXTFt2jTs2bMH586dw9WrV+Hr64t7770Xw4YNw3PPPQe1mpeL21mLFi3wxRdfIDExEfv378fly5eRlZUFZ2dnBAQEICwsDAMHDsQzzzxj8UGoQGU7S0lJwcKFC/HNN98gLS0NHh4eCA0NxdixYzFu3Dg4OdXt1vGuXbvis88+Q2JiIpKTk5Geno7s7GxotVoEBQWhS5cuePrppzFkyBA4OzvX56Og21h9zoNOnTohNjYWSUlJOHr0KLKyspCbmwt3d3eEhIQgPDwcEyZMQKdOneoc3xNPPIFVq1YhMTERhw4dQkZGBnJycuDm5oa2bduie/fuGDFihPJgYkuGDx+OoqIiJCUl4dKlSygqKkKrVq3Qu3dvPPfcc4iMjKxzfLcjlYhIYwdBRERERER0K+Gqg0RERERERA7GjhYREREREZGDsaNFRERERETkYOxoERERERERORg7WkRERERERA7GjhYREREREZGDsaNFRERERETkYOxoERERERERORg7WkRERERERA7GjhYREREREZGDsaNFRERERETkYOxoERFRneXk5MDNzQ0qlQoqlQqpqamNHZJDHT9+HLNmzUKfPn3QokULaLVaeHh4ICAgAAMGDMDbb7+NU6dONXaYRET0N6QSEWnsIIiI6Oa0bNkyTJkyRfl7xowZeOeddxoxIsfIz8/HpEmT8Pnnn6PqZdLT0xMqlQrXrl0zyx8VFYV169bBy8vrBkdKRER/VxzRIiKiOlu9ejUAKJ2ttWvXwmg0NmZI9ZadnY2ePXtiw4YNAIBhw4YhISEBhYWFuHbtGvLy8lBSUoKff/4ZM2bMgK+vL3bs2IH09PRGjpyIiP5OOKJFRER1cvDgQXTt2hVeXl64cuUKQkJCoNfrsX37dkRFRTV2eHX26KOPYvfu3dBoNNi8eTMGDx5cY/6ioiL83//9H2JiYtCuXbsbFCUREf3dcUSLiIjqxDSaNXz4cLi6umLMmDEAgP/+9782lf/6668REREBLy8v6HQ6hIWFYdGiRTAYDHjjjTegUqnw0EMPWS1/7tw5vPzyy+jYsSN0Oh3c3d3RoUMHTJ06FRcuXKjTe/rmm2+we/duAMBbb71VaycLANzd3REbG1utk3Xu3Dnl3rVz587hzJkzmDBhAgIDA6HVatGmTRuz/Hl5eZg/fz66dOmCJk2awM3NDXfffTcmTZqEs2fPWv0Mqh7DmjZt2kClUuHTTz+tsXxqair++c9/olWrVtBqtQgICEBMTAwuX75c6+dARETXESIiIjsVFxeLl5eXAJC9e/eKiMiZM2dEpVKJWq2W9PT0Gsu/+uqrAkB5eXl5iVqtFgDy4IMPyqxZswSA9O3b12L59evXi1arVcprtVpxc3NT/vb09JT4+Hi731f//v0FgPj4+EhRUZHd5avS6/VKPBs2bBCdTicAxN3dXTw8PKR169ZK3mPHjkmrVq2U/K6uruLp6Wn2/r788ssaj6HX663G0rp1awEga9assVp+06ZNyjF1Op3Z5+nj4yO///57vT4PIqLbDUe0iIjIblu2bEFubi7atWuH3r17AwDatm2LBx54AOXl5Vi3bp3Vsps2bcLixYsBAM888wwuXryInJwc5OfnY+XKlfjtt9/w0UcfWS2/a9cujBkzBkajEdOnT4der0dxcTEKCwtx4sQJDB06FPn5+Rg6dKhdI1sGgwE///wzgMrpg25ubjaXrc3EiRPRsWNHHDhwAIWFhSgoKMDOnTsBVC68ERUVhYsXL6Jly5b49ttvlfvBDh06hF69eqG0tBSjRo3C4cOHHRaTpRgDAwOxf/9+5Ofno7CwEPHx8QgICMDVq1cxePBg5OfnN9jxiYhuNexoERGR3UzTBk3TBU1qmz4oIpg7dy4A4LHHHsP69evRsmVLAICrqyuio6Px0UcfIScnx2L5iooKTJ48GRUVFfjPf/6DhQsXKtPiVCoV7rnnHsTFxeHJJ5/EtWvX8P7779v8ns6fP4/CwkIAQOfOnW0uZwtfX18kJCSgW7duyr727dsDAJYvXw69Xg+NRoPvv/8eAwYMgJNT5eU5LCwMO3fuRJs2bVBaWorZs2c7NK6q1Go1du3ahR49egAAVCoV+vXrh++//x4uLi64cOECVqxY0WDHJyK61bCjRUREdjl79iwSExOhUqkwevRos7Rhw4bBzc0NJ06cwK+//lqt7KFDh3D69GkAwKxZs6BSqarlGTt2LAICAiwee8+ePUhNTYWfnx/Gjx9vNUZThy8+Pt7m95Wdna1s+/j4WM33xBNPwN/fv9pr6tSpVsu8+OKL0Ol0FtM2b94MABgyZAhCQ0OrpXt6emL69OkAgO+++w55eXk2vR97xcTEoFmzZtX2BwcHY8iQIQAqRyOJiMg27GgREZFd1qxZAxFBeHh4tQUdmjRpgkGDBgH4a9SrqoMHDwIANBqNMuXweiqVCn379rWYtnfvXgCVC0e0aNHCYofH398f0dHRACpHqRwtOzsbGRkZ1V41dYD69OljcX9ZWRmOHDkCoHK6ojWPPfYYgMoRPdNn6GgRERG1ph05cgQGg6FBjk9EdKthR4uIiGxWUVGhrFx3/bRBk7FjxwIA4uLiUFBQYJaWmZkJoHIqnYuLi9XjmKYTXs+0+p3BYLDY2TG9TFMPi4uLbX5vvr6+yvbVq1et5tu3bx9ERHlZ6xRWZWmkyHQc03PHrL1nAGjVqpWy/eeff9Z6vLqo6fimtPLy8ho/GyIi+gs7WkREZLP4+HhcvHgRADB+/Hjl3qiqr/79+wMACgoKEBcXZ7EeS1MGbWHqlPTs2dOss1PTy1atW7eGh4cHgMopjo7k7Ozs0PqIiOjvjx0tIiKymaXpgPbkv+OOOwAAWVlZKCsrs1ru0qVLFvf7+/sDaJgpgRqNBuHh4QCAhIQEu0bD6srHx0fphJk6sJZUTas6OqZWq5XtkpISq+Vtua/L2mdeNU2tVtd4/xoREf2FHS0iIrJJZmYmtm/fDgD48ssvkZ+fb/X122+/AQB+/fVXnDx5UqmjS5cuACqn/llaLAOoXJlwz549FtNM9zqlp6cjOTnZYe/NZPLkyQAqp/R9+OGHDq//ei4uLrj33nsBQHlQsiUJCQkAACcnJ+UzBABvb29lOy0tzWLZU6dOITc3t9ZYfvzxx1rT7r33Xmg0mlrrIiIidrSIiMhGn332GQwGA5o2bYqoqCjodDqrr+7du6NDhw4AzEe1OnfujHbt2gEA3n33XYtT+9avX291xOrhhx9Wyr/yyis1jooBNd9rZck//vEPPPLIIwCAOXPmYOvWrXaVr4sRI0YAqOy8Hjt2rFp6QUEBFi1aBAAYMGAAmjZtqqR5eHggKCgIQOWzzSxZsGCBTXGsWLECWVlZ1fafPHkSX375JQBg+PDhNtVFRETsaBERkY1MHaaBAwfWuJCFydChQwEA69atQ3l5OYDKe7PefPNNAJX3e40dO1ZZ4KKkpASrV6/GxIkTzUZqqlKr1VixYgXUajV++eUXPPjgg9i9e7fZSnhnz57FihUr0L17dyxfvtzu97l582YEBwfDYDDg6aefxvDhw5GQkICioiIlT3l5OY4cOYK5c+fWe2Rt0qRJCAwMhMFgwOOPP47vvvsOFRUVAICjR48iMjISer0eWq0Wb731VrXyI0eOBFD57LLly5crUx7T0tIwfvx4bN68Ge7u7rXGYTAY8Nhjj+HAgQMAKkcWExISEBkZidLSUtx1112IiYmp13slIrqtCBERUS2SkpIEgACQHTt22FTmyJEjSplt27aZpb388stKmkqlEm9vb9FoNAJAIiIiZObMmQJAIiMjLda9detW8fT0VOrQaDTi6+srWq1W2QdA3nrrrTq932vXrsmoUaNEpVKZ1efp6Sk+Pj6iVqvN9j/55JNy8uRJszr0er2Srtfrazze0aNHpWXLlkp+V1dXadKkifK3VquVL774wmLZ/Px8CQkJUfI6OTmJl5eX8rls3LhRWrduLQBkzZo1VmPctGmT8pnqdDpxd3dX0ry8vOTAgQN1+iyJiG5XHNEiIqJamUazmjZtin79+tlUplOnTggODjYrb7JkyRJ89dVXeOihh+Dp6YnS0lIEBwfjvffeQ3x8PAoLCwEAXl5eFuseNGgQTp8+jXnz5qFHjx7Q6XTIzc2FVqtFWFgYxo8fj61bt2LatGl1er+enp5Yv349jh07hpkzZ6J3797w9/dHaWkpSkpK4O/vj8jISMyfPx+nT5/G119/jfbt29fpWAAQGhqKlJQUvPHGG+jcuTPUajVKS0sRFBSEmJgYpKSkKA8Nvp5Op8Mvv/yCf/3rXwgMDIRarYZGo8HTTz+NpKQkZWpibXr27Ink5GSMGTMGTZs2RXl5OVq2bIno6GgcPXoU3bp1q/P7IyK6HalE7Fj7loiI6Abo06cPfv31V8yfPx9z585t7HBuWefOnUNgYCAAQK/XV3sANRER1R1HtIiI6G/lp59+UlYkND2Ti4iI6GbDjhYREd1wkydPxqeffor09HRl5cHc3Fx8/PHHGDhwIAAgIiIC3bt3b8wwiYiI6kxdexYiIiLH2rt3r7IioFarhbu7O3Jzc5VOV0hICNatW9eYIRIREdULO1pERHTDzZ8/H9u2bcP+/fuRkZGBvLw8eHt7o2PHjnjqqacwYcIEm5YkJyIi+rviYhhEREREREQOxnu0iIiIiIiIHIwdLSIiIiIiIgdjR4uIiIiIiMjB2NEiIiIiIiJyMHa0iIiIiIiIHIwdLSIiIiIiIgdjR4uIiIiIiMjB2NEiIiIiIiJysP8HILEkoIwqrFgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion Distribution Information:\n",
      "Emotion\n",
      "Confident or Attentive        18418\n",
      "Passionate or Amused          17212\n",
      "Frustrated or Impatient       16325\n",
      "Distressed or Defiant         11175\n",
      "Worried or Apathetic           6601\n",
      "Tensed or Annoyed              4845\n",
      "Delighted or Happy             4296\n",
      "Tired or Bored                 3154\n",
      "Pleased or Glad                2963\n",
      "Anxious or Dejected            2962\n",
      "Excited or Adventurous         2959\n",
      "Aroused or Astonished          2958\n",
      "Polite or Sleepy               2948\n",
      "Miserable or Sad               2939\n",
      "Frustrated or Discontented     2809\n",
      "Name: count, dtype: int64\n",
      "Total Instances in Emotion Distribution: 102564\n",
      "Percentages for each class:\n",
      "Emotion\n",
      "Confident or Attentive        17.957568\n",
      "Passionate or Amused          16.781717\n",
      "Frustrated or Impatient       15.916891\n",
      "Distressed or Defiant         10.895636\n",
      "Worried or Apathetic           6.435981\n",
      "Tensed or Annoyed              4.723880\n",
      "Delighted or Happy             4.188604\n",
      "Tired or Bored                 3.075153\n",
      "Pleased or Glad                2.888928\n",
      "Anxious or Dejected            2.887953\n",
      "Excited or Adventurous         2.885028\n",
      "Aroused or Astonished          2.884053\n",
      "Polite or Sleepy               2.874303\n",
      "Miserable or Sad               2.865528\n",
      "Frustrated or Discontented     2.738778\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age Group Distribution Information:\n",
      "AGE\n",
      "25-29    44821\n",
      "20-24    38528\n",
      "30-34    12409\n",
      "35-39     6728\n",
      "Name: count, dtype: int64\n",
      "Total Instances in Age Group Distribution: 102486\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"Cleans data by handling missing values in crucial columns.\"\"\"\n",
    "    df = data.copy()\n",
    "    print(\"Missing values before cleaning:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Drop rows where crucial columns ('Emotion', 'GENDER', 'AGE') have missing values\n",
    "    crucial_columns = ['Emotion', 'GENDER', 'AGE']\n",
    "    df = df.dropna(subset=crucial_columns)\n",
    "\n",
    "    df = df[df['Emotion'] != 'Neutral']\n",
    "    \n",
    "    print(\"\\nMissing values after cleaning:\")\n",
    "    print(df.isnull().sum())\n",
    "    return df\n",
    "\n",
    "def balance_emotion_data(data):\n",
    "    \"\"\"Balances the Emotion data using ADASYN or SMOTE.\"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate target size for balanced classes\n",
    "    emotion_counts = df['Emotion'].value_counts()\n",
    "    target_size = int(np.median(emotion_counts))  # Use median as target size for balancing\n",
    "    print(f\"Target size per class: {target_size}\")\n",
    "    \n",
    "    print(\"\\nOld Emotion Class Distribution:\")\n",
    "    print(emotion_counts)\n",
    "    print(f\"Total Instances before balancing: {emotion_counts.sum()}\")\n",
    "    \n",
    "    X = df.drop(['Emotion', 'Emotion_Type'], axis=1)\n",
    "    y = df['Emotion']\n",
    "    \n",
    "    # Convert categorical variables to numeric codes\n",
    "    X['GENDER'] = pd.Categorical(X['GENDER']).codes\n",
    "    X['AGE'] = pd.Categorical(X['AGE']).codes\n",
    "    \n",
    "    # Handle missing values in numeric columns\n",
    "    numeric_columns = X.select_dtypes(include=[np.number]).columns\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = X.copy()\n",
    "    X_imputed[numeric_columns] = imputer.fit_transform(X[numeric_columns])\n",
    "    \n",
    "    # Handle missing values in target variable 'y' if any\n",
    "    y = y.fillna(y.mode()[0])\n",
    "    \n",
    "    # Create sampling strategy dictionary to control synthetic data generation\n",
    "    sampling_strategy = {}\n",
    "    for emotion in y.unique():\n",
    "        count = Counter(y)[emotion]\n",
    "        if count < target_size:\n",
    "            sampling_strategy[emotion] = target_size\n",
    "    \n",
    "    # Apply ADASYN for resampling\n",
    "    try:\n",
    "        adasyn = ADASYN(random_state=42, n_neighbors=5, sampling_strategy=sampling_strategy)\n",
    "        X_resampled, y_resampled = adasyn.fit_resample(X_imputed, y)\n",
    "        \n",
    "        print(\"\\nNew Emotion Class Distribution:\")\n",
    "        print(Counter(y_resampled))\n",
    "        print(f\"Total Instances after balancing: {sum(Counter(y_resampled).values())}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"ADASYN failed with error: {str(e)}\")\n",
    "        print(\"Falling back to SMOTE...\")\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE(random_state=42, sampling_strategy=sampling_strategy)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X_imputed.columns)\n",
    "    df_resampled['Emotion'] = y_resampled\n",
    "    \n",
    "    # Convert numeric values back to categorical\n",
    "    gender_map = {0: 'F', 1: 'M'}\n",
    "    age_map = {0: '20-24', 1: '25-29', 2: '30-34', 3: '35-39'}\n",
    "    \n",
    "    df_resampled['GENDER'] = df_resampled['GENDER'].map(gender_map)\n",
    "    df_resampled['AGE'] = df_resampled['AGE'].map(age_map)\n",
    "    print(df_resampled.head())\n",
    "    \n",
    "    # Add back 'Emotion_Type'\n",
    "    emotion_type_map = dict(zip(data['Emotion'], data['Emotion_Type']))\n",
    "    df_resampled['Emotion_Type'] = df_resampled['Emotion'].map(emotion_type_map)\n",
    "    \n",
    "    return df_resampled, df\n",
    "\n",
    "def create_visualizations(data, old_data):\n",
    "    \"\"\"Creates visualizations for the dataset.\"\"\"\n",
    "    \n",
    "    print(\"\\nHeatmap Information:\")\n",
    "    heatmap_data = data.groupby(['GENDER', 'AGE']).size().unstack(fill_value=0)\n",
    "    print(heatmap_data)\n",
    "    print(f\"Total Instances in Heatmap: {heatmap_data.sum().sum()}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        heatmap_data, annot=True, cmap='coolwarm', fmt='d', linewidths=1, cbar=False,\n",
    "        annot_kws={\"size\": 20}\n",
    "    )\n",
    "    plt.title('Heatmap of Instance Counts by Gender and Age Group', fontsize=16)\n",
    "    plt.xlabel('Age Group', fontsize=18)\n",
    "    plt.ylabel('Gender', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nEmotion Distribution Information:\")\n",
    "    emotion_counts = data['Emotion'].value_counts()\n",
    "    total_count = emotion_counts.sum()\n",
    "    emotion_percentages = (emotion_counts / total_count) * 100\n",
    "    print(emotion_counts)\n",
    "    print(f\"Total Instances in Emotion Distribution: {total_count}\")\n",
    "    print(\"Percentages for each class:\")\n",
    "    print(emotion_percentages)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(\n",
    "        emotion_counts, labels=emotion_counts.index, autopct='%1.1f%%',\n",
    "        startangle=90, textprops={'fontsize': 14}, wedgeprops={'width': 0.3}\n",
    "    )\n",
    "    plt.title('Distribution of Emotion Types', fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nAge Group Distribution Information:\")\n",
    "    age_counts = data['AGE'].value_counts()\n",
    "    print(age_counts)\n",
    "    print(f\"Total Instances in Age Group Distribution: {age_counts.sum()}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=age_counts.index, y=age_counts.values, palette='viridis')\n",
    "    plt.xlabel('Age Group', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.title('Age Group Distribution', fontsize=16)\n",
    "    plt.xticks(rotation=45, fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "cleaned_data = clean_data(data)\n",
    "balanced_data, old_data = balance_emotion_data(cleaned_data)\n",
    "create_visualizations(balanced_data, old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de3c1b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:26.527035Z",
     "iopub.status.busy": "2025-02-25T04:59:26.526510Z",
     "iopub.status.idle": "2025-02-25T04:59:26.730214Z",
     "shell.execute_reply": "2025-02-25T04:59:26.729244Z"
    },
    "papermill": {
     "duration": 0.22904,
     "end_time": "2025-02-25T04:59:26.731650",
     "exception": false,
     "start_time": "2025-02-25T04:59:26.502610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102564\n",
      "Emotion Labels and Corresponding Encodings:\n",
      "{'Frustrated or Impatient': 0, 'Tensed or Annoyed': 1, 'Distressed or Defiant': 2, 'Confident or Attentive': 3, 'Passionate or Amused': 4, 'Pleased or Glad': 5, 'Delighted or Happy': 6, 'Worried or Apathetic': 7, 'Frustrated or Discontented': 8, 'Aroused or Astonished': 9, 'Miserable or Sad': 10, 'Anxious or Dejected': 11, 'Tired or Bored': 12, 'Polite or Sleepy': 13, 'Excited or Adventurous': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1008d6e0ffc7>:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Emotion'] = df['Emotion'].replace(label_to_num)\n",
      "<ipython-input-8-1008d6e0ffc7>:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Emotion_Type'] = df['Emotion_Type'].replace(emotion_type_map)\n"
     ]
    }
   ],
   "source": [
    "print(len(balanced_data))\n",
    "df = balanced_data\n",
    "df['AGE'] = df['AGE'].replace({'20-24': '20-29', '25-29': '20-29', '30-34': '30-39', '35-39': '30-39'})\n",
    "protected_attribute_names = ['AGE', 'GENDER']\n",
    "df['AGE'] = df['AGE'].map({\"20-29\": 0, \"30-39\": 1})\n",
    "df['GENDER'] = df['GENDER'].map({\"F\": 0, \"M\": 1})\n",
    "emotion_labels = [\n",
    "    'Frustrated or Impatient', 'Tensed or Annoyed', 'Distressed or Defiant', \n",
    "    'Confident or Attentive', 'Passionate or Amused', 'Pleased or Glad', 'Delighted or Happy', \n",
    "    'Worried or Apathetic', 'Frustrated or Discontented', 'Aroused or Astonished', 'Miserable or Sad', \n",
    "    'Anxious or Dejected', 'Tired or Bored', 'Polite or Sleepy', 'Excited or Adventurous'\n",
    "]\n",
    "label_to_num = {label: num for num, label in enumerate(emotion_labels)}\n",
    "print(\"Emotion Labels and Corresponding Encodings:\")\n",
    "print(label_to_num)\n",
    "df['Emotion'] = df['Emotion'].replace(label_to_num)\n",
    "emotion_type_map = {'Positive': 1, 'Negative': 0}\n",
    "df['Emotion_Type'] = df['Emotion_Type'].replace(emotion_type_map)\n",
    "# Drop missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442c8e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:26.779255Z",
     "iopub.status.busy": "2025-02-25T04:59:26.778957Z",
     "iopub.status.idle": "2025-02-25T04:59:26.782872Z",
     "shell.execute_reply": "2025-02-25T04:59:26.781800Z"
    },
    "papermill": {
     "duration": 0.029781,
     "end_time": "2025-02-25T04:59:26.784422",
     "exception": false,
     "start_time": "2025-02-25T04:59:26.754641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define label and protected attributes\n",
    "label_names = ['Emotion_Type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b5d3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:26.831397Z",
     "iopub.status.busy": "2025-02-25T04:59:26.831072Z",
     "iopub.status.idle": "2025-02-25T04:59:39.462454Z",
     "shell.execute_reply": "2025-02-25T04:59:39.461360Z"
    },
    "papermill": {
     "duration": 12.657262,
     "end_time": "2025-02-25T04:59:39.464188",
     "exception": false,
     "start_time": "2025-02-25T04:59:26.806926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef596cd3",
   "metadata": {
    "papermill": {
     "duration": 0.022115,
     "end_time": "2025-02-25T04:59:39.509229",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.487114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fair AI (AIF360) - Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466ac71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:39.555853Z",
     "iopub.status.busy": "2025-02-25T04:59:39.555217Z",
     "iopub.status.idle": "2025-02-25T04:59:39.723231Z",
     "shell.execute_reply": "2025-02-25T04:59:39.722141Z"
    },
    "papermill": {
     "duration": 0.193278,
     "end_time": "2025-02-25T04:59:39.724961",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.531683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, Flatten, Dense, MaxPooling1D, Dropout, BatchNormalization, GRU, SimpleRNN, LSTM, \n",
    "    SpatialDropout1D, LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, classification_report, \n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric, MDSSClassificationMetric\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing, CalibratedEqOddsPostprocessing, RejectOptionClassification\n",
    "\n",
    "positive_emotion_numbers = [0.0, 4.0, 5.0, 6.0, 7.0, 10.0, 14.0, 15.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e27e7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:39.772718Z",
     "iopub.status.busy": "2025-02-25T04:59:39.772087Z",
     "iopub.status.idle": "2025-02-25T04:59:39.785240Z",
     "shell.execute_reply": "2025-02-25T04:59:39.784294Z"
    },
    "papermill": {
     "duration": 0.038475,
     "end_time": "2025-02-25T04:59:39.786693",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.748218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_fairness_metrics_CM(original_dataset, classified_dataset, privileged_groups, unprivileged_groups, description):\n",
    "    global fairness_results\n",
    "    \n",
    "    metrics = ClassificationMetric(\n",
    "        original_dataset,\n",
    "        classified_dataset,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups\n",
    "    )\n",
    "    consistency_value = metrics.consistency()\n",
    "    if isinstance(consistency_value, (np.ndarray, list)):\n",
    "        consistency_value = np.mean(consistency_value)\n",
    "    \n",
    "    fairness_metrics = {\n",
    "        \"Description\": description,\n",
    "        \"Accuracy\": metrics.accuracy(),\n",
    "        \"Base Rate\": metrics.base_rate(),\n",
    "        \"Selection Rate\": metrics.selection_rate(),\n",
    "        \"Disparate Impact\": metrics.disparate_impact(),\n",
    "        \"Statistical Parity Difference\": metrics.statistical_parity_difference(),\n",
    "        \"Between Group Coefficient of Variation\": metrics.between_group_coefficient_of_variation(),\n",
    "        \"Between Group Generalized Entropy Index\": metrics.between_group_generalized_entropy_index(),\n",
    "        \"Between Group Theil Index\": metrics.between_group_theil_index(),\n",
    "        \"Mean Difference\": metrics.mean_difference(),\n",
    "        \"Smoothed Empirical Differential Fairness\": metrics.smoothed_empirical_differential_fairness(),\n",
    "        \"Consistency\": consistency_value,\n",
    "        \"Average Absolute Odds Difference\": metrics.average_abs_odds_difference(),\n",
    "        \"Average Odds Difference\": metrics.average_odds_difference(),\n",
    "        \"Average Predictive Value Difference\": metrics.average_predictive_value_difference(),\n",
    "        \"Between All Groups Coefficient of Variation\": metrics.between_all_groups_coefficient_of_variation(),\n",
    "        \"Between All Groups Generalized Entropy Index\": metrics.between_all_groups_generalized_entropy_index(),\n",
    "        \"Between All Groups Theil Index\": metrics.between_all_groups_theil_index(),\n",
    "        \"Coefficient of Variation\": metrics.coefficient_of_variation(),\n",
    "        \"Differential Fairness Bias Amplification\": metrics.differential_fairness_bias_amplification(),\n",
    "        \"Equal Opportunity Difference\": metrics.equal_opportunity_difference(),\n",
    "        \"Equalized Odds Difference\": metrics.equalized_odds_difference(),\n",
    "        \"Error Rate\": metrics.error_rate(),\n",
    "        \"Error Rate Difference\": metrics.error_rate_difference(),\n",
    "        \"Error Rate Ratio\": metrics.error_rate_ratio(),\n",
    "        \"False Discovery Rate\": metrics.false_discovery_rate(),\n",
    "        \"False Discovery Rate Difference\": metrics.false_discovery_rate_difference(),\n",
    "        \"False Discovery Rate Ratio\": metrics.false_discovery_rate_ratio(),\n",
    "        \"False Negative Rate\": metrics.false_negative_rate(),\n",
    "        \"False Negative Rate Difference\": metrics.false_negative_rate_difference(),\n",
    "        \"False Negative Rate Ratio\": metrics.false_negative_rate_ratio(),\n",
    "        \"False Omission Rate\": metrics.false_omission_rate(),\n",
    "        \"False Omission Rate Difference\": metrics.false_omission_rate_difference(),\n",
    "        \"False Omission Rate Ratio\": metrics.false_omission_rate_ratio(),\n",
    "        \"False Positive Rate\": metrics.false_positive_rate(),\n",
    "        \"False Positive Rate Difference\": metrics.false_positive_rate_difference(),\n",
    "        \"False Positive Rate Ratio\": metrics.false_positive_rate_ratio(),\n",
    "        \"Generalized Entropy Index\": metrics.generalized_entropy_index(),\n",
    "        \"Generalized Equalized Odds Difference\": metrics.generalized_equalized_odds_difference(),\n",
    "        \"Generalized False Negative Rate\": metrics.generalized_false_negative_rate(),\n",
    "        \"Generalized False Positive Rate\": metrics.generalized_false_positive_rate(),\n",
    "        \"Generalized True Negative Rate\": metrics.generalized_true_negative_rate(),\n",
    "        \"Generalized True Positive Rate\": metrics.generalized_true_positive_rate(),\n",
    "        \"Negative Predictive Value\": metrics.negative_predictive_value(),\n",
    "        \"Number of False Negatives\": metrics.num_false_negatives(),\n",
    "        \"Number of False Positives\": metrics.num_false_positives(),\n",
    "        \"Number of Generalized False Negatives\": metrics.num_generalized_false_negatives(),\n",
    "        \"Number of Generalized False Positives\": metrics.num_generalized_false_positives(),\n",
    "        \"Number of Generalized True Negatives\": metrics.num_generalized_true_negatives(),\n",
    "        \"Number of Generalized True Positives\": metrics.num_generalized_true_positives(),\n",
    "        \"Number of Instances\": metrics.num_instances(),\n",
    "        \"Number of Negatives\": metrics.num_negatives(),\n",
    "        \"Number of Positives\": metrics.num_positives(),\n",
    "        \"Number of Predicted Negatives\": metrics.num_pred_negatives(),\n",
    "        \"Number of Predicted Positives\": metrics.num_pred_positives(),\n",
    "        \"Number of True Negatives\": metrics.num_true_negatives(),\n",
    "        \"Number of True Positives\": metrics.num_true_positives(),\n",
    "        \"Positive Predictive Value\": metrics.positive_predictive_value(),\n",
    "        \"Power\": metrics.power(),\n",
    "        \"Precision\": metrics.precision(),\n",
    "        \"Recall\": metrics.recall(),\n",
    "        \"Selection Rate\": metrics.selection_rate(),\n",
    "        \"Sensitivity\": metrics.sensitivity(),\n",
    "        \"Specificity\": metrics.specificity(),\n",
    "        \"Theil Index\": metrics.theil_index(),\n",
    "        \"True Negative Rate\": metrics.true_negative_rate(),\n",
    "        \"True Positive Rate\": metrics.true_positive_rate(),\n",
    "        \"True Positive Rate Difference\": metrics.true_positive_rate_difference()\n",
    "    }\n",
    "    fairness_metrics_df = pd.DataFrame([fairness_metrics])\n",
    "    fairness_results = pd.concat([fairness_results, fairness_metrics_df], ignore_index=True)\n",
    "    \n",
    "    for key, value in fairness_metrics.items():\n",
    "        if key != \"Description\":\n",
    "            if isinstance(value, (np.ndarray, list)):\n",
    "                value = np.mean(value)\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5029c9f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:39.832967Z",
     "iopub.status.busy": "2025-02-25T04:59:39.832602Z",
     "iopub.status.idle": "2025-02-25T04:59:39.843285Z",
     "shell.execute_reply": "2025-02-25T04:59:39.842424Z"
    },
    "papermill": {
     "duration": 0.035296,
     "end_time": "2025-02-25T04:59:39.844898",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.809602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_fairness_metrics_MDSSCM(original_dataset, classified_dataset, privileged_groups, unprivileged_groups, description):\n",
    "    global fairness_results\n",
    "    \n",
    "    metrics = ClassificationMetric(\n",
    "        original_dataset,\n",
    "        classified_dataset,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups\n",
    "    )\n",
    "    consistency_value = metrics.consistency()\n",
    "    if isinstance(consistency_value, (np.ndarray, list)):\n",
    "        consistency_value = np.mean(consistency_value)\n",
    "    \n",
    "    fairness_metrics = {\n",
    "        \"Description\": description,\n",
    "        \"Accuracy\": metrics.accuracy(),\n",
    "        \"Base Rate\": metrics.base_rate(),\n",
    "        \"Selection Rate\": metrics.selection_rate(),\n",
    "        \"Disparate Impact\": metrics.disparate_impact(),\n",
    "        \"Statistical Parity Difference\": metrics.statistical_parity_difference(),\n",
    "        \"Between Group Coefficient of Variation\": metrics.between_group_coefficient_of_variation(),\n",
    "        \"Between Group Generalized Entropy Index\": metrics.between_group_generalized_entropy_index(),\n",
    "        \"Between Group Theil Index\": metrics.between_group_theil_index(),\n",
    "        \"Mean Difference\": metrics.mean_difference(),\n",
    "        \"Smoothed Empirical Differential Fairness\": metrics.smoothed_empirical_differential_fairness(),\n",
    "        \"Consistency\": consistency_value,\n",
    "        \"Average Absolute Odds Difference\": metrics.average_abs_odds_difference(),\n",
    "        \"Average Odds Difference\": metrics.average_odds_difference(),\n",
    "        \"Average Predictive Value Difference\": metrics.average_predictive_value_difference(),\n",
    "        \"Between All Groups Coefficient of Variation\": metrics.between_all_groups_coefficient_of_variation(),\n",
    "        \"Between All Groups Generalized Entropy Index\": metrics.between_all_groups_generalized_entropy_index(),\n",
    "        \"Between All Groups Theil Index\": metrics.between_all_groups_theil_index(),\n",
    "        \"Coefficient of Variation\": metrics.coefficient_of_variation(),\n",
    "        \"Differential Fairness Bias Amplification\": metrics.differential_fairness_bias_amplification(),\n",
    "        \"Equal Opportunity Difference\": metrics.equal_opportunity_difference(),\n",
    "        \"Equalized Odds Difference\": metrics.equalized_odds_difference(),\n",
    "        \"Error Rate\": metrics.error_rate(),\n",
    "        \"Error Rate Difference\": metrics.error_rate_difference(),\n",
    "        \"Error Rate Ratio\": metrics.error_rate_ratio(),\n",
    "        \"False Discovery Rate\": metrics.false_discovery_rate(),\n",
    "        \"False Discovery Rate Difference\": metrics.false_discovery_rate_difference(),\n",
    "        \"False Discovery Rate Ratio\": metrics.false_discovery_rate_ratio(),\n",
    "        \"False Negative Rate\": metrics.false_negative_rate(),\n",
    "        \"False Negative Rate Difference\": metrics.false_negative_rate_difference(),\n",
    "        \"False Negative Rate Ratio\": metrics.false_negative_rate_ratio(),\n",
    "        \"False Omission Rate\": metrics.false_omission_rate(),\n",
    "        \"False Omission Rate Difference\": metrics.false_omission_rate_difference(),\n",
    "        \"False Omission Rate Ratio\": metrics.false_omission_rate_ratio(),\n",
    "        \"False Positive Rate\": metrics.false_positive_rate(),\n",
    "        \"False Positive Rate Difference\": metrics.false_positive_rate_difference(),\n",
    "        \"False Positive Rate Ratio\": metrics.false_positive_rate_ratio(),\n",
    "        \"Generalized Entropy Index\": metrics.generalized_entropy_index(),\n",
    "        \"Generalized Equalized Odds Difference\": metrics.generalized_equalized_odds_difference(),\n",
    "        \"Generalized False Negative Rate\": metrics.generalized_false_negative_rate(),\n",
    "        \"Generalized False Positive Rate\": metrics.generalized_false_positive_rate(),\n",
    "        \"Generalized True Negative Rate\": metrics.generalized_true_negative_rate(),\n",
    "        \"Generalized True Positive Rate\": metrics.generalized_true_positive_rate(),\n",
    "        \"Negative Predictive Value\": metrics.negative_predictive_value(),\n",
    "        \"Number of False Negatives\": metrics.num_false_negatives(),\n",
    "        \"Number of False Positives\": metrics.num_false_positives(),\n",
    "        \"Number of Generalized False Negatives\": metrics.num_generalized_false_negatives(),\n",
    "        \"Number of Generalized False Positives\": metrics.num_generalized_false_positives(),\n",
    "        \"Number of Generalized True Negatives\": metrics.num_generalized_true_negatives(),\n",
    "        \"Number of Generalized True Positives\": metrics.num_generalized_true_positives(),\n",
    "        \"Number of Instances\": metrics.num_instances(),\n",
    "        \"Number of Negatives\": metrics.num_negatives(),\n",
    "        \"Number of Positives\": metrics.num_positives(),\n",
    "        \"Number of Predicted Negatives\": metrics.num_pred_negatives(),\n",
    "        \"Number of Predicted Positives\": metrics.num_pred_positives(),\n",
    "        \"Number of True Negatives\": metrics.num_true_negatives(),\n",
    "        \"Number of True Positives\": metrics.num_true_positives(),\n",
    "        \"Positive Predictive Value\": metrics.positive_predictive_value(),\n",
    "        \"Power\": metrics.power(),\n",
    "        \"Precision\": metrics.precision(),\n",
    "        \"Recall\": metrics.recall(),\n",
    "        \"Selection Rate\": metrics.selection_rate(),\n",
    "        \"Sensitivity\": metrics.sensitivity(),\n",
    "        \"Specificity\": metrics.specificity(),\n",
    "        \"Theil Index\": metrics.theil_index(),\n",
    "        \"True Negative Rate\": metrics.true_negative_rate(),\n",
    "        \"True Positive Rate\": metrics.true_positive_rate(),\n",
    "        \"True Positive Rate Difference\": metrics.true_positive_rate_difference()\n",
    "    }\n",
    "    fairness_metrics_df = pd.DataFrame([fairness_metrics])\n",
    "    fairness_results = pd.concat([fairness_results, fairness_metrics_df], ignore_index=True)\n",
    "    \n",
    "    for key, value in fairness_metrics.items():\n",
    "        if key != \"Description\":\n",
    "            if isinstance(value, (np.ndarray, list)):\n",
    "                value = np.mean(value)\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29bb3a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:39.890693Z",
     "iopub.status.busy": "2025-02-25T04:59:39.890373Z",
     "iopub.status.idle": "2025-02-25T04:59:39.900858Z",
     "shell.execute_reply": "2025-02-25T04:59:39.900029Z"
    },
    "papermill": {
     "duration": 0.035181,
     "end_time": "2025-02-25T04:59:39.902280",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.867099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "protected_attribute_configs = [\n",
    "    {\n",
    "        \"desc\" : \"GENDER Mitigation\",\n",
    "        \"protected_attribute_names\": [\"GENDER\"],\n",
    "        \"privileged_protected_attributes\": [{\"GENDER\": 0}],\n",
    "        \"unprivileged_protected_attributes\": [{\"GENDER\": 1}],\n",
    "        \"sensitive_attribute\": \"GENDER\"\n",
    "    },\n",
    "    {\n",
    "        \"desc\" : \"AGE Mitigation\",\n",
    "        \"protected_attribute_names\": [\"AGE\"],\n",
    "        \"privileged_protected_attributes\": [{\"AGE\": 0}],\n",
    "        \"unprivileged_protected_attributes\": [{\"AGE\": 1}],\n",
    "        \"sensitive_attribute\": \"AGE\"\n",
    "    },\n",
    "    {\n",
    "        \n",
    "        \"desc\" : \"AGE&GENDER Mitigation\",\n",
    "        \"protected_attribute_names\": [\"GENDER\", \"AGE\"],\n",
    "        \"privileged_protected_attributes\": [{\"GENDER\": 0, \"AGE\": 0}],\n",
    "        \"unprivileged_protected_attributes\": [{\"GENDER\": 1, \"AGE\": 1}],\n",
    "        \"sensitive_attribute\": \"AGE\"\n",
    "    }\n",
    "]\n",
    "\n",
    "fairness_results = pd.DataFrame({\n",
    "    \"Description\": [\"Ideal Values\"],  # Start with the Ideal Values row\n",
    "    \"Accuracy\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Base Rate\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Selection Rate\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Disparate Impact\": [1.0],  # Ideal value\n",
    "    \"Statistical Parity Difference\": [0.0],  # Ideal value\n",
    "    \"Between Group Coefficient of Variation\": [0.0],  # Ideal value\n",
    "    \"Between Group Generalized Entropy Index\": [0.0],  # Ideal value\n",
    "    \"Between Group Theil Index\": [0.0],  # Ideal value\n",
    "    \"Mean Difference\": [0.0],  # Ideal value\n",
    "    \"Smoothed Empirical Differential Fairness\": [0.0],  # Ideal value\n",
    "    \"Consistency\": [1.0],  # Ideal value\n",
    "    \"Average Absolute Odds Difference\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Average Odds Difference\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Average Predictive Value Difference\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Between All Groups Coefficient of Variation\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Between All Groups Generalized Entropy Index\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Between All Groups Theil Index\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Coefficient of Variation\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Differential Fairness Bias Amplification\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Equal Opportunity Difference\": [0.0],  # Ideal value\n",
    "    \"Equalized Odds Difference\": [0.0],  # Ideal value\n",
    "    \"Error Rate\": [0.0],  # Ideal value\n",
    "    \"Error Rate Difference\": [0.0],  # Ideal value\n",
    "    \"Error Rate Ratio\": [1.0],  # Ideal value\n",
    "    \"False Discovery Rate\": [0.0],  # Ideal value\n",
    "    \"False Discovery Rate Difference\": [0.0],  # Ideal value\n",
    "    \"False Discovery Rate Ratio\": [1.0],  # Ideal value\n",
    "    \"False Negative Rate\": [0.0],  # Ideal value\n",
    "    \"False Negative Rate Difference\": [0.0],  # Ideal value\n",
    "    \"False Negative Rate Ratio\": [1.0],  # Ideal value\n",
    "    \"False Omission Rate\": [0.0],  # Ideal value\n",
    "    \"False Omission Rate Difference\": [0.0],  # Ideal value\n",
    "    \"False Omission Rate Ratio\": [1.0],  # Ideal value\n",
    "    \"False Positive Rate\": [0.0],  # Ideal value\n",
    "    \"False Positive Rate Difference\": [0.0],  # Ideal value\n",
    "    \"False Positive Rate Ratio\": [1.0],  # Ideal value\n",
    "    \"Generalized Entropy Index\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Generalized Equalized Odds Difference\": [0.0],  # Ideal value\n",
    "    \"Generalized False Negative Rate\": [0.0],  # Ideal value\n",
    "    \"Generalized False Positive Rate\": [0.0],  # Ideal value\n",
    "    \"Generalized True Negative Rate\": [1.0],  # Ideal value\n",
    "    \"Generalized True Positive Rate\": [1.0],  # Ideal value\n",
    "    \"Negative Predictive Value\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of False Negatives\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of False Positives\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of Generalized False Negatives\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of Generalized False Positives\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of Generalized True Negatives\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of Generalized True Positives\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Number of Instances\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Number of Negatives\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Number of Positives\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Number of Predicted Negatives\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Number of Predicted Positives\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Number of True Negatives\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Number of True Positives\": 'N/A',  # Ideal value (depends on context)\n",
    "    \"Positive Predictive Value\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Power\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Precision\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Recall\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Selection Rate\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Sensitivity\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Specificity\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"Theil Index\": 'N/A',  # Ideal value (context-dependent)\n",
    "    \"True Negative Rate\": [1.0],  # Ideal value\n",
    "    \"True Positive Rate\": [1.0],  # Ideal value\n",
    "    \"True Positive Rate Difference\": [0.0]  # Ideal value\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54cf5364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:39.948840Z",
     "iopub.status.busy": "2025-02-25T04:59:39.948527Z",
     "iopub.status.idle": "2025-02-25T04:59:39.967485Z",
     "shell.execute_reply": "2025-02-25T04:59:39.966663Z"
    },
    "papermill": {
     "duration": 0.044448,
     "end_time": "2025-02-25T04:59:39.969059",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.924611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Base Rate</th>\n",
       "      <th>Selection Rate</th>\n",
       "      <th>Disparate Impact</th>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <th>Between Group Coefficient of Variation</th>\n",
       "      <th>Between Group Generalized Entropy Index</th>\n",
       "      <th>Between Group Theil Index</th>\n",
       "      <th>Mean Difference</th>\n",
       "      <th>...</th>\n",
       "      <th>Positive Predictive Value</th>\n",
       "      <th>Power</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>True Positive Rate</th>\n",
       "      <th>True Positive Rate Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ideal Values</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Description Accuracy Base Rate Selection Rate  Disparate Impact  \\\n",
       "0  Ideal Values      N/A       N/A            N/A               1.0   \n",
       "\n",
       "   Statistical Parity Difference  Between Group Coefficient of Variation  \\\n",
       "0                            0.0                                     0.0   \n",
       "\n",
       "   Between Group Generalized Entropy Index  Between Group Theil Index  \\\n",
       "0                                      0.0                        0.0   \n",
       "\n",
       "   Mean Difference  ...  Positive Predictive Value  Power Precision Recall  \\\n",
       "0              0.0  ...                        N/A    N/A       N/A    N/A   \n",
       "\n",
       "  Sensitivity Specificity Theil Index True Negative Rate True Positive Rate  \\\n",
       "0         N/A         N/A         N/A                1.0                1.0   \n",
       "\n",
       "  True Positive Rate Difference  \n",
       "0                           0.0  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6bb0f",
   "metadata": {
    "papermill": {
     "duration": 0.021964,
     "end_time": "2025-02-25T04:59:40.014433",
     "exception": false,
     "start_time": "2025-02-25T04:59:39.992469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f6d8ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:59:40.061964Z",
     "iopub.status.busy": "2025-02-25T04:59:40.061596Z",
     "iopub.status.idle": "2025-02-25T05:21:18.458858Z",
     "shell.execute_reply": "2025-02-25T05:21:18.457841Z"
    },
    "papermill": {
     "duration": 1298.422146,
     "end_time": "2025-02-25T05:21:18.460449",
     "exception": false,
     "start_time": "2025-02-25T04:59:40.038303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.4655 - loss: 1.4821 - val_accuracy: 0.7569 - val_loss: 0.6382 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7422 - loss: 0.6840 - val_accuracy: 0.7771 - val_loss: 0.5828 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7926 - loss: 0.5535 - val_accuracy: 0.8287 - val_loss: 0.4438 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.4790 - val_accuracy: 0.8481 - val_loss: 0.3950 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8407 - loss: 0.4249 - val_accuracy: 0.8832 - val_loss: 0.3238 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8586 - loss: 0.3730 - val_accuracy: 0.8808 - val_loss: 0.3188 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.3482 - val_accuracy: 0.8819 - val_loss: 0.2952 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8753 - loss: 0.3291 - val_accuracy: 0.8809 - val_loss: 0.3003 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8814 - loss: 0.3112 - val_accuracy: 0.8652 - val_loss: 0.3490 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8857 - loss: 0.2970 - val_accuracy: 0.8966 - val_loss: 0.2599 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8891 - loss: 0.2895 - val_accuracy: 0.8927 - val_loss: 0.2642 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.2830 - val_accuracy: 0.9016 - val_loss: 0.2514 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8914 - loss: 0.2757 - val_accuracy: 0.8996 - val_loss: 0.2544 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8934 - loss: 0.2747 - val_accuracy: 0.8899 - val_loss: 0.2700 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8991 - loss: 0.2609 - val_accuracy: 0.8913 - val_loss: 0.2483 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.2512 - val_accuracy: 0.9065 - val_loss: 0.2350 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9031 - loss: 0.2482 - val_accuracy: 0.9072 - val_loss: 0.2258 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2474 - val_accuracy: 0.9026 - val_loss: 0.2399 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9067 - loss: 0.2375 - val_accuracy: 0.9133 - val_loss: 0.2123 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.2379 - val_accuracy: 0.9132 - val_loss: 0.2191 - learning_rate: 9.2400e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 0.2318 - val_accuracy: 0.9137 - val_loss: 0.2104 - learning_rate: 9.2400e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2341 - val_accuracy: 0.9155 - val_loss: 0.2081 - learning_rate: 9.2400e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9090 - loss: 0.2301 - val_accuracy: 0.9094 - val_loss: 0.2254 - learning_rate: 9.2400e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2261 - val_accuracy: 0.9104 - val_loss: 0.2080 - learning_rate: 9.2400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2278 - val_accuracy: 0.9142 - val_loss: 0.2046 - learning_rate: 9.2400e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2194 - val_accuracy: 0.9072 - val_loss: 0.2294 - learning_rate: 9.2400e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2203 - val_accuracy: 0.9221 - val_loss: 0.1871 - learning_rate: 9.2400e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.2173 - val_accuracy: 0.9137 - val_loss: 0.2041 - learning_rate: 9.2400e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9143 - loss: 0.2159 - val_accuracy: 0.9204 - val_loss: 0.1941 - learning_rate: 9.2400e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9176 - loss: 0.2092 - val_accuracy: 0.9203 - val_loss: 0.1925 - learning_rate: 9.2400e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2123 - val_accuracy: 0.9154 - val_loss: 0.2111 - learning_rate: 9.2400e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2237/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2100\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.2100 - val_accuracy: 0.9171 - val_loss: 0.1969 - learning_rate: 9.2400e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.1763 - val_accuracy: 0.9264 - val_loss: 0.1775 - learning_rate: 4.6200e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.1684 - val_accuracy: 0.9292 - val_loss: 0.1683 - learning_rate: 4.6200e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.1692 - val_accuracy: 0.9320 - val_loss: 0.1708 - learning_rate: 4.6200e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9350 - loss: 0.1620 - val_accuracy: 0.9346 - val_loss: 0.1600 - learning_rate: 4.6200e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.1619 - val_accuracy: 0.9321 - val_loss: 0.1633 - learning_rate: 4.6200e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.1623 - val_accuracy: 0.9318 - val_loss: 0.1699 - learning_rate: 4.6200e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.1611 - val_accuracy: 0.9306 - val_loss: 0.1660 - learning_rate: 4.6200e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9341 - loss: 0.1644 - val_accuracy: 0.9295 - val_loss: 0.1723 - learning_rate: 4.6200e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1528\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1528 - val_accuracy: 0.9297 - val_loss: 0.1714 - learning_rate: 4.6200e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9431 - loss: 0.1409 - val_accuracy: 0.9401 - val_loss: 0.1431 - learning_rate: 2.3100e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9460 - loss: 0.1340 - val_accuracy: 0.9409 - val_loss: 0.1426 - learning_rate: 2.3100e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1331 - val_accuracy: 0.9407 - val_loss: 0.1472 - learning_rate: 2.3100e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1312 - val_accuracy: 0.9390 - val_loss: 0.1434 - learning_rate: 2.3100e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1336 - val_accuracy: 0.9430 - val_loss: 0.1393 - learning_rate: 2.3100e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.1313 - val_accuracy: 0.9421 - val_loss: 0.1410 - learning_rate: 2.3100e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.1301 - val_accuracy: 0.9402 - val_loss: 0.1417 - learning_rate: 2.3100e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.1282 - val_accuracy: 0.9443 - val_loss: 0.1367 - learning_rate: 2.3100e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.1263 - val_accuracy: 0.9467 - val_loss: 0.1340 - learning_rate: 2.3100e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.1295 - val_accuracy: 0.9439 - val_loss: 0.1389 - learning_rate: 2.3100e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9506 - loss: 0.1235 - val_accuracy: 0.9401 - val_loss: 0.1416 - learning_rate: 2.3100e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1248 - val_accuracy: 0.9411 - val_loss: 0.1424 - learning_rate: 2.3100e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.1259 - val_accuracy: 0.9450 - val_loss: 0.1383 - learning_rate: 2.3100e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2239/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9503 - loss: 0.1235\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9503 - loss: 0.1235 - val_accuracy: 0.9421 - val_loss: 0.1390 - learning_rate: 2.3100e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1126 - val_accuracy: 0.9472 - val_loss: 0.1309 - learning_rate: 1.1550e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.1125 - val_accuracy: 0.9461 - val_loss: 0.1312 - learning_rate: 1.1550e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.1121 - val_accuracy: 0.9503 - val_loss: 0.1278 - learning_rate: 1.1550e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.1108 - val_accuracy: 0.9461 - val_loss: 0.1330 - learning_rate: 1.1550e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.1096 - val_accuracy: 0.9492 - val_loss: 0.1278 - learning_rate: 1.1550e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9561 - loss: 0.1095 - val_accuracy: 0.9492 - val_loss: 0.1257 - learning_rate: 1.1550e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9562 - loss: 0.1074 - val_accuracy: 0.9506 - val_loss: 0.1255 - learning_rate: 1.1550e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1079 - val_accuracy: 0.9483 - val_loss: 0.1274 - learning_rate: 1.1550e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.1064 - val_accuracy: 0.9504 - val_loss: 0.1267 - learning_rate: 1.1550e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9564 - loss: 0.1088 - val_accuracy: 0.9491 - val_loss: 0.1276 - learning_rate: 1.1550e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1059 - val_accuracy: 0.9491 - val_loss: 0.1285 - learning_rate: 1.1550e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2235/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.1054\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9575 - loss: 0.1054 - val_accuracy: 0.9497 - val_loss: 0.1299 - learning_rate: 1.1550e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1017 - val_accuracy: 0.9519 - val_loss: 0.1209 - learning_rate: 5.7750e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.0997 - val_accuracy: 0.9521 - val_loss: 0.1228 - learning_rate: 5.7750e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.0967 - val_accuracy: 0.9528 - val_loss: 0.1212 - learning_rate: 5.7750e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9618 - loss: 0.0961 - val_accuracy: 0.9523 - val_loss: 0.1235 - learning_rate: 5.7750e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.0972 - val_accuracy: 0.9528 - val_loss: 0.1244 - learning_rate: 5.7750e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2236/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.0997\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9592 - loss: 0.0997 - val_accuracy: 0.9519 - val_loss: 0.1218 - learning_rate: 5.7750e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.0969 - val_accuracy: 0.9542 - val_loss: 0.1184 - learning_rate: 2.8875e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.0966 - val_accuracy: 0.9543 - val_loss: 0.1186 - learning_rate: 2.8875e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.0918 - val_accuracy: 0.9547 - val_loss: 0.1180 - learning_rate: 2.8875e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9621 - loss: 0.0929 - val_accuracy: 0.9534 - val_loss: 0.1203 - learning_rate: 2.8875e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9614 - loss: 0.0964 - val_accuracy: 0.9543 - val_loss: 0.1204 - learning_rate: 2.8875e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.0922 - val_accuracy: 0.9545 - val_loss: 0.1193 - learning_rate: 2.8875e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.0903 - val_accuracy: 0.9537 - val_loss: 0.1206 - learning_rate: 2.8875e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2238/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.0954\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.4437499885389116e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.0954 - val_accuracy: 0.9556 - val_loss: 0.1184 - learning_rate: 2.8875e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.0889 - val_accuracy: 0.9550 - val_loss: 0.1181 - learning_rate: 1.4437e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9643 - loss: 0.0893 - val_accuracy: 0.9560 - val_loss: 0.1175 - learning_rate: 1.4437e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.0913 - val_accuracy: 0.9558 - val_loss: 0.1173 - learning_rate: 1.4437e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0917 - val_accuracy: 0.9552 - val_loss: 0.1175 - learning_rate: 1.4437e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9631 - loss: 0.0922 - val_accuracy: 0.9556 - val_loss: 0.1181 - learning_rate: 1.4437e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9617 - loss: 0.0935 - val_accuracy: 0.9552 - val_loss: 0.1173 - learning_rate: 1.4437e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0900 - val_accuracy: 0.9555 - val_loss: 0.1169 - learning_rate: 1.4437e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9632 - loss: 0.0911 - val_accuracy: 0.9556 - val_loss: 0.1174 - learning_rate: 1.4437e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9631 - loss: 0.0927 - val_accuracy: 0.9556 - val_loss: 0.1170 - learning_rate: 1.4437e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.0883 - val_accuracy: 0.9554 - val_loss: 0.1177 - learning_rate: 1.4437e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9651 - loss: 0.0879 - val_accuracy: 0.9554 - val_loss: 0.1175 - learning_rate: 1.4437e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.0907 - val_accuracy: 0.9559 - val_loss: 0.1163 - learning_rate: 1.4437e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.0892 - val_accuracy: 0.9555 - val_loss: 0.1171 - learning_rate: 1.4437e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.0908 - val_accuracy: 0.9552 - val_loss: 0.1177 - learning_rate: 1.4437e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.0896 - val_accuracy: 0.9563 - val_loss: 0.1174 - learning_rate: 1.4437e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9632 - loss: 0.0920 - val_accuracy: 0.9571 - val_loss: 0.1169 - learning_rate: 1.4437e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.0904\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 7.218749942694558e-06.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.0904 - val_accuracy: 0.9556 - val_loss: 0.1174 - learning_rate: 1.4437e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9643 - loss: 0.0895 - val_accuracy: 0.9556 - val_loss: 0.1166 - learning_rate: 7.2187e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9646 - loss: 0.0888 - val_accuracy: 0.9556 - val_loss: 0.1172 - learning_rate: 7.2187e-06\n",
      "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy: 0.9555\n",
      "Precision: 0.9561\n",
      "Recall: 0.9555\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2402\n",
      "           1       0.90      0.91      0.91       722\n",
      "           2       0.97      0.96      0.96      1686\n",
      "           3       0.97      0.96      0.96      2795\n",
      "           4       0.97      0.96      0.96      2574\n",
      "           5       0.92      0.91      0.92       415\n",
      "           6       0.96      0.97      0.97       678\n",
      "           7       0.98      0.92      0.95      1027\n",
      "           8       0.79      0.85      0.82       424\n",
      "           9       0.96      0.99      0.97       474\n",
      "          10       0.96      1.00      0.98       411\n",
      "          11       0.99      1.00      1.00       441\n",
      "          12       0.91      0.99      0.95       469\n",
      "          13       0.95      1.00      0.98       412\n",
      "          14       1.00      1.00      1.00       442\n",
      "\n",
      "    accuracy                           0.96     15372\n",
      "   macro avg       0.95      0.96      0.95     15372\n",
      "weighted avg       0.96      0.96      0.96     15372\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "def build_gru_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Single GRU Layer with 128 units\n",
    "    model.add(GRU(128, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.000924)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load data\n",
    "X = df.drop(columns=['Emotion'])\n",
    "y = df['Emotion']\n",
    "\n",
    "# Splitting Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  \n",
    "\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build and train GRU model\n",
    "gru_model = build_gru_model(input_shape, num_classes)\n",
    "history = gru_model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=100, batch_size=32, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions on test data\n",
    "predictions = gru_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "pred_df = X_test.copy()\n",
    "pred_df['Emotion'] = predicted_labels\n",
    "pred_df['Emotion_Type'] = pred_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "y_pred = pred_df['Emotion'].values\n",
    "pred_df.drop(columns=['Emotion'], inplace=True)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = tf.math.confusion_matrix(y_test, predicted_labels).numpy()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- ROC CURVE FOR MULTI-CLASS TEST DATA ---\n",
    "n_classes = len(np.unique(y_test))  \n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], predictions[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve for Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02290e4",
   "metadata": {
    "papermill": {
     "duration": 1.330534,
     "end_time": "2025-02-25T05:21:21.072820",
     "exception": false,
     "start_time": "2025-02-25T05:21:19.742286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GRU - Preprocessing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0adf712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T05:21:23.764275Z",
     "iopub.status.busy": "2025-02-25T05:21:23.763800Z",
     "iopub.status.idle": "2025-02-25T07:31:06.652751Z",
     "shell.execute_reply": "2025-02-25T07:31:06.651771Z"
    },
    "papermill": {
     "duration": 7787.117797,
     "end_time": "2025-02-25T07:31:09.501205",
     "exception": false,
     "start_time": "2025-02-25T05:21:22.383408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected Attribute Names: ['GENDER']\n",
      "Privileged Protected Attributes: [{'GENDER': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1}]\n",
      "Sensitive Attribute: GENDER\n",
      "Description: GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.5137\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5110\n",
      "  Disparate Impact: 0.8015\n",
      "  Statistical Parity Difference: -0.1116\n",
      "  Between Group Coefficient of Variation: 0.1243\n",
      "  Between Group Generalized Entropy Index: 0.0077\n",
      "  Between Group Theil Index: 0.0078\n",
      "  Mean Difference: -0.1116\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1186\n",
      "  Average Odds Difference: -0.1186\n",
      "  Average Predictive Value Difference: 0.1435\n",
      "  Between All Groups Coefficient of Variation: 0.1243\n",
      "  Between All Groups Generalized Entropy Index: 0.0077\n",
      "  Between All Groups Theil Index: 0.0078\n",
      "  Coefficient of Variation: 0.6944\n",
      "  Differential Fairness Bias Amplification: -0.0595\n",
      "  Equal Opportunity Difference: -0.0935\n",
      "  Equalized Odds Difference: 0.1436\n",
      "  Error Rate: 0.4863\n",
      "  Error Rate Difference: -0.0232\n",
      "  Error Rate Ratio: 0.9533\n",
      "  False Discovery Rate: 0.4799\n",
      "  False Discovery Rate Difference: -0.1679\n",
      "  False Discovery Rate Ratio: 0.6935\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: 0.0935\n",
      "  False Negative Rate Ratio: 1.2194\n",
      "  False Omission Rate: 0.4929\n",
      "  False Omission Rate Difference: 0.1191\n",
      "  False Omission Rate Ratio: 1.2760\n",
      "  False Positive Rate: 0.4972\n",
      "  False Positive Rate Difference: -0.1436\n",
      "  False Positive Rate Ratio: 0.7403\n",
      "  Generalized Entropy Index: 0.2411\n",
      "  Generalized Equalized Odds Difference: 0.1436\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.4972\n",
      "  Generalized True Negative Rate: 0.5028\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.5071\n",
      "  Number of False Negatives: 3705.0000\n",
      "  Number of False Positives: 3770.0000\n",
      "  Number of Generalized False Negatives: 3705.0000\n",
      "  Number of Generalized False Positives: 3770.0000\n",
      "  Number of Generalized True Negatives: 3812.0000\n",
      "  Number of Generalized True Positives: 4085.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7517.0000\n",
      "  Number of Predicted Positives: 7855.0000\n",
      "  Number of True Negatives: 3812.0000\n",
      "  Number of True Positives: 4085.0000\n",
      "  Positive Predictive Value: 0.5201\n",
      "  Power: 4085.0000\n",
      "  Precision: 0.5201\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.5028\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5028\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: -0.0935\n",
      "  Accuracy: 0.5137\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5110\n",
      "  Disparate Impact: 0.8015\n",
      "  Statistical Parity Difference: -0.1116\n",
      "  Between Group Coefficient of Variation: 0.1243\n",
      "  Between Group Generalized Entropy Index: 0.0077\n",
      "  Between Group Theil Index: 0.0078\n",
      "  Mean Difference: -0.1116\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1186\n",
      "  Average Odds Difference: -0.1186\n",
      "  Average Predictive Value Difference: 0.1435\n",
      "  Between All Groups Coefficient of Variation: 0.1243\n",
      "  Between All Groups Generalized Entropy Index: 0.0077\n",
      "  Between All Groups Theil Index: 0.0078\n",
      "  Coefficient of Variation: 0.6944\n",
      "  Differential Fairness Bias Amplification: -0.0595\n",
      "  Equal Opportunity Difference: -0.0935\n",
      "  Equalized Odds Difference: 0.1436\n",
      "  Error Rate: 0.4863\n",
      "  Error Rate Difference: -0.0232\n",
      "  Error Rate Ratio: 0.9533\n",
      "  False Discovery Rate: 0.4799\n",
      "  False Discovery Rate Difference: -0.1679\n",
      "  False Discovery Rate Ratio: 0.6935\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: 0.0935\n",
      "  False Negative Rate Ratio: 1.2194\n",
      "  False Omission Rate: 0.4929\n",
      "  False Omission Rate Difference: 0.1191\n",
      "  False Omission Rate Ratio: 1.2760\n",
      "  False Positive Rate: 0.4972\n",
      "  False Positive Rate Difference: -0.1436\n",
      "  False Positive Rate Ratio: 0.7403\n",
      "  Generalized Entropy Index: 0.2411\n",
      "  Generalized Equalized Odds Difference: 0.1436\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.4972\n",
      "  Generalized True Negative Rate: 0.5028\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.5071\n",
      "  Number of False Negatives: 3705.0000\n",
      "  Number of False Positives: 3770.0000\n",
      "  Number of Generalized False Negatives: 3705.0000\n",
      "  Number of Generalized False Positives: 3770.0000\n",
      "  Number of Generalized True Negatives: 3812.0000\n",
      "  Number of Generalized True Positives: 4085.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7517.0000\n",
      "  Number of Predicted Positives: 7855.0000\n",
      "  Number of True Negatives: 3812.0000\n",
      "  Number of True Positives: 4085.0000\n",
      "  Positive Predictive Value: 0.5201\n",
      "  Power: 4085.0000\n",
      "  Precision: 0.5201\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.5028\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5028\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: -0.0935\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.3624 - loss: 1.9357 - val_accuracy: 0.7027 - val_loss: 0.8453 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.6631 - loss: 0.9509 - val_accuracy: 0.7440 - val_loss: 0.7056 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7322 - loss: 0.7447 - val_accuracy: 0.8036 - val_loss: 0.5374 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.6341 - val_accuracy: 0.8142 - val_loss: 0.4838 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7913 - loss: 0.5701 - val_accuracy: 0.8319 - val_loss: 0.4218 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.5116 - val_accuracy: 0.8378 - val_loss: 0.4069 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.4812 - val_accuracy: 0.8500 - val_loss: 0.3799 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.4519 - val_accuracy: 0.8521 - val_loss: 0.3628 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.4340 - val_accuracy: 0.8443 - val_loss: 0.3815 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.4106 - val_accuracy: 0.8603 - val_loss: 0.3547 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.4047 - val_accuracy: 0.8613 - val_loss: 0.3392 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.3925 - val_accuracy: 0.8611 - val_loss: 0.3453 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 0.3790 - val_accuracy: 0.8668 - val_loss: 0.3268 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 0.3695 - val_accuracy: 0.8740 - val_loss: 0.3007 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 0.3621 - val_accuracy: 0.8717 - val_loss: 0.3049 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8638 - loss: 0.3508 - val_accuracy: 0.8652 - val_loss: 0.3283 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.3532 - val_accuracy: 0.8753 - val_loss: 0.3137 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3437 - val_accuracy: 0.8601 - val_loss: 0.3297 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8708 - loss: 0.3343\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8708 - loss: 0.3343 - val_accuracy: 0.8702 - val_loss: 0.3232 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2925 - val_accuracy: 0.8968 - val_loss: 0.2501 - learning_rate: 4.6200e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.2793 - val_accuracy: 0.8910 - val_loss: 0.2574 - learning_rate: 4.6200e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.2760 - val_accuracy: 0.8997 - val_loss: 0.2446 - learning_rate: 4.6200e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.2712 - val_accuracy: 0.8948 - val_loss: 0.2640 - learning_rate: 4.6200e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.2744 - val_accuracy: 0.8990 - val_loss: 0.2419 - learning_rate: 4.6200e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.2723 - val_accuracy: 0.8931 - val_loss: 0.2523 - learning_rate: 4.6200e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.2683 - val_accuracy: 0.8945 - val_loss: 0.2680 - learning_rate: 4.6200e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8957 - loss: 0.2631 - val_accuracy: 0.9039 - val_loss: 0.2301 - learning_rate: 4.6200e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.2591 - val_accuracy: 0.9065 - val_loss: 0.2294 - learning_rate: 4.6200e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2558 - val_accuracy: 0.8984 - val_loss: 0.2494 - learning_rate: 4.6200e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8986 - loss: 0.2536 - val_accuracy: 0.9033 - val_loss: 0.2325 - learning_rate: 4.6200e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.2538 - val_accuracy: 0.9066 - val_loss: 0.2262 - learning_rate: 4.6200e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.2544 - val_accuracy: 0.9041 - val_loss: 0.2283 - learning_rate: 4.6200e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2471 - val_accuracy: 0.9029 - val_loss: 0.2358 - learning_rate: 4.6200e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.2472 - val_accuracy: 0.9054 - val_loss: 0.2379 - learning_rate: 4.6200e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.2467 - val_accuracy: 0.9053 - val_loss: 0.2285 - learning_rate: 4.6200e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.2478\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.2478 - val_accuracy: 0.9002 - val_loss: 0.2317 - learning_rate: 4.6200e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.2203 - val_accuracy: 0.9151 - val_loss: 0.2061 - learning_rate: 2.3100e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2129 - val_accuracy: 0.9183 - val_loss: 0.1980 - learning_rate: 2.3100e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2159 - val_accuracy: 0.9151 - val_loss: 0.2079 - learning_rate: 2.3100e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2111 - val_accuracy: 0.9158 - val_loss: 0.2031 - learning_rate: 2.3100e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2083 - val_accuracy: 0.9148 - val_loss: 0.2022 - learning_rate: 2.3100e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9158 - loss: 0.2097 - val_accuracy: 0.9156 - val_loss: 0.2011 - learning_rate: 2.3100e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9182 - loss: 0.2047 - val_accuracy: 0.9210 - val_loss: 0.1935 - learning_rate: 2.3100e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.1993 - val_accuracy: 0.9130 - val_loss: 0.2108 - learning_rate: 2.3100e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2006 - val_accuracy: 0.9156 - val_loss: 0.1981 - learning_rate: 2.3100e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2031 - val_accuracy: 0.9168 - val_loss: 0.2086 - learning_rate: 2.3100e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2033 - val_accuracy: 0.9198 - val_loss: 0.1964 - learning_rate: 2.3100e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.1963\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.1963 - val_accuracy: 0.9202 - val_loss: 0.1994 - learning_rate: 2.3100e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.1895 - val_accuracy: 0.9222 - val_loss: 0.1879 - learning_rate: 1.1550e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.1860 - val_accuracy: 0.9232 - val_loss: 0.1858 - learning_rate: 1.1550e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.1873 - val_accuracy: 0.9186 - val_loss: 0.1957 - learning_rate: 1.1550e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1797 - val_accuracy: 0.9226 - val_loss: 0.1849 - learning_rate: 1.1550e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.1794 - val_accuracy: 0.9251 - val_loss: 0.1819 - learning_rate: 1.1550e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.1796 - val_accuracy: 0.9254 - val_loss: 0.1820 - learning_rate: 1.1550e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9277 - loss: 0.1798 - val_accuracy: 0.9258 - val_loss: 0.1805 - learning_rate: 1.1550e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.1809 - val_accuracy: 0.9256 - val_loss: 0.1838 - learning_rate: 1.1550e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1777 - val_accuracy: 0.9270 - val_loss: 0.1825 - learning_rate: 1.1550e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9291 - loss: 0.1755 - val_accuracy: 0.9245 - val_loss: 0.1825 - learning_rate: 1.1550e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.1770 - val_accuracy: 0.9245 - val_loss: 0.1830 - learning_rate: 1.1550e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.1754 - val_accuracy: 0.9272 - val_loss: 0.1781 - learning_rate: 1.1550e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.1741 - val_accuracy: 0.9249 - val_loss: 0.1824 - learning_rate: 1.1550e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.1730 - val_accuracy: 0.9230 - val_loss: 0.1858 - learning_rate: 1.1550e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.1750 - val_accuracy: 0.9236 - val_loss: 0.1851 - learning_rate: 1.1550e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.1747 - val_accuracy: 0.9252 - val_loss: 0.1808 - learning_rate: 1.1550e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2558/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.1713\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.1713 - val_accuracy: 0.9254 - val_loss: 0.1809 - learning_rate: 1.1550e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9311 - loss: 0.1666 - val_accuracy: 0.9260 - val_loss: 0.1768 - learning_rate: 5.7750e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.1613 - val_accuracy: 0.9279 - val_loss: 0.1747 - learning_rate: 5.7750e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9346 - loss: 0.1620 - val_accuracy: 0.9288 - val_loss: 0.1736 - learning_rate: 5.7750e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1618 - val_accuracy: 0.9298 - val_loss: 0.1748 - learning_rate: 5.7750e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.1596 - val_accuracy: 0.9295 - val_loss: 0.1729 - learning_rate: 5.7750e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1614 - val_accuracy: 0.9289 - val_loss: 0.1748 - learning_rate: 5.7750e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9357 - loss: 0.1606 - val_accuracy: 0.9279 - val_loss: 0.1756 - learning_rate: 5.7750e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.1611 - val_accuracy: 0.9305 - val_loss: 0.1711 - learning_rate: 5.7750e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.1615 - val_accuracy: 0.9317 - val_loss: 0.1708 - learning_rate: 5.7750e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1616 - val_accuracy: 0.9301 - val_loss: 0.1713 - learning_rate: 5.7750e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.1569 - val_accuracy: 0.9306 - val_loss: 0.1720 - learning_rate: 5.7750e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.1600 - val_accuracy: 0.9267 - val_loss: 0.1795 - learning_rate: 5.7750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.1638 - val_accuracy: 0.9290 - val_loss: 0.1718 - learning_rate: 5.7750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.1586\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9358 - loss: 0.1586 - val_accuracy: 0.9287 - val_loss: 0.1710 - learning_rate: 5.7750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.1565 - val_accuracy: 0.9311 - val_loss: 0.1688 - learning_rate: 2.8875e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.1557 - val_accuracy: 0.9325 - val_loss: 0.1683 - learning_rate: 2.8875e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9373 - loss: 0.1568 - val_accuracy: 0.9303 - val_loss: 0.1705 - learning_rate: 2.8875e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1546 - val_accuracy: 0.9320 - val_loss: 0.1691 - learning_rate: 2.8875e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9389 - loss: 0.1533 - val_accuracy: 0.9325 - val_loss: 0.1687 - learning_rate: 2.8875e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.1521 - val_accuracy: 0.9306 - val_loss: 0.1701 - learning_rate: 2.8875e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.1508\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.4437499885389116e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.1508 - val_accuracy: 0.9304 - val_loss: 0.1708 - learning_rate: 2.8875e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.1521 - val_accuracy: 0.9312 - val_loss: 0.1673 - learning_rate: 1.4437e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.1481 - val_accuracy: 0.9312 - val_loss: 0.1666 - learning_rate: 1.4437e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.1501 - val_accuracy: 0.9320 - val_loss: 0.1671 - learning_rate: 1.4437e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9406 - loss: 0.1483 - val_accuracy: 0.9325 - val_loss: 0.1662 - learning_rate: 1.4437e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.1526 - val_accuracy: 0.9312 - val_loss: 0.1673 - learning_rate: 1.4437e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.1496 - val_accuracy: 0.9312 - val_loss: 0.1662 - learning_rate: 1.4437e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1489 - val_accuracy: 0.9334 - val_loss: 0.1670 - learning_rate: 1.4437e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9403 - loss: 0.1479 - val_accuracy: 0.9327 - val_loss: 0.1662 - learning_rate: 1.4437e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.1496\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 7.218749942694558e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.1496 - val_accuracy: 0.9327 - val_loss: 0.1664 - learning_rate: 1.4437e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1501 - val_accuracy: 0.9320 - val_loss: 0.1651 - learning_rate: 7.2187e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1479 - val_accuracy: 0.9332 - val_loss: 0.1656 - learning_rate: 7.2187e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1463 - val_accuracy: 0.9327 - val_loss: 0.1660 - learning_rate: 7.2187e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1479 - val_accuracy: 0.9326 - val_loss: 0.1656 - learning_rate: 7.2187e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1455 - val_accuracy: 0.9333 - val_loss: 0.1656 - learning_rate: 7.2187e-06\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.3614 - loss: 1.9203 - val_accuracy: 0.6535 - val_loss: 0.9497 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.6416 - loss: 0.9955 - val_accuracy: 0.7401 - val_loss: 0.7094 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7116 - loss: 0.7920 - val_accuracy: 0.7880 - val_loss: 0.5760 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7559 - loss: 0.6722 - val_accuracy: 0.7775 - val_loss: 0.5652 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.5808 - val_accuracy: 0.8314 - val_loss: 0.4467 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.5313 - val_accuracy: 0.8445 - val_loss: 0.4202 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.4847 - val_accuracy: 0.8455 - val_loss: 0.3910 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.4702 - val_accuracy: 0.8551 - val_loss: 0.3742 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.4417 - val_accuracy: 0.8609 - val_loss: 0.3518 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.4230 - val_accuracy: 0.8570 - val_loss: 0.3770 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.4073 - val_accuracy: 0.8581 - val_loss: 0.3565 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.3937 - val_accuracy: 0.8502 - val_loss: 0.4039 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.3830 - val_accuracy: 0.8630 - val_loss: 0.3426 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.3678 - val_accuracy: 0.8615 - val_loss: 0.3281 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.3573 - val_accuracy: 0.8816 - val_loss: 0.3074 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3447 - val_accuracy: 0.8722 - val_loss: 0.3153 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8669 - loss: 0.3469 - val_accuracy: 0.8486 - val_loss: 0.3934 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.3459 - val_accuracy: 0.8706 - val_loss: 0.3356 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8728 - loss: 0.3301 - val_accuracy: 0.8770 - val_loss: 0.3085 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8734 - loss: 0.3278 - val_accuracy: 0.8854 - val_loss: 0.2912 - learning_rate: 9.2400e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3197 - val_accuracy: 0.8882 - val_loss: 0.2964 - learning_rate: 9.2400e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8785 - loss: 0.3200 - val_accuracy: 0.8755 - val_loss: 0.3064 - learning_rate: 9.2400e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.3159 - val_accuracy: 0.8926 - val_loss: 0.2651 - learning_rate: 9.2400e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8813 - loss: 0.3095 - val_accuracy: 0.8926 - val_loss: 0.2708 - learning_rate: 9.2400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3061 - val_accuracy: 0.8952 - val_loss: 0.2613 - learning_rate: 9.2400e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.3060 - val_accuracy: 0.8693 - val_loss: 0.3447 - learning_rate: 9.2400e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8831 - loss: 0.3059 - val_accuracy: 0.8930 - val_loss: 0.2645 - learning_rate: 9.2400e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.2964 - val_accuracy: 0.8640 - val_loss: 0.3207 - learning_rate: 9.2400e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.2990 - val_accuracy: 0.8845 - val_loss: 0.2843 - learning_rate: 9.2400e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8862 - loss: 0.2947 - val_accuracy: 0.8981 - val_loss: 0.2517 - learning_rate: 9.2400e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.2812 - val_accuracy: 0.8972 - val_loss: 0.2561 - learning_rate: 9.2400e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8862 - loss: 0.2915 - val_accuracy: 0.9072 - val_loss: 0.2364 - learning_rate: 9.2400e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.2821 - val_accuracy: 0.8775 - val_loss: 0.3327 - learning_rate: 9.2400e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8923 - loss: 0.2780 - val_accuracy: 0.8826 - val_loss: 0.2923 - learning_rate: 9.2400e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.2788 - val_accuracy: 0.8954 - val_loss: 0.2605 - learning_rate: 9.2400e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.2711 - val_accuracy: 0.8986 - val_loss: 0.2553 - learning_rate: 9.2400e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.2725\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.2725 - val_accuracy: 0.8980 - val_loss: 0.2539 - learning_rate: 9.2400e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2292 - val_accuracy: 0.9097 - val_loss: 0.2230 - learning_rate: 4.6200e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9106 - loss: 0.2278 - val_accuracy: 0.9140 - val_loss: 0.2151 - learning_rate: 4.6200e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2160 - val_accuracy: 0.9137 - val_loss: 0.2080 - learning_rate: 4.6200e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2170 - val_accuracy: 0.9207 - val_loss: 0.2035 - learning_rate: 4.6200e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 0.2121 - val_accuracy: 0.9230 - val_loss: 0.1987 - learning_rate: 4.6200e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2145 - val_accuracy: 0.9154 - val_loss: 0.2085 - learning_rate: 4.6200e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2109 - val_accuracy: 0.9124 - val_loss: 0.2188 - learning_rate: 4.6200e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9173 - loss: 0.2030 - val_accuracy: 0.9021 - val_loss: 0.2567 - learning_rate: 4.6200e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2064 - val_accuracy: 0.9121 - val_loss: 0.2181 - learning_rate: 4.6200e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2045 - val_accuracy: 0.9204 - val_loss: 0.1969 - learning_rate: 4.6200e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.2068 - val_accuracy: 0.9177 - val_loss: 0.2015 - learning_rate: 4.6200e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2061 - val_accuracy: 0.9189 - val_loss: 0.2065 - learning_rate: 4.6200e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9207 - loss: 0.2001 - val_accuracy: 0.9178 - val_loss: 0.2009 - learning_rate: 4.6200e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.2045 - val_accuracy: 0.9222 - val_loss: 0.2022 - learning_rate: 4.6200e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2024\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2024 - val_accuracy: 0.9203 - val_loss: 0.1988 - learning_rate: 4.6200e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.1791 - val_accuracy: 0.9215 - val_loss: 0.2013 - learning_rate: 2.3100e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.1756 - val_accuracy: 0.9270 - val_loss: 0.1818 - learning_rate: 2.3100e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.1752 - val_accuracy: 0.9284 - val_loss: 0.1800 - learning_rate: 2.3100e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.1701 - val_accuracy: 0.9274 - val_loss: 0.1768 - learning_rate: 2.3100e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.1697 - val_accuracy: 0.9308 - val_loss: 0.1754 - learning_rate: 2.3100e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.1678 - val_accuracy: 0.9300 - val_loss: 0.1742 - learning_rate: 2.3100e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9329 - loss: 0.1694 - val_accuracy: 0.9331 - val_loss: 0.1725 - learning_rate: 2.3100e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.1645 - val_accuracy: 0.9321 - val_loss: 0.1752 - learning_rate: 2.3100e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.1649 - val_accuracy: 0.9353 - val_loss: 0.1668 - learning_rate: 2.3100e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.1632 - val_accuracy: 0.9325 - val_loss: 0.1705 - learning_rate: 2.3100e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.1615 - val_accuracy: 0.9355 - val_loss: 0.1696 - learning_rate: 2.3100e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.1635 - val_accuracy: 0.9319 - val_loss: 0.1713 - learning_rate: 2.3100e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.1652 - val_accuracy: 0.9361 - val_loss: 0.1684 - learning_rate: 2.3100e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9350 - loss: 0.1640\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9350 - loss: 0.1640 - val_accuracy: 0.9318 - val_loss: 0.1737 - learning_rate: 2.3100e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.1491 - val_accuracy: 0.9385 - val_loss: 0.1576 - learning_rate: 1.1550e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1480 - val_accuracy: 0.9390 - val_loss: 0.1612 - learning_rate: 1.1550e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9403 - loss: 0.1466 - val_accuracy: 0.9411 - val_loss: 0.1576 - learning_rate: 1.1550e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.1451 - val_accuracy: 0.9407 - val_loss: 0.1591 - learning_rate: 1.1550e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1444 - val_accuracy: 0.9406 - val_loss: 0.1565 - learning_rate: 1.1550e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1428 - val_accuracy: 0.9411 - val_loss: 0.1574 - learning_rate: 1.1550e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.1420 - val_accuracy: 0.9410 - val_loss: 0.1573 - learning_rate: 1.1550e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9411 - loss: 0.1450 - val_accuracy: 0.9402 - val_loss: 0.1598 - learning_rate: 1.1550e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.1405 - val_accuracy: 0.9388 - val_loss: 0.1616 - learning_rate: 1.1550e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.1436\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9410 - loss: 0.1436 - val_accuracy: 0.9380 - val_loss: 0.1610 - learning_rate: 1.1550e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1339 - val_accuracy: 0.9409 - val_loss: 0.1546 - learning_rate: 5.7750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1351 - val_accuracy: 0.9439 - val_loss: 0.1526 - learning_rate: 5.7750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9468 - loss: 0.1308 - val_accuracy: 0.9436 - val_loss: 0.1534 - learning_rate: 5.7750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.1315 - val_accuracy: 0.9414 - val_loss: 0.1549 - learning_rate: 5.7750e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1305 - val_accuracy: 0.9435 - val_loss: 0.1518 - learning_rate: 5.7750e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9474 - loss: 0.1318 - val_accuracy: 0.9434 - val_loss: 0.1500 - learning_rate: 5.7750e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.1300 - val_accuracy: 0.9451 - val_loss: 0.1517 - learning_rate: 5.7750e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1308 - val_accuracy: 0.9432 - val_loss: 0.1517 - learning_rate: 5.7750e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.1299 - val_accuracy: 0.9440 - val_loss: 0.1543 - learning_rate: 5.7750e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1279 - val_accuracy: 0.9433 - val_loss: 0.1524 - learning_rate: 5.7750e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2552/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1312\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1312 - val_accuracy: 0.9435 - val_loss: 0.1530 - learning_rate: 5.7750e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.1261 - val_accuracy: 0.9456 - val_loss: 0.1486 - learning_rate: 2.8875e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.1236 - val_accuracy: 0.9453 - val_loss: 0.1490 - learning_rate: 2.8875e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1266 - val_accuracy: 0.9458 - val_loss: 0.1505 - learning_rate: 2.8875e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9505 - loss: 0.1221 - val_accuracy: 0.9470 - val_loss: 0.1502 - learning_rate: 2.8875e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.1254 - val_accuracy: 0.9465 - val_loss: 0.1471 - learning_rate: 2.8875e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9501 - loss: 0.1239 - val_accuracy: 0.9456 - val_loss: 0.1497 - learning_rate: 2.8875e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1225 - val_accuracy: 0.9466 - val_loss: 0.1478 - learning_rate: 2.8875e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1231 - val_accuracy: 0.9456 - val_loss: 0.1479 - learning_rate: 2.8875e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9499 - loss: 0.1227 - val_accuracy: 0.9479 - val_loss: 0.1474 - learning_rate: 2.8875e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2558/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1221\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.4437499885389116e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1221 - val_accuracy: 0.9457 - val_loss: 0.1482 - learning_rate: 2.8875e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.1224 - val_accuracy: 0.9475 - val_loss: 0.1466 - learning_rate: 1.4437e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1196 - val_accuracy: 0.9469 - val_loss: 0.1469 - learning_rate: 1.4437e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9504 - loss: 0.1239 - val_accuracy: 0.9469 - val_loss: 0.1468 - learning_rate: 1.4437e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "             ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "100269  0.753268  35.601801  27.140880  42.990728  25.452107   6.307113   \n",
      "54177   0.778693  36.477197  29.782416  30.659146  22.402436   7.000259   \n",
      "72314   1.036600  36.157688   8.626632  34.598679  26.970434  10.984250   \n",
      "35868   0.714620  36.390218  17.532840  32.494466  28.533071   6.097250   \n",
      "61221   0.938040  35.660040  15.348672  30.620434  23.222784   7.130857   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "38762   1.177088  33.736279  17.317280  33.923321  28.709299   6.795250   \n",
      "39255   0.678480  37.097290  14.702088  41.203505  27.110927   7.781000   \n",
      "18106   0.994070  37.189723  33.303168  44.760379  31.166822   7.123750   \n",
      "19754   0.530640  34.346477   9.320520  41.026998  28.526449   6.425750   \n",
      "69306   0.801840  36.802808   6.544968  32.556290  22.455020   7.000259   \n",
      "\n",
      "         emg_trap  emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "100269  20.490083  4.965156  0.0     1.0           0.0  \n",
      "54177    7.740000  5.488553  0.0     0.0           1.0  \n",
      "72314    7.863000  9.246732  0.0     0.0           1.0  \n",
      "35868    6.771139  5.152500  0.0     1.0           0.0  \n",
      "61221    6.097250  4.847041  0.0     0.0           1.0  \n",
      "...           ...       ...  ...     ...           ...  \n",
      "38762    6.576958  5.768500  0.0     1.0           0.0  \n",
      "39255    9.560985  5.358000  0.0     1.0           0.0  \n",
      "18106   10.026026  9.013000  0.0     1.0           0.0  \n",
      "19754    7.945067  7.206000  1.0     1.0           1.0  \n",
      "69306   10.820000  7.241739  0.0     0.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "             ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "100269  0.753268  35.601801  27.140880  42.990728  25.452107   6.307113   \n",
      "54177   0.778693  36.477197  29.782416  30.659146  22.402436   7.000259   \n",
      "72314   1.036600  36.157688   8.626632  34.598679  26.970434  10.984250   \n",
      "35868   0.714620  36.390218  17.532840  32.494466  28.533071   6.097250   \n",
      "61221   0.938040  35.660040  15.348672  30.620434  23.222784   7.130857   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "38762   1.177088  33.736279  17.317280  33.923321  28.709299   6.795250   \n",
      "39255   0.678480  37.097290  14.702088  41.203505  27.110927   7.781000   \n",
      "18106   0.994070  37.189723  33.303168  44.760379  31.166822   7.123750   \n",
      "19754   0.530640  34.346477   9.320520  41.026998  28.526449   6.425750   \n",
      "69306   0.801840  36.802808   6.544968  32.556290  22.455020   7.000259   \n",
      "\n",
      "         emg_trap  emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "100269  20.490083  4.965156  0.0     1.0           1.0  \n",
      "54177    7.740000  5.488553  0.0     0.0           0.0  \n",
      "72314    7.863000  9.246732  0.0     0.0           0.0  \n",
      "35868    6.771139  5.152500  0.0     1.0           1.0  \n",
      "61221    6.097250  4.847041  0.0     0.0           0.0  \n",
      "...           ...       ...  ...     ...           ...  \n",
      "38762    6.576958  5.768500  0.0     1.0           1.0  \n",
      "39255    9.560985  5.358000  0.0     1.0           1.0  \n",
      "18106   10.026026  9.013000  0.0     1.0           0.0  \n",
      "19754    7.945067  7.206000  1.0     1.0           0.0  \n",
      "69306   10.820000  7.241739  0.0     0.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5091\n",
      "  Base Rate: 0.5074\n",
      "  Selection Rate: 0.5102\n",
      "  Disparate Impact: 0.7847\n",
      "  Statistical Parity Difference: -0.1219\n",
      "  Between Group Coefficient of Variation: 0.1250\n",
      "  Between Group Generalized Entropy Index: 0.0078\n",
      "  Between Group Theil Index: 0.0079\n",
      "  Mean Difference: -0.1219\n",
      "  Smoothed Empirical Differential Fairness: 0.2677\n",
      "  Consistency: 0.9508\n",
      "  Average Absolute Odds Difference: 0.1269\n",
      "  Average Odds Difference: -0.1269\n",
      "  Average Predictive Value Difference: 0.1338\n",
      "  Between All Groups Coefficient of Variation: 0.1250\n",
      "  Between All Groups Generalized Entropy Index: 0.0078\n",
      "  Between All Groups Theil Index: 0.0079\n",
      "  Coefficient of Variation: 0.6987\n",
      "  Differential Fairness Bias Amplification: -0.0201\n",
      "  Equal Opportunity Difference: -0.1104\n",
      "  Equalized Odds Difference: 0.1434\n",
      "  Error Rate: 0.4909\n",
      "  Error Rate Difference: -0.0143\n",
      "  Error Rate Ratio: 0.9713\n",
      "  False Discovery Rate: 0.4838\n",
      "  False Discovery Rate Difference: -0.1500\n",
      "  False Discovery Rate Ratio: 0.7243\n",
      "  False Negative Rate: 0.4810\n",
      "  False Negative Rate Difference: 0.1104\n",
      "  False Negative Rate Ratio: 1.2609\n",
      "  False Omission Rate: 0.4983\n",
      "  False Omission Rate Difference: 0.1177\n",
      "  False Omission Rate Ratio: 1.2694\n",
      "  False Positive Rate: 0.5012\n",
      "  False Positive Rate Difference: -0.1434\n",
      "  False Positive Rate Ratio: 0.7428\n",
      "  Generalized Entropy Index: 0.2441\n",
      "  Generalized Equalized Odds Difference: 0.1434\n",
      "  Generalized False Negative Rate: 0.4810\n",
      "  Generalized False Positive Rate: 0.5012\n",
      "  Generalized True Negative Rate: 0.4988\n",
      "  Generalized True Positive Rate: 0.5190\n",
      "  Negative Predictive Value: 0.5017\n",
      "  Number of False Negatives: 2501.0000\n",
      "  Number of False Positives: 2530.0000\n",
      "  Number of Generalized False Negatives: 2501.0000\n",
      "  Number of Generalized False Positives: 2530.0000\n",
      "  Number of Generalized True Negatives: 2518.0000\n",
      "  Number of Generalized True Positives: 2699.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5048.0000\n",
      "  Number of Positives: 5200.0000\n",
      "  Number of Predicted Negatives: 5019.0000\n",
      "  Number of Predicted Positives: 5229.0000\n",
      "  Number of True Negatives: 2518.0000\n",
      "  Number of True Positives: 2699.0000\n",
      "  Positive Predictive Value: 0.5162\n",
      "  Power: 2699.0000\n",
      "  Precision: 0.5162\n",
      "  Recall: 0.5190\n",
      "  Sensitivity: 0.5190\n",
      "  Specificity: 0.4988\n",
      "  Theil Index: 0.3385\n",
      "  True Negative Rate: 0.4988\n",
      "  True Positive Rate: 0.5190\n",
      "  True Positive Rate Difference: -0.1104\n",
      "  Accuracy: 0.5091\n",
      "  Base Rate: 0.5074\n",
      "  Selection Rate: 0.5102\n",
      "  Disparate Impact: 0.7847\n",
      "  Statistical Parity Difference: -0.1219\n",
      "  Between Group Coefficient of Variation: 0.1250\n",
      "  Between Group Generalized Entropy Index: 0.0078\n",
      "  Between Group Theil Index: 0.0079\n",
      "  Mean Difference: -0.1219\n",
      "  Smoothed Empirical Differential Fairness: 0.2677\n",
      "  Consistency: 0.9508\n",
      "  Average Absolute Odds Difference: 0.1269\n",
      "  Average Odds Difference: -0.1269\n",
      "  Average Predictive Value Difference: 0.1338\n",
      "  Between All Groups Coefficient of Variation: 0.1250\n",
      "  Between All Groups Generalized Entropy Index: 0.0078\n",
      "  Between All Groups Theil Index: 0.0079\n",
      "  Coefficient of Variation: 0.6987\n",
      "  Differential Fairness Bias Amplification: -0.0201\n",
      "  Equal Opportunity Difference: -0.1104\n",
      "  Equalized Odds Difference: 0.1434\n",
      "  Error Rate: 0.4909\n",
      "  Error Rate Difference: -0.0143\n",
      "  Error Rate Ratio: 0.9713\n",
      "  False Discovery Rate: 0.4838\n",
      "  False Discovery Rate Difference: -0.1500\n",
      "  False Discovery Rate Ratio: 0.7243\n",
      "  False Negative Rate: 0.4810\n",
      "  False Negative Rate Difference: 0.1104\n",
      "  False Negative Rate Ratio: 1.2609\n",
      "  False Omission Rate: 0.4983\n",
      "  False Omission Rate Difference: 0.1177\n",
      "  False Omission Rate Ratio: 1.2694\n",
      "  False Positive Rate: 0.5012\n",
      "  False Positive Rate Difference: -0.1434\n",
      "  False Positive Rate Ratio: 0.7428\n",
      "  Generalized Entropy Index: 0.2441\n",
      "  Generalized Equalized Odds Difference: 0.1434\n",
      "  Generalized False Negative Rate: 0.4810\n",
      "  Generalized False Positive Rate: 0.5012\n",
      "  Generalized True Negative Rate: 0.4988\n",
      "  Generalized True Positive Rate: 0.5190\n",
      "  Negative Predictive Value: 0.5017\n",
      "  Number of False Negatives: 2501.0000\n",
      "  Number of False Positives: 2530.0000\n",
      "  Number of Generalized False Negatives: 2501.0000\n",
      "  Number of Generalized False Positives: 2530.0000\n",
      "  Number of Generalized True Negatives: 2518.0000\n",
      "  Number of Generalized True Positives: 2699.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5048.0000\n",
      "  Number of Positives: 5200.0000\n",
      "  Number of Predicted Negatives: 5019.0000\n",
      "  Number of Predicted Positives: 5229.0000\n",
      "  Number of True Negatives: 2518.0000\n",
      "  Number of True Positives: 2699.0000\n",
      "  Positive Predictive Value: 0.5162\n",
      "  Power: 2699.0000\n",
      "  Precision: 0.5162\n",
      "  Recall: 0.5190\n",
      "  Sensitivity: 0.5190\n",
      "  Specificity: 0.4988\n",
      "  Theil Index: 0.3385\n",
      "  True Negative Rate: 0.4988\n",
      "  True Positive Rate: 0.5190\n",
      "  True Positive Rate Difference: -0.1104\n",
      "  Accuracy: 0.5193\n",
      "  Base Rate: 0.5020\n",
      "  Selection Rate: 0.5183\n",
      "  Disparate Impact: 0.8336\n",
      "  Statistical Parity Difference: -0.0933\n",
      "  Between Group Coefficient of Variation: 0.1088\n",
      "  Between Group Generalized Entropy Index: 0.0059\n",
      "  Between Group Theil Index: 0.0060\n",
      "  Mean Difference: -0.0933\n",
      "  Smoothed Empirical Differential Fairness: 0.2630\n",
      "  Consistency: 0.9519\n",
      "  Average Absolute Odds Difference: 0.1001\n",
      "  Average Odds Difference: -0.1001\n",
      "  Average Predictive Value Difference: 0.1334\n",
      "  Between All Groups Coefficient of Variation: 0.1088\n",
      "  Between All Groups Generalized Entropy Index: 0.0059\n",
      "  Between All Groups Theil Index: 0.0060\n",
      "  Coefficient of Variation: 0.6819\n",
      "  Differential Fairness Bias Amplification: -0.0703\n",
      "  Equal Opportunity Difference: -0.0925\n",
      "  Equalized Odds Difference: 0.1077\n",
      "  Error Rate: 0.4807\n",
      "  Error Rate Difference: -0.0095\n",
      "  Error Rate Ratio: 0.9804\n",
      "  False Discovery Rate: 0.4795\n",
      "  False Discovery Rate Difference: -0.1405\n",
      "  False Discovery Rate Ratio: 0.7386\n",
      "  False Negative Rate: 0.4625\n",
      "  False Negative Rate Difference: 0.0925\n",
      "  False Negative Rate Ratio: 1.2232\n",
      "  False Omission Rate: 0.4820\n",
      "  False Omission Rate Difference: 0.1263\n",
      "  False Omission Rate Ratio: 1.3020\n",
      "  False Positive Rate: 0.4990\n",
      "  False Positive Rate Difference: -0.1077\n",
      "  False Positive Rate Ratio: 0.8009\n",
      "  Generalized Entropy Index: 0.2325\n",
      "  Generalized Equalized Odds Difference: 0.1077\n",
      "  Generalized False Negative Rate: 0.4625\n",
      "  Generalized False Positive Rate: 0.4990\n",
      "  Generalized True Negative Rate: 0.5010\n",
      "  Generalized True Positive Rate: 0.5375\n",
      "  Negative Predictive Value: 0.5180\n",
      "  Number of False Negatives: 2379.0000\n",
      "  Number of False Positives: 2547.0000\n",
      "  Number of Generalized False Negatives: 2379.0000\n",
      "  Number of Generalized False Positives: 2547.0000\n",
      "  Number of Generalized True Negatives: 2557.0000\n",
      "  Number of Generalized True Positives: 2765.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5104.0000\n",
      "  Number of Positives: 5144.0000\n",
      "  Number of Predicted Negatives: 4936.0000\n",
      "  Number of Predicted Positives: 5312.0000\n",
      "  Number of True Negatives: 2557.0000\n",
      "  Number of True Positives: 2765.0000\n",
      "  Positive Predictive Value: 0.5205\n",
      "  Power: 2765.0000\n",
      "  Precision: 0.5205\n",
      "  Recall: 0.5375\n",
      "  Sensitivity: 0.5375\n",
      "  Specificity: 0.5010\n",
      "  Theil Index: 0.3227\n",
      "  True Negative Rate: 0.5010\n",
      "  True Positive Rate: 0.5375\n",
      "  True Positive Rate Difference: -0.0925\n",
      "  Accuracy: 0.5193\n",
      "  Base Rate: 0.5020\n",
      "  Selection Rate: 0.5183\n",
      "  Disparate Impact: 0.8336\n",
      "  Statistical Parity Difference: -0.0933\n",
      "  Between Group Coefficient of Variation: 0.1088\n",
      "  Between Group Generalized Entropy Index: 0.0059\n",
      "  Between Group Theil Index: 0.0060\n",
      "  Mean Difference: -0.0933\n",
      "  Smoothed Empirical Differential Fairness: 0.2630\n",
      "  Consistency: 0.9519\n",
      "  Average Absolute Odds Difference: 0.1001\n",
      "  Average Odds Difference: -0.1001\n",
      "  Average Predictive Value Difference: 0.1334\n",
      "  Between All Groups Coefficient of Variation: 0.1088\n",
      "  Between All Groups Generalized Entropy Index: 0.0059\n",
      "  Between All Groups Theil Index: 0.0060\n",
      "  Coefficient of Variation: 0.6819\n",
      "  Differential Fairness Bias Amplification: -0.0703\n",
      "  Equal Opportunity Difference: -0.0925\n",
      "  Equalized Odds Difference: 0.1077\n",
      "  Error Rate: 0.4807\n",
      "  Error Rate Difference: -0.0095\n",
      "  Error Rate Ratio: 0.9804\n",
      "  False Discovery Rate: 0.4795\n",
      "  False Discovery Rate Difference: -0.1405\n",
      "  False Discovery Rate Ratio: 0.7386\n",
      "  False Negative Rate: 0.4625\n",
      "  False Negative Rate Difference: 0.0925\n",
      "  False Negative Rate Ratio: 1.2232\n",
      "  False Omission Rate: 0.4820\n",
      "  False Omission Rate Difference: 0.1263\n",
      "  False Omission Rate Ratio: 1.3020\n",
      "  False Positive Rate: 0.4990\n",
      "  False Positive Rate Difference: -0.1077\n",
      "  False Positive Rate Ratio: 0.8009\n",
      "  Generalized Entropy Index: 0.2325\n",
      "  Generalized Equalized Odds Difference: 0.1077\n",
      "  Generalized False Negative Rate: 0.4625\n",
      "  Generalized False Positive Rate: 0.4990\n",
      "  Generalized True Negative Rate: 0.5010\n",
      "  Generalized True Positive Rate: 0.5375\n",
      "  Negative Predictive Value: 0.5180\n",
      "  Number of False Negatives: 2379.0000\n",
      "  Number of False Positives: 2547.0000\n",
      "  Number of Generalized False Negatives: 2379.0000\n",
      "  Number of Generalized False Positives: 2547.0000\n",
      "  Number of Generalized True Negatives: 2557.0000\n",
      "  Number of Generalized True Positives: 2765.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5104.0000\n",
      "  Number of Positives: 5144.0000\n",
      "  Number of Predicted Negatives: 4936.0000\n",
      "  Number of Predicted Positives: 5312.0000\n",
      "  Number of True Negatives: 2557.0000\n",
      "  Number of True Positives: 2765.0000\n",
      "  Positive Predictive Value: 0.5205\n",
      "  Power: 2765.0000\n",
      "  Precision: 0.5205\n",
      "  Recall: 0.5375\n",
      "  Sensitivity: 0.5375\n",
      "  Specificity: 0.5010\n",
      "  Theil Index: 0.3227\n",
      "  True Negative Rate: 0.5010\n",
      "  True Positive Rate: 0.5375\n",
      "  True Positive Rate Difference: -0.0925\n",
      "Protected Attribute Names: ['AGE']\n",
      "Privileged Protected Attributes: [{'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.5137\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5110\n",
      "  Disparate Impact: 1.1443\n",
      "  Statistical Parity Difference: 0.0718\n",
      "  Between Group Coefficient of Variation: 0.0313\n",
      "  Between Group Generalized Entropy Index: 0.0005\n",
      "  Between Group Theil Index: 0.0005\n",
      "  Mean Difference: 0.0718\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1271\n",
      "  Average Odds Difference: 0.0716\n",
      "  Average Predictive Value Difference: -0.0247\n",
      "  Between All Groups Coefficient of Variation: 0.0313\n",
      "  Between All Groups Generalized Entropy Index: 0.0005\n",
      "  Between All Groups Theil Index: 0.0005\n",
      "  Coefficient of Variation: 0.6944\n",
      "  Differential Fairness Bias Amplification: 0.1372\n",
      "  Equal Opportunity Difference: 0.1987\n",
      "  Equalized Odds Difference: 0.1987\n",
      "  Error Rate: 0.4863\n",
      "  Error Rate Difference: -0.1271\n",
      "  Error Rate Ratio: 0.7509\n",
      "  False Discovery Rate: 0.4799\n",
      "  False Discovery Rate Difference: -0.1046\n",
      "  False Discovery Rate Ratio: 0.7916\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: -0.1987\n",
      "  False Negative Rate Ratio: 0.6126\n",
      "  False Omission Rate: 0.4929\n",
      "  False Omission Rate Difference: -0.1541\n",
      "  False Omission Rate Ratio: 0.7029\n",
      "  False Positive Rate: 0.4972\n",
      "  False Positive Rate Difference: -0.0555\n",
      "  False Positive Rate Ratio: 0.8907\n",
      "  Generalized Entropy Index: 0.2411\n",
      "  Generalized Equalized Odds Difference: 0.1987\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.4972\n",
      "  Generalized True Negative Rate: 0.5028\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.5071\n",
      "  Number of False Negatives: 3705.0000\n",
      "  Number of False Positives: 3770.0000\n",
      "  Number of Generalized False Negatives: 3705.0000\n",
      "  Number of Generalized False Positives: 3770.0000\n",
      "  Number of Generalized True Negatives: 3812.0000\n",
      "  Number of Generalized True Positives: 4085.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7517.0000\n",
      "  Number of Predicted Positives: 7855.0000\n",
      "  Number of True Negatives: 3812.0000\n",
      "  Number of True Positives: 4085.0000\n",
      "  Positive Predictive Value: 0.5201\n",
      "  Power: 4085.0000\n",
      "  Precision: 0.5201\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.5028\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5028\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: 0.1987\n",
      "  Accuracy: 0.5137\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5110\n",
      "  Disparate Impact: 1.1443\n",
      "  Statistical Parity Difference: 0.0718\n",
      "  Between Group Coefficient of Variation: 0.0313\n",
      "  Between Group Generalized Entropy Index: 0.0005\n",
      "  Between Group Theil Index: 0.0005\n",
      "  Mean Difference: 0.0718\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1271\n",
      "  Average Odds Difference: 0.0716\n",
      "  Average Predictive Value Difference: -0.0247\n",
      "  Between All Groups Coefficient of Variation: 0.0313\n",
      "  Between All Groups Generalized Entropy Index: 0.0005\n",
      "  Between All Groups Theil Index: 0.0005\n",
      "  Coefficient of Variation: 0.6944\n",
      "  Differential Fairness Bias Amplification: 0.1372\n",
      "  Equal Opportunity Difference: 0.1987\n",
      "  Equalized Odds Difference: 0.1987\n",
      "  Error Rate: 0.4863\n",
      "  Error Rate Difference: -0.1271\n",
      "  Error Rate Ratio: 0.7509\n",
      "  False Discovery Rate: 0.4799\n",
      "  False Discovery Rate Difference: -0.1046\n",
      "  False Discovery Rate Ratio: 0.7916\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: -0.1987\n",
      "  False Negative Rate Ratio: 0.6126\n",
      "  False Omission Rate: 0.4929\n",
      "  False Omission Rate Difference: -0.1541\n",
      "  False Omission Rate Ratio: 0.7029\n",
      "  False Positive Rate: 0.4972\n",
      "  False Positive Rate Difference: -0.0555\n",
      "  False Positive Rate Ratio: 0.8907\n",
      "  Generalized Entropy Index: 0.2411\n",
      "  Generalized Equalized Odds Difference: 0.1987\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.4972\n",
      "  Generalized True Negative Rate: 0.5028\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.5071\n",
      "  Number of False Negatives: 3705.0000\n",
      "  Number of False Positives: 3770.0000\n",
      "  Number of Generalized False Negatives: 3705.0000\n",
      "  Number of Generalized False Positives: 3770.0000\n",
      "  Number of Generalized True Negatives: 3812.0000\n",
      "  Number of Generalized True Positives: 4085.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7517.0000\n",
      "  Number of Predicted Positives: 7855.0000\n",
      "  Number of True Negatives: 3812.0000\n",
      "  Number of True Positives: 4085.0000\n",
      "  Positive Predictive Value: 0.5201\n",
      "  Power: 4085.0000\n",
      "  Precision: 0.5201\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.5028\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5028\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: 0.1987\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.3476 - loss: 1.9687 - val_accuracy: 0.6204 - val_loss: 1.0691 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.6690 - loss: 0.9322 - val_accuracy: 0.7633 - val_loss: 0.6423 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.7126 - val_accuracy: 0.7877 - val_loss: 0.5567 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.6096 - val_accuracy: 0.8235 - val_loss: 0.4690 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.5286 - val_accuracy: 0.8153 - val_loss: 0.4681 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 0.5028 - val_accuracy: 0.8383 - val_loss: 0.4054 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.4583 - val_accuracy: 0.8523 - val_loss: 0.3688 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 0.4309 - val_accuracy: 0.8333 - val_loss: 0.4096 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.4116 - val_accuracy: 0.8552 - val_loss: 0.3445 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.4006 - val_accuracy: 0.8520 - val_loss: 0.3611 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8480 - loss: 0.3863 - val_accuracy: 0.8632 - val_loss: 0.3402 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.3751 - val_accuracy: 0.8745 - val_loss: 0.3077 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 0.3718 - val_accuracy: 0.8545 - val_loss: 0.3526 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 0.3630 - val_accuracy: 0.8777 - val_loss: 0.3080 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.3525 - val_accuracy: 0.8681 - val_loss: 0.3210 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.3493 - val_accuracy: 0.8644 - val_loss: 0.3313 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.3386 - val_accuracy: 0.8829 - val_loss: 0.2946 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.3358 - val_accuracy: 0.8717 - val_loss: 0.3016 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8713 - loss: 0.3362 - val_accuracy: 0.8810 - val_loss: 0.2908 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8710 - loss: 0.3310 - val_accuracy: 0.8787 - val_loss: 0.2978 - learning_rate: 9.2400e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.3257 - val_accuracy: 0.8827 - val_loss: 0.2895 - learning_rate: 9.2400e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8767 - loss: 0.3147 - val_accuracy: 0.8738 - val_loss: 0.3061 - learning_rate: 9.2400e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.3176 - val_accuracy: 0.8655 - val_loss: 0.3307 - learning_rate: 9.2400e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.3085 - val_accuracy: 0.8735 - val_loss: 0.3043 - learning_rate: 9.2400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.3057 - val_accuracy: 0.8843 - val_loss: 0.2831 - learning_rate: 9.2400e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.3036 - val_accuracy: 0.8860 - val_loss: 0.2876 - learning_rate: 9.2400e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.2969 - val_accuracy: 0.8881 - val_loss: 0.2702 - learning_rate: 9.2400e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.2966 - val_accuracy: 0.8871 - val_loss: 0.2855 - learning_rate: 9.2400e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.2946 - val_accuracy: 0.8887 - val_loss: 0.2809 - learning_rate: 9.2400e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.2980 - val_accuracy: 0.8762 - val_loss: 0.2928 - learning_rate: 9.2400e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8845 - loss: 0.2945 - val_accuracy: 0.8880 - val_loss: 0.2720 - learning_rate: 9.2400e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8875 - loss: 0.2894\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.2894 - val_accuracy: 0.8860 - val_loss: 0.2759 - learning_rate: 9.2400e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.2560 - val_accuracy: 0.9065 - val_loss: 0.2279 - learning_rate: 4.6200e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2394 - val_accuracy: 0.9057 - val_loss: 0.2288 - learning_rate: 4.6200e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.2369 - val_accuracy: 0.9097 - val_loss: 0.2230 - learning_rate: 4.6200e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.2367 - val_accuracy: 0.9003 - val_loss: 0.2415 - learning_rate: 4.6200e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9085 - loss: 0.2310 - val_accuracy: 0.9091 - val_loss: 0.2222 - learning_rate: 4.6200e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2271 - val_accuracy: 0.9035 - val_loss: 0.2320 - learning_rate: 4.6200e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9088 - loss: 0.2301 - val_accuracy: 0.9069 - val_loss: 0.2272 - learning_rate: 4.6200e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2304 - val_accuracy: 0.9105 - val_loss: 0.2240 - learning_rate: 4.6200e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.2281 - val_accuracy: 0.9061 - val_loss: 0.2275 - learning_rate: 4.6200e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2253\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2253 - val_accuracy: 0.9013 - val_loss: 0.2404 - learning_rate: 4.6200e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.2010 - val_accuracy: 0.9163 - val_loss: 0.2015 - learning_rate: 2.3100e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.1960 - val_accuracy: 0.9204 - val_loss: 0.1928 - learning_rate: 2.3100e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.1952 - val_accuracy: 0.9235 - val_loss: 0.1906 - learning_rate: 2.3100e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.1905 - val_accuracy: 0.9230 - val_loss: 0.1934 - learning_rate: 2.3100e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.1931 - val_accuracy: 0.9213 - val_loss: 0.1980 - learning_rate: 2.3100e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1907 - val_accuracy: 0.9175 - val_loss: 0.2097 - learning_rate: 2.3100e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.1853 - val_accuracy: 0.9231 - val_loss: 0.1891 - learning_rate: 2.3100e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.1855 - val_accuracy: 0.9237 - val_loss: 0.1874 - learning_rate: 2.3100e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.1857 - val_accuracy: 0.9248 - val_loss: 0.1887 - learning_rate: 2.3100e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.1816 - val_accuracy: 0.9239 - val_loss: 0.1926 - learning_rate: 2.3100e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.1862 - val_accuracy: 0.9249 - val_loss: 0.1855 - learning_rate: 2.3100e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.1861 - val_accuracy: 0.9217 - val_loss: 0.1967 - learning_rate: 2.3100e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.1825 - val_accuracy: 0.9229 - val_loss: 0.1907 - learning_rate: 2.3100e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.1794 - val_accuracy: 0.9216 - val_loss: 0.1931 - learning_rate: 2.3100e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.1796 - val_accuracy: 0.9224 - val_loss: 0.1884 - learning_rate: 2.3100e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1798\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1799 - val_accuracy: 0.9265 - val_loss: 0.1859 - learning_rate: 2.3100e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1663 - val_accuracy: 0.9314 - val_loss: 0.1720 - learning_rate: 1.1550e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9332 - loss: 0.1640 - val_accuracy: 0.9317 - val_loss: 0.1808 - learning_rate: 1.1550e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.1622 - val_accuracy: 0.9303 - val_loss: 0.1793 - learning_rate: 1.1550e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9373 - loss: 0.1589 - val_accuracy: 0.9341 - val_loss: 0.1695 - learning_rate: 1.1550e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9367 - loss: 0.1590 - val_accuracy: 0.9324 - val_loss: 0.1708 - learning_rate: 1.1550e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.1637 - val_accuracy: 0.9323 - val_loss: 0.1686 - learning_rate: 1.1550e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.1588 - val_accuracy: 0.9340 - val_loss: 0.1706 - learning_rate: 1.1550e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.1601 - val_accuracy: 0.9312 - val_loss: 0.1728 - learning_rate: 1.1550e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1594 - val_accuracy: 0.9343 - val_loss: 0.1720 - learning_rate: 1.1550e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.1590 - val_accuracy: 0.9326 - val_loss: 0.1714 - learning_rate: 1.1550e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9371 - loss: 0.1593\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.1593 - val_accuracy: 0.9282 - val_loss: 0.1769 - learning_rate: 1.1550e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1494 - val_accuracy: 0.9364 - val_loss: 0.1647 - learning_rate: 5.7750e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9410 - loss: 0.1466 - val_accuracy: 0.9372 - val_loss: 0.1691 - learning_rate: 5.7750e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1488 - val_accuracy: 0.9372 - val_loss: 0.1633 - learning_rate: 5.7750e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1427 - val_accuracy: 0.9363 - val_loss: 0.1621 - learning_rate: 5.7750e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.1461 - val_accuracy: 0.9395 - val_loss: 0.1607 - learning_rate: 5.7750e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9416 - loss: 0.1450 - val_accuracy: 0.9381 - val_loss: 0.1614 - learning_rate: 5.7750e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1434 - val_accuracy: 0.9366 - val_loss: 0.1611 - learning_rate: 5.7750e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1438 - val_accuracy: 0.9390 - val_loss: 0.1595 - learning_rate: 5.7750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.1468 - val_accuracy: 0.9390 - val_loss: 0.1622 - learning_rate: 5.7750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.1457 - val_accuracy: 0.9388 - val_loss: 0.1596 - learning_rate: 5.7750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1472 - val_accuracy: 0.9353 - val_loss: 0.1661 - learning_rate: 5.7750e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.1445 - val_accuracy: 0.9383 - val_loss: 0.1595 - learning_rate: 5.7750e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1433\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1433 - val_accuracy: 0.9369 - val_loss: 0.1630 - learning_rate: 5.7750e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.1401 - val_accuracy: 0.9386 - val_loss: 0.1559 - learning_rate: 2.8875e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1383 - val_accuracy: 0.9400 - val_loss: 0.1569 - learning_rate: 2.8875e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1390 - val_accuracy: 0.9404 - val_loss: 0.1558 - learning_rate: 2.8875e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.1374 - val_accuracy: 0.9414 - val_loss: 0.1552 - learning_rate: 2.8875e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.1400 - val_accuracy: 0.9422 - val_loss: 0.1567 - learning_rate: 2.8875e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1389 - val_accuracy: 0.9412 - val_loss: 0.1561 - learning_rate: 2.8875e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9441 - loss: 0.1377 - val_accuracy: 0.9400 - val_loss: 0.1560 - learning_rate: 2.8875e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.1401 - val_accuracy: 0.9408 - val_loss: 0.1546 - learning_rate: 2.8875e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.1352 - val_accuracy: 0.9403 - val_loss: 0.1577 - learning_rate: 2.8875e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.1381 - val_accuracy: 0.9409 - val_loss: 0.1558 - learning_rate: 2.8875e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1344 - val_accuracy: 0.9416 - val_loss: 0.1544 - learning_rate: 2.8875e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1378 - val_accuracy: 0.9428 - val_loss: 0.1561 - learning_rate: 2.8875e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1363 - val_accuracy: 0.9401 - val_loss: 0.1557 - learning_rate: 2.8875e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1357 - val_accuracy: 0.9424 - val_loss: 0.1523 - learning_rate: 2.8875e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.1363 - val_accuracy: 0.9418 - val_loss: 0.1546 - learning_rate: 2.8875e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9436 - loss: 0.1381 - val_accuracy: 0.9418 - val_loss: 0.1542 - learning_rate: 2.8875e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1357 - val_accuracy: 0.9419 - val_loss: 0.1539 - learning_rate: 2.8875e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1365 - val_accuracy: 0.9427 - val_loss: 0.1535 - learning_rate: 2.8875e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.3798 - loss: 1.8951 - val_accuracy: 0.7034 - val_loss: 0.8396 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.6621 - loss: 0.9299 - val_accuracy: 0.7657 - val_loss: 0.6403 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.7372 - val_accuracy: 0.8068 - val_loss: 0.5111 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.6307 - val_accuracy: 0.8218 - val_loss: 0.4603 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.5497 - val_accuracy: 0.8224 - val_loss: 0.4626 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.5046 - val_accuracy: 0.8551 - val_loss: 0.3709 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.4679 - val_accuracy: 0.8627 - val_loss: 0.3628 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.4398 - val_accuracy: 0.8627 - val_loss: 0.3580 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.4152 - val_accuracy: 0.8498 - val_loss: 0.3706 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.4058 - val_accuracy: 0.8686 - val_loss: 0.3376 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.3885 - val_accuracy: 0.8493 - val_loss: 0.3604 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.3758 - val_accuracy: 0.8736 - val_loss: 0.3129 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.3706 - val_accuracy: 0.8745 - val_loss: 0.3164 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.3598 - val_accuracy: 0.8839 - val_loss: 0.2956 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8638 - loss: 0.3530 - val_accuracy: 0.8806 - val_loss: 0.2974 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8673 - loss: 0.3433 - val_accuracy: 0.8752 - val_loss: 0.3070 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3437 - val_accuracy: 0.8688 - val_loss: 0.3200 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.3259 - val_accuracy: 0.8753 - val_loss: 0.3048 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.3239 - val_accuracy: 0.8805 - val_loss: 0.2921 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.3191 - val_accuracy: 0.8920 - val_loss: 0.2664 - learning_rate: 9.2400e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.3140 - val_accuracy: 0.8747 - val_loss: 0.3083 - learning_rate: 9.2400e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8801 - loss: 0.3097 - val_accuracy: 0.8850 - val_loss: 0.2834 - learning_rate: 9.2400e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8788 - loss: 0.3079 - val_accuracy: 0.8755 - val_loss: 0.2999 - learning_rate: 9.2400e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.3015 - val_accuracy: 0.8798 - val_loss: 0.2967 - learning_rate: 9.2400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.2949\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.2949 - val_accuracy: 0.8640 - val_loss: 0.3370 - learning_rate: 9.2400e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.2581 - val_accuracy: 0.9111 - val_loss: 0.2160 - learning_rate: 4.6200e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.2485 - val_accuracy: 0.9029 - val_loss: 0.2311 - learning_rate: 4.6200e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.2384 - val_accuracy: 0.9125 - val_loss: 0.2139 - learning_rate: 4.6200e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9091 - loss: 0.2303 - val_accuracy: 0.8902 - val_loss: 0.2624 - learning_rate: 4.6200e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9078 - loss: 0.2334 - val_accuracy: 0.9115 - val_loss: 0.2173 - learning_rate: 4.6200e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.2295 - val_accuracy: 0.9012 - val_loss: 0.2380 - learning_rate: 4.6200e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.2294 - val_accuracy: 0.9056 - val_loss: 0.2283 - learning_rate: 4.6200e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2251 - val_accuracy: 0.9156 - val_loss: 0.2098 - learning_rate: 4.6200e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9111 - loss: 0.2246 - val_accuracy: 0.9189 - val_loss: 0.1977 - learning_rate: 4.6200e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.2209 - val_accuracy: 0.9062 - val_loss: 0.2368 - learning_rate: 4.6200e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9124 - loss: 0.2217 - val_accuracy: 0.9128 - val_loss: 0.2143 - learning_rate: 4.6200e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.2209 - val_accuracy: 0.9102 - val_loss: 0.2144 - learning_rate: 4.6200e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9154 - loss: 0.2123 - val_accuracy: 0.9180 - val_loss: 0.1996 - learning_rate: 4.6200e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2187\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9136 - loss: 0.2187 - val_accuracy: 0.9059 - val_loss: 0.2436 - learning_rate: 4.6200e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.1953 - val_accuracy: 0.9214 - val_loss: 0.1941 - learning_rate: 2.3100e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9258 - loss: 0.1835 - val_accuracy: 0.9228 - val_loss: 0.1889 - learning_rate: 2.3100e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.1824 - val_accuracy: 0.9296 - val_loss: 0.1785 - learning_rate: 2.3100e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1837 - val_accuracy: 0.9259 - val_loss: 0.1838 - learning_rate: 2.3100e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1808 - val_accuracy: 0.9246 - val_loss: 0.1827 - learning_rate: 2.3100e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.1832 - val_accuracy: 0.9291 - val_loss: 0.1780 - learning_rate: 2.3100e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.1756 - val_accuracy: 0.9321 - val_loss: 0.1705 - learning_rate: 2.3100e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.1779 - val_accuracy: 0.9332 - val_loss: 0.1697 - learning_rate: 2.3100e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.1772 - val_accuracy: 0.9296 - val_loss: 0.1784 - learning_rate: 2.3100e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9300 - loss: 0.1742 - val_accuracy: 0.9255 - val_loss: 0.1925 - learning_rate: 2.3100e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.1728 - val_accuracy: 0.9298 - val_loss: 0.1794 - learning_rate: 2.3100e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.1711 - val_accuracy: 0.9287 - val_loss: 0.1788 - learning_rate: 2.3100e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.1697\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.1697 - val_accuracy: 0.9266 - val_loss: 0.1897 - learning_rate: 2.3100e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.1560 - val_accuracy: 0.9321 - val_loss: 0.1692 - learning_rate: 1.1550e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1543 - val_accuracy: 0.9369 - val_loss: 0.1627 - learning_rate: 1.1550e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.1535 - val_accuracy: 0.9366 - val_loss: 0.1611 - learning_rate: 1.1550e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.1470 - val_accuracy: 0.9351 - val_loss: 0.1659 - learning_rate: 1.1550e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1508 - val_accuracy: 0.9366 - val_loss: 0.1607 - learning_rate: 1.1550e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9404 - loss: 0.1516 - val_accuracy: 0.9356 - val_loss: 0.1655 - learning_rate: 1.1550e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.1508 - val_accuracy: 0.9368 - val_loss: 0.1604 - learning_rate: 1.1550e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9431 - loss: 0.1449 - val_accuracy: 0.9348 - val_loss: 0.1653 - learning_rate: 1.1550e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1405 - val_accuracy: 0.9350 - val_loss: 0.1635 - learning_rate: 1.1550e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.1473 - val_accuracy: 0.9370 - val_loss: 0.1606 - learning_rate: 1.1550e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1476 - val_accuracy: 0.9341 - val_loss: 0.1691 - learning_rate: 1.1550e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.1441 - val_accuracy: 0.9363 - val_loss: 0.1592 - learning_rate: 1.1550e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1427 - val_accuracy: 0.9342 - val_loss: 0.1671 - learning_rate: 1.1550e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.1460 - val_accuracy: 0.9371 - val_loss: 0.1641 - learning_rate: 1.1550e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.1449 - val_accuracy: 0.9359 - val_loss: 0.1567 - learning_rate: 1.1550e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.1444 - val_accuracy: 0.9343 - val_loss: 0.1650 - learning_rate: 1.1550e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.1464 - val_accuracy: 0.9399 - val_loss: 0.1584 - learning_rate: 1.1550e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1432 - val_accuracy: 0.9380 - val_loss: 0.1566 - learning_rate: 1.1550e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1422 - val_accuracy: 0.9353 - val_loss: 0.1623 - learning_rate: 1.1550e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2558/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1445\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1445 - val_accuracy: 0.9346 - val_loss: 0.1650 - learning_rate: 1.1550e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.1336 - val_accuracy: 0.9381 - val_loss: 0.1571 - learning_rate: 5.7750e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.1331 - val_accuracy: 0.9404 - val_loss: 0.1534 - learning_rate: 5.7750e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1306 - val_accuracy: 0.9394 - val_loss: 0.1531 - learning_rate: 5.7750e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.1299 - val_accuracy: 0.9398 - val_loss: 0.1526 - learning_rate: 5.7750e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1291 - val_accuracy: 0.9388 - val_loss: 0.1564 - learning_rate: 5.7750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.1307 - val_accuracy: 0.9415 - val_loss: 0.1504 - learning_rate: 5.7750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1297 - val_accuracy: 0.9407 - val_loss: 0.1511 - learning_rate: 5.7750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.1284 - val_accuracy: 0.9410 - val_loss: 0.1518 - learning_rate: 5.7750e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.1279 - val_accuracy: 0.9419 - val_loss: 0.1495 - learning_rate: 5.7750e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.1276 - val_accuracy: 0.9410 - val_loss: 0.1502 - learning_rate: 5.7750e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.1303 - val_accuracy: 0.9423 - val_loss: 0.1496 - learning_rate: 5.7750e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.1267 - val_accuracy: 0.9397 - val_loss: 0.1602 - learning_rate: 5.7750e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.1232 - val_accuracy: 0.9350 - val_loss: 0.1652 - learning_rate: 5.7750e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1291\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1291 - val_accuracy: 0.9425 - val_loss: 0.1516 - learning_rate: 5.7750e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1218 - val_accuracy: 0.9435 - val_loss: 0.1503 - learning_rate: 2.8875e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.1246 - val_accuracy: 0.9427 - val_loss: 0.1479 - learning_rate: 2.8875e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.1216 - val_accuracy: 0.9444 - val_loss: 0.1459 - learning_rate: 2.8875e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1221 - val_accuracy: 0.9442 - val_loss: 0.1466 - learning_rate: 2.8875e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9512 - loss: 0.1231 - val_accuracy: 0.9439 - val_loss: 0.1462 - learning_rate: 2.8875e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9526 - loss: 0.1217 - val_accuracy: 0.9424 - val_loss: 0.1480 - learning_rate: 2.8875e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9516 - loss: 0.1199 - val_accuracy: 0.9432 - val_loss: 0.1499 - learning_rate: 2.8875e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1190\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.4437499885389116e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1190 - val_accuracy: 0.9437 - val_loss: 0.1473 - learning_rate: 2.8875e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1173 - val_accuracy: 0.9437 - val_loss: 0.1462 - learning_rate: 1.4437e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9526 - loss: 0.1187 - val_accuracy: 0.9436 - val_loss: 0.1448 - learning_rate: 1.4437e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9501 - loss: 0.1234 - val_accuracy: 0.9439 - val_loss: 0.1462 - learning_rate: 1.4437e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.1200 - val_accuracy: 0.9435 - val_loss: 0.1464 - learning_rate: 1.4437e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.1200 - val_accuracy: 0.9451 - val_loss: 0.1471 - learning_rate: 1.4437e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.1180 - val_accuracy: 0.9448 - val_loss: 0.1458 - learning_rate: 1.4437e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "2840   0.936887  34.898597  16.417104  27.581067  28.539404  5.935770   \n",
      "67101  0.744645  36.003373  10.062789  32.201352  22.356873  6.261107   \n",
      "13384  0.987320  36.361149  12.556873  31.555262  27.440214  5.727500   \n",
      "46824  0.832900  35.926738  17.883744  30.852708  25.105380  7.493833   \n",
      "41791  0.686916  36.399887  38.097360  41.436461  25.175485  7.781000   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "604    1.509705  37.329515   4.703808  27.426218  28.635868  9.091057   \n",
      "9546   0.625920  36.236636  27.381384  29.710545  23.683471  7.390902   \n",
      "91111  0.670914  34.929978  45.328644  30.685687  24.971024  7.138243   \n",
      "48740  0.839460  34.199301  46.362753  30.727005  25.000212  6.754142   \n",
      "6323   0.777040  35.586271  31.824672  29.526646  24.309574  7.306509   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "2840    5.316750   6.077601  1.0     0.0           0.0  \n",
      "67101  13.243000  12.702751  0.0     0.0           1.0  \n",
      "13384   8.150032  12.503750  0.0     0.0           1.0  \n",
      "46824   6.240601   4.742019  0.0     0.0           0.0  \n",
      "41791   9.052853   5.645500  0.0     1.0           1.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "604     5.440000  14.842083  1.0     0.0           0.0  \n",
      "9546    6.220250   6.205800  1.0     0.0           1.0  \n",
      "91111   9.382041   5.371166  0.0     0.0           0.0  \n",
      "48740   8.232750   5.602664  0.0     0.0           0.0  \n",
      "6323    5.645500   7.484694  1.0     0.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "2840   0.936887  34.898597  16.417104  27.581067  28.539404  5.935770   \n",
      "67101  0.744645  36.003373  10.062789  32.201352  22.356873  6.261107   \n",
      "13384  0.987320  36.361149  12.556873  31.555262  27.440214  5.727500   \n",
      "46824  0.832900  35.926738  17.883744  30.852708  25.105380  7.493833   \n",
      "41791  0.686916  36.399887  38.097360  41.436461  25.175485  7.781000   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "604    1.509705  37.329515   4.703808  27.426218  28.635868  9.091057   \n",
      "9546   0.625920  36.236636  27.381384  29.710545  23.683471  7.390902   \n",
      "91111  0.670914  34.929978  45.328644  30.685687  24.971024  7.138243   \n",
      "48740  0.839460  34.199301  46.362753  30.727005  25.000212  6.754142   \n",
      "6323   0.777040  35.586271  31.824672  29.526646  24.309574  7.306509   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "2840    5.316750   6.077601  1.0     0.0           0.0  \n",
      "67101  13.243000  12.702751  0.0     0.0           1.0  \n",
      "13384   8.150032  12.503750  0.0     0.0           1.0  \n",
      "46824   6.240601   4.742019  0.0     0.0           1.0  \n",
      "41791   9.052853   5.645500  0.0     1.0           1.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "604     5.440000  14.842083  1.0     0.0           0.0  \n",
      "9546    6.220250   6.205800  1.0     0.0           0.0  \n",
      "91111   9.382041   5.371166  0.0     0.0           1.0  \n",
      "48740   8.232750   5.602664  0.0     0.0           0.0  \n",
      "6323    5.645500   7.484694  1.0     0.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5220\n",
      "  Base Rate: 0.5011\n",
      "  Selection Rate: 0.5162\n",
      "  Disparate Impact: 1.1329\n",
      "  Statistical Parity Difference: 0.0669\n",
      "  Between Group Coefficient of Variation: 0.0201\n",
      "  Between Group Generalized Entropy Index: 0.0002\n",
      "  Between Group Theil Index: 0.0002\n",
      "  Mean Difference: 0.0669\n",
      "  Smoothed Empirical Differential Fairness: 0.0296\n",
      "  Consistency: 0.9502\n",
      "  Average Absolute Odds Difference: 0.1201\n",
      "  Average Odds Difference: 0.0638\n",
      "  Average Predictive Value Difference: -0.0025\n",
      "  Between All Groups Coefficient of Variation: 0.0201\n",
      "  Between All Groups Generalized Entropy Index: 0.0002\n",
      "  Between All Groups Theil Index: 0.0002\n",
      "  Coefficient of Variation: 0.6809\n",
      "  Differential Fairness Bias Amplification: 0.1151\n",
      "  Equal Opportunity Difference: 0.1839\n",
      "  Equalized Odds Difference: 0.1839\n",
      "  Error Rate: 0.4780\n",
      "  Error Rate Difference: -0.1218\n",
      "  Error Rate Ratio: 0.7568\n",
      "  False Discovery Rate: 0.4777\n",
      "  False Discovery Rate Difference: -0.1199\n",
      "  False Discovery Rate Ratio: 0.7615\n",
      "  False Negative Rate: 0.4619\n",
      "  False Negative Rate Difference: -0.1839\n",
      "  False Negative Rate Ratio: 0.6302\n",
      "  False Omission Rate: 0.4784\n",
      "  False Omission Rate Difference: -0.1249\n",
      "  False Omission Rate Ratio: 0.7499\n",
      "  False Positive Rate: 0.4942\n",
      "  False Positive Rate Difference: -0.0562\n",
      "  False Positive Rate Ratio: 0.8886\n",
      "  Generalized Entropy Index: 0.2318\n",
      "  Generalized Equalized Odds Difference: 0.1839\n",
      "  Generalized False Negative Rate: 0.4619\n",
      "  Generalized False Positive Rate: 0.4942\n",
      "  Generalized True Negative Rate: 0.5058\n",
      "  Generalized True Positive Rate: 0.5381\n",
      "  Negative Predictive Value: 0.5216\n",
      "  Number of False Negatives: 2372.0000\n",
      "  Number of False Positives: 2527.0000\n",
      "  Number of Generalized False Negatives: 2372.0000\n",
      "  Number of Generalized False Positives: 2527.0000\n",
      "  Number of Generalized True Negatives: 2586.0000\n",
      "  Number of Generalized True Positives: 2763.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5113.0000\n",
      "  Number of Positives: 5135.0000\n",
      "  Number of Predicted Negatives: 4958.0000\n",
      "  Number of Predicted Positives: 5290.0000\n",
      "  Number of True Negatives: 2586.0000\n",
      "  Number of True Positives: 2763.0000\n",
      "  Positive Predictive Value: 0.5223\n",
      "  Power: 2763.0000\n",
      "  Precision: 0.5223\n",
      "  Recall: 0.5381\n",
      "  Sensitivity: 0.5381\n",
      "  Specificity: 0.5058\n",
      "  Theil Index: 0.3217\n",
      "  True Negative Rate: 0.5058\n",
      "  True Positive Rate: 0.5381\n",
      "  True Positive Rate Difference: 0.1839\n",
      "  Accuracy: 0.5220\n",
      "  Base Rate: 0.5011\n",
      "  Selection Rate: 0.5162\n",
      "  Disparate Impact: 1.1329\n",
      "  Statistical Parity Difference: 0.0669\n",
      "  Between Group Coefficient of Variation: 0.0201\n",
      "  Between Group Generalized Entropy Index: 0.0002\n",
      "  Between Group Theil Index: 0.0002\n",
      "  Mean Difference: 0.0669\n",
      "  Smoothed Empirical Differential Fairness: 0.0296\n",
      "  Consistency: 0.9502\n",
      "  Average Absolute Odds Difference: 0.1201\n",
      "  Average Odds Difference: 0.0638\n",
      "  Average Predictive Value Difference: -0.0025\n",
      "  Between All Groups Coefficient of Variation: 0.0201\n",
      "  Between All Groups Generalized Entropy Index: 0.0002\n",
      "  Between All Groups Theil Index: 0.0002\n",
      "  Coefficient of Variation: 0.6809\n",
      "  Differential Fairness Bias Amplification: 0.1151\n",
      "  Equal Opportunity Difference: 0.1839\n",
      "  Equalized Odds Difference: 0.1839\n",
      "  Error Rate: 0.4780\n",
      "  Error Rate Difference: -0.1218\n",
      "  Error Rate Ratio: 0.7568\n",
      "  False Discovery Rate: 0.4777\n",
      "  False Discovery Rate Difference: -0.1199\n",
      "  False Discovery Rate Ratio: 0.7615\n",
      "  False Negative Rate: 0.4619\n",
      "  False Negative Rate Difference: -0.1839\n",
      "  False Negative Rate Ratio: 0.6302\n",
      "  False Omission Rate: 0.4784\n",
      "  False Omission Rate Difference: -0.1249\n",
      "  False Omission Rate Ratio: 0.7499\n",
      "  False Positive Rate: 0.4942\n",
      "  False Positive Rate Difference: -0.0562\n",
      "  False Positive Rate Ratio: 0.8886\n",
      "  Generalized Entropy Index: 0.2318\n",
      "  Generalized Equalized Odds Difference: 0.1839\n",
      "  Generalized False Negative Rate: 0.4619\n",
      "  Generalized False Positive Rate: 0.4942\n",
      "  Generalized True Negative Rate: 0.5058\n",
      "  Generalized True Positive Rate: 0.5381\n",
      "  Negative Predictive Value: 0.5216\n",
      "  Number of False Negatives: 2372.0000\n",
      "  Number of False Positives: 2527.0000\n",
      "  Number of Generalized False Negatives: 2372.0000\n",
      "  Number of Generalized False Positives: 2527.0000\n",
      "  Number of Generalized True Negatives: 2586.0000\n",
      "  Number of Generalized True Positives: 2763.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5113.0000\n",
      "  Number of Positives: 5135.0000\n",
      "  Number of Predicted Negatives: 4958.0000\n",
      "  Number of Predicted Positives: 5290.0000\n",
      "  Number of True Negatives: 2586.0000\n",
      "  Number of True Positives: 2763.0000\n",
      "  Positive Predictive Value: 0.5223\n",
      "  Power: 2763.0000\n",
      "  Precision: 0.5223\n",
      "  Recall: 0.5381\n",
      "  Sensitivity: 0.5381\n",
      "  Specificity: 0.5058\n",
      "  Theil Index: 0.3217\n",
      "  True Negative Rate: 0.5058\n",
      "  True Positive Rate: 0.5381\n",
      "  True Positive Rate Difference: 0.1839\n",
      "  Accuracy: 0.5207\n",
      "  Base Rate: 0.5037\n",
      "  Selection Rate: 0.5123\n",
      "  Disparate Impact: 1.1478\n",
      "  Statistical Parity Difference: 0.0737\n",
      "  Between Group Coefficient of Variation: 0.0329\n",
      "  Between Group Generalized Entropy Index: 0.0005\n",
      "  Between Group Theil Index: 0.0005\n",
      "  Mean Difference: 0.0737\n",
      "  Smoothed Empirical Differential Fairness: 0.0226\n",
      "  Consistency: 0.9497\n",
      "  Average Absolute Odds Difference: 0.1013\n",
      "  Average Odds Difference: 0.0748\n",
      "  Average Predictive Value Difference: -0.0265\n",
      "  Between All Groups Coefficient of Variation: 0.0329\n",
      "  Between All Groups Generalized Entropy Index: 0.0005\n",
      "  Between All Groups Theil Index: 0.0005\n",
      "  Coefficient of Variation: 0.6864\n",
      "  Differential Fairness Bias Amplification: 0.1362\n",
      "  Equal Opportunity Difference: 0.1761\n",
      "  Equalized Odds Difference: 0.1761\n",
      "  Error Rate: 0.4793\n",
      "  Error Rate Difference: -0.1005\n",
      "  Error Rate Ratio: 0.7982\n",
      "  False Discovery Rate: 0.4762\n",
      "  False Discovery Rate Difference: -0.0770\n",
      "  False Discovery Rate Ratio: 0.8436\n",
      "  False Negative Rate: 0.4673\n",
      "  False Negative Rate Difference: -0.1761\n",
      "  False Negative Rate Ratio: 0.6475\n",
      "  False Omission Rate: 0.4826\n",
      "  False Omission Rate Difference: -0.1300\n",
      "  False Omission Rate Ratio: 0.7420\n",
      "  False Positive Rate: 0.4915\n",
      "  False Positive Rate Difference: -0.0265\n",
      "  False Positive Rate Ratio: 0.9466\n",
      "  Generalized Entropy Index: 0.2356\n",
      "  Generalized Equalized Odds Difference: 0.1761\n",
      "  Generalized False Negative Rate: 0.4673\n",
      "  Generalized False Positive Rate: 0.4915\n",
      "  Generalized True Negative Rate: 0.5085\n",
      "  Generalized True Positive Rate: 0.5327\n",
      "  Negative Predictive Value: 0.5174\n",
      "  Number of False Negatives: 2412.0000\n",
      "  Number of False Positives: 2500.0000\n",
      "  Number of Generalized False Negatives: 2412.0000\n",
      "  Number of Generalized False Positives: 2500.0000\n",
      "  Number of Generalized True Negatives: 2586.0000\n",
      "  Number of Generalized True Positives: 2750.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5086.0000\n",
      "  Number of Positives: 5162.0000\n",
      "  Number of Predicted Negatives: 4998.0000\n",
      "  Number of Predicted Positives: 5250.0000\n",
      "  Number of True Negatives: 2586.0000\n",
      "  Number of True Positives: 2750.0000\n",
      "  Positive Predictive Value: 0.5238\n",
      "  Power: 2750.0000\n",
      "  Precision: 0.5238\n",
      "  Recall: 0.5327\n",
      "  Sensitivity: 0.5327\n",
      "  Specificity: 0.5085\n",
      "  Theil Index: 0.3268\n",
      "  True Negative Rate: 0.5085\n",
      "  True Positive Rate: 0.5327\n",
      "  True Positive Rate Difference: 0.1761\n",
      "  Accuracy: 0.5207\n",
      "  Base Rate: 0.5037\n",
      "  Selection Rate: 0.5123\n",
      "  Disparate Impact: 1.1478\n",
      "  Statistical Parity Difference: 0.0737\n",
      "  Between Group Coefficient of Variation: 0.0329\n",
      "  Between Group Generalized Entropy Index: 0.0005\n",
      "  Between Group Theil Index: 0.0005\n",
      "  Mean Difference: 0.0737\n",
      "  Smoothed Empirical Differential Fairness: 0.0226\n",
      "  Consistency: 0.9497\n",
      "  Average Absolute Odds Difference: 0.1013\n",
      "  Average Odds Difference: 0.0748\n",
      "  Average Predictive Value Difference: -0.0265\n",
      "  Between All Groups Coefficient of Variation: 0.0329\n",
      "  Between All Groups Generalized Entropy Index: 0.0005\n",
      "  Between All Groups Theil Index: 0.0005\n",
      "  Coefficient of Variation: 0.6864\n",
      "  Differential Fairness Bias Amplification: 0.1362\n",
      "  Equal Opportunity Difference: 0.1761\n",
      "  Equalized Odds Difference: 0.1761\n",
      "  Error Rate: 0.4793\n",
      "  Error Rate Difference: -0.1005\n",
      "  Error Rate Ratio: 0.7982\n",
      "  False Discovery Rate: 0.4762\n",
      "  False Discovery Rate Difference: -0.0770\n",
      "  False Discovery Rate Ratio: 0.8436\n",
      "  False Negative Rate: 0.4673\n",
      "  False Negative Rate Difference: -0.1761\n",
      "  False Negative Rate Ratio: 0.6475\n",
      "  False Omission Rate: 0.4826\n",
      "  False Omission Rate Difference: -0.1300\n",
      "  False Omission Rate Ratio: 0.7420\n",
      "  False Positive Rate: 0.4915\n",
      "  False Positive Rate Difference: -0.0265\n",
      "  False Positive Rate Ratio: 0.9466\n",
      "  Generalized Entropy Index: 0.2356\n",
      "  Generalized Equalized Odds Difference: 0.1761\n",
      "  Generalized False Negative Rate: 0.4673\n",
      "  Generalized False Positive Rate: 0.4915\n",
      "  Generalized True Negative Rate: 0.5085\n",
      "  Generalized True Positive Rate: 0.5327\n",
      "  Negative Predictive Value: 0.5174\n",
      "  Number of False Negatives: 2412.0000\n",
      "  Number of False Positives: 2500.0000\n",
      "  Number of Generalized False Negatives: 2412.0000\n",
      "  Number of Generalized False Positives: 2500.0000\n",
      "  Number of Generalized True Negatives: 2586.0000\n",
      "  Number of Generalized True Positives: 2750.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5086.0000\n",
      "  Number of Positives: 5162.0000\n",
      "  Number of Predicted Negatives: 4998.0000\n",
      "  Number of Predicted Positives: 5250.0000\n",
      "  Number of True Negatives: 2586.0000\n",
      "  Number of True Positives: 2750.0000\n",
      "  Positive Predictive Value: 0.5238\n",
      "  Power: 2750.0000\n",
      "  Precision: 0.5238\n",
      "  Recall: 0.5327\n",
      "  Sensitivity: 0.5327\n",
      "  Specificity: 0.5085\n",
      "  Theil Index: 0.3268\n",
      "  True Negative Rate: 0.5085\n",
      "  True Positive Rate: 0.5327\n",
      "  True Positive Rate Difference: 0.1761\n",
      "Protected Attribute Names: ['GENDER', 'AGE']\n",
      "Privileged Protected Attributes: [{'GENDER': 0, 'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1, 'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE&GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.5137\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5110\n",
      "  Disparate Impact: 1.0726\n",
      "  Statistical Parity Difference: 0.0414\n",
      "  Between Group Coefficient of Variation: 0.8837\n",
      "  Between Group Generalized Entropy Index: 0.3905\n",
      "  Between Group Theil Index: 0.5760\n",
      "  Mean Difference: 0.0414\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0613\n",
      "  Average Odds Difference: 0.0613\n",
      "  Average Predictive Value Difference: 0.1802\n",
      "  Between All Groups Coefficient of Variation: 0.1320\n",
      "  Between All Groups Generalized Entropy Index: 0.0087\n",
      "  Between All Groups Theil Index: 0.0089\n",
      "  Coefficient of Variation: 0.6944\n",
      "  Differential Fairness Bias Amplification: -0.2375\n",
      "  Equal Opportunity Difference: 0.0469\n",
      "  Equalized Odds Difference: 0.0757\n",
      "  Error Rate: 0.4863\n",
      "  Error Rate Difference: -0.0260\n",
      "  Error Rate Ratio: 0.9527\n",
      "  False Discovery Rate: 0.4799\n",
      "  False Discovery Rate Difference: -0.1681\n",
      "  False Discovery Rate Ratio: 0.7078\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: -0.0469\n",
      "  False Negative Rate Ratio: 0.9019\n",
      "  False Omission Rate: 0.4929\n",
      "  False Omission Rate Difference: 0.1922\n",
      "  False Omission Rate Ratio: 1.3713\n",
      "  False Positive Rate: 0.4972\n",
      "  False Positive Rate Difference: 0.0757\n",
      "  False Positive Rate Ratio: 1.1234\n",
      "  Generalized Entropy Index: 0.2411\n",
      "  Generalized Equalized Odds Difference: 0.0757\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.4972\n",
      "  Generalized True Negative Rate: 0.5028\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.5071\n",
      "  Number of False Negatives: 3705.0000\n",
      "  Number of False Positives: 3770.0000\n",
      "  Number of Generalized False Negatives: 3705.0000\n",
      "  Number of Generalized False Positives: 3770.0000\n",
      "  Number of Generalized True Negatives: 3812.0000\n",
      "  Number of Generalized True Positives: 4085.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7517.0000\n",
      "  Number of Predicted Positives: 7855.0000\n",
      "  Number of True Negatives: 3812.0000\n",
      "  Number of True Positives: 4085.0000\n",
      "  Positive Predictive Value: 0.5201\n",
      "  Power: 4085.0000\n",
      "  Precision: 0.5201\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.5028\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5028\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: 0.0469\n",
      "  Accuracy: 0.5137\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5110\n",
      "  Disparate Impact: 1.0726\n",
      "  Statistical Parity Difference: 0.0414\n",
      "  Between Group Coefficient of Variation: 0.8837\n",
      "  Between Group Generalized Entropy Index: 0.3905\n",
      "  Between Group Theil Index: 0.5760\n",
      "  Mean Difference: 0.0414\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0613\n",
      "  Average Odds Difference: 0.0613\n",
      "  Average Predictive Value Difference: 0.1802\n",
      "  Between All Groups Coefficient of Variation: 0.1320\n",
      "  Between All Groups Generalized Entropy Index: 0.0087\n",
      "  Between All Groups Theil Index: 0.0089\n",
      "  Coefficient of Variation: 0.6944\n",
      "  Differential Fairness Bias Amplification: -0.2375\n",
      "  Equal Opportunity Difference: 0.0469\n",
      "  Equalized Odds Difference: 0.0757\n",
      "  Error Rate: 0.4863\n",
      "  Error Rate Difference: -0.0260\n",
      "  Error Rate Ratio: 0.9527\n",
      "  False Discovery Rate: 0.4799\n",
      "  False Discovery Rate Difference: -0.1681\n",
      "  False Discovery Rate Ratio: 0.7078\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: -0.0469\n",
      "  False Negative Rate Ratio: 0.9019\n",
      "  False Omission Rate: 0.4929\n",
      "  False Omission Rate Difference: 0.1922\n",
      "  False Omission Rate Ratio: 1.3713\n",
      "  False Positive Rate: 0.4972\n",
      "  False Positive Rate Difference: 0.0757\n",
      "  False Positive Rate Ratio: 1.1234\n",
      "  Generalized Entropy Index: 0.2411\n",
      "  Generalized Equalized Odds Difference: 0.0757\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.4972\n",
      "  Generalized True Negative Rate: 0.5028\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.5071\n",
      "  Number of False Negatives: 3705.0000\n",
      "  Number of False Positives: 3770.0000\n",
      "  Number of Generalized False Negatives: 3705.0000\n",
      "  Number of Generalized False Positives: 3770.0000\n",
      "  Number of Generalized True Negatives: 3812.0000\n",
      "  Number of Generalized True Positives: 4085.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7517.0000\n",
      "  Number of Predicted Positives: 7855.0000\n",
      "  Number of True Negatives: 3812.0000\n",
      "  Number of True Positives: 4085.0000\n",
      "  Positive Predictive Value: 0.5201\n",
      "  Power: 4085.0000\n",
      "  Precision: 0.5201\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.5028\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5028\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: 0.0469\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.3680 - loss: 1.9406 - val_accuracy: 0.6904 - val_loss: 0.8724 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.6715 - loss: 0.9262 - val_accuracy: 0.7472 - val_loss: 0.6738 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.7094 - val_accuracy: 0.7948 - val_loss: 0.5347 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.6021 - val_accuracy: 0.8084 - val_loss: 0.5215 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 0.5314 - val_accuracy: 0.8310 - val_loss: 0.4381 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.4950 - val_accuracy: 0.8471 - val_loss: 0.3914 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.4595 - val_accuracy: 0.8455 - val_loss: 0.3796 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.4368 - val_accuracy: 0.8595 - val_loss: 0.3657 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.4223 - val_accuracy: 0.8612 - val_loss: 0.3538 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.4002 - val_accuracy: 0.8616 - val_loss: 0.3428 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8497 - loss: 0.3955 - val_accuracy: 0.8705 - val_loss: 0.3257 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.3779 - val_accuracy: 0.8649 - val_loss: 0.3455 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 0.3668 - val_accuracy: 0.8753 - val_loss: 0.3098 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8617 - loss: 0.3609 - val_accuracy: 0.8715 - val_loss: 0.3166 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.3556 - val_accuracy: 0.8649 - val_loss: 0.3277 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.3505 - val_accuracy: 0.8672 - val_loss: 0.3140 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8665 - loss: 0.3434 - val_accuracy: 0.8768 - val_loss: 0.2962 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.3342 - val_accuracy: 0.8834 - val_loss: 0.2914 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8710 - loss: 0.3302 - val_accuracy: 0.8743 - val_loss: 0.3079 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.3212 - val_accuracy: 0.8734 - val_loss: 0.3189 - learning_rate: 9.2400e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.3241 - val_accuracy: 0.8840 - val_loss: 0.2758 - learning_rate: 9.2400e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.3189 - val_accuracy: 0.8881 - val_loss: 0.2734 - learning_rate: 9.2400e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.8810 - loss: 0.3080 - val_accuracy: 0.8870 - val_loss: 0.2712 - learning_rate: 9.2400e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8831 - loss: 0.3018 - val_accuracy: 0.8811 - val_loss: 0.2932 - learning_rate: 9.2400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8804 - loss: 0.3068 - val_accuracy: 0.8772 - val_loss: 0.2929 - learning_rate: 9.2400e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3051 - val_accuracy: 0.8856 - val_loss: 0.2797 - learning_rate: 9.2400e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.2987 - val_accuracy: 0.8821 - val_loss: 0.2788 - learning_rate: 9.2400e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.2952 - val_accuracy: 0.8880 - val_loss: 0.2665 - learning_rate: 9.2400e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.2900 - val_accuracy: 0.8935 - val_loss: 0.2615 - learning_rate: 9.2400e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8870 - loss: 0.2876 - val_accuracy: 0.8891 - val_loss: 0.2850 - learning_rate: 9.2400e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.2945 - val_accuracy: 0.8824 - val_loss: 0.2894 - learning_rate: 9.2400e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8887 - loss: 0.2883 - val_accuracy: 0.8918 - val_loss: 0.2618 - learning_rate: 9.2400e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.2845 - val_accuracy: 0.8956 - val_loss: 0.2506 - learning_rate: 9.2400e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.2828 - val_accuracy: 0.8972 - val_loss: 0.2636 - learning_rate: 9.2400e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.2778 - val_accuracy: 0.8960 - val_loss: 0.2512 - learning_rate: 9.2400e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8902 - loss: 0.2796 - val_accuracy: 0.8933 - val_loss: 0.2624 - learning_rate: 9.2400e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.2768 - val_accuracy: 0.8969 - val_loss: 0.2498 - learning_rate: 9.2400e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.2757 - val_accuracy: 0.8918 - val_loss: 0.2671 - learning_rate: 9.2400e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.2797 - val_accuracy: 0.8988 - val_loss: 0.2496 - learning_rate: 9.2400e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.2713 - val_accuracy: 0.8900 - val_loss: 0.2731 - learning_rate: 9.2400e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8933 - loss: 0.2736 - val_accuracy: 0.8896 - val_loss: 0.2849 - learning_rate: 9.2400e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.2736 - val_accuracy: 0.8927 - val_loss: 0.2700 - learning_rate: 9.2400e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.2663 - val_accuracy: 0.8964 - val_loss: 0.2514 - learning_rate: 9.2400e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8941 - loss: 0.2693 - val_accuracy: 0.8995 - val_loss: 0.2477 - learning_rate: 9.2400e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8941 - loss: 0.2677 - val_accuracy: 0.8934 - val_loss: 0.2538 - learning_rate: 9.2400e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.2643 - val_accuracy: 0.8968 - val_loss: 0.2458 - learning_rate: 9.2400e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8967 - loss: 0.2605 - val_accuracy: 0.8962 - val_loss: 0.2548 - learning_rate: 9.2400e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.2596 - val_accuracy: 0.8885 - val_loss: 0.2777 - learning_rate: 9.2400e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.2594 - val_accuracy: 0.8979 - val_loss: 0.2527 - learning_rate: 9.2400e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.2563 - val_accuracy: 0.8924 - val_loss: 0.2581 - learning_rate: 9.2400e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.2621\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.2621 - val_accuracy: 0.8838 - val_loss: 0.2808 - learning_rate: 9.2400e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.2229 - val_accuracy: 0.9150 - val_loss: 0.2050 - learning_rate: 4.6200e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9155 - loss: 0.2118 - val_accuracy: 0.9105 - val_loss: 0.2143 - learning_rate: 4.6200e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9131 - loss: 0.2122 - val_accuracy: 0.9102 - val_loss: 0.2179 - learning_rate: 4.6200e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.2068 - val_accuracy: 0.9093 - val_loss: 0.2168 - learning_rate: 4.6200e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.2079 - val_accuracy: 0.9120 - val_loss: 0.2166 - learning_rate: 4.6200e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2045\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2045 - val_accuracy: 0.9074 - val_loss: 0.2192 - learning_rate: 4.6200e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.1871 - val_accuracy: 0.9204 - val_loss: 0.1930 - learning_rate: 2.3100e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.1848 - val_accuracy: 0.9208 - val_loss: 0.1943 - learning_rate: 2.3100e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.1772 - val_accuracy: 0.9229 - val_loss: 0.1860 - learning_rate: 2.3100e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9287 - loss: 0.1770 - val_accuracy: 0.9271 - val_loss: 0.1817 - learning_rate: 2.3100e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.1727 - val_accuracy: 0.9208 - val_loss: 0.1948 - learning_rate: 2.3100e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.1719 - val_accuracy: 0.9258 - val_loss: 0.1871 - learning_rate: 2.3100e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9309 - loss: 0.1727 - val_accuracy: 0.9251 - val_loss: 0.1881 - learning_rate: 2.3100e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.1720 - val_accuracy: 0.9259 - val_loss: 0.1854 - learning_rate: 2.3100e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.1695\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.1695 - val_accuracy: 0.9215 - val_loss: 0.1945 - learning_rate: 2.3100e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1558 - val_accuracy: 0.9305 - val_loss: 0.1752 - learning_rate: 1.1550e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.1549 - val_accuracy: 0.9294 - val_loss: 0.1763 - learning_rate: 1.1550e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9367 - loss: 0.1540 - val_accuracy: 0.9277 - val_loss: 0.1775 - learning_rate: 1.1550e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.1517 - val_accuracy: 0.9319 - val_loss: 0.1717 - learning_rate: 1.1550e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9365 - loss: 0.1552 - val_accuracy: 0.9318 - val_loss: 0.1718 - learning_rate: 1.1550e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.1510 - val_accuracy: 0.9324 - val_loss: 0.1761 - learning_rate: 1.1550e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.1499 - val_accuracy: 0.9316 - val_loss: 0.1720 - learning_rate: 1.1550e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9392 - loss: 0.1487 - val_accuracy: 0.9282 - val_loss: 0.1756 - learning_rate: 1.1550e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.1516\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.1516 - val_accuracy: 0.9317 - val_loss: 0.1739 - learning_rate: 1.1550e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1434 - val_accuracy: 0.9335 - val_loss: 0.1665 - learning_rate: 5.7750e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9414 - loss: 0.1429 - val_accuracy: 0.9326 - val_loss: 0.1685 - learning_rate: 5.7750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1397 - val_accuracy: 0.9325 - val_loss: 0.1692 - learning_rate: 5.7750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9443 - loss: 0.1397 - val_accuracy: 0.9349 - val_loss: 0.1682 - learning_rate: 5.7750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.1403 - val_accuracy: 0.9335 - val_loss: 0.1683 - learning_rate: 5.7750e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.1413\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.1413 - val_accuracy: 0.9344 - val_loss: 0.1679 - learning_rate: 5.7750e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1332 - val_accuracy: 0.9360 - val_loss: 0.1650 - learning_rate: 2.8875e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.1345 - val_accuracy: 0.9339 - val_loss: 0.1670 - learning_rate: 2.8875e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1352 - val_accuracy: 0.9354 - val_loss: 0.1656 - learning_rate: 2.8875e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1335 - val_accuracy: 0.9357 - val_loss: 0.1640 - learning_rate: 2.8875e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.1348 - val_accuracy: 0.9355 - val_loss: 0.1637 - learning_rate: 2.8875e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.1358 - val_accuracy: 0.9363 - val_loss: 0.1629 - learning_rate: 2.8875e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.1334 - val_accuracy: 0.9346 - val_loss: 0.1658 - learning_rate: 2.8875e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1350 - val_accuracy: 0.9351 - val_loss: 0.1640 - learning_rate: 2.8875e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.1331 - val_accuracy: 0.9371 - val_loss: 0.1643 - learning_rate: 2.8875e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1318 - val_accuracy: 0.9347 - val_loss: 0.1663 - learning_rate: 2.8875e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1341\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.4437499885389116e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9464 - loss: 0.1341 - val_accuracy: 0.9354 - val_loss: 0.1642 - learning_rate: 2.8875e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9485 - loss: 0.1285 - val_accuracy: 0.9364 - val_loss: 0.1632 - learning_rate: 1.4437e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9474 - loss: 0.1299 - val_accuracy: 0.9361 - val_loss: 0.1637 - learning_rate: 1.4437e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1266 - val_accuracy: 0.9355 - val_loss: 0.1635 - learning_rate: 1.4437e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.1296 - val_accuracy: 0.9362 - val_loss: 0.1637 - learning_rate: 1.4437e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9474 - loss: 0.1305 - val_accuracy: 0.9361 - val_loss: 0.1625 - learning_rate: 1.4437e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.1279 - val_accuracy: 0.9369 - val_loss: 0.1640 - learning_rate: 1.4437e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9484 - loss: 0.1289 - val_accuracy: 0.9368 - val_loss: 0.1640 - learning_rate: 1.4437e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1309 - val_accuracy: 0.9362 - val_loss: 0.1630 - learning_rate: 1.4437e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.3751 - loss: 1.9014 - val_accuracy: 0.6844 - val_loss: 0.8928 - learning_rate: 9.2400e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.6604 - loss: 0.9488 - val_accuracy: 0.7456 - val_loss: 0.7155 - learning_rate: 9.2400e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.7709 - val_accuracy: 0.7939 - val_loss: 0.5535 - learning_rate: 9.2400e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7627 - loss: 0.6484 - val_accuracy: 0.8174 - val_loss: 0.4833 - learning_rate: 9.2400e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 0.5710 - val_accuracy: 0.8200 - val_loss: 0.4634 - learning_rate: 9.2400e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.5175 - val_accuracy: 0.8337 - val_loss: 0.4332 - learning_rate: 9.2400e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.4792 - val_accuracy: 0.8367 - val_loss: 0.3994 - learning_rate: 9.2400e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.4462 - val_accuracy: 0.8362 - val_loss: 0.4082 - learning_rate: 9.2400e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.4321 - val_accuracy: 0.8528 - val_loss: 0.3740 - learning_rate: 9.2400e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.4167 - val_accuracy: 0.8582 - val_loss: 0.3464 - learning_rate: 9.2400e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3984 - val_accuracy: 0.8644 - val_loss: 0.3440 - learning_rate: 9.2400e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8524 - loss: 0.3881 - val_accuracy: 0.8797 - val_loss: 0.3114 - learning_rate: 9.2400e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8538 - loss: 0.3845 - val_accuracy: 0.8746 - val_loss: 0.3209 - learning_rate: 9.2400e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.3691 - val_accuracy: 0.8693 - val_loss: 0.3201 - learning_rate: 9.2400e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8641 - loss: 0.3512 - val_accuracy: 0.8792 - val_loss: 0.3019 - learning_rate: 9.2400e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.3424 - val_accuracy: 0.8745 - val_loss: 0.3184 - learning_rate: 9.2400e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.3478 - val_accuracy: 0.8852 - val_loss: 0.2868 - learning_rate: 9.2400e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.3377 - val_accuracy: 0.8770 - val_loss: 0.3135 - learning_rate: 9.2400e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8726 - loss: 0.3342 - val_accuracy: 0.8837 - val_loss: 0.2884 - learning_rate: 9.2400e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.3296 - val_accuracy: 0.8700 - val_loss: 0.3214 - learning_rate: 9.2400e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.3237 - val_accuracy: 0.8959 - val_loss: 0.2557 - learning_rate: 9.2400e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8809 - loss: 0.3070 - val_accuracy: 0.8887 - val_loss: 0.2798 - learning_rate: 9.2400e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.3158 - val_accuracy: 0.8869 - val_loss: 0.2754 - learning_rate: 9.2400e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3075 - val_accuracy: 0.8923 - val_loss: 0.2639 - learning_rate: 9.2400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8802 - loss: 0.3051 - val_accuracy: 0.8770 - val_loss: 0.2894 - learning_rate: 9.2400e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.3021\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004619999963324517.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.3021 - val_accuracy: 0.8740 - val_loss: 0.2944 - learning_rate: 9.2400e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9005 - loss: 0.2524 - val_accuracy: 0.9095 - val_loss: 0.2161 - learning_rate: 4.6200e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9031 - loss: 0.2450 - val_accuracy: 0.9096 - val_loss: 0.2200 - learning_rate: 4.6200e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9031 - loss: 0.2421 - val_accuracy: 0.9131 - val_loss: 0.2087 - learning_rate: 4.6200e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.2375 - val_accuracy: 0.9097 - val_loss: 0.2143 - learning_rate: 4.6200e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2416 - val_accuracy: 0.8917 - val_loss: 0.2767 - learning_rate: 4.6200e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 0.2348 - val_accuracy: 0.9159 - val_loss: 0.2048 - learning_rate: 4.6200e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.2325 - val_accuracy: 0.9158 - val_loss: 0.2037 - learning_rate: 4.6200e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2300 - val_accuracy: 0.9124 - val_loss: 0.2099 - learning_rate: 4.6200e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9076 - loss: 0.2304 - val_accuracy: 0.9105 - val_loss: 0.2164 - learning_rate: 4.6200e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2277 - val_accuracy: 0.9111 - val_loss: 0.2087 - learning_rate: 4.6200e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.2245 - val_accuracy: 0.9138 - val_loss: 0.2067 - learning_rate: 4.6200e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.2234 - val_accuracy: 0.9122 - val_loss: 0.2006 - learning_rate: 4.6200e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.2228 - val_accuracy: 0.9138 - val_loss: 0.1991 - learning_rate: 4.6200e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.2167 - val_accuracy: 0.9074 - val_loss: 0.2124 - learning_rate: 4.6200e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.2157 - val_accuracy: 0.9067 - val_loss: 0.2244 - learning_rate: 4.6200e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9131 - loss: 0.2205 - val_accuracy: 0.9106 - val_loss: 0.2190 - learning_rate: 4.6200e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2153 - val_accuracy: 0.9150 - val_loss: 0.1967 - learning_rate: 4.6200e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9135 - loss: 0.2216 - val_accuracy: 0.9128 - val_loss: 0.2029 - learning_rate: 4.6200e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2093 - val_accuracy: 0.9187 - val_loss: 0.1941 - learning_rate: 4.6200e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2137 - val_accuracy: 0.9124 - val_loss: 0.2053 - learning_rate: 4.6200e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9159 - loss: 0.2118 - val_accuracy: 0.9143 - val_loss: 0.2028 - learning_rate: 4.6200e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.2136 - val_accuracy: 0.9176 - val_loss: 0.1976 - learning_rate: 4.6200e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2097 - val_accuracy: 0.9156 - val_loss: 0.2018 - learning_rate: 4.6200e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9154 - loss: 0.2109 - val_accuracy: 0.9205 - val_loss: 0.1836 - learning_rate: 4.6200e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.2059 - val_accuracy: 0.9095 - val_loss: 0.2256 - learning_rate: 4.6200e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2107 - val_accuracy: 0.9172 - val_loss: 0.1965 - learning_rate: 4.6200e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9179 - loss: 0.2050 - val_accuracy: 0.9158 - val_loss: 0.1913 - learning_rate: 4.6200e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2082 - val_accuracy: 0.9194 - val_loss: 0.1959 - learning_rate: 4.6200e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2029\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00023099999816622585.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2029 - val_accuracy: 0.9212 - val_loss: 0.1849 - learning_rate: 4.6200e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.1759 - val_accuracy: 0.9294 - val_loss: 0.1673 - learning_rate: 2.3100e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.1732 - val_accuracy: 0.9304 - val_loss: 0.1691 - learning_rate: 2.3100e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.1730 - val_accuracy: 0.9327 - val_loss: 0.1623 - learning_rate: 2.3100e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.1715 - val_accuracy: 0.9287 - val_loss: 0.1721 - learning_rate: 2.3100e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.1664 - val_accuracy: 0.9254 - val_loss: 0.1717 - learning_rate: 2.3100e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9341 - loss: 0.1666 - val_accuracy: 0.9281 - val_loss: 0.1738 - learning_rate: 2.3100e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9322 - loss: 0.1682 - val_accuracy: 0.9302 - val_loss: 0.1660 - learning_rate: 2.3100e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.1662\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00011549999908311293.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.1662 - val_accuracy: 0.9270 - val_loss: 0.1656 - learning_rate: 2.3100e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.1506 - val_accuracy: 0.9355 - val_loss: 0.1533 - learning_rate: 1.1550e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1507 - val_accuracy: 0.9369 - val_loss: 0.1496 - learning_rate: 1.1550e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.1448 - val_accuracy: 0.9364 - val_loss: 0.1531 - learning_rate: 1.1550e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.1468 - val_accuracy: 0.9313 - val_loss: 0.1671 - learning_rate: 1.1550e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.1451 - val_accuracy: 0.9288 - val_loss: 0.1689 - learning_rate: 1.1550e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9416 - loss: 0.1466 - val_accuracy: 0.9363 - val_loss: 0.1500 - learning_rate: 1.1550e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.1441\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 5.774999954155646e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.1441 - val_accuracy: 0.9353 - val_loss: 0.1514 - learning_rate: 1.1550e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9450 - loss: 0.1347 - val_accuracy: 0.9396 - val_loss: 0.1451 - learning_rate: 5.7750e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1350 - val_accuracy: 0.9411 - val_loss: 0.1438 - learning_rate: 5.7750e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.1354 - val_accuracy: 0.9409 - val_loss: 0.1437 - learning_rate: 5.7750e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1354 - val_accuracy: 0.9407 - val_loss: 0.1424 - learning_rate: 5.7750e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1338 - val_accuracy: 0.9416 - val_loss: 0.1432 - learning_rate: 5.7750e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.1332 - val_accuracy: 0.9406 - val_loss: 0.1431 - learning_rate: 5.7750e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9464 - loss: 0.1335 - val_accuracy: 0.9414 - val_loss: 0.1411 - learning_rate: 5.7750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1325 - val_accuracy: 0.9421 - val_loss: 0.1406 - learning_rate: 5.7750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.1311 - val_accuracy: 0.9353 - val_loss: 0.1504 - learning_rate: 5.7750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.1317 - val_accuracy: 0.9412 - val_loss: 0.1406 - learning_rate: 5.7750e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1325 - val_accuracy: 0.9405 - val_loss: 0.1416 - learning_rate: 5.7750e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.1309 - val_accuracy: 0.9406 - val_loss: 0.1424 - learning_rate: 5.7750e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1328 - val_accuracy: 0.9439 - val_loss: 0.1366 - learning_rate: 5.7750e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1329 - val_accuracy: 0.9422 - val_loss: 0.1421 - learning_rate: 5.7750e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1308 - val_accuracy: 0.9413 - val_loss: 0.1414 - learning_rate: 5.7750e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.1281 - val_accuracy: 0.9429 - val_loss: 0.1391 - learning_rate: 5.7750e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9468 - loss: 0.1324 - val_accuracy: 0.9442 - val_loss: 0.1396 - learning_rate: 5.7750e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.1297\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.887499977077823e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.1297 - val_accuracy: 0.9438 - val_loss: 0.1379 - learning_rate: 5.7750e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1256 - val_accuracy: 0.9454 - val_loss: 0.1361 - learning_rate: 2.8875e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9504 - loss: 0.1237 - val_accuracy: 0.9438 - val_loss: 0.1368 - learning_rate: 2.8875e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.1257 - val_accuracy: 0.9437 - val_loss: 0.1371 - learning_rate: 2.8875e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1292 - val_accuracy: 0.9446 - val_loss: 0.1372 - learning_rate: 2.8875e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1218 - val_accuracy: 0.9440 - val_loss: 0.1380 - learning_rate: 2.8875e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9509 - loss: 0.1234\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.4437499885389116e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9509 - loss: 0.1234 - val_accuracy: 0.9442 - val_loss: 0.1370 - learning_rate: 2.8875e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.1205 - val_accuracy: 0.9446 - val_loss: 0.1349 - learning_rate: 1.4437e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.1248 - val_accuracy: 0.9452 - val_loss: 0.1358 - learning_rate: 1.4437e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.1185 - val_accuracy: 0.9447 - val_loss: 0.1367 - learning_rate: 1.4437e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1213 - val_accuracy: 0.9446 - val_loss: 0.1372 - learning_rate: 1.4437e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1209 - val_accuracy: 0.9452 - val_loss: 0.1342 - learning_rate: 1.4437e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 0.1198 - val_accuracy: 0.9453 - val_loss: 0.1364 - learning_rate: 1.4437e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "53623  0.682296  36.545170  31.132559  31.240933  22.423318  7.452500   \n",
      "89652  0.679862  35.641249  14.837423  32.109080  23.675021  5.809750   \n",
      "84666  0.829620  36.128712  15.644352  42.363341  28.516483  6.549000   \n",
      "17577  1.646377  35.388075  35.652936  45.848490  33.463113  5.727500   \n",
      "7067   0.786900  35.780020  29.435472  29.681496  24.316574  8.916716   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "47400  0.878900  35.071485  35.144786  30.685211  25.098398  6.630873   \n",
      "41071  0.785547  34.423953  11.015808  40.845694  27.864409  8.684500   \n",
      "57384  0.691262  38.569512  17.250516  36.321109  32.520054  5.645648   \n",
      "65477  1.181217  36.187018  10.231248  36.121652  20.127208  6.959500   \n",
      "37493  0.911756  37.746226  17.305544  33.349658  30.290389  7.945250   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "53623   7.168582   5.768500  0.0     0.0           1.0  \n",
      "89652  13.398955   4.772655  0.0     1.0           0.0  \n",
      "84666   6.087380   4.495500  0.0     1.0           0.0  \n",
      "17577  18.789095   6.220122  0.0     1.0           0.0  \n",
      "7067    5.440000   8.602237  1.0     0.0           1.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "47400   6.855948  23.879599  0.0     0.0           0.0  \n",
      "41071   9.998500   5.522250  0.0     1.0           1.0  \n",
      "57384   5.838346   4.823957  0.0     1.0           0.0  \n",
      "65477   9.998500   5.645500  0.0     1.0           0.0  \n",
      "37493   6.288505   4.906519  0.0     1.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "53623  0.682296  36.545170  31.132559  31.240933  22.423318  7.452500   \n",
      "89652  0.679862  35.641249  14.837423  32.109080  23.675021  5.809750   \n",
      "84666  0.829620  36.128712  15.644352  42.363341  28.516483  6.549000   \n",
      "17577  1.646377  35.388075  35.652936  45.848490  33.463113  5.727500   \n",
      "7067   0.786900  35.780020  29.435472  29.681496  24.316574  8.916716   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "47400  0.878900  35.071485  35.144786  30.685211  25.098398  6.630873   \n",
      "41071  0.785547  34.423953  11.015808  40.845694  27.864409  8.684500   \n",
      "57384  0.691262  38.569512  17.250516  36.321109  32.520054  5.645648   \n",
      "65477  1.181217  36.187018  10.231248  36.121652  20.127208  6.959500   \n",
      "37493  0.911756  37.746226  17.305544  33.349658  30.290389  7.945250   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "53623   7.168582   5.768500  0.0     0.0           0.0  \n",
      "89652  13.398955   4.772655  0.0     1.0           0.0  \n",
      "84666   6.087380   4.495500  0.0     1.0           0.0  \n",
      "17577  18.789095   6.220122  0.0     1.0           0.0  \n",
      "7067    5.440000   8.602237  1.0     0.0           1.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "47400   6.855948  23.879599  0.0     0.0           0.0  \n",
      "41071   9.998500   5.522250  0.0     1.0           1.0  \n",
      "57384   5.838346   4.823957  0.0     1.0           1.0  \n",
      "65477   9.998500   5.645500  0.0     1.0           1.0  \n",
      "37493   6.288505   4.906519  0.0     1.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5199\n",
      "  Base Rate: 0.5054\n",
      "  Selection Rate: 0.5124\n",
      "  Disparate Impact: 0.9619\n",
      "  Statistical Parity Difference: -0.0223\n",
      "  Between Group Coefficient of Variation: 0.8825\n",
      "  Between Group Generalized Entropy Index: 0.3894\n",
      "  Between Group Theil Index: 0.5732\n",
      "  Mean Difference: -0.0223\n",
      "  Smoothed Empirical Differential Fairness: 0.6701\n",
      "  Consistency: 0.9508\n",
      "  Average Absolute Odds Difference: 0.0209\n",
      "  Average Odds Difference: -0.0038\n",
      "  Average Predictive Value Difference: 0.1931\n",
      "  Between All Groups Coefficient of Variation: 0.1356\n",
      "  Between All Groups Generalized Entropy Index: 0.0092\n",
      "  Between All Groups Theil Index: 0.0093\n",
      "  Coefficient of Variation: 0.6880\n",
      "  Differential Fairness Bias Amplification: -0.2915\n",
      "  Equal Opportunity Difference: -0.0247\n",
      "  Equalized Odds Difference: 0.0247\n",
      "  Error Rate: 0.4801\n",
      "  Error Rate Difference: -0.0098\n",
      "  Error Rate Ratio: 0.9817\n",
      "  False Discovery Rate: 0.4753\n",
      "  False Discovery Rate Difference: -0.1773\n",
      "  False Discovery Rate Ratio: 0.6843\n",
      "  False Negative Rate: 0.4680\n",
      "  False Negative Rate Difference: 0.0247\n",
      "  False Negative Rate Ratio: 1.0552\n",
      "  False Omission Rate: 0.4851\n",
      "  False Omission Rate Difference: 0.2088\n",
      "  False Omission Rate Ratio: 1.4161\n",
      "  False Positive Rate: 0.4924\n",
      "  False Positive Rate Difference: 0.0170\n",
      "  False Positive Rate Ratio: 1.0278\n",
      "  Generalized Entropy Index: 0.2367\n",
      "  Generalized Equalized Odds Difference: 0.0247\n",
      "  Generalized False Negative Rate: 0.4680\n",
      "  Generalized False Positive Rate: 0.4924\n",
      "  Generalized True Negative Rate: 0.5076\n",
      "  Generalized True Positive Rate: 0.5320\n",
      "  Negative Predictive Value: 0.5149\n",
      "  Number of False Negatives: 2424.0000\n",
      "  Number of False Positives: 2496.0000\n",
      "  Number of Generalized False Negatives: 2424.0000\n",
      "  Number of Generalized False Positives: 2496.0000\n",
      "  Number of Generalized True Negatives: 2573.0000\n",
      "  Number of Generalized True Positives: 2755.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5069.0000\n",
      "  Number of Positives: 5179.0000\n",
      "  Number of Predicted Negatives: 4997.0000\n",
      "  Number of Predicted Positives: 5251.0000\n",
      "  Number of True Negatives: 2573.0000\n",
      "  Number of True Positives: 2755.0000\n",
      "  Positive Predictive Value: 0.5247\n",
      "  Power: 2755.0000\n",
      "  Precision: 0.5247\n",
      "  Recall: 0.5320\n",
      "  Sensitivity: 0.5320\n",
      "  Specificity: 0.5076\n",
      "  Theil Index: 0.3283\n",
      "  True Negative Rate: 0.5076\n",
      "  True Positive Rate: 0.5320\n",
      "  True Positive Rate Difference: -0.0247\n",
      "  Accuracy: 0.5199\n",
      "  Base Rate: 0.5054\n",
      "  Selection Rate: 0.5124\n",
      "  Disparate Impact: 0.9619\n",
      "  Statistical Parity Difference: -0.0223\n",
      "  Between Group Coefficient of Variation: 0.8825\n",
      "  Between Group Generalized Entropy Index: 0.3894\n",
      "  Between Group Theil Index: 0.5732\n",
      "  Mean Difference: -0.0223\n",
      "  Smoothed Empirical Differential Fairness: 0.6701\n",
      "  Consistency: 0.9508\n",
      "  Average Absolute Odds Difference: 0.0209\n",
      "  Average Odds Difference: -0.0038\n",
      "  Average Predictive Value Difference: 0.1931\n",
      "  Between All Groups Coefficient of Variation: 0.1356\n",
      "  Between All Groups Generalized Entropy Index: 0.0092\n",
      "  Between All Groups Theil Index: 0.0093\n",
      "  Coefficient of Variation: 0.6880\n",
      "  Differential Fairness Bias Amplification: -0.2915\n",
      "  Equal Opportunity Difference: -0.0247\n",
      "  Equalized Odds Difference: 0.0247\n",
      "  Error Rate: 0.4801\n",
      "  Error Rate Difference: -0.0098\n",
      "  Error Rate Ratio: 0.9817\n",
      "  False Discovery Rate: 0.4753\n",
      "  False Discovery Rate Difference: -0.1773\n",
      "  False Discovery Rate Ratio: 0.6843\n",
      "  False Negative Rate: 0.4680\n",
      "  False Negative Rate Difference: 0.0247\n",
      "  False Negative Rate Ratio: 1.0552\n",
      "  False Omission Rate: 0.4851\n",
      "  False Omission Rate Difference: 0.2088\n",
      "  False Omission Rate Ratio: 1.4161\n",
      "  False Positive Rate: 0.4924\n",
      "  False Positive Rate Difference: 0.0170\n",
      "  False Positive Rate Ratio: 1.0278\n",
      "  Generalized Entropy Index: 0.2367\n",
      "  Generalized Equalized Odds Difference: 0.0247\n",
      "  Generalized False Negative Rate: 0.4680\n",
      "  Generalized False Positive Rate: 0.4924\n",
      "  Generalized True Negative Rate: 0.5076\n",
      "  Generalized True Positive Rate: 0.5320\n",
      "  Negative Predictive Value: 0.5149\n",
      "  Number of False Negatives: 2424.0000\n",
      "  Number of False Positives: 2496.0000\n",
      "  Number of Generalized False Negatives: 2424.0000\n",
      "  Number of Generalized False Positives: 2496.0000\n",
      "  Number of Generalized True Negatives: 2573.0000\n",
      "  Number of Generalized True Positives: 2755.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5069.0000\n",
      "  Number of Positives: 5179.0000\n",
      "  Number of Predicted Negatives: 4997.0000\n",
      "  Number of Predicted Positives: 5251.0000\n",
      "  Number of True Negatives: 2573.0000\n",
      "  Number of True Positives: 2755.0000\n",
      "  Positive Predictive Value: 0.5247\n",
      "  Power: 2755.0000\n",
      "  Precision: 0.5247\n",
      "  Recall: 0.5320\n",
      "  Sensitivity: 0.5320\n",
      "  Specificity: 0.5076\n",
      "  Theil Index: 0.3283\n",
      "  True Negative Rate: 0.5076\n",
      "  True Positive Rate: 0.5320\n",
      "  True Positive Rate Difference: -0.0247\n",
      "  Accuracy: 0.5181\n",
      "  Base Rate: 0.5026\n",
      "  Selection Rate: 0.5138\n",
      "  Disparate Impact: 1.0187\n",
      "  Statistical Parity Difference: 0.0106\n",
      "  Between Group Coefficient of Variation: 0.8710\n",
      "  Between Group Generalized Entropy Index: 0.3793\n",
      "  Between Group Theil Index: 0.5629\n",
      "  Mean Difference: 0.0106\n",
      "  Smoothed Empirical Differential Fairness: 0.6539\n",
      "  Consistency: 0.9521\n",
      "  Average Absolute Odds Difference: 0.0296\n",
      "  Average Odds Difference: 0.0296\n",
      "  Average Predictive Value Difference: 0.1752\n",
      "  Between All Groups Coefficient of Variation: 0.1297\n",
      "  Between All Groups Generalized Entropy Index: 0.0084\n",
      "  Between All Groups Theil Index: 0.0085\n",
      "  Coefficient of Variation: 0.6864\n",
      "  Differential Fairness Bias Amplification: -0.2958\n",
      "  Equal Opportunity Difference: 0.0044\n",
      "  Equalized Odds Difference: 0.0548\n",
      "  Error Rate: 0.4819\n",
      "  Error Rate Difference: -0.0061\n",
      "  Error Rate Ratio: 0.9887\n",
      "  False Discovery Rate: 0.4798\n",
      "  False Discovery Rate Difference: -0.1535\n",
      "  False Discovery Rate Ratio: 0.7290\n",
      "  False Negative Rate: 0.4683\n",
      "  False Negative Rate Difference: -0.0044\n",
      "  False Negative Rate Ratio: 0.9905\n",
      "  False Omission Rate: 0.4840\n",
      "  False Omission Rate Difference: 0.1969\n",
      "  False Omission Rate Ratio: 1.3895\n",
      "  False Positive Rate: 0.4956\n",
      "  False Positive Rate Difference: 0.0548\n",
      "  False Positive Rate Ratio: 1.0908\n",
      "  Generalized Entropy Index: 0.2356\n",
      "  Generalized Equalized Odds Difference: 0.0548\n",
      "  Generalized False Negative Rate: 0.4683\n",
      "  Generalized False Positive Rate: 0.4956\n",
      "  Generalized True Negative Rate: 0.5044\n",
      "  Generalized True Positive Rate: 0.5317\n",
      "  Negative Predictive Value: 0.5160\n",
      "  Number of False Negatives: 2412.0000\n",
      "  Number of False Positives: 2526.0000\n",
      "  Number of Generalized False Negatives: 2412.0000\n",
      "  Number of Generalized False Positives: 2526.0000\n",
      "  Number of Generalized True Negatives: 2571.0000\n",
      "  Number of Generalized True Positives: 2739.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5097.0000\n",
      "  Number of Positives: 5151.0000\n",
      "  Number of Predicted Negatives: 4983.0000\n",
      "  Number of Predicted Positives: 5265.0000\n",
      "  Number of True Negatives: 2571.0000\n",
      "  Number of True Positives: 2739.0000\n",
      "  Positive Predictive Value: 0.5202\n",
      "  Power: 2739.0000\n",
      "  Precision: 0.5202\n",
      "  Recall: 0.5317\n",
      "  Sensitivity: 0.5317\n",
      "  Specificity: 0.5044\n",
      "  Theil Index: 0.3269\n",
      "  True Negative Rate: 0.5044\n",
      "  True Positive Rate: 0.5317\n",
      "  True Positive Rate Difference: 0.0044\n",
      "  Accuracy: 0.5181\n",
      "  Base Rate: 0.5026\n",
      "  Selection Rate: 0.5138\n",
      "  Disparate Impact: 1.0187\n",
      "  Statistical Parity Difference: 0.0106\n",
      "  Between Group Coefficient of Variation: 0.8710\n",
      "  Between Group Generalized Entropy Index: 0.3793\n",
      "  Between Group Theil Index: 0.5629\n",
      "  Mean Difference: 0.0106\n",
      "  Smoothed Empirical Differential Fairness: 0.6539\n",
      "  Consistency: 0.9521\n",
      "  Average Absolute Odds Difference: 0.0296\n",
      "  Average Odds Difference: 0.0296\n",
      "  Average Predictive Value Difference: 0.1752\n",
      "  Between All Groups Coefficient of Variation: 0.1297\n",
      "  Between All Groups Generalized Entropy Index: 0.0084\n",
      "  Between All Groups Theil Index: 0.0085\n",
      "  Coefficient of Variation: 0.6864\n",
      "  Differential Fairness Bias Amplification: -0.2958\n",
      "  Equal Opportunity Difference: 0.0044\n",
      "  Equalized Odds Difference: 0.0548\n",
      "  Error Rate: 0.4819\n",
      "  Error Rate Difference: -0.0061\n",
      "  Error Rate Ratio: 0.9887\n",
      "  False Discovery Rate: 0.4798\n",
      "  False Discovery Rate Difference: -0.1535\n",
      "  False Discovery Rate Ratio: 0.7290\n",
      "  False Negative Rate: 0.4683\n",
      "  False Negative Rate Difference: -0.0044\n",
      "  False Negative Rate Ratio: 0.9905\n",
      "  False Omission Rate: 0.4840\n",
      "  False Omission Rate Difference: 0.1969\n",
      "  False Omission Rate Ratio: 1.3895\n",
      "  False Positive Rate: 0.4956\n",
      "  False Positive Rate Difference: 0.0548\n",
      "  False Positive Rate Ratio: 1.0908\n",
      "  Generalized Entropy Index: 0.2356\n",
      "  Generalized Equalized Odds Difference: 0.0548\n",
      "  Generalized False Negative Rate: 0.4683\n",
      "  Generalized False Positive Rate: 0.4956\n",
      "  Generalized True Negative Rate: 0.5044\n",
      "  Generalized True Positive Rate: 0.5317\n",
      "  Negative Predictive Value: 0.5160\n",
      "  Number of False Negatives: 2412.0000\n",
      "  Number of False Positives: 2526.0000\n",
      "  Number of Generalized False Negatives: 2412.0000\n",
      "  Number of Generalized False Positives: 2526.0000\n",
      "  Number of Generalized True Negatives: 2571.0000\n",
      "  Number of Generalized True Positives: 2739.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5097.0000\n",
      "  Number of Positives: 5151.0000\n",
      "  Number of Predicted Negatives: 4983.0000\n",
      "  Number of Predicted Positives: 5265.0000\n",
      "  Number of True Negatives: 2571.0000\n",
      "  Number of True Positives: 2739.0000\n",
      "  Positive Predictive Value: 0.5202\n",
      "  Power: 2739.0000\n",
      "  Precision: 0.5202\n",
      "  Recall: 0.5317\n",
      "  Sensitivity: 0.5317\n",
      "  Specificity: 0.5044\n",
      "  Theil Index: 0.3269\n",
      "  True Negative Rate: 0.5044\n",
      "  True Positive Rate: 0.5317\n",
      "  True Positive Rate Difference: 0.0044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for config in protected_attribute_configs:\n",
    "    protected_attribute_names = config[\"protected_attribute_names\"]\n",
    "    privileged_protected_attributes = config[\"privileged_protected_attributes\"]\n",
    "    unprivileged_protected_attributes = config[\"unprivileged_protected_attributes\"]\n",
    "    sensitive_attribute = config[\"sensitive_attribute\"]\n",
    "    desc = config[\"desc\"]\n",
    "\n",
    "    print(\"Protected Attribute Names:\", protected_attribute_names)\n",
    "    print(\"Privileged Protected Attributes:\", privileged_protected_attributes)\n",
    "    print(\"Unprivileged Protected Attributes:\", unprivileged_protected_attributes)\n",
    "    print(\"Sensitive Attribute:\", sensitive_attribute)\n",
    "    print(\"Description:\", desc)\n",
    "\n",
    "    # Creating BinaryLabelDataset\n",
    "    print(\"Creating BinaryLabelDataset...\")\n",
    "    binary_dataset = BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=['Emotion_Type'],\n",
    "        protected_attribute_names=protected_attribute_names\n",
    "    )\n",
    "    print(\"BinaryLabelDataset created.\\n\")\n",
    "\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_bld = BinaryLabelDataset(df=pred_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "\n",
    "    compute_fairness_metrics_CM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"GRU model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"GRU model-CM-{desc}\")\n",
    "    \n",
    "    reweighing = Reweighing(\n",
    "        privileged_groups=privileged_protected_attributes,\n",
    "        unprivileged_groups=unprivileged_protected_attributes\n",
    "    )\n",
    "    reweighed_dataset = reweighing.fit_transform(binary_dataset)\n",
    "\n",
    "\n",
    "    dir_remover = DisparateImpactRemover(repair_level=0.1, sensitive_attribute=sensitive_attribute)\n",
    "    dir_processed = dir_remover.fit_transform(binary_dataset)\n",
    "    \n",
    "    # Perform a 70%-15%-15% split for training, validation, and test sets\n",
    "    train_dir, temp_dir = dir_processed.split([0.8], shuffle=True)\n",
    "    val_dir, test_dir = temp_dir.split([0.5], shuffle=True)\n",
    "    \n",
    "    # Perform the same split on the reweighted dataset\n",
    "    train_reweighed, temp_reweighed = reweighed_dataset.split([0.8], shuffle=True)\n",
    "    val_reweighed, test_reweighed = temp_reweighed.split([0.5], shuffle=True)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    train_dir_df = train_dir.convert_to_dataframe()[0]\n",
    "    val_dir_df = val_dir.convert_to_dataframe()[0]\n",
    "    test_dir_df = test_dir.convert_to_dataframe()[0]\n",
    "    \n",
    "    train_reweighed_df = train_reweighed.convert_to_dataframe()[0]\n",
    "    val_reweighed_df = val_reweighed.convert_to_dataframe()[0]\n",
    "    test_reweighed_df = test_reweighed.convert_to_dataframe()[0]\n",
    "\n",
    "    dir_weights = train_dir.instance_weights\n",
    "    rw_weights = train_reweighed.instance_weights\n",
    "    \n",
    "    def prepare_data_for_gru(dataset, weights):\n",
    "        features = dataset.drop(columns=['Emotion', 'Emotion_Type'])\n",
    "        labels = dataset['Emotion']\n",
    "        features_reshaped = np.expand_dims(features.values, axis=2)\n",
    "        return features_reshaped, labels, weights\n",
    "    \n",
    "    # Prepare data for GRU model with train, validation, and test splits\n",
    "    X_train_dir, y_train_dir, train_weights_dir = prepare_data_for_gru(train_dir_df, dir_weights)\n",
    "    X_val_dir, y_val_dir, _ = prepare_data_for_gru(val_dir_df, dir_weights)\n",
    "    X_test_dir, y_test_dir, _ = prepare_data_for_gru(test_dir_df, dir_weights)\n",
    "    \n",
    "    X_train_reweighed, y_train_reweighed, train_weights_rw = prepare_data_for_gru(train_reweighed_df, rw_weights)\n",
    "    X_val_reweighed, y_val_reweighed, _ = prepare_data_for_gru(val_reweighed_df, rw_weights)\n",
    "    X_test_reweighed, y_test_reweighed, _ = prepare_data_for_gru(test_reweighed_df, rw_weights)\n",
    "\n",
    "    gru_dir = build_gru_model(X_train_dir.shape[1:], num_classes)\n",
    "    gru_dir.fit(\n",
    "        X_train_dir, y_train_dir, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_dir, y_val_dir), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_dir = np.argmax(gru_dir.predict(X_test_dir), axis=1)\n",
    "    \n",
    "    gru_reweighed = build_gru_model(X_train_reweighed.shape[1:], num_classes)\n",
    "    gru_reweighed.fit(\n",
    "        X_train_reweighed, y_train_reweighed, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_reweighed, y_val_reweighed), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_reweighed = np.argmax(gru_reweighed.predict(X_test_reweighed), axis=1)\n",
    "\n",
    "    pred_reweighed_df = test_reweighed_df.copy()\n",
    "    pred_reweighed_df['Emotion'] = y_pred_reweighed\n",
    "    \n",
    "    pred_dir_df = test_dir_df.copy()\n",
    "    pred_dir_df['Emotion'] = y_pred_dir\n",
    "    \n",
    "    pred_reweighed_df['Emotion_Type'] = pred_reweighed_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    pred_dir_df['Emotion_Type'] = pred_dir_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    \n",
    "    pred_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    pred_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    print(pred_dir_df)\n",
    "    \n",
    "    pred_reweighed_bld = BinaryLabelDataset(df=pred_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_dir_bld = BinaryLabelDataset(df=pred_dir_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    \n",
    "    test_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    print(test_dir_df)\n",
    "    test_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    test_dir = BinaryLabelDataset(df=test_dir_df, label_names=['Emotion_Type'], protected_attribute_names=test_dir.protected_attribute_names)\n",
    "    test_reweighed = BinaryLabelDataset(df=test_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=test_reweighed.protected_attribute_names)\n",
    "    \n",
    "    compute_fairness_metrics_CM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"GRU DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"GRU DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_CM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"GRU Reweighed model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"GRU Reweighed model-CM-{desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b9fc1",
   "metadata": {
    "papermill": {
     "duration": 9.316081,
     "end_time": "2025-02-25T07:31:28.164262",
     "exception": false,
     "start_time": "2025-02-25T07:31:18.848181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e635cce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T07:31:45.962169Z",
     "iopub.status.busy": "2025-02-25T07:31:45.961499Z",
     "iopub.status.idle": "2025-02-25T07:52:19.522024Z",
     "shell.execute_reply": "2025-02-25T07:52:19.521133Z"
    },
    "papermill": {
     "duration": 1250.054446,
     "end_time": "2025-02-25T07:52:27.118448",
     "exception": false,
     "start_time": "2025-02-25T07:31:37.064002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.4155 - loss: 1.6809 - val_accuracy: 0.6848 - val_loss: 0.8149 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7158 - loss: 0.7539 - val_accuracy: 0.7870 - val_loss: 0.5473 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7769 - loss: 0.5951 - val_accuracy: 0.8241 - val_loss: 0.4607 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.5087 - val_accuracy: 0.8391 - val_loss: 0.4098 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.4458 - val_accuracy: 0.8692 - val_loss: 0.3433 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.4027 - val_accuracy: 0.8666 - val_loss: 0.3274 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8597 - loss: 0.3721 - val_accuracy: 0.8717 - val_loss: 0.3161 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8682 - loss: 0.3459 - val_accuracy: 0.8891 - val_loss: 0.2834 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8737 - loss: 0.3320 - val_accuracy: 0.8888 - val_loss: 0.2725 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.3147 - val_accuracy: 0.8885 - val_loss: 0.2755 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.3033 - val_accuracy: 0.8960 - val_loss: 0.2583 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 0.2907 - val_accuracy: 0.9061 - val_loss: 0.2387 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8928 - loss: 0.2774 - val_accuracy: 0.8986 - val_loss: 0.2575 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.2713 - val_accuracy: 0.9053 - val_loss: 0.2370 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8978 - loss: 0.2632 - val_accuracy: 0.9130 - val_loss: 0.2181 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.2547 - val_accuracy: 0.9074 - val_loss: 0.2342 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9002 - loss: 0.2530 - val_accuracy: 0.9073 - val_loss: 0.2366 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9027 - loss: 0.2440 - val_accuracy: 0.9072 - val_loss: 0.2286 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.2405 - val_accuracy: 0.9102 - val_loss: 0.2136 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9067 - loss: 0.2361 - val_accuracy: 0.9105 - val_loss: 0.2261 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9113 - loss: 0.2297 - val_accuracy: 0.9121 - val_loss: 0.2156 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.2290 - val_accuracy: 0.9126 - val_loss: 0.2117 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9114 - loss: 0.2231 - val_accuracy: 0.9176 - val_loss: 0.1994 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9104 - loss: 0.2225 - val_accuracy: 0.9197 - val_loss: 0.2013 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2204 - val_accuracy: 0.9169 - val_loss: 0.2014 - learning_rate: 8.5700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2124 - val_accuracy: 0.9013 - val_loss: 0.2419 - learning_rate: 8.5700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2138 - val_accuracy: 0.9212 - val_loss: 0.1887 - learning_rate: 8.5700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2110 - val_accuracy: 0.9141 - val_loss: 0.2137 - learning_rate: 8.5700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.2084 - val_accuracy: 0.9114 - val_loss: 0.2224 - learning_rate: 8.5700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2081 - val_accuracy: 0.9242 - val_loss: 0.1870 - learning_rate: 8.5700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.2010 - val_accuracy: 0.9212 - val_loss: 0.1909 - learning_rate: 8.5700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2015 - val_accuracy: 0.9260 - val_loss: 0.1870 - learning_rate: 8.5700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.2045 - val_accuracy: 0.9220 - val_loss: 0.1911 - learning_rate: 8.5700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.1958 - val_accuracy: 0.9124 - val_loss: 0.2248 - learning_rate: 8.5700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.1974 - val_accuracy: 0.9227 - val_loss: 0.1848 - learning_rate: 8.5700e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.1911 - val_accuracy: 0.9210 - val_loss: 0.1956 - learning_rate: 8.5700e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.1920 - val_accuracy: 0.9291 - val_loss: 0.1698 - learning_rate: 8.5700e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.1867 - val_accuracy: 0.9285 - val_loss: 0.1717 - learning_rate: 8.5700e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.1904 - val_accuracy: 0.9252 - val_loss: 0.1833 - learning_rate: 8.5700e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.1848 - val_accuracy: 0.9258 - val_loss: 0.1743 - learning_rate: 8.5700e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1814 - val_accuracy: 0.9205 - val_loss: 0.1934 - learning_rate: 8.5700e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.1848 - val_accuracy: 0.9312 - val_loss: 0.1659 - learning_rate: 8.5700e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.1816 - val_accuracy: 0.9252 - val_loss: 0.1782 - learning_rate: 8.5700e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.1839 - val_accuracy: 0.9198 - val_loss: 0.2006 - learning_rate: 8.5700e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.1797 - val_accuracy: 0.9174 - val_loss: 0.2028 - learning_rate: 8.5700e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9296 - loss: 0.1772 - val_accuracy: 0.9233 - val_loss: 0.1846 - learning_rate: 8.5700e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2238/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.1807\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.1807 - val_accuracy: 0.9290 - val_loss: 0.1795 - learning_rate: 8.5700e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.1515 - val_accuracy: 0.9404 - val_loss: 0.1446 - learning_rate: 4.2850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.1443 - val_accuracy: 0.9415 - val_loss: 0.1444 - learning_rate: 4.2850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1414 - val_accuracy: 0.9333 - val_loss: 0.1636 - learning_rate: 4.2850e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.1407 - val_accuracy: 0.9381 - val_loss: 0.1451 - learning_rate: 4.2850e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.1429 - val_accuracy: 0.9407 - val_loss: 0.1467 - learning_rate: 4.2850e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1409 - val_accuracy: 0.9368 - val_loss: 0.1595 - learning_rate: 4.2850e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2241/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9431 - loss: 0.1410\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9431 - loss: 0.1410 - val_accuracy: 0.9293 - val_loss: 0.1704 - learning_rate: 4.2850e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.1215 - val_accuracy: 0.9409 - val_loss: 0.1446 - learning_rate: 2.1425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9493 - loss: 0.1233 - val_accuracy: 0.9462 - val_loss: 0.1362 - learning_rate: 2.1425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9521 - loss: 0.1199 - val_accuracy: 0.9409 - val_loss: 0.1412 - learning_rate: 2.1425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9513 - loss: 0.1192 - val_accuracy: 0.9431 - val_loss: 0.1393 - learning_rate: 2.1425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9518 - loss: 0.1198 - val_accuracy: 0.9450 - val_loss: 0.1377 - learning_rate: 2.1425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1169 - val_accuracy: 0.9437 - val_loss: 0.1376 - learning_rate: 2.1425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 0.1135 - val_accuracy: 0.9479 - val_loss: 0.1316 - learning_rate: 2.1425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1145 - val_accuracy: 0.9463 - val_loss: 0.1362 - learning_rate: 2.1425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9535 - loss: 0.1149 - val_accuracy: 0.9472 - val_loss: 0.1299 - learning_rate: 2.1425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9547 - loss: 0.1133 - val_accuracy: 0.9404 - val_loss: 0.1446 - learning_rate: 2.1425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1155 - val_accuracy: 0.9485 - val_loss: 0.1324 - learning_rate: 2.1425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9557 - loss: 0.1093 - val_accuracy: 0.9474 - val_loss: 0.1315 - learning_rate: 2.1425e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1124 - val_accuracy: 0.9441 - val_loss: 0.1434 - learning_rate: 2.1425e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2233/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.1135\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.1135 - val_accuracy: 0.9467 - val_loss: 0.1386 - learning_rate: 2.1425e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9583 - loss: 0.1024 - val_accuracy: 0.9484 - val_loss: 0.1303 - learning_rate: 1.0713e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9582 - loss: 0.1037 - val_accuracy: 0.9523 - val_loss: 0.1224 - learning_rate: 1.0713e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9588 - loss: 0.1010 - val_accuracy: 0.9521 - val_loss: 0.1249 - learning_rate: 1.0713e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9589 - loss: 0.1017 - val_accuracy: 0.9505 - val_loss: 0.1266 - learning_rate: 1.0713e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9579 - loss: 0.1031 - val_accuracy: 0.9530 - val_loss: 0.1230 - learning_rate: 1.0713e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.0974 - val_accuracy: 0.9502 - val_loss: 0.1261 - learning_rate: 1.0713e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2236/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9598 - loss: 0.1007\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9598 - loss: 0.1007 - val_accuracy: 0.9526 - val_loss: 0.1239 - learning_rate: 1.0713e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.0961 - val_accuracy: 0.9522 - val_loss: 0.1236 - learning_rate: 5.3563e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.0953 - val_accuracy: 0.9543 - val_loss: 0.1213 - learning_rate: 5.3563e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.0950 - val_accuracy: 0.9532 - val_loss: 0.1202 - learning_rate: 5.3563e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9627 - loss: 0.0943 - val_accuracy: 0.9535 - val_loss: 0.1200 - learning_rate: 5.3563e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.0924 - val_accuracy: 0.9547 - val_loss: 0.1205 - learning_rate: 5.3563e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9615 - loss: 0.0938 - val_accuracy: 0.9533 - val_loss: 0.1211 - learning_rate: 5.3563e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.0918 - val_accuracy: 0.9530 - val_loss: 0.1222 - learning_rate: 5.3563e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.0904 - val_accuracy: 0.9541 - val_loss: 0.1200 - learning_rate: 5.3563e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9635 - loss: 0.0914 - val_accuracy: 0.9539 - val_loss: 0.1199 - learning_rate: 5.3563e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9611 - loss: 0.0964 - val_accuracy: 0.9531 - val_loss: 0.1208 - learning_rate: 5.3563e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9630 - loss: 0.0928 - val_accuracy: 0.9533 - val_loss: 0.1215 - learning_rate: 5.3563e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0930 - val_accuracy: 0.9524 - val_loss: 0.1220 - learning_rate: 5.3563e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9634 - loss: 0.0927 - val_accuracy: 0.9541 - val_loss: 0.1197 - learning_rate: 5.3563e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9637 - loss: 0.0905 - val_accuracy: 0.9534 - val_loss: 0.1229 - learning_rate: 5.3563e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9629 - loss: 0.0905 - val_accuracy: 0.9550 - val_loss: 0.1190 - learning_rate: 5.3563e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9611 - loss: 0.0967 - val_accuracy: 0.9543 - val_loss: 0.1203 - learning_rate: 5.3563e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.0900 - val_accuracy: 0.9538 - val_loss: 0.1240 - learning_rate: 5.3563e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.0924 - val_accuracy: 0.9546 - val_loss: 0.1195 - learning_rate: 5.3563e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.0908 - val_accuracy: 0.9550 - val_loss: 0.1189 - learning_rate: 5.3563e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.0887 - val_accuracy: 0.9524 - val_loss: 0.1215 - learning_rate: 5.3563e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9647 - loss: 0.0888 - val_accuracy: 0.9543 - val_loss: 0.1201 - learning_rate: 5.3563e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.0910 - val_accuracy: 0.9540 - val_loss: 0.1185 - learning_rate: 5.3563e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.0908 - val_accuracy: 0.9547 - val_loss: 0.1190 - learning_rate: 5.3563e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.0875 - val_accuracy: 0.9557 - val_loss: 0.1201 - learning_rate: 5.3563e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9629 - loss: 0.0890 - val_accuracy: 0.9557 - val_loss: 0.1197 - learning_rate: 5.3563e-05\n",
      "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy: 0.9567\n",
      "Precision: 0.9572\n",
      "Recall: 0.9567\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2402\n",
      "           1       0.91      0.91      0.91       722\n",
      "           2       0.97      0.97      0.97      1686\n",
      "           3       0.97      0.97      0.97      2795\n",
      "           4       0.97      0.96      0.96      2574\n",
      "           5       0.92      0.92      0.92       415\n",
      "           6       0.96      0.97      0.96       678\n",
      "           7       0.98      0.93      0.96      1027\n",
      "           8       0.79      0.84      0.82       424\n",
      "           9       0.96      0.99      0.97       474\n",
      "          10       0.95      1.00      0.97       411\n",
      "          11       1.00      1.00      1.00       441\n",
      "          12       0.92      0.98      0.95       469\n",
      "          13       0.97      1.00      0.99       412\n",
      "          14       1.00      1.00      1.00       442\n",
      "\n",
      "    accuracy                           0.96     15372\n",
      "   macro avg       0.95      0.96      0.95     15372\n",
      "weighted avg       0.96      0.96      0.96     15372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Single LSTM Layer with 128 units\n",
    "    model.add(LSTM(128, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.000857)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load data\n",
    "X = df.drop(columns=['Emotion'])\n",
    "y = df['Emotion']\n",
    "\n",
    "# Splitting Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  \n",
    "\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build and train LSTM model\n",
    "lstm_model = build_lstm_model(input_shape, num_classes)\n",
    "history = lstm_model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=100, batch_size=32, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions on test data\n",
    "predictions = lstm_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "pred_df = X_test.copy()\n",
    "pred_df['Emotion'] = predicted_labels\n",
    "pred_df['Emotion_Type'] = pred_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "y_pred = pred_df['Emotion'].values\n",
    "pred_df.drop(columns=['Emotion'], inplace=True)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = tf.math.confusion_matrix(y_test, predicted_labels).numpy()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- ROC CURVE FOR MULTI-CLASS TEST DATA ---\n",
    "n_classes = len(np.unique(y_test))  \n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], predictions[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve for Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474baff",
   "metadata": {
    "papermill": {
     "duration": 9.828991,
     "end_time": "2025-02-25T07:52:47.009058",
     "exception": false,
     "start_time": "2025-02-25T07:52:37.180067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LSTM - Preprocessing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec24ec65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T07:53:06.590483Z",
     "iopub.status.busy": "2025-02-25T07:53:06.590182Z",
     "iopub.status.idle": "2025-02-25T09:52:23.800091Z",
     "shell.execute_reply": "2025-02-25T09:52:23.799005Z"
    },
    "papermill": {
     "duration": 7167.042696,
     "end_time": "2025-02-25T09:52:23.801457",
     "exception": false,
     "start_time": "2025-02-25T07:52:56.758761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected Attribute Names: ['GENDER']\n",
      "Privileged Protected Attributes: [{'GENDER': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1}]\n",
      "Sensitive Attribute: GENDER\n",
      "Description: GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.5128\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5121\n",
      "  Disparate Impact: 0.8032\n",
      "  Statistical Parity Difference: -0.1108\n",
      "  Between Group Coefficient of Variation: 0.1237\n",
      "  Between Group Generalized Entropy Index: 0.0077\n",
      "  Between Group Theil Index: 0.0077\n",
      "  Mean Difference: -0.1108\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1173\n",
      "  Average Odds Difference: -0.1173\n",
      "  Average Predictive Value Difference: 0.1432\n",
      "  Between All Groups Coefficient of Variation: 0.1237\n",
      "  Between All Groups Generalized Entropy Index: 0.0077\n",
      "  Between All Groups Theil Index: 0.0077\n",
      "  Coefficient of Variation: 0.6943\n",
      "  Differential Fairness Bias Amplification: -0.0607\n",
      "  Equal Opportunity Difference: -0.0959\n",
      "  Equalized Odds Difference: 0.1387\n",
      "  Error Rate: 0.4872\n",
      "  Error Rate Difference: -0.0201\n",
      "  Error Rate Ratio: 0.9596\n",
      "  False Discovery Rate: 0.4809\n",
      "  False Discovery Rate Difference: -0.1640\n",
      "  False Discovery Rate Ratio: 0.7004\n",
      "  False Negative Rate: 0.4755\n",
      "  False Negative Rate Difference: 0.0959\n",
      "  False Negative Rate Ratio: 1.2256\n",
      "  False Omission Rate: 0.4939\n",
      "  False Omission Rate Difference: 0.1224\n",
      "  False Omission Rate Ratio: 1.2840\n",
      "  False Positive Rate: 0.4993\n",
      "  False Positive Rate Difference: -0.1387\n",
      "  False Positive Rate Ratio: 0.7492\n",
      "  Generalized Entropy Index: 0.2410\n",
      "  Generalized Equalized Odds Difference: 0.1387\n",
      "  Generalized False Negative Rate: 0.4755\n",
      "  Generalized False Positive Rate: 0.4993\n",
      "  Generalized True Negative Rate: 0.5007\n",
      "  Generalized True Positive Rate: 0.5245\n",
      "  Negative Predictive Value: 0.5061\n",
      "  Number of False Negatives: 3704.0000\n",
      "  Number of False Positives: 3786.0000\n",
      "  Number of Generalized False Negatives: 3704.0000\n",
      "  Number of Generalized False Positives: 3786.0000\n",
      "  Number of Generalized True Negatives: 3796.0000\n",
      "  Number of Generalized True Positives: 4086.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7500.0000\n",
      "  Number of Predicted Positives: 7872.0000\n",
      "  Number of True Negatives: 3796.0000\n",
      "  Number of True Positives: 4086.0000\n",
      "  Positive Predictive Value: 0.5191\n",
      "  Power: 4086.0000\n",
      "  Precision: 0.5191\n",
      "  Recall: 0.5245\n",
      "  Sensitivity: 0.5245\n",
      "  Specificity: 0.5007\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5007\n",
      "  True Positive Rate: 0.5245\n",
      "  True Positive Rate Difference: -0.0959\n",
      "  Accuracy: 0.5128\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5121\n",
      "  Disparate Impact: 0.8032\n",
      "  Statistical Parity Difference: -0.1108\n",
      "  Between Group Coefficient of Variation: 0.1237\n",
      "  Between Group Generalized Entropy Index: 0.0077\n",
      "  Between Group Theil Index: 0.0077\n",
      "  Mean Difference: -0.1108\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1173\n",
      "  Average Odds Difference: -0.1173\n",
      "  Average Predictive Value Difference: 0.1432\n",
      "  Between All Groups Coefficient of Variation: 0.1237\n",
      "  Between All Groups Generalized Entropy Index: 0.0077\n",
      "  Between All Groups Theil Index: 0.0077\n",
      "  Coefficient of Variation: 0.6943\n",
      "  Differential Fairness Bias Amplification: -0.0607\n",
      "  Equal Opportunity Difference: -0.0959\n",
      "  Equalized Odds Difference: 0.1387\n",
      "  Error Rate: 0.4872\n",
      "  Error Rate Difference: -0.0201\n",
      "  Error Rate Ratio: 0.9596\n",
      "  False Discovery Rate: 0.4809\n",
      "  False Discovery Rate Difference: -0.1640\n",
      "  False Discovery Rate Ratio: 0.7004\n",
      "  False Negative Rate: 0.4755\n",
      "  False Negative Rate Difference: 0.0959\n",
      "  False Negative Rate Ratio: 1.2256\n",
      "  False Omission Rate: 0.4939\n",
      "  False Omission Rate Difference: 0.1224\n",
      "  False Omission Rate Ratio: 1.2840\n",
      "  False Positive Rate: 0.4993\n",
      "  False Positive Rate Difference: -0.1387\n",
      "  False Positive Rate Ratio: 0.7492\n",
      "  Generalized Entropy Index: 0.2410\n",
      "  Generalized Equalized Odds Difference: 0.1387\n",
      "  Generalized False Negative Rate: 0.4755\n",
      "  Generalized False Positive Rate: 0.4993\n",
      "  Generalized True Negative Rate: 0.5007\n",
      "  Generalized True Positive Rate: 0.5245\n",
      "  Negative Predictive Value: 0.5061\n",
      "  Number of False Negatives: 3704.0000\n",
      "  Number of False Positives: 3786.0000\n",
      "  Number of Generalized False Negatives: 3704.0000\n",
      "  Number of Generalized False Positives: 3786.0000\n",
      "  Number of Generalized True Negatives: 3796.0000\n",
      "  Number of Generalized True Positives: 4086.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7500.0000\n",
      "  Number of Predicted Positives: 7872.0000\n",
      "  Number of True Negatives: 3796.0000\n",
      "  Number of True Positives: 4086.0000\n",
      "  Positive Predictive Value: 0.5191\n",
      "  Power: 4086.0000\n",
      "  Precision: 0.5191\n",
      "  Recall: 0.5245\n",
      "  Sensitivity: 0.5245\n",
      "  Specificity: 0.5007\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5007\n",
      "  True Positive Rate: 0.5245\n",
      "  True Positive Rate Difference: -0.0959\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.3067 - loss: 2.1202 - val_accuracy: 0.6592 - val_loss: 0.9589 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 1.0265 - val_accuracy: 0.7434 - val_loss: 0.7136 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7159 - loss: 0.7856 - val_accuracy: 0.7869 - val_loss: 0.5823 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.6572 - val_accuracy: 0.8080 - val_loss: 0.5100 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.5772 - val_accuracy: 0.8261 - val_loss: 0.4465 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.5257 - val_accuracy: 0.8176 - val_loss: 0.4793 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.4940 - val_accuracy: 0.8543 - val_loss: 0.3912 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.4642 - val_accuracy: 0.8485 - val_loss: 0.3843 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.4412 - val_accuracy: 0.8593 - val_loss: 0.3548 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.4202 - val_accuracy: 0.8582 - val_loss: 0.3595 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8447 - loss: 0.4072 - val_accuracy: 0.8657 - val_loss: 0.3430 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3879 - val_accuracy: 0.8731 - val_loss: 0.3190 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 0.3815 - val_accuracy: 0.8666 - val_loss: 0.3245 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.3676 - val_accuracy: 0.8768 - val_loss: 0.2998 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8612 - loss: 0.3599 - val_accuracy: 0.8774 - val_loss: 0.3025 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.3492 - val_accuracy: 0.8659 - val_loss: 0.3188 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8664 - loss: 0.3437 - val_accuracy: 0.8872 - val_loss: 0.2812 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8714 - loss: 0.3347 - val_accuracy: 0.8766 - val_loss: 0.3043 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.3307 - val_accuracy: 0.8843 - val_loss: 0.2817 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3247 - val_accuracy: 0.8857 - val_loss: 0.2762 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.3230 - val_accuracy: 0.8868 - val_loss: 0.2821 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.3145 - val_accuracy: 0.8906 - val_loss: 0.2639 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8814 - loss: 0.3029 - val_accuracy: 0.8912 - val_loss: 0.2673 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.3074 - val_accuracy: 0.8839 - val_loss: 0.2768 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.3066 - val_accuracy: 0.8847 - val_loss: 0.2781 - learning_rate: 8.5700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8809 - loss: 0.2989 - val_accuracy: 0.8988 - val_loss: 0.2455 - learning_rate: 8.5700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.2919 - val_accuracy: 0.8923 - val_loss: 0.2671 - learning_rate: 8.5700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.2923 - val_accuracy: 0.8972 - val_loss: 0.2485 - learning_rate: 8.5700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.2836 - val_accuracy: 0.8916 - val_loss: 0.2669 - learning_rate: 8.5700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.2844 - val_accuracy: 0.8928 - val_loss: 0.2535 - learning_rate: 8.5700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.2761\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.2761 - val_accuracy: 0.8967 - val_loss: 0.2488 - learning_rate: 8.5700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.2496 - val_accuracy: 0.9105 - val_loss: 0.2263 - learning_rate: 4.2850e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2396 - val_accuracy: 0.9105 - val_loss: 0.2104 - learning_rate: 4.2850e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9035 - loss: 0.2372 - val_accuracy: 0.9077 - val_loss: 0.2212 - learning_rate: 4.2850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.2316 - val_accuracy: 0.9027 - val_loss: 0.2426 - learning_rate: 4.2850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9078 - loss: 0.2324 - val_accuracy: 0.9168 - val_loss: 0.2050 - learning_rate: 4.2850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9091 - loss: 0.2267 - val_accuracy: 0.9140 - val_loss: 0.2067 - learning_rate: 4.2850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.2285 - val_accuracy: 0.9132 - val_loss: 0.2057 - learning_rate: 4.2850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2246 - val_accuracy: 0.9122 - val_loss: 0.2128 - learning_rate: 4.2850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2234 - val_accuracy: 0.9071 - val_loss: 0.2220 - learning_rate: 4.2850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2259\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2259 - val_accuracy: 0.9120 - val_loss: 0.2124 - learning_rate: 4.2850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2018 - val_accuracy: 0.9215 - val_loss: 0.1849 - learning_rate: 2.1425e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.1988 - val_accuracy: 0.9200 - val_loss: 0.1952 - learning_rate: 2.1425e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.2015 - val_accuracy: 0.9254 - val_loss: 0.1863 - learning_rate: 2.1425e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.1968 - val_accuracy: 0.9243 - val_loss: 0.1847 - learning_rate: 2.1425e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.1958 - val_accuracy: 0.9264 - val_loss: 0.1862 - learning_rate: 2.1425e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.1949 - val_accuracy: 0.9243 - val_loss: 0.1830 - learning_rate: 2.1425e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.1933 - val_accuracy: 0.9214 - val_loss: 0.1917 - learning_rate: 2.1425e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.1956 - val_accuracy: 0.9239 - val_loss: 0.1840 - learning_rate: 2.1425e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.1947 - val_accuracy: 0.9213 - val_loss: 0.1935 - learning_rate: 2.1425e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.1912 - val_accuracy: 0.9252 - val_loss: 0.1803 - learning_rate: 2.1425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.1890 - val_accuracy: 0.9280 - val_loss: 0.1789 - learning_rate: 2.1425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.1889 - val_accuracy: 0.9252 - val_loss: 0.1810 - learning_rate: 2.1425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.1873 - val_accuracy: 0.9250 - val_loss: 0.1866 - learning_rate: 2.1425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.1869 - val_accuracy: 0.9240 - val_loss: 0.1807 - learning_rate: 2.1425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.1900 - val_accuracy: 0.9250 - val_loss: 0.1797 - learning_rate: 2.1425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.1855\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.1855 - val_accuracy: 0.9262 - val_loss: 0.1821 - learning_rate: 2.1425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.1801 - val_accuracy: 0.9314 - val_loss: 0.1680 - learning_rate: 1.0713e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9302 - loss: 0.1706 - val_accuracy: 0.9305 - val_loss: 0.1709 - learning_rate: 1.0713e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.1688 - val_accuracy: 0.9319 - val_loss: 0.1714 - learning_rate: 1.0713e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.1739 - val_accuracy: 0.9313 - val_loss: 0.1697 - learning_rate: 1.0713e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.1670 - val_accuracy: 0.9354 - val_loss: 0.1650 - learning_rate: 1.0713e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.1690 - val_accuracy: 0.9309 - val_loss: 0.1665 - learning_rate: 1.0713e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9308 - loss: 0.1680 - val_accuracy: 0.9295 - val_loss: 0.1699 - learning_rate: 1.0713e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.1710 - val_accuracy: 0.9334 - val_loss: 0.1678 - learning_rate: 1.0713e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.1666 - val_accuracy: 0.9287 - val_loss: 0.1721 - learning_rate: 1.0713e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9330 - loss: 0.1655 - val_accuracy: 0.9336 - val_loss: 0.1643 - learning_rate: 1.0713e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.1651 - val_accuracy: 0.9332 - val_loss: 0.1641 - learning_rate: 1.0713e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9332 - loss: 0.1650 - val_accuracy: 0.9303 - val_loss: 0.1732 - learning_rate: 1.0713e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1637 - val_accuracy: 0.9338 - val_loss: 0.1664 - learning_rate: 1.0713e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.1652 - val_accuracy: 0.9352 - val_loss: 0.1625 - learning_rate: 1.0713e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9335 - loss: 0.1650 - val_accuracy: 0.9334 - val_loss: 0.1606 - learning_rate: 1.0713e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9328 - loss: 0.1642 - val_accuracy: 0.9337 - val_loss: 0.1628 - learning_rate: 1.0713e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.1664 - val_accuracy: 0.9366 - val_loss: 0.1616 - learning_rate: 1.0713e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1633 - val_accuracy: 0.9338 - val_loss: 0.1643 - learning_rate: 1.0713e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.1639 - val_accuracy: 0.9296 - val_loss: 0.1694 - learning_rate: 1.0713e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.1639\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.1639 - val_accuracy: 0.9330 - val_loss: 0.1667 - learning_rate: 1.0713e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.1547 - val_accuracy: 0.9363 - val_loss: 0.1561 - learning_rate: 5.3563e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.1589 - val_accuracy: 0.9348 - val_loss: 0.1589 - learning_rate: 5.3563e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.1556 - val_accuracy: 0.9371 - val_loss: 0.1554 - learning_rate: 5.3563e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.1571 - val_accuracy: 0.9358 - val_loss: 0.1603 - learning_rate: 5.3563e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9366 - loss: 0.1543 - val_accuracy: 0.9391 - val_loss: 0.1555 - learning_rate: 5.3563e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.1586 - val_accuracy: 0.9362 - val_loss: 0.1601 - learning_rate: 5.3563e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9389 - loss: 0.1538 - val_accuracy: 0.9378 - val_loss: 0.1573 - learning_rate: 5.3563e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.1546\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 2.678125019883737e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.1546 - val_accuracy: 0.9355 - val_loss: 0.1616 - learning_rate: 5.3563e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1497 - val_accuracy: 0.9389 - val_loss: 0.1543 - learning_rate: 2.6781e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.1502 - val_accuracy: 0.9382 - val_loss: 0.1546 - learning_rate: 2.6781e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.1497 - val_accuracy: 0.9377 - val_loss: 0.1554 - learning_rate: 2.6781e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1525 - val_accuracy: 0.9394 - val_loss: 0.1565 - learning_rate: 2.6781e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.1535 - val_accuracy: 0.9376 - val_loss: 0.1554 - learning_rate: 2.6781e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2550/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.1495\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.3390625099418685e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.1495 - val_accuracy: 0.9376 - val_loss: 0.1554 - learning_rate: 2.6781e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.1504 - val_accuracy: 0.9392 - val_loss: 0.1536 - learning_rate: 1.3391e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.1491 - val_accuracy: 0.9386 - val_loss: 0.1538 - learning_rate: 1.3391e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9382 - loss: 0.1529 - val_accuracy: 0.9378 - val_loss: 0.1557 - learning_rate: 1.3391e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.1526 - val_accuracy: 0.9389 - val_loss: 0.1543 - learning_rate: 1.3391e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1496 - val_accuracy: 0.9396 - val_loss: 0.1523 - learning_rate: 1.3391e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1482 - val_accuracy: 0.9392 - val_loss: 0.1523 - learning_rate: 1.3391e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1489 - val_accuracy: 0.9388 - val_loss: 0.1535 - learning_rate: 1.3391e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 0.1501 - val_accuracy: 0.9392 - val_loss: 0.1536 - learning_rate: 1.3391e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 0.1492 - val_accuracy: 0.9381 - val_loss: 0.1550 - learning_rate: 1.3391e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2986 - loss: 2.1406 - val_accuracy: 0.6624 - val_loss: 0.9387 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 1.0221 - val_accuracy: 0.7367 - val_loss: 0.6949 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.7830 - val_accuracy: 0.7585 - val_loss: 0.6328 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.6753 - val_accuracy: 0.8017 - val_loss: 0.5025 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7783 - loss: 0.5960 - val_accuracy: 0.8117 - val_loss: 0.4733 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.5489 - val_accuracy: 0.8392 - val_loss: 0.4140 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.4999 - val_accuracy: 0.8313 - val_loss: 0.4116 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4741 - val_accuracy: 0.8438 - val_loss: 0.3981 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.4514 - val_accuracy: 0.8514 - val_loss: 0.3808 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.4251 - val_accuracy: 0.8382 - val_loss: 0.3931 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.4101 - val_accuracy: 0.8616 - val_loss: 0.3555 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3893 - val_accuracy: 0.8634 - val_loss: 0.3323 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 0.3768 - val_accuracy: 0.8646 - val_loss: 0.3301 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.3662 - val_accuracy: 0.8778 - val_loss: 0.3152 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 0.3647 - val_accuracy: 0.8675 - val_loss: 0.3366 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3487 - val_accuracy: 0.8620 - val_loss: 0.3621 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.3435 - val_accuracy: 0.8797 - val_loss: 0.3032 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3328 - val_accuracy: 0.8573 - val_loss: 0.3332 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3300 - val_accuracy: 0.8622 - val_loss: 0.3430 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.3198 - val_accuracy: 0.8916 - val_loss: 0.2758 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.3170 - val_accuracy: 0.8978 - val_loss: 0.2513 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.3110 - val_accuracy: 0.8567 - val_loss: 0.3397 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.3081 - val_accuracy: 0.8873 - val_loss: 0.2840 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.3006 - val_accuracy: 0.8931 - val_loss: 0.2666 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.2935 - val_accuracy: 0.8897 - val_loss: 0.2779 - learning_rate: 8.5700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2957\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2957 - val_accuracy: 0.8742 - val_loss: 0.3102 - learning_rate: 8.5700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8985 - loss: 0.2565 - val_accuracy: 0.9002 - val_loss: 0.2432 - learning_rate: 4.2850e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2407 - val_accuracy: 0.9092 - val_loss: 0.2290 - learning_rate: 4.2850e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2334 - val_accuracy: 0.9083 - val_loss: 0.2317 - learning_rate: 4.2850e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9072 - loss: 0.2356 - val_accuracy: 0.9091 - val_loss: 0.2228 - learning_rate: 4.2850e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.2373 - val_accuracy: 0.9106 - val_loss: 0.2200 - learning_rate: 4.2850e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2300 - val_accuracy: 0.9117 - val_loss: 0.2187 - learning_rate: 4.2850e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2304 - val_accuracy: 0.9157 - val_loss: 0.2082 - learning_rate: 4.2850e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2236 - val_accuracy: 0.9121 - val_loss: 0.2103 - learning_rate: 4.2850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2252 - val_accuracy: 0.9120 - val_loss: 0.2135 - learning_rate: 4.2850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2259 - val_accuracy: 0.9199 - val_loss: 0.1962 - learning_rate: 4.2850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2216 - val_accuracy: 0.9174 - val_loss: 0.2026 - learning_rate: 4.2850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2157 - val_accuracy: 0.9160 - val_loss: 0.1993 - learning_rate: 4.2850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2175 - val_accuracy: 0.9190 - val_loss: 0.2074 - learning_rate: 4.2850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2186 - val_accuracy: 0.9180 - val_loss: 0.2024 - learning_rate: 4.2850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2198\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2198 - val_accuracy: 0.9146 - val_loss: 0.2088 - learning_rate: 4.2850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.1937 - val_accuracy: 0.9291 - val_loss: 0.1794 - learning_rate: 2.1425e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.1861 - val_accuracy: 0.9257 - val_loss: 0.1834 - learning_rate: 2.1425e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9226 - loss: 0.1950 - val_accuracy: 0.9319 - val_loss: 0.1718 - learning_rate: 2.1425e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.1842 - val_accuracy: 0.9244 - val_loss: 0.1856 - learning_rate: 2.1425e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9285 - loss: 0.1808 - val_accuracy: 0.9294 - val_loss: 0.1743 - learning_rate: 2.1425e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.1866 - val_accuracy: 0.9227 - val_loss: 0.1882 - learning_rate: 2.1425e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.1827 - val_accuracy: 0.9231 - val_loss: 0.1880 - learning_rate: 2.1425e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.1840\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1840 - val_accuracy: 0.9232 - val_loss: 0.1914 - learning_rate: 2.1425e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.1690 - val_accuracy: 0.9356 - val_loss: 0.1629 - learning_rate: 1.0713e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9341 - loss: 0.1692 - val_accuracy: 0.9335 - val_loss: 0.1649 - learning_rate: 1.0713e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1657 - val_accuracy: 0.9341 - val_loss: 0.1647 - learning_rate: 1.0713e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9349 - loss: 0.1660 - val_accuracy: 0.9325 - val_loss: 0.1676 - learning_rate: 1.0713e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.1671 - val_accuracy: 0.9344 - val_loss: 0.1638 - learning_rate: 1.0713e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.1643\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.1643 - val_accuracy: 0.9336 - val_loss: 0.1663 - learning_rate: 1.0713e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1529 - val_accuracy: 0.9348 - val_loss: 0.1590 - learning_rate: 5.3563e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.1576 - val_accuracy: 0.9368 - val_loss: 0.1574 - learning_rate: 5.3563e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1547 - val_accuracy: 0.9350 - val_loss: 0.1611 - learning_rate: 5.3563e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 0.1548 - val_accuracy: 0.9380 - val_loss: 0.1543 - learning_rate: 5.3563e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1557 - val_accuracy: 0.9362 - val_loss: 0.1561 - learning_rate: 5.3563e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.1514 - val_accuracy: 0.9361 - val_loss: 0.1575 - learning_rate: 5.3563e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.1544 - val_accuracy: 0.9365 - val_loss: 0.1578 - learning_rate: 5.3563e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1517 - val_accuracy: 0.9377 - val_loss: 0.1574 - learning_rate: 5.3563e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1493\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.678125019883737e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9404 - loss: 0.1493 - val_accuracy: 0.9359 - val_loss: 0.1576 - learning_rate: 5.3563e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1473 - val_accuracy: 0.9400 - val_loss: 0.1528 - learning_rate: 2.6781e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.1486 - val_accuracy: 0.9385 - val_loss: 0.1520 - learning_rate: 2.6781e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1494 - val_accuracy: 0.9398 - val_loss: 0.1521 - learning_rate: 2.6781e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.1452 - val_accuracy: 0.9385 - val_loss: 0.1522 - learning_rate: 2.6781e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1431 - val_accuracy: 0.9401 - val_loss: 0.1500 - learning_rate: 2.6781e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1482 - val_accuracy: 0.9397 - val_loss: 0.1499 - learning_rate: 2.6781e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.1504 - val_accuracy: 0.9395 - val_loss: 0.1520 - learning_rate: 2.6781e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1472 - val_accuracy: 0.9401 - val_loss: 0.1518 - learning_rate: 2.6781e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1474 - val_accuracy: 0.9402 - val_loss: 0.1519 - learning_rate: 2.6781e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1467\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.3390625099418685e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9416 - loss: 0.1467 - val_accuracy: 0.9391 - val_loss: 0.1515 - learning_rate: 2.6781e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1428 - val_accuracy: 0.9394 - val_loss: 0.1501 - learning_rate: 1.3391e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1448 - val_accuracy: 0.9394 - val_loss: 0.1495 - learning_rate: 1.3391e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1454 - val_accuracy: 0.9399 - val_loss: 0.1498 - learning_rate: 1.3391e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1451 - val_accuracy: 0.9410 - val_loss: 0.1493 - learning_rate: 1.3391e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1447 - val_accuracy: 0.9410 - val_loss: 0.1489 - learning_rate: 1.3391e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.1427 - val_accuracy: 0.9417 - val_loss: 0.1482 - learning_rate: 1.3391e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.1430 - val_accuracy: 0.9411 - val_loss: 0.1498 - learning_rate: 1.3391e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9436 - loss: 0.1447 - val_accuracy: 0.9396 - val_loss: 0.1492 - learning_rate: 1.3391e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1443 - val_accuracy: 0.9415 - val_loss: 0.1484 - learning_rate: 1.3391e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1430 - val_accuracy: 0.9405 - val_loss: 0.1485 - learning_rate: 1.3391e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1455\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.695312549709342e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1455 - val_accuracy: 0.9411 - val_loss: 0.1500 - learning_rate: 1.3391e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.1427 - val_accuracy: 0.9413 - val_loss: 0.1482 - learning_rate: 6.6953e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.1430 - val_accuracy: 0.9415 - val_loss: 0.1484 - learning_rate: 6.6953e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1416 - val_accuracy: 0.9415 - val_loss: 0.1478 - learning_rate: 6.6953e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1416 - val_accuracy: 0.9417 - val_loss: 0.1476 - learning_rate: 6.6953e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.1432 - val_accuracy: 0.9415 - val_loss: 0.1481 - learning_rate: 6.6953e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.1432 - val_accuracy: 0.9406 - val_loss: 0.1480 - learning_rate: 6.6953e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1435 - val_accuracy: 0.9418 - val_loss: 0.1481 - learning_rate: 6.6953e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9427 - loss: 0.1449 - val_accuracy: 0.9414 - val_loss: 0.1477 - learning_rate: 6.6953e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9446 - loss: 0.1414\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.347656274854671e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9446 - loss: 0.1414 - val_accuracy: 0.9407 - val_loss: 0.1484 - learning_rate: 6.6953e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1390 - val_accuracy: 0.9414 - val_loss: 0.1476 - learning_rate: 3.3477e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9441 - loss: 0.1436 - val_accuracy: 0.9420 - val_loss: 0.1472 - learning_rate: 3.3477e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.1416 - val_accuracy: 0.9418 - val_loss: 0.1477 - learning_rate: 3.3477e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9446 - loss: 0.1420 - val_accuracy: 0.9412 - val_loss: 0.1474 - learning_rate: 3.3477e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.1393 - val_accuracy: 0.9414 - val_loss: 0.1478 - learning_rate: 3.3477e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.1403 - val_accuracy: 0.9415 - val_loss: 0.1477 - learning_rate: 3.3477e-06\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "42067  0.731040  35.683145  37.190568  41.020322  25.097006   8.889750   \n",
      "4068   0.781795  37.600943  10.203648  27.261646  33.133566  13.284000   \n",
      "67482  0.431197  35.812459  10.846272  32.246591  22.353351   7.169837   \n",
      "15777  0.336800  35.915573  40.123872  45.478398  31.734770   5.029500   \n",
      "84663  0.773760  36.516101  15.631120  42.052104  28.281582   7.206000   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "52045  0.682830  36.477197  17.978352  34.559966  25.455949   8.474552   \n",
      "56175  0.654408  36.157688  17.252928  31.375414  22.553189   6.523766   \n",
      "94453  0.674812  36.756301  21.873897  30.808221  25.088126   7.069973   \n",
      "97651  0.418018  35.913098   7.021783  33.695340  25.445428   8.168097   \n",
      "10558  0.865760  37.378185  33.764448  30.165489  23.690868   8.790614   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "42067  10.918302   5.440000  0.0     1.0           1.0  \n",
      "4068  -71.808750   9.723269  0.0     0.0           0.0  \n",
      "67482  11.148500   9.246732  0.0     0.0           1.0  \n",
      "15777   8.812887   9.916500  0.0     1.0           0.0  \n",
      "84663   6.126210   4.700750  0.0     1.0           0.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "52045   9.136250   6.322128  0.0     0.0           0.0  \n",
      "56175   8.479000   7.180186  0.0     0.0           0.0  \n",
      "94453   7.787613  28.744283  0.0     0.0           1.0  \n",
      "97651  10.146348   6.084043  0.0     0.0           1.0  \n",
      "10558   6.138250   6.401887  1.0     0.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "42067  0.731040  35.683145  37.190568  41.020322  25.097006   8.889750   \n",
      "4068   0.781795  37.600943  10.203648  27.261646  33.133566  13.284000   \n",
      "67482  0.431197  35.812459  10.846272  32.246591  22.353351   7.169837   \n",
      "15777  0.336800  35.915573  40.123872  45.478398  31.734770   5.029500   \n",
      "84663  0.773760  36.516101  15.631120  42.052104  28.281582   7.206000   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "52045  0.682830  36.477197  17.978352  34.559966  25.455949   8.474552   \n",
      "56175  0.654408  36.157688  17.252928  31.375414  22.553189   6.523766   \n",
      "94453  0.674812  36.756301  21.873897  30.808221  25.088126   7.069973   \n",
      "97651  0.418018  35.913098   7.021783  33.695340  25.445428   8.168097   \n",
      "10558  0.865760  37.378185  33.764448  30.165489  23.690868   8.790614   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "42067  10.918302   5.440000  0.0     1.0           1.0  \n",
      "4068  -71.808750   9.723269  0.0     0.0           1.0  \n",
      "67482  11.148500   9.246732  0.0     0.0           0.0  \n",
      "15777   8.812887   9.916500  0.0     1.0           0.0  \n",
      "84663   6.126210   4.700750  0.0     1.0           0.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "52045   9.136250   6.322128  0.0     0.0           1.0  \n",
      "56175   8.479000   7.180186  0.0     0.0           1.0  \n",
      "94453   7.787613  28.744283  0.0     0.0           1.0  \n",
      "97651  10.146348   6.084043  0.0     0.0           0.0  \n",
      "10558   6.138250   6.401887  1.0     0.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5105\n",
      "  Base Rate: 0.5029\n",
      "  Selection Rate: 0.5070\n",
      "  Disparate Impact: 0.7844\n",
      "  Statistical Parity Difference: -0.1211\n",
      "  Between Group Coefficient of Variation: 0.1306\n",
      "  Between Group Generalized Entropy Index: 0.0085\n",
      "  Between Group Theil Index: 0.0086\n",
      "  Mean Difference: -0.1211\n",
      "  Smoothed Empirical Differential Fairness: 0.2923\n",
      "  Consistency: 0.9521\n",
      "  Average Absolute Odds Difference: 0.1270\n",
      "  Average Odds Difference: -0.1270\n",
      "  Average Predictive Value Difference: 0.1471\n",
      "  Between All Groups Coefficient of Variation: 0.1306\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6967\n",
      "  Differential Fairness Bias Amplification: -0.0482\n",
      "  Equal Opportunity Difference: -0.1171\n",
      "  Equalized Odds Difference: 0.1369\n",
      "  Error Rate: 0.4895\n",
      "  Error Rate Difference: -0.0075\n",
      "  Error Rate Ratio: 0.9847\n",
      "  False Discovery Rate: 0.4867\n",
      "  False Discovery Rate Difference: -0.1567\n",
      "  False Discovery Rate Ratio: 0.7142\n",
      "  False Negative Rate: 0.4825\n",
      "  False Negative Rate Difference: 0.1171\n",
      "  False Negative Rate Ratio: 1.2779\n",
      "  False Omission Rate: 0.4923\n",
      "  False Omission Rate Difference: 0.1375\n",
      "  False Omission Rate Ratio: 1.3261\n",
      "  False Positive Rate: 0.4965\n",
      "  False Positive Rate Difference: -0.1369\n",
      "  False Positive Rate Ratio: 0.7505\n",
      "  Generalized Entropy Index: 0.2427\n",
      "  Generalized Equalized Odds Difference: 0.1369\n",
      "  Generalized False Negative Rate: 0.4825\n",
      "  Generalized False Positive Rate: 0.4965\n",
      "  Generalized True Negative Rate: 0.5035\n",
      "  Generalized True Positive Rate: 0.5175\n",
      "  Negative Predictive Value: 0.5077\n",
      "  Number of False Negatives: 2487.0000\n",
      "  Number of False Positives: 2529.0000\n",
      "  Number of Generalized False Negatives: 2487.0000\n",
      "  Number of Generalized False Positives: 2529.0000\n",
      "  Number of Generalized True Negatives: 2565.0000\n",
      "  Number of Generalized True Positives: 2667.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5094.0000\n",
      "  Number of Positives: 5154.0000\n",
      "  Number of Predicted Negatives: 5052.0000\n",
      "  Number of Predicted Positives: 5196.0000\n",
      "  Number of True Negatives: 2565.0000\n",
      "  Number of True Positives: 2667.0000\n",
      "  Positive Predictive Value: 0.5133\n",
      "  Power: 2667.0000\n",
      "  Precision: 0.5133\n",
      "  Recall: 0.5175\n",
      "  Sensitivity: 0.5175\n",
      "  Specificity: 0.5035\n",
      "  Theil Index: 0.3366\n",
      "  True Negative Rate: 0.5035\n",
      "  True Positive Rate: 0.5175\n",
      "  True Positive Rate Difference: -0.1171\n",
      "  Accuracy: 0.5105\n",
      "  Base Rate: 0.5029\n",
      "  Selection Rate: 0.5070\n",
      "  Disparate Impact: 0.7844\n",
      "  Statistical Parity Difference: -0.1211\n",
      "  Between Group Coefficient of Variation: 0.1306\n",
      "  Between Group Generalized Entropy Index: 0.0085\n",
      "  Between Group Theil Index: 0.0086\n",
      "  Mean Difference: -0.1211\n",
      "  Smoothed Empirical Differential Fairness: 0.2923\n",
      "  Consistency: 0.9521\n",
      "  Average Absolute Odds Difference: 0.1270\n",
      "  Average Odds Difference: -0.1270\n",
      "  Average Predictive Value Difference: 0.1471\n",
      "  Between All Groups Coefficient of Variation: 0.1306\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6967\n",
      "  Differential Fairness Bias Amplification: -0.0482\n",
      "  Equal Opportunity Difference: -0.1171\n",
      "  Equalized Odds Difference: 0.1369\n",
      "  Error Rate: 0.4895\n",
      "  Error Rate Difference: -0.0075\n",
      "  Error Rate Ratio: 0.9847\n",
      "  False Discovery Rate: 0.4867\n",
      "  False Discovery Rate Difference: -0.1567\n",
      "  False Discovery Rate Ratio: 0.7142\n",
      "  False Negative Rate: 0.4825\n",
      "  False Negative Rate Difference: 0.1171\n",
      "  False Negative Rate Ratio: 1.2779\n",
      "  False Omission Rate: 0.4923\n",
      "  False Omission Rate Difference: 0.1375\n",
      "  False Omission Rate Ratio: 1.3261\n",
      "  False Positive Rate: 0.4965\n",
      "  False Positive Rate Difference: -0.1369\n",
      "  False Positive Rate Ratio: 0.7505\n",
      "  Generalized Entropy Index: 0.2427\n",
      "  Generalized Equalized Odds Difference: 0.1369\n",
      "  Generalized False Negative Rate: 0.4825\n",
      "  Generalized False Positive Rate: 0.4965\n",
      "  Generalized True Negative Rate: 0.5035\n",
      "  Generalized True Positive Rate: 0.5175\n",
      "  Negative Predictive Value: 0.5077\n",
      "  Number of False Negatives: 2487.0000\n",
      "  Number of False Positives: 2529.0000\n",
      "  Number of Generalized False Negatives: 2487.0000\n",
      "  Number of Generalized False Positives: 2529.0000\n",
      "  Number of Generalized True Negatives: 2565.0000\n",
      "  Number of Generalized True Positives: 2667.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5094.0000\n",
      "  Number of Positives: 5154.0000\n",
      "  Number of Predicted Negatives: 5052.0000\n",
      "  Number of Predicted Positives: 5196.0000\n",
      "  Number of True Negatives: 2565.0000\n",
      "  Number of True Positives: 2667.0000\n",
      "  Positive Predictive Value: 0.5133\n",
      "  Power: 2667.0000\n",
      "  Precision: 0.5133\n",
      "  Recall: 0.5175\n",
      "  Sensitivity: 0.5175\n",
      "  Specificity: 0.5035\n",
      "  Theil Index: 0.3366\n",
      "  True Negative Rate: 0.5035\n",
      "  True Positive Rate: 0.5175\n",
      "  True Positive Rate Difference: -0.1171\n",
      "  Accuracy: 0.5148\n",
      "  Base Rate: 0.5036\n",
      "  Selection Rate: 0.5177\n",
      "  Disparate Impact: 0.7925\n",
      "  Statistical Parity Difference: -0.1186\n",
      "  Between Group Coefficient of Variation: 0.1302\n",
      "  Between Group Generalized Entropy Index: 0.0085\n",
      "  Between Group Theil Index: 0.0086\n",
      "  Mean Difference: -0.1186\n",
      "  Smoothed Empirical Differential Fairness: 0.3011\n",
      "  Consistency: 0.9515\n",
      "  Average Absolute Odds Difference: 0.1265\n",
      "  Average Odds Difference: -0.1265\n",
      "  Average Predictive Value Difference: 0.1517\n",
      "  Between All Groups Coefficient of Variation: 0.1302\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6867\n",
      "  Differential Fairness Bias Amplification: -0.0568\n",
      "  Equal Opportunity Difference: -0.1001\n",
      "  Equalized Odds Difference: 0.1528\n",
      "  Error Rate: 0.4852\n",
      "  Error Rate Difference: -0.0267\n",
      "  Error Rate Ratio: 0.9464\n",
      "  False Discovery Rate: 0.4822\n",
      "  False Discovery Rate Difference: -0.1772\n",
      "  False Discovery Rate Ratio: 0.6794\n",
      "  False Negative Rate: 0.4677\n",
      "  False Negative Rate Difference: 0.1001\n",
      "  False Negative Rate Ratio: 1.2413\n",
      "  False Omission Rate: 0.4884\n",
      "  False Omission Rate Difference: 0.1261\n",
      "  False Omission Rate Ratio: 1.2980\n",
      "  False Positive Rate: 0.5029\n",
      "  False Positive Rate Difference: -0.1528\n",
      "  False Positive Rate Ratio: 0.7277\n",
      "  Generalized Entropy Index: 0.2358\n",
      "  Generalized Equalized Odds Difference: 0.1528\n",
      "  Generalized False Negative Rate: 0.4677\n",
      "  Generalized False Positive Rate: 0.5029\n",
      "  Generalized True Negative Rate: 0.4971\n",
      "  Generalized True Positive Rate: 0.5323\n",
      "  Negative Predictive Value: 0.5116\n",
      "  Number of False Negatives: 2414.0000\n",
      "  Number of False Positives: 2558.0000\n",
      "  Number of Generalized False Negatives: 2414.0000\n",
      "  Number of Generalized False Positives: 2558.0000\n",
      "  Number of Generalized True Negatives: 2529.0000\n",
      "  Number of Generalized True Positives: 2747.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5087.0000\n",
      "  Number of Positives: 5161.0000\n",
      "  Number of Predicted Negatives: 4943.0000\n",
      "  Number of Predicted Positives: 5305.0000\n",
      "  Number of True Negatives: 2529.0000\n",
      "  Number of True Positives: 2747.0000\n",
      "  Positive Predictive Value: 0.5178\n",
      "  Power: 2747.0000\n",
      "  Precision: 0.5178\n",
      "  Recall: 0.5323\n",
      "  Sensitivity: 0.5323\n",
      "  Specificity: 0.4971\n",
      "  Theil Index: 0.3273\n",
      "  True Negative Rate: 0.4971\n",
      "  True Positive Rate: 0.5323\n",
      "  True Positive Rate Difference: -0.1001\n",
      "  Accuracy: 0.5148\n",
      "  Base Rate: 0.5036\n",
      "  Selection Rate: 0.5177\n",
      "  Disparate Impact: 0.7925\n",
      "  Statistical Parity Difference: -0.1186\n",
      "  Between Group Coefficient of Variation: 0.1302\n",
      "  Between Group Generalized Entropy Index: 0.0085\n",
      "  Between Group Theil Index: 0.0086\n",
      "  Mean Difference: -0.1186\n",
      "  Smoothed Empirical Differential Fairness: 0.3011\n",
      "  Consistency: 0.9515\n",
      "  Average Absolute Odds Difference: 0.1265\n",
      "  Average Odds Difference: -0.1265\n",
      "  Average Predictive Value Difference: 0.1517\n",
      "  Between All Groups Coefficient of Variation: 0.1302\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6867\n",
      "  Differential Fairness Bias Amplification: -0.0568\n",
      "  Equal Opportunity Difference: -0.1001\n",
      "  Equalized Odds Difference: 0.1528\n",
      "  Error Rate: 0.4852\n",
      "  Error Rate Difference: -0.0267\n",
      "  Error Rate Ratio: 0.9464\n",
      "  False Discovery Rate: 0.4822\n",
      "  False Discovery Rate Difference: -0.1772\n",
      "  False Discovery Rate Ratio: 0.6794\n",
      "  False Negative Rate: 0.4677\n",
      "  False Negative Rate Difference: 0.1001\n",
      "  False Negative Rate Ratio: 1.2413\n",
      "  False Omission Rate: 0.4884\n",
      "  False Omission Rate Difference: 0.1261\n",
      "  False Omission Rate Ratio: 1.2980\n",
      "  False Positive Rate: 0.5029\n",
      "  False Positive Rate Difference: -0.1528\n",
      "  False Positive Rate Ratio: 0.7277\n",
      "  Generalized Entropy Index: 0.2358\n",
      "  Generalized Equalized Odds Difference: 0.1528\n",
      "  Generalized False Negative Rate: 0.4677\n",
      "  Generalized False Positive Rate: 0.5029\n",
      "  Generalized True Negative Rate: 0.4971\n",
      "  Generalized True Positive Rate: 0.5323\n",
      "  Negative Predictive Value: 0.5116\n",
      "  Number of False Negatives: 2414.0000\n",
      "  Number of False Positives: 2558.0000\n",
      "  Number of Generalized False Negatives: 2414.0000\n",
      "  Number of Generalized False Positives: 2558.0000\n",
      "  Number of Generalized True Negatives: 2529.0000\n",
      "  Number of Generalized True Positives: 2747.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5087.0000\n",
      "  Number of Positives: 5161.0000\n",
      "  Number of Predicted Negatives: 4943.0000\n",
      "  Number of Predicted Positives: 5305.0000\n",
      "  Number of True Negatives: 2529.0000\n",
      "  Number of True Positives: 2747.0000\n",
      "  Positive Predictive Value: 0.5178\n",
      "  Power: 2747.0000\n",
      "  Precision: 0.5178\n",
      "  Recall: 0.5323\n",
      "  Sensitivity: 0.5323\n",
      "  Specificity: 0.4971\n",
      "  Theil Index: 0.3273\n",
      "  True Negative Rate: 0.4971\n",
      "  True Positive Rate: 0.5323\n",
      "  True Positive Rate Difference: -0.1001\n",
      "Protected Attribute Names: ['AGE']\n",
      "Privileged Protected Attributes: [{'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.5128\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5121\n",
      "  Disparate Impact: 1.1290\n",
      "  Statistical Parity Difference: 0.0645\n",
      "  Between Group Coefficient of Variation: 0.0284\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0645\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1283\n",
      "  Average Odds Difference: 0.0643\n",
      "  Average Predictive Value Difference: -0.0236\n",
      "  Between All Groups Coefficient of Variation: 0.0284\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6943\n",
      "  Differential Fairness Bias Amplification: 0.1212\n",
      "  Equal Opportunity Difference: 0.1927\n",
      "  Equalized Odds Difference: 0.1927\n",
      "  Error Rate: 0.4872\n",
      "  Error Rate Difference: -0.1283\n",
      "  Error Rate Ratio: 0.7491\n",
      "  False Discovery Rate: 0.4809\n",
      "  False Discovery Rate Difference: -0.1067\n",
      "  False Discovery Rate Ratio: 0.7880\n",
      "  False Negative Rate: 0.4755\n",
      "  False Negative Rate Difference: -0.1927\n",
      "  False Negative Rate Ratio: 0.6234\n",
      "  False Omission Rate: 0.4939\n",
      "  False Omission Rate Difference: -0.1539\n",
      "  False Omission Rate Ratio: 0.7040\n",
      "  False Positive Rate: 0.4993\n",
      "  False Positive Rate Difference: -0.0640\n",
      "  False Positive Rate Ratio: 0.8748\n",
      "  Generalized Entropy Index: 0.2410\n",
      "  Generalized Equalized Odds Difference: 0.1927\n",
      "  Generalized False Negative Rate: 0.4755\n",
      "  Generalized False Positive Rate: 0.4993\n",
      "  Generalized True Negative Rate: 0.5007\n",
      "  Generalized True Positive Rate: 0.5245\n",
      "  Negative Predictive Value: 0.5061\n",
      "  Number of False Negatives: 3704.0000\n",
      "  Number of False Positives: 3786.0000\n",
      "  Number of Generalized False Negatives: 3704.0000\n",
      "  Number of Generalized False Positives: 3786.0000\n",
      "  Number of Generalized True Negatives: 3796.0000\n",
      "  Number of Generalized True Positives: 4086.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7500.0000\n",
      "  Number of Predicted Positives: 7872.0000\n",
      "  Number of True Negatives: 3796.0000\n",
      "  Number of True Positives: 4086.0000\n",
      "  Positive Predictive Value: 0.5191\n",
      "  Power: 4086.0000\n",
      "  Precision: 0.5191\n",
      "  Recall: 0.5245\n",
      "  Sensitivity: 0.5245\n",
      "  Specificity: 0.5007\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5007\n",
      "  True Positive Rate: 0.5245\n",
      "  True Positive Rate Difference: 0.1927\n",
      "  Accuracy: 0.5128\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5121\n",
      "  Disparate Impact: 1.1290\n",
      "  Statistical Parity Difference: 0.0645\n",
      "  Between Group Coefficient of Variation: 0.0284\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0645\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1283\n",
      "  Average Odds Difference: 0.0643\n",
      "  Average Predictive Value Difference: -0.0236\n",
      "  Between All Groups Coefficient of Variation: 0.0284\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6943\n",
      "  Differential Fairness Bias Amplification: 0.1212\n",
      "  Equal Opportunity Difference: 0.1927\n",
      "  Equalized Odds Difference: 0.1927\n",
      "  Error Rate: 0.4872\n",
      "  Error Rate Difference: -0.1283\n",
      "  Error Rate Ratio: 0.7491\n",
      "  False Discovery Rate: 0.4809\n",
      "  False Discovery Rate Difference: -0.1067\n",
      "  False Discovery Rate Ratio: 0.7880\n",
      "  False Negative Rate: 0.4755\n",
      "  False Negative Rate Difference: -0.1927\n",
      "  False Negative Rate Ratio: 0.6234\n",
      "  False Omission Rate: 0.4939\n",
      "  False Omission Rate Difference: -0.1539\n",
      "  False Omission Rate Ratio: 0.7040\n",
      "  False Positive Rate: 0.4993\n",
      "  False Positive Rate Difference: -0.0640\n",
      "  False Positive Rate Ratio: 0.8748\n",
      "  Generalized Entropy Index: 0.2410\n",
      "  Generalized Equalized Odds Difference: 0.1927\n",
      "  Generalized False Negative Rate: 0.4755\n",
      "  Generalized False Positive Rate: 0.4993\n",
      "  Generalized True Negative Rate: 0.5007\n",
      "  Generalized True Positive Rate: 0.5245\n",
      "  Negative Predictive Value: 0.5061\n",
      "  Number of False Negatives: 3704.0000\n",
      "  Number of False Positives: 3786.0000\n",
      "  Number of Generalized False Negatives: 3704.0000\n",
      "  Number of Generalized False Positives: 3786.0000\n",
      "  Number of Generalized True Negatives: 3796.0000\n",
      "  Number of Generalized True Positives: 4086.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7500.0000\n",
      "  Number of Predicted Positives: 7872.0000\n",
      "  Number of True Negatives: 3796.0000\n",
      "  Number of True Positives: 4086.0000\n",
      "  Positive Predictive Value: 0.5191\n",
      "  Power: 4086.0000\n",
      "  Precision: 0.5191\n",
      "  Recall: 0.5245\n",
      "  Sensitivity: 0.5245\n",
      "  Specificity: 0.5007\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5007\n",
      "  True Positive Rate: 0.5245\n",
      "  True Positive Rate Difference: 0.1927\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.3083 - loss: 2.1111 - val_accuracy: 0.6188 - val_loss: 1.0522 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6387 - loss: 1.0174 - val_accuracy: 0.7658 - val_loss: 0.6530 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.7665 - val_accuracy: 0.8025 - val_loss: 0.5413 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7589 - loss: 0.6521 - val_accuracy: 0.8254 - val_loss: 0.4563 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.5749 - val_accuracy: 0.8323 - val_loss: 0.4347 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.5276 - val_accuracy: 0.8466 - val_loss: 0.3937 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.4867 - val_accuracy: 0.8331 - val_loss: 0.4250 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.4598 - val_accuracy: 0.8189 - val_loss: 0.4524 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.4440 - val_accuracy: 0.8683 - val_loss: 0.3398 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.4178 - val_accuracy: 0.8656 - val_loss: 0.3442 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8437 - loss: 0.4049 - val_accuracy: 0.8759 - val_loss: 0.3184 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3972 - val_accuracy: 0.8793 - val_loss: 0.3134 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 0.3782 - val_accuracy: 0.8750 - val_loss: 0.3134 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3682 - val_accuracy: 0.8713 - val_loss: 0.3109 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3638 - val_accuracy: 0.8768 - val_loss: 0.3001 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3507 - val_accuracy: 0.8791 - val_loss: 0.3015 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3468 - val_accuracy: 0.8683 - val_loss: 0.3247 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3401 - val_accuracy: 0.8749 - val_loss: 0.3074 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.3321 - val_accuracy: 0.8841 - val_loss: 0.2934 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8687 - loss: 0.3328 - val_accuracy: 0.8847 - val_loss: 0.2891 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8698 - loss: 0.3274 - val_accuracy: 0.8743 - val_loss: 0.3131 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.3201 - val_accuracy: 0.8857 - val_loss: 0.2893 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.3132 - val_accuracy: 0.8930 - val_loss: 0.2630 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3091 - val_accuracy: 0.8951 - val_loss: 0.2654 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.3010 - val_accuracy: 0.8895 - val_loss: 0.2714 - learning_rate: 8.5700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2983 - val_accuracy: 0.8961 - val_loss: 0.2574 - learning_rate: 8.5700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2997 - val_accuracy: 0.8942 - val_loss: 0.2656 - learning_rate: 8.5700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2951 - val_accuracy: 0.8963 - val_loss: 0.2742 - learning_rate: 8.5700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2913 - val_accuracy: 0.9009 - val_loss: 0.2521 - learning_rate: 8.5700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.2865 - val_accuracy: 0.8767 - val_loss: 0.3011 - learning_rate: 8.5700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.2874 - val_accuracy: 0.8933 - val_loss: 0.2627 - learning_rate: 8.5700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.2806 - val_accuracy: 0.8991 - val_loss: 0.2548 - learning_rate: 8.5700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 0.2798 - val_accuracy: 0.8959 - val_loss: 0.2577 - learning_rate: 8.5700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2850\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2850 - val_accuracy: 0.8866 - val_loss: 0.2788 - learning_rate: 8.5700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9034 - loss: 0.2444 - val_accuracy: 0.9142 - val_loss: 0.2170 - learning_rate: 4.2850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2354 - val_accuracy: 0.9118 - val_loss: 0.2281 - learning_rate: 4.2850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9068 - loss: 0.2332 - val_accuracy: 0.9174 - val_loss: 0.2136 - learning_rate: 4.2850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2299 - val_accuracy: 0.9139 - val_loss: 0.2130 - learning_rate: 4.2850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2274 - val_accuracy: 0.9072 - val_loss: 0.2368 - learning_rate: 4.2850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2261 - val_accuracy: 0.9183 - val_loss: 0.2079 - learning_rate: 4.2850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2291 - val_accuracy: 0.9191 - val_loss: 0.2086 - learning_rate: 4.2850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.2261 - val_accuracy: 0.9135 - val_loss: 0.2168 - learning_rate: 4.2850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2214 - val_accuracy: 0.9171 - val_loss: 0.2111 - learning_rate: 4.2850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9122 - loss: 0.2196 - val_accuracy: 0.9130 - val_loss: 0.2223 - learning_rate: 4.2850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2191\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2191 - val_accuracy: 0.9112 - val_loss: 0.2308 - learning_rate: 4.2850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.1983 - val_accuracy: 0.9241 - val_loss: 0.1924 - learning_rate: 2.1425e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.1998 - val_accuracy: 0.9205 - val_loss: 0.1977 - learning_rate: 2.1425e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.1932 - val_accuracy: 0.9275 - val_loss: 0.1870 - learning_rate: 2.1425e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.1925 - val_accuracy: 0.9259 - val_loss: 0.1912 - learning_rate: 2.1425e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.1878 - val_accuracy: 0.9270 - val_loss: 0.1918 - learning_rate: 2.1425e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.1867 - val_accuracy: 0.9243 - val_loss: 0.1933 - learning_rate: 2.1425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.1880 - val_accuracy: 0.9211 - val_loss: 0.1962 - learning_rate: 2.1425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.1878 - val_accuracy: 0.9271 - val_loss: 0.1853 - learning_rate: 2.1425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.1850 - val_accuracy: 0.9283 - val_loss: 0.1832 - learning_rate: 2.1425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9258 - loss: 0.1857 - val_accuracy: 0.9269 - val_loss: 0.1901 - learning_rate: 2.1425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.1849 - val_accuracy: 0.9288 - val_loss: 0.1896 - learning_rate: 2.1425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.1831 - val_accuracy: 0.9242 - val_loss: 0.1954 - learning_rate: 2.1425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 0.1841 - val_accuracy: 0.9304 - val_loss: 0.1794 - learning_rate: 2.1425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.1804 - val_accuracy: 0.9310 - val_loss: 0.1786 - learning_rate: 2.1425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 0.1822 - val_accuracy: 0.9278 - val_loss: 0.1864 - learning_rate: 2.1425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.1855 - val_accuracy: 0.9316 - val_loss: 0.1873 - learning_rate: 2.1425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9278 - loss: 0.1786 - val_accuracy: 0.9285 - val_loss: 0.1830 - learning_rate: 2.1425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.1817 - val_accuracy: 0.9263 - val_loss: 0.1905 - learning_rate: 2.1425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.1767\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.1767 - val_accuracy: 0.9294 - val_loss: 0.1804 - learning_rate: 2.1425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9312 - loss: 0.1676 - val_accuracy: 0.9339 - val_loss: 0.1744 - learning_rate: 1.0713e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.1630 - val_accuracy: 0.9348 - val_loss: 0.1714 - learning_rate: 1.0713e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.1637 - val_accuracy: 0.9330 - val_loss: 0.1737 - learning_rate: 1.0713e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9331 - loss: 0.1651 - val_accuracy: 0.9360 - val_loss: 0.1703 - learning_rate: 1.0713e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1641 - val_accuracy: 0.9326 - val_loss: 0.1747 - learning_rate: 1.0713e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1608 - val_accuracy: 0.9335 - val_loss: 0.1758 - learning_rate: 1.0713e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.1594 - val_accuracy: 0.9357 - val_loss: 0.1712 - learning_rate: 1.0713e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.1588 - val_accuracy: 0.9347 - val_loss: 0.1676 - learning_rate: 1.0713e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.1608 - val_accuracy: 0.9340 - val_loss: 0.1736 - learning_rate: 1.0713e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.1591 - val_accuracy: 0.9324 - val_loss: 0.1713 - learning_rate: 1.0713e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.1606 - val_accuracy: 0.9359 - val_loss: 0.1724 - learning_rate: 1.0713e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.1580 - val_accuracy: 0.9305 - val_loss: 0.1746 - learning_rate: 1.0713e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.1567\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.1567 - val_accuracy: 0.9361 - val_loss: 0.1741 - learning_rate: 1.0713e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9381 - loss: 0.1540 - val_accuracy: 0.9361 - val_loss: 0.1687 - learning_rate: 5.3563e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.1503 - val_accuracy: 0.9383 - val_loss: 0.1665 - learning_rate: 5.3563e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9389 - loss: 0.1515 - val_accuracy: 0.9389 - val_loss: 0.1646 - learning_rate: 5.3563e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.1481 - val_accuracy: 0.9375 - val_loss: 0.1672 - learning_rate: 5.3563e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.1502 - val_accuracy: 0.9372 - val_loss: 0.1662 - learning_rate: 5.3563e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9397 - loss: 0.1497 - val_accuracy: 0.9378 - val_loss: 0.1635 - learning_rate: 5.3563e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1483 - val_accuracy: 0.9353 - val_loss: 0.1673 - learning_rate: 5.3563e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1505 - val_accuracy: 0.9340 - val_loss: 0.1696 - learning_rate: 5.3563e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1486 - val_accuracy: 0.9371 - val_loss: 0.1645 - learning_rate: 5.3563e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.1470 - val_accuracy: 0.9360 - val_loss: 0.1641 - learning_rate: 5.3563e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.1468\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.678125019883737e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.1468 - val_accuracy: 0.9374 - val_loss: 0.1672 - learning_rate: 5.3563e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.1424 - val_accuracy: 0.9396 - val_loss: 0.1630 - learning_rate: 2.6781e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1458 - val_accuracy: 0.9400 - val_loss: 0.1621 - learning_rate: 2.6781e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.1416 - val_accuracy: 0.9396 - val_loss: 0.1611 - learning_rate: 2.6781e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9430 - loss: 0.1423 - val_accuracy: 0.9410 - val_loss: 0.1607 - learning_rate: 2.6781e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.1439 - val_accuracy: 0.9407 - val_loss: 0.1608 - learning_rate: 2.6781e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1422 - val_accuracy: 0.9410 - val_loss: 0.1623 - learning_rate: 2.6781e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1400 - val_accuracy: 0.9408 - val_loss: 0.1610 - learning_rate: 2.6781e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1414 - val_accuracy: 0.9399 - val_loss: 0.1609 - learning_rate: 2.6781e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1419\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.3390625099418685e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1419 - val_accuracy: 0.9415 - val_loss: 0.1617 - learning_rate: 2.6781e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1406 - val_accuracy: 0.9416 - val_loss: 0.1600 - learning_rate: 1.3391e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.1387 - val_accuracy: 0.9407 - val_loss: 0.1601 - learning_rate: 1.3391e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9436 - loss: 0.1419 - val_accuracy: 0.9416 - val_loss: 0.1591 - learning_rate: 1.3391e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.3050 - loss: 2.1199 - val_accuracy: 0.6458 - val_loss: 1.0198 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 1.0328 - val_accuracy: 0.7423 - val_loss: 0.6838 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7175 - loss: 0.7815 - val_accuracy: 0.7810 - val_loss: 0.5749 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.6602 - val_accuracy: 0.8240 - val_loss: 0.4559 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.5760 - val_accuracy: 0.8313 - val_loss: 0.4439 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.5240 - val_accuracy: 0.8603 - val_loss: 0.3857 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8193 - loss: 0.4837 - val_accuracy: 0.8123 - val_loss: 0.4863 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 0.4510 - val_accuracy: 0.8612 - val_loss: 0.3670 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.4316 - val_accuracy: 0.8555 - val_loss: 0.3655 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 0.4162 - val_accuracy: 0.8745 - val_loss: 0.3130 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8509 - loss: 0.3937 - val_accuracy: 0.8581 - val_loss: 0.3771 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8525 - loss: 0.3849 - val_accuracy: 0.8618 - val_loss: 0.3410 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.3753 - val_accuracy: 0.8646 - val_loss: 0.3325 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.3623 - val_accuracy: 0.8845 - val_loss: 0.2816 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8696 - loss: 0.3440 - val_accuracy: 0.8804 - val_loss: 0.2937 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 0.3401 - val_accuracy: 0.8639 - val_loss: 0.3306 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.3352 - val_accuracy: 0.8929 - val_loss: 0.2683 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8741 - loss: 0.3252 - val_accuracy: 0.8870 - val_loss: 0.2812 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8767 - loss: 0.3198 - val_accuracy: 0.9000 - val_loss: 0.2531 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8796 - loss: 0.3137 - val_accuracy: 0.8912 - val_loss: 0.2635 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.3100 - val_accuracy: 0.8839 - val_loss: 0.2815 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.3068 - val_accuracy: 0.8886 - val_loss: 0.2675 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3046 - val_accuracy: 0.8883 - val_loss: 0.2804 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.2955\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2955 - val_accuracy: 0.8937 - val_loss: 0.2577 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.2560 - val_accuracy: 0.9104 - val_loss: 0.2177 - learning_rate: 4.2850e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.2532 - val_accuracy: 0.9040 - val_loss: 0.2334 - learning_rate: 4.2850e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9053 - loss: 0.2435 - val_accuracy: 0.9096 - val_loss: 0.2200 - learning_rate: 4.2850e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.2410 - val_accuracy: 0.9133 - val_loss: 0.2221 - learning_rate: 4.2850e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9059 - loss: 0.2381 - val_accuracy: 0.9099 - val_loss: 0.2143 - learning_rate: 4.2850e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2353 - val_accuracy: 0.9197 - val_loss: 0.2003 - learning_rate: 4.2850e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9077 - loss: 0.2348 - val_accuracy: 0.9179 - val_loss: 0.2048 - learning_rate: 4.2850e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2299 - val_accuracy: 0.9145 - val_loss: 0.2085 - learning_rate: 4.2850e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2279 - val_accuracy: 0.9143 - val_loss: 0.2019 - learning_rate: 4.2850e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2233 - val_accuracy: 0.9091 - val_loss: 0.2097 - learning_rate: 4.2850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2558/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.2292\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.2292 - val_accuracy: 0.9164 - val_loss: 0.2081 - learning_rate: 4.2850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2064 - val_accuracy: 0.9234 - val_loss: 0.1940 - learning_rate: 2.1425e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.1991 - val_accuracy: 0.9307 - val_loss: 0.1754 - learning_rate: 2.1425e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.1985 - val_accuracy: 0.9275 - val_loss: 0.1781 - learning_rate: 2.1425e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.1939 - val_accuracy: 0.9263 - val_loss: 0.1877 - learning_rate: 2.1425e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.1979 - val_accuracy: 0.9317 - val_loss: 0.1748 - learning_rate: 2.1425e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.1942 - val_accuracy: 0.9295 - val_loss: 0.1779 - learning_rate: 2.1425e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.1914 - val_accuracy: 0.9311 - val_loss: 0.1738 - learning_rate: 2.1425e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.1907 - val_accuracy: 0.9298 - val_loss: 0.1745 - learning_rate: 2.1425e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.1869 - val_accuracy: 0.9315 - val_loss: 0.1708 - learning_rate: 2.1425e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.1840 - val_accuracy: 0.9300 - val_loss: 0.1738 - learning_rate: 2.1425e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9258 - loss: 0.1876 - val_accuracy: 0.9299 - val_loss: 0.1717 - learning_rate: 2.1425e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.1806 - val_accuracy: 0.9322 - val_loss: 0.1691 - learning_rate: 2.1425e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9275 - loss: 0.1836 - val_accuracy: 0.9302 - val_loss: 0.1792 - learning_rate: 2.1425e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.1849 - val_accuracy: 0.9345 - val_loss: 0.1651 - learning_rate: 2.1425e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.1838 - val_accuracy: 0.9294 - val_loss: 0.1705 - learning_rate: 2.1425e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9274 - loss: 0.1822 - val_accuracy: 0.9325 - val_loss: 0.1715 - learning_rate: 2.1425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.1782 - val_accuracy: 0.9313 - val_loss: 0.1675 - learning_rate: 2.1425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1824 - val_accuracy: 0.9314 - val_loss: 0.1716 - learning_rate: 2.1425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.1797\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.1797 - val_accuracy: 0.9299 - val_loss: 0.1733 - learning_rate: 2.1425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.1653 - val_accuracy: 0.9382 - val_loss: 0.1564 - learning_rate: 1.0713e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.1671 - val_accuracy: 0.9401 - val_loss: 0.1524 - learning_rate: 1.0713e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.1630 - val_accuracy: 0.9368 - val_loss: 0.1617 - learning_rate: 1.0713e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.1641 - val_accuracy: 0.9362 - val_loss: 0.1567 - learning_rate: 1.0713e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.1597 - val_accuracy: 0.9375 - val_loss: 0.1561 - learning_rate: 1.0713e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.1581 - val_accuracy: 0.9366 - val_loss: 0.1581 - learning_rate: 1.0713e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.1604\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.1604 - val_accuracy: 0.9358 - val_loss: 0.1603 - learning_rate: 1.0713e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.1533 - val_accuracy: 0.9402 - val_loss: 0.1499 - learning_rate: 5.3563e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1526 - val_accuracy: 0.9410 - val_loss: 0.1502 - learning_rate: 5.3563e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1521 - val_accuracy: 0.9407 - val_loss: 0.1495 - learning_rate: 5.3563e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.1472 - val_accuracy: 0.9410 - val_loss: 0.1490 - learning_rate: 5.3563e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1492 - val_accuracy: 0.9415 - val_loss: 0.1481 - learning_rate: 5.3563e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.1526 - val_accuracy: 0.9407 - val_loss: 0.1495 - learning_rate: 5.3563e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.1538 - val_accuracy: 0.9417 - val_loss: 0.1476 - learning_rate: 5.3563e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.1514 - val_accuracy: 0.9391 - val_loss: 0.1500 - learning_rate: 5.3563e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9427 - loss: 0.1484 - val_accuracy: 0.9412 - val_loss: 0.1500 - learning_rate: 5.3563e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.1507 - val_accuracy: 0.9418 - val_loss: 0.1492 - learning_rate: 5.3563e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1476 - val_accuracy: 0.9395 - val_loss: 0.1476 - learning_rate: 5.3563e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1529 - val_accuracy: 0.9415 - val_loss: 0.1474 - learning_rate: 5.3563e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.1464 - val_accuracy: 0.9418 - val_loss: 0.1458 - learning_rate: 5.3563e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.1463 - val_accuracy: 0.9427 - val_loss: 0.1443 - learning_rate: 5.3563e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.1479 - val_accuracy: 0.9414 - val_loss: 0.1473 - learning_rate: 5.3563e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1505 - val_accuracy: 0.9416 - val_loss: 0.1482 - learning_rate: 5.3563e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.1502 - val_accuracy: 0.9421 - val_loss: 0.1471 - learning_rate: 5.3563e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.1462 - val_accuracy: 0.9420 - val_loss: 0.1442 - learning_rate: 5.3563e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.1463 - val_accuracy: 0.9438 - val_loss: 0.1421 - learning_rate: 5.3563e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1463 - val_accuracy: 0.9399 - val_loss: 0.1480 - learning_rate: 5.3563e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.1449 - val_accuracy: 0.9420 - val_loss: 0.1445 - learning_rate: 5.3563e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1467 - val_accuracy: 0.9409 - val_loss: 0.1472 - learning_rate: 5.3563e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.1460 - val_accuracy: 0.9427 - val_loss: 0.1445 - learning_rate: 5.3563e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1449\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 2.678125019883737e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1449 - val_accuracy: 0.9419 - val_loss: 0.1444 - learning_rate: 5.3563e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.1412 - val_accuracy: 0.9434 - val_loss: 0.1410 - learning_rate: 2.6781e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9438 - loss: 0.1428 - val_accuracy: 0.9425 - val_loss: 0.1426 - learning_rate: 2.6781e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9450 - loss: 0.1425 - val_accuracy: 0.9429 - val_loss: 0.1417 - learning_rate: 2.6781e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1408 - val_accuracy: 0.9447 - val_loss: 0.1402 - learning_rate: 2.6781e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1412 - val_accuracy: 0.9422 - val_loss: 0.1426 - learning_rate: 2.6781e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1418 - val_accuracy: 0.9446 - val_loss: 0.1420 - learning_rate: 2.6781e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1412 - val_accuracy: 0.9433 - val_loss: 0.1423 - learning_rate: 2.6781e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1413 - val_accuracy: 0.9444 - val_loss: 0.1403 - learning_rate: 2.6781e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1433 - val_accuracy: 0.9440 - val_loss: 0.1396 - learning_rate: 2.6781e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.1371 - val_accuracy: 0.9438 - val_loss: 0.1411 - learning_rate: 2.6781e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1401 - val_accuracy: 0.9444 - val_loss: 0.1415 - learning_rate: 2.6781e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1394 - val_accuracy: 0.9441 - val_loss: 0.1397 - learning_rate: 2.6781e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1356 - val_accuracy: 0.9416 - val_loss: 0.1427 - learning_rate: 2.6781e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1397\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.3390625099418685e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1397 - val_accuracy: 0.9448 - val_loss: 0.1401 - learning_rate: 2.6781e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1378 - val_accuracy: 0.9449 - val_loss: 0.1390 - learning_rate: 1.3391e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "14866  0.839460  35.547533  31.152312  45.300808  34.173081  7.616378   \n",
      "43103  0.944629  37.621052  37.403472  31.345868  25.119401  6.261107   \n",
      "12664  1.003740  36.545170  16.011816  32.390188  27.524348  5.563250   \n",
      "45116  0.333500  36.370819  36.737160  30.959946  24.900942  6.630873   \n",
      "13917  1.421000  35.388075  31.117116  42.167986  34.174622  6.384720   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "58585  0.872320  35.593604  13.475952  29.604071  23.313931  7.534500   \n",
      "93804  0.798581  36.555133  21.244779  32.879083  25.096612  6.815927   \n",
      "94147  0.772310  36.466396  21.022089  31.326035  25.094600  6.655247   \n",
      "792    0.694900  36.362852   7.080578  27.484257  28.634328  8.847164   \n",
      "5968   0.803320  35.857496  31.521096  29.545973  24.348137  8.799338   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "14866  15.453515   6.672000  0.0     1.0           0.0  \n",
      "43103   9.464750   5.070579  0.0     0.0           0.0  \n",
      "12664   7.168582  24.865250  0.0     0.0           1.0  \n",
      "45116  12.744612   5.563178  0.0     0.0           0.0  \n",
      "13917   9.957500   6.179250  0.0     1.0           1.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "58585   6.536743   5.070579  0.0     0.0           1.0  \n",
      "93804   6.774107  44.187966  0.0     0.0           1.0  \n",
      "94147  15.155318  56.227146  0.0     0.0           1.0  \n",
      "792     5.029500   7.456639  1.0     0.0           0.0  \n",
      "5968   37.829479  14.196535  1.0     0.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "14866  0.839460  35.547533  31.152312  45.300808  34.173081  7.616378   \n",
      "43103  0.944629  37.621052  37.403472  31.345868  25.119401  6.261107   \n",
      "12664  1.003740  36.545170  16.011816  32.390188  27.524348  5.563250   \n",
      "45116  0.333500  36.370819  36.737160  30.959946  24.900942  6.630873   \n",
      "13917  1.421000  35.388075  31.117116  42.167986  34.174622  6.384720   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "58585  0.872320  35.593604  13.475952  29.604071  23.313931  7.534500   \n",
      "93804  0.798581  36.555133  21.244779  32.879083  25.096612  6.815927   \n",
      "94147  0.772310  36.466396  21.022089  31.326035  25.094600  6.655247   \n",
      "792    0.694900  36.362852   7.080578  27.484257  28.634328  8.847164   \n",
      "5968   0.803320  35.857496  31.521096  29.545973  24.348137  8.799338   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "14866  15.453515   6.672000  0.0     1.0           0.0  \n",
      "43103   9.464750   5.070579  0.0     0.0           0.0  \n",
      "12664   7.168582  24.865250  0.0     0.0           1.0  \n",
      "45116  12.744612   5.563178  0.0     0.0           0.0  \n",
      "13917   9.957500   6.179250  0.0     1.0           0.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "58585   6.536743   5.070579  0.0     0.0           0.0  \n",
      "93804   6.774107  44.187966  0.0     0.0           1.0  \n",
      "94147  15.155318  56.227146  0.0     0.0           1.0  \n",
      "792     5.029500   7.456639  1.0     0.0           0.0  \n",
      "5968   37.829479  14.196535  1.0     0.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5174\n",
      "  Base Rate: 0.5070\n",
      "  Selection Rate: 0.5023\n",
      "  Disparate Impact: 1.1482\n",
      "  Statistical Parity Difference: 0.0724\n",
      "  Between Group Coefficient of Variation: 0.0233\n",
      "  Between Group Generalized Entropy Index: 0.0003\n",
      "  Between Group Theil Index: 0.0003\n",
      "  Mean Difference: 0.0724\n",
      "  Smoothed Empirical Differential Fairness: 0.0275\n",
      "  Consistency: 0.9529\n",
      "  Average Absolute Odds Difference: 0.1004\n",
      "  Average Odds Difference: 0.0689\n",
      "  Average Predictive Value Difference: 0.0014\n",
      "  Between All Groups Coefficient of Variation: 0.0233\n",
      "  Between All Groups Generalized Entropy Index: 0.0003\n",
      "  Between All Groups Theil Index: 0.0003\n",
      "  Coefficient of Variation: 0.6980\n",
      "  Differential Fairness Bias Amplification: 0.1251\n",
      "  Equal Opportunity Difference: 0.1693\n",
      "  Equalized Odds Difference: 0.1693\n",
      "  Error Rate: 0.4826\n",
      "  Error Rate Difference: -0.1026\n",
      "  Error Rate Ratio: 0.7957\n",
      "  False Discovery Rate: 0.4757\n",
      "  False Discovery Rate Difference: -0.1031\n",
      "  False Discovery Rate Ratio: 0.7928\n",
      "  False Negative Rate: 0.4806\n",
      "  False Negative Rate Difference: -0.1693\n",
      "  False Negative Rate Ratio: 0.6703\n",
      "  False Omission Rate: 0.4896\n",
      "  False Omission Rate Difference: -0.1004\n",
      "  False Omission Rate Ratio: 0.8017\n",
      "  False Positive Rate: 0.4848\n",
      "  False Positive Rate Difference: -0.0315\n",
      "  False Positive Rate Ratio: 0.9357\n",
      "  Generalized Entropy Index: 0.2436\n",
      "  Generalized Equalized Odds Difference: 0.1693\n",
      "  Generalized False Negative Rate: 0.4806\n",
      "  Generalized False Positive Rate: 0.4848\n",
      "  Generalized True Negative Rate: 0.5152\n",
      "  Generalized True Positive Rate: 0.5194\n",
      "  Negative Predictive Value: 0.5104\n",
      "  Number of False Negatives: 2497.0000\n",
      "  Number of False Positives: 2449.0000\n",
      "  Number of Generalized False Negatives: 2497.0000\n",
      "  Number of Generalized False Positives: 2449.0000\n",
      "  Number of Generalized True Negatives: 2603.0000\n",
      "  Number of Generalized True Positives: 2699.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5052.0000\n",
      "  Number of Positives: 5196.0000\n",
      "  Number of Predicted Negatives: 5100.0000\n",
      "  Number of Predicted Positives: 5148.0000\n",
      "  Number of True Negatives: 2603.0000\n",
      "  Number of True Positives: 2699.0000\n",
      "  Positive Predictive Value: 0.5243\n",
      "  Power: 2699.0000\n",
      "  Precision: 0.5243\n",
      "  Recall: 0.5194\n",
      "  Sensitivity: 0.5194\n",
      "  Specificity: 0.5152\n",
      "  Theil Index: 0.3375\n",
      "  True Negative Rate: 0.5152\n",
      "  True Positive Rate: 0.5194\n",
      "  True Positive Rate Difference: 0.1693\n",
      "  Accuracy: 0.5174\n",
      "  Base Rate: 0.5070\n",
      "  Selection Rate: 0.5023\n",
      "  Disparate Impact: 1.1482\n",
      "  Statistical Parity Difference: 0.0724\n",
      "  Between Group Coefficient of Variation: 0.0233\n",
      "  Between Group Generalized Entropy Index: 0.0003\n",
      "  Between Group Theil Index: 0.0003\n",
      "  Mean Difference: 0.0724\n",
      "  Smoothed Empirical Differential Fairness: 0.0275\n",
      "  Consistency: 0.9529\n",
      "  Average Absolute Odds Difference: 0.1004\n",
      "  Average Odds Difference: 0.0689\n",
      "  Average Predictive Value Difference: 0.0014\n",
      "  Between All Groups Coefficient of Variation: 0.0233\n",
      "  Between All Groups Generalized Entropy Index: 0.0003\n",
      "  Between All Groups Theil Index: 0.0003\n",
      "  Coefficient of Variation: 0.6980\n",
      "  Differential Fairness Bias Amplification: 0.1251\n",
      "  Equal Opportunity Difference: 0.1693\n",
      "  Equalized Odds Difference: 0.1693\n",
      "  Error Rate: 0.4826\n",
      "  Error Rate Difference: -0.1026\n",
      "  Error Rate Ratio: 0.7957\n",
      "  False Discovery Rate: 0.4757\n",
      "  False Discovery Rate Difference: -0.1031\n",
      "  False Discovery Rate Ratio: 0.7928\n",
      "  False Negative Rate: 0.4806\n",
      "  False Negative Rate Difference: -0.1693\n",
      "  False Negative Rate Ratio: 0.6703\n",
      "  False Omission Rate: 0.4896\n",
      "  False Omission Rate Difference: -0.1004\n",
      "  False Omission Rate Ratio: 0.8017\n",
      "  False Positive Rate: 0.4848\n",
      "  False Positive Rate Difference: -0.0315\n",
      "  False Positive Rate Ratio: 0.9357\n",
      "  Generalized Entropy Index: 0.2436\n",
      "  Generalized Equalized Odds Difference: 0.1693\n",
      "  Generalized False Negative Rate: 0.4806\n",
      "  Generalized False Positive Rate: 0.4848\n",
      "  Generalized True Negative Rate: 0.5152\n",
      "  Generalized True Positive Rate: 0.5194\n",
      "  Negative Predictive Value: 0.5104\n",
      "  Number of False Negatives: 2497.0000\n",
      "  Number of False Positives: 2449.0000\n",
      "  Number of Generalized False Negatives: 2497.0000\n",
      "  Number of Generalized False Positives: 2449.0000\n",
      "  Number of Generalized True Negatives: 2603.0000\n",
      "  Number of Generalized True Positives: 2699.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5052.0000\n",
      "  Number of Positives: 5196.0000\n",
      "  Number of Predicted Negatives: 5100.0000\n",
      "  Number of Predicted Positives: 5148.0000\n",
      "  Number of True Negatives: 2603.0000\n",
      "  Number of True Positives: 2699.0000\n",
      "  Positive Predictive Value: 0.5243\n",
      "  Power: 2699.0000\n",
      "  Precision: 0.5243\n",
      "  Recall: 0.5194\n",
      "  Sensitivity: 0.5194\n",
      "  Specificity: 0.5152\n",
      "  Theil Index: 0.3375\n",
      "  True Negative Rate: 0.5152\n",
      "  True Positive Rate: 0.5194\n",
      "  True Positive Rate Difference: 0.1693\n",
      "  Accuracy: 0.5175\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5208\n",
      "  Disparate Impact: 1.1389\n",
      "  Statistical Parity Difference: 0.0706\n",
      "  Between Group Coefficient of Variation: 0.0290\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0706\n",
      "  Smoothed Empirical Differential Fairness: 0.0128\n",
      "  Consistency: 0.9513\n",
      "  Average Absolute Odds Difference: 0.1151\n",
      "  Average Odds Difference: 0.0702\n",
      "  Average Predictive Value Difference: -0.0244\n",
      "  Between All Groups Coefficient of Variation: 0.0290\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6849\n",
      "  Differential Fairness Bias Amplification: 0.1421\n",
      "  Equal Opportunity Difference: 0.1853\n",
      "  Equalized Odds Difference: 0.1853\n",
      "  Error Rate: 0.4825\n",
      "  Error Rate Difference: -0.1152\n",
      "  Error Rate Ratio: 0.7709\n",
      "  False Discovery Rate: 0.4767\n",
      "  False Discovery Rate Difference: -0.0935\n",
      "  False Discovery Rate Ratio: 0.8112\n",
      "  False Negative Rate: 0.4623\n",
      "  False Negative Rate Difference: -0.1853\n",
      "  False Negative Rate Ratio: 0.6257\n",
      "  False Omission Rate: 0.4889\n",
      "  False Omission Rate Difference: -0.1424\n",
      "  False Omission Rate Ratio: 0.7215\n",
      "  False Positive Rate: 0.5034\n",
      "  False Positive Rate Difference: -0.0449\n",
      "  False Positive Rate Ratio: 0.9121\n",
      "  Generalized Entropy Index: 0.2346\n",
      "  Generalized Equalized Odds Difference: 0.1853\n",
      "  Generalized False Negative Rate: 0.4623\n",
      "  Generalized False Positive Rate: 0.5034\n",
      "  Generalized True Negative Rate: 0.4966\n",
      "  Generalized True Positive Rate: 0.5377\n",
      "  Negative Predictive Value: 0.5111\n",
      "  Number of False Negatives: 2401.0000\n",
      "  Number of False Positives: 2544.0000\n",
      "  Number of Generalized False Negatives: 2401.0000\n",
      "  Number of Generalized False Positives: 2544.0000\n",
      "  Number of Generalized True Negatives: 2510.0000\n",
      "  Number of Generalized True Positives: 2793.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5054.0000\n",
      "  Number of Positives: 5194.0000\n",
      "  Number of Predicted Negatives: 4911.0000\n",
      "  Number of Predicted Positives: 5337.0000\n",
      "  Number of True Negatives: 2510.0000\n",
      "  Number of True Positives: 2793.0000\n",
      "  Positive Predictive Value: 0.5233\n",
      "  Power: 2793.0000\n",
      "  Precision: 0.5233\n",
      "  Recall: 0.5377\n",
      "  Sensitivity: 0.5377\n",
      "  Specificity: 0.4966\n",
      "  Theil Index: 0.3255\n",
      "  True Negative Rate: 0.4966\n",
      "  True Positive Rate: 0.5377\n",
      "  True Positive Rate Difference: 0.1853\n",
      "  Accuracy: 0.5175\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5208\n",
      "  Disparate Impact: 1.1389\n",
      "  Statistical Parity Difference: 0.0706\n",
      "  Between Group Coefficient of Variation: 0.0290\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0706\n",
      "  Smoothed Empirical Differential Fairness: 0.0128\n",
      "  Consistency: 0.9513\n",
      "  Average Absolute Odds Difference: 0.1151\n",
      "  Average Odds Difference: 0.0702\n",
      "  Average Predictive Value Difference: -0.0244\n",
      "  Between All Groups Coefficient of Variation: 0.0290\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6849\n",
      "  Differential Fairness Bias Amplification: 0.1421\n",
      "  Equal Opportunity Difference: 0.1853\n",
      "  Equalized Odds Difference: 0.1853\n",
      "  Error Rate: 0.4825\n",
      "  Error Rate Difference: -0.1152\n",
      "  Error Rate Ratio: 0.7709\n",
      "  False Discovery Rate: 0.4767\n",
      "  False Discovery Rate Difference: -0.0935\n",
      "  False Discovery Rate Ratio: 0.8112\n",
      "  False Negative Rate: 0.4623\n",
      "  False Negative Rate Difference: -0.1853\n",
      "  False Negative Rate Ratio: 0.6257\n",
      "  False Omission Rate: 0.4889\n",
      "  False Omission Rate Difference: -0.1424\n",
      "  False Omission Rate Ratio: 0.7215\n",
      "  False Positive Rate: 0.5034\n",
      "  False Positive Rate Difference: -0.0449\n",
      "  False Positive Rate Ratio: 0.9121\n",
      "  Generalized Entropy Index: 0.2346\n",
      "  Generalized Equalized Odds Difference: 0.1853\n",
      "  Generalized False Negative Rate: 0.4623\n",
      "  Generalized False Positive Rate: 0.5034\n",
      "  Generalized True Negative Rate: 0.4966\n",
      "  Generalized True Positive Rate: 0.5377\n",
      "  Negative Predictive Value: 0.5111\n",
      "  Number of False Negatives: 2401.0000\n",
      "  Number of False Positives: 2544.0000\n",
      "  Number of Generalized False Negatives: 2401.0000\n",
      "  Number of Generalized False Positives: 2544.0000\n",
      "  Number of Generalized True Negatives: 2510.0000\n",
      "  Number of Generalized True Positives: 2793.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5054.0000\n",
      "  Number of Positives: 5194.0000\n",
      "  Number of Predicted Negatives: 4911.0000\n",
      "  Number of Predicted Positives: 5337.0000\n",
      "  Number of True Negatives: 2510.0000\n",
      "  Number of True Positives: 2793.0000\n",
      "  Positive Predictive Value: 0.5233\n",
      "  Power: 2793.0000\n",
      "  Precision: 0.5233\n",
      "  Recall: 0.5377\n",
      "  Sensitivity: 0.5377\n",
      "  Specificity: 0.4966\n",
      "  Theil Index: 0.3255\n",
      "  True Negative Rate: 0.4966\n",
      "  True Positive Rate: 0.5377\n",
      "  True Positive Rate Difference: 0.1853\n",
      "Protected Attribute Names: ['GENDER', 'AGE']\n",
      "Privileged Protected Attributes: [{'GENDER': 0, 'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1, 'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE&GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.5128\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5121\n",
      "  Disparate Impact: 1.0575\n",
      "  Statistical Parity Difference: 0.0329\n",
      "  Between Group Coefficient of Variation: 0.8840\n",
      "  Between Group Generalized Entropy Index: 0.3908\n",
      "  Between Group Theil Index: 0.5762\n",
      "  Mean Difference: 0.0329\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0525\n",
      "  Average Odds Difference: 0.0525\n",
      "  Average Predictive Value Difference: 0.1790\n",
      "  Between All Groups Coefficient of Variation: 0.1304\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6943\n",
      "  Differential Fairness Bias Amplification: -0.2635\n",
      "  Equal Opportunity Difference: 0.0386\n",
      "  Equalized Odds Difference: 0.0665\n",
      "  Error Rate: 0.4872\n",
      "  Error Rate Difference: -0.0245\n",
      "  Error Rate Ratio: 0.9554\n",
      "  False Discovery Rate: 0.4809\n",
      "  False Discovery Rate Difference: -0.1678\n",
      "  False Discovery Rate Ratio: 0.7081\n",
      "  False Negative Rate: 0.4755\n",
      "  False Negative Rate Difference: -0.0386\n",
      "  False Negative Rate Ratio: 0.9189\n",
      "  False Omission Rate: 0.4939\n",
      "  False Omission Rate Difference: 0.1901\n",
      "  False Omission Rate Ratio: 1.3675\n",
      "  False Positive Rate: 0.4993\n",
      "  False Positive Rate Difference: 0.0665\n",
      "  False Positive Rate Ratio: 1.1082\n",
      "  Generalized Entropy Index: 0.2410\n",
      "  Generalized Equalized Odds Difference: 0.0665\n",
      "  Generalized False Negative Rate: 0.4755\n",
      "  Generalized False Positive Rate: 0.4993\n",
      "  Generalized True Negative Rate: 0.5007\n",
      "  Generalized True Positive Rate: 0.5245\n",
      "  Negative Predictive Value: 0.5061\n",
      "  Number of False Negatives: 3704.0000\n",
      "  Number of False Positives: 3786.0000\n",
      "  Number of Generalized False Negatives: 3704.0000\n",
      "  Number of Generalized False Positives: 3786.0000\n",
      "  Number of Generalized True Negatives: 3796.0000\n",
      "  Number of Generalized True Positives: 4086.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7500.0000\n",
      "  Number of Predicted Positives: 7872.0000\n",
      "  Number of True Negatives: 3796.0000\n",
      "  Number of True Positives: 4086.0000\n",
      "  Positive Predictive Value: 0.5191\n",
      "  Power: 4086.0000\n",
      "  Precision: 0.5191\n",
      "  Recall: 0.5245\n",
      "  Sensitivity: 0.5245\n",
      "  Specificity: 0.5007\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5007\n",
      "  True Positive Rate: 0.5245\n",
      "  True Positive Rate Difference: 0.0386\n",
      "  Accuracy: 0.5128\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5121\n",
      "  Disparate Impact: 1.0575\n",
      "  Statistical Parity Difference: 0.0329\n",
      "  Between Group Coefficient of Variation: 0.8840\n",
      "  Between Group Generalized Entropy Index: 0.3908\n",
      "  Between Group Theil Index: 0.5762\n",
      "  Mean Difference: 0.0329\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0525\n",
      "  Average Odds Difference: 0.0525\n",
      "  Average Predictive Value Difference: 0.1790\n",
      "  Between All Groups Coefficient of Variation: 0.1304\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6943\n",
      "  Differential Fairness Bias Amplification: -0.2635\n",
      "  Equal Opportunity Difference: 0.0386\n",
      "  Equalized Odds Difference: 0.0665\n",
      "  Error Rate: 0.4872\n",
      "  Error Rate Difference: -0.0245\n",
      "  Error Rate Ratio: 0.9554\n",
      "  False Discovery Rate: 0.4809\n",
      "  False Discovery Rate Difference: -0.1678\n",
      "  False Discovery Rate Ratio: 0.7081\n",
      "  False Negative Rate: 0.4755\n",
      "  False Negative Rate Difference: -0.0386\n",
      "  False Negative Rate Ratio: 0.9189\n",
      "  False Omission Rate: 0.4939\n",
      "  False Omission Rate Difference: 0.1901\n",
      "  False Omission Rate Ratio: 1.3675\n",
      "  False Positive Rate: 0.4993\n",
      "  False Positive Rate Difference: 0.0665\n",
      "  False Positive Rate Ratio: 1.1082\n",
      "  Generalized Entropy Index: 0.2410\n",
      "  Generalized Equalized Odds Difference: 0.0665\n",
      "  Generalized False Negative Rate: 0.4755\n",
      "  Generalized False Positive Rate: 0.4993\n",
      "  Generalized True Negative Rate: 0.5007\n",
      "  Generalized True Positive Rate: 0.5245\n",
      "  Negative Predictive Value: 0.5061\n",
      "  Number of False Negatives: 3704.0000\n",
      "  Number of False Positives: 3786.0000\n",
      "  Number of Generalized False Negatives: 3704.0000\n",
      "  Number of Generalized False Positives: 3786.0000\n",
      "  Number of Generalized True Negatives: 3796.0000\n",
      "  Number of Generalized True Positives: 4086.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7500.0000\n",
      "  Number of Predicted Positives: 7872.0000\n",
      "  Number of True Negatives: 3796.0000\n",
      "  Number of True Positives: 4086.0000\n",
      "  Positive Predictive Value: 0.5191\n",
      "  Power: 4086.0000\n",
      "  Precision: 0.5191\n",
      "  Recall: 0.5245\n",
      "  Sensitivity: 0.5245\n",
      "  Specificity: 0.5007\n",
      "  Theil Index: 0.3343\n",
      "  True Negative Rate: 0.5007\n",
      "  True Positive Rate: 0.5245\n",
      "  True Positive Rate Difference: 0.0386\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.3241 - loss: 2.0659 - val_accuracy: 0.6443 - val_loss: 1.0074 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 1.0277 - val_accuracy: 0.7305 - val_loss: 0.7216 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.8072 - val_accuracy: 0.7659 - val_loss: 0.6221 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.6678 - val_accuracy: 0.8125 - val_loss: 0.4968 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5914 - val_accuracy: 0.8079 - val_loss: 0.4916 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.5327 - val_accuracy: 0.8294 - val_loss: 0.4502 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 0.4947 - val_accuracy: 0.8173 - val_loss: 0.4500 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.4699 - val_accuracy: 0.8434 - val_loss: 0.4021 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.4417 - val_accuracy: 0.8448 - val_loss: 0.3915 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8396 - loss: 0.4306 - val_accuracy: 0.8514 - val_loss: 0.3641 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8396 - loss: 0.4159 - val_accuracy: 0.8641 - val_loss: 0.3377 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8466 - loss: 0.3995 - val_accuracy: 0.8557 - val_loss: 0.3523 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.3900 - val_accuracy: 0.8584 - val_loss: 0.3468 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3746 - val_accuracy: 0.8670 - val_loss: 0.3390 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8598 - loss: 0.3644 - val_accuracy: 0.8618 - val_loss: 0.3343 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3612 - val_accuracy: 0.8685 - val_loss: 0.3205 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3467 - val_accuracy: 0.8810 - val_loss: 0.2943 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3423 - val_accuracy: 0.8672 - val_loss: 0.3307 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.3376 - val_accuracy: 0.8790 - val_loss: 0.2918 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8700 - loss: 0.3311 - val_accuracy: 0.8822 - val_loss: 0.2845 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.3219 - val_accuracy: 0.8765 - val_loss: 0.3022 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.3235 - val_accuracy: 0.8793 - val_loss: 0.2862 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.3166 - val_accuracy: 0.8847 - val_loss: 0.2763 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.3122 - val_accuracy: 0.8876 - val_loss: 0.2692 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3104 - val_accuracy: 0.8862 - val_loss: 0.2703 - learning_rate: 8.5700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3110 - val_accuracy: 0.8856 - val_loss: 0.2715 - learning_rate: 8.5700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.3019 - val_accuracy: 0.8851 - val_loss: 0.2822 - learning_rate: 8.5700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2949 - val_accuracy: 0.8788 - val_loss: 0.2939 - learning_rate: 8.5700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2910\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2910 - val_accuracy: 0.8860 - val_loss: 0.2761 - learning_rate: 8.5700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.2610 - val_accuracy: 0.9080 - val_loss: 0.2359 - learning_rate: 4.2850e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.2470 - val_accuracy: 0.9070 - val_loss: 0.2295 - learning_rate: 4.2850e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8979 - loss: 0.2528 - val_accuracy: 0.8985 - val_loss: 0.2405 - learning_rate: 4.2850e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9017 - loss: 0.2455 - val_accuracy: 0.9094 - val_loss: 0.2248 - learning_rate: 4.2850e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.2431 - val_accuracy: 0.9061 - val_loss: 0.2277 - learning_rate: 4.2850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.2427 - val_accuracy: 0.9093 - val_loss: 0.2270 - learning_rate: 4.2850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9053 - loss: 0.2375 - val_accuracy: 0.9076 - val_loss: 0.2322 - learning_rate: 4.2850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.2345 - val_accuracy: 0.9036 - val_loss: 0.2372 - learning_rate: 4.2850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2400\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2400 - val_accuracy: 0.9037 - val_loss: 0.2345 - learning_rate: 4.2850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2175 - val_accuracy: 0.9163 - val_loss: 0.2079 - learning_rate: 2.1425e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2132 - val_accuracy: 0.9178 - val_loss: 0.2091 - learning_rate: 2.1425e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2088 - val_accuracy: 0.9241 - val_loss: 0.1978 - learning_rate: 2.1425e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9173 - loss: 0.2059 - val_accuracy: 0.9153 - val_loss: 0.2169 - learning_rate: 2.1425e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2062 - val_accuracy: 0.9219 - val_loss: 0.1984 - learning_rate: 2.1425e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2035 - val_accuracy: 0.9173 - val_loss: 0.2044 - learning_rate: 2.1425e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.1979 - val_accuracy: 0.9213 - val_loss: 0.2003 - learning_rate: 2.1425e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.1995 - val_accuracy: 0.9220 - val_loss: 0.1955 - learning_rate: 2.1425e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2018 - val_accuracy: 0.9155 - val_loss: 0.2032 - learning_rate: 2.1425e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2020 - val_accuracy: 0.9232 - val_loss: 0.1942 - learning_rate: 2.1425e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.1948 - val_accuracy: 0.9184 - val_loss: 0.2078 - learning_rate: 2.1425e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.1973 - val_accuracy: 0.9240 - val_loss: 0.1908 - learning_rate: 2.1425e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.1950 - val_accuracy: 0.9230 - val_loss: 0.1916 - learning_rate: 2.1425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1923 - val_accuracy: 0.9254 - val_loss: 0.1929 - learning_rate: 2.1425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1934 - val_accuracy: 0.9239 - val_loss: 0.1988 - learning_rate: 2.1425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.1909 - val_accuracy: 0.9227 - val_loss: 0.1962 - learning_rate: 2.1425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.1913 - val_accuracy: 0.9250 - val_loss: 0.1897 - learning_rate: 2.1425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9240 - loss: 0.1923 - val_accuracy: 0.9202 - val_loss: 0.2029 - learning_rate: 2.1425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.1931 - val_accuracy: 0.9285 - val_loss: 0.1835 - learning_rate: 2.1425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.1928 - val_accuracy: 0.9240 - val_loss: 0.1925 - learning_rate: 2.1425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1917 - val_accuracy: 0.9240 - val_loss: 0.1921 - learning_rate: 2.1425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.1920 - val_accuracy: 0.9242 - val_loss: 0.1953 - learning_rate: 2.1425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.1875 - val_accuracy: 0.9241 - val_loss: 0.1911 - learning_rate: 2.1425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.1891 - val_accuracy: 0.9291 - val_loss: 0.1823 - learning_rate: 2.1425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.1830 - val_accuracy: 0.9245 - val_loss: 0.1948 - learning_rate: 2.1425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.1870 - val_accuracy: 0.9286 - val_loss: 0.1848 - learning_rate: 2.1425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.1860 - val_accuracy: 0.9268 - val_loss: 0.1910 - learning_rate: 2.1425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.1863 - val_accuracy: 0.9286 - val_loss: 0.1847 - learning_rate: 2.1425e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.1855\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.1855 - val_accuracy: 0.9281 - val_loss: 0.1879 - learning_rate: 2.1425e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9298 - loss: 0.1722 - val_accuracy: 0.9299 - val_loss: 0.1772 - learning_rate: 1.0713e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.1704 - val_accuracy: 0.9335 - val_loss: 0.1715 - learning_rate: 1.0713e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.1696 - val_accuracy: 0.9312 - val_loss: 0.1777 - learning_rate: 1.0713e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.1676 - val_accuracy: 0.9343 - val_loss: 0.1734 - learning_rate: 1.0713e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.1651 - val_accuracy: 0.9316 - val_loss: 0.1799 - learning_rate: 1.0713e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9331 - loss: 0.1667 - val_accuracy: 0.9345 - val_loss: 0.1703 - learning_rate: 1.0713e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.1669 - val_accuracy: 0.9303 - val_loss: 0.1754 - learning_rate: 1.0713e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.1663 - val_accuracy: 0.9334 - val_loss: 0.1707 - learning_rate: 1.0713e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.1607 - val_accuracy: 0.9363 - val_loss: 0.1700 - learning_rate: 1.0713e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.1626 - val_accuracy: 0.9337 - val_loss: 0.1724 - learning_rate: 1.0713e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.1639 - val_accuracy: 0.9329 - val_loss: 0.1700 - learning_rate: 1.0713e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.1614 - val_accuracy: 0.9333 - val_loss: 0.1730 - learning_rate: 1.0713e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.1606 - val_accuracy: 0.9353 - val_loss: 0.1695 - learning_rate: 1.0713e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9350 - loss: 0.1622 - val_accuracy: 0.9344 - val_loss: 0.1701 - learning_rate: 1.0713e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9346 - loss: 0.1642 - val_accuracy: 0.9342 - val_loss: 0.1698 - learning_rate: 1.0713e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.1629 - val_accuracy: 0.9279 - val_loss: 0.1787 - learning_rate: 1.0713e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9345 - loss: 0.1612 - val_accuracy: 0.9356 - val_loss: 0.1674 - learning_rate: 1.0713e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9359 - loss: 0.1616 - val_accuracy: 0.9359 - val_loss: 0.1650 - learning_rate: 1.0713e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.1628 - val_accuracy: 0.9349 - val_loss: 0.1711 - learning_rate: 1.0713e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.1633 - val_accuracy: 0.9348 - val_loss: 0.1672 - learning_rate: 1.0713e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1610 - val_accuracy: 0.9338 - val_loss: 0.1698 - learning_rate: 1.0713e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.1557 - val_accuracy: 0.9364 - val_loss: 0.1678 - learning_rate: 1.0713e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m2551/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.1547\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.1547 - val_accuracy: 0.9335 - val_loss: 0.1731 - learning_rate: 1.0713e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.1486 - val_accuracy: 0.9356 - val_loss: 0.1640 - learning_rate: 5.3563e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.1524 - val_accuracy: 0.9369 - val_loss: 0.1642 - learning_rate: 5.3563e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9389 - loss: 0.1540 - val_accuracy: 0.9385 - val_loss: 0.1605 - learning_rate: 5.3563e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1502 - val_accuracy: 0.9373 - val_loss: 0.1602 - learning_rate: 5.3563e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.1499 - val_accuracy: 0.9364 - val_loss: 0.1641 - learning_rate: 5.3563e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.1520 - val_accuracy: 0.9381 - val_loss: 0.1618 - learning_rate: 5.3563e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 0.1496 - val_accuracy: 0.9389 - val_loss: 0.1606 - learning_rate: 5.3563e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9411 - loss: 0.1499 - val_accuracy: 0.9400 - val_loss: 0.1604 - learning_rate: 5.3563e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.1507\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.678125019883737e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1507 - val_accuracy: 0.9375 - val_loss: 0.1614 - learning_rate: 5.3563e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9430 - loss: 0.1448 - val_accuracy: 0.9387 - val_loss: 0.1612 - learning_rate: 2.6781e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.3086 - loss: 2.1166 - val_accuracy: 0.6599 - val_loss: 0.9712 - learning_rate: 8.5700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.6343 - loss: 1.0293 - val_accuracy: 0.7406 - val_loss: 0.7186 - learning_rate: 8.5700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7139 - loss: 0.7831 - val_accuracy: 0.7901 - val_loss: 0.5646 - learning_rate: 8.5700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.6533 - val_accuracy: 0.8116 - val_loss: 0.4898 - learning_rate: 8.5700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.5723 - val_accuracy: 0.8150 - val_loss: 0.4691 - learning_rate: 8.5700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.5151 - val_accuracy: 0.8516 - val_loss: 0.3947 - learning_rate: 8.5700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4773 - val_accuracy: 0.8554 - val_loss: 0.3966 - learning_rate: 8.5700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.4484 - val_accuracy: 0.8472 - val_loss: 0.4307 - learning_rate: 8.5700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.4266 - val_accuracy: 0.8673 - val_loss: 0.3404 - learning_rate: 8.5700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.4067 - val_accuracy: 0.8640 - val_loss: 0.3345 - learning_rate: 8.5700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.3966 - val_accuracy: 0.8603 - val_loss: 0.3730 - learning_rate: 8.5700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 0.3767 - val_accuracy: 0.8631 - val_loss: 0.3585 - learning_rate: 8.5700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3677 - val_accuracy: 0.8789 - val_loss: 0.3107 - learning_rate: 8.5700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.3538 - val_accuracy: 0.8824 - val_loss: 0.2914 - learning_rate: 8.5700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.3535 - val_accuracy: 0.8738 - val_loss: 0.3089 - learning_rate: 8.5700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.3421 - val_accuracy: 0.8774 - val_loss: 0.3055 - learning_rate: 8.5700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8728 - loss: 0.3312 - val_accuracy: 0.8862 - val_loss: 0.2793 - learning_rate: 8.5700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8780 - loss: 0.3196 - val_accuracy: 0.8899 - val_loss: 0.2767 - learning_rate: 8.5700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.3223 - val_accuracy: 0.8915 - val_loss: 0.2662 - learning_rate: 8.5700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.3100 - val_accuracy: 0.8762 - val_loss: 0.2943 - learning_rate: 8.5700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8812 - loss: 0.3066 - val_accuracy: 0.8922 - val_loss: 0.2722 - learning_rate: 8.5700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.3012 - val_accuracy: 0.8924 - val_loss: 0.2664 - learning_rate: 8.5700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2934 - val_accuracy: 0.8984 - val_loss: 0.2400 - learning_rate: 8.5700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.2861 - val_accuracy: 0.8957 - val_loss: 0.2614 - learning_rate: 8.5700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.2895 - val_accuracy: 0.8843 - val_loss: 0.2794 - learning_rate: 8.5700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.2835 - val_accuracy: 0.8904 - val_loss: 0.2686 - learning_rate: 8.5700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.2788 - val_accuracy: 0.9038 - val_loss: 0.2351 - learning_rate: 8.5700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8904 - loss: 0.2777 - val_accuracy: 0.9002 - val_loss: 0.2399 - learning_rate: 8.5700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.2719 - val_accuracy: 0.9058 - val_loss: 0.2308 - learning_rate: 8.5700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8942 - loss: 0.2693 - val_accuracy: 0.9057 - val_loss: 0.2239 - learning_rate: 8.5700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8934 - loss: 0.2709 - val_accuracy: 0.9005 - val_loss: 0.2422 - learning_rate: 8.5700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.2675 - val_accuracy: 0.8922 - val_loss: 0.2667 - learning_rate: 8.5700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8957 - loss: 0.2607 - val_accuracy: 0.8788 - val_loss: 0.2867 - learning_rate: 8.5700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2637 - val_accuracy: 0.9085 - val_loss: 0.2247 - learning_rate: 8.5700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 0.2591 - val_accuracy: 0.9113 - val_loss: 0.2166 - learning_rate: 8.5700e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.2533 - val_accuracy: 0.9042 - val_loss: 0.2376 - learning_rate: 8.5700e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.2561 - val_accuracy: 0.9094 - val_loss: 0.2185 - learning_rate: 8.5700e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2461 - val_accuracy: 0.9026 - val_loss: 0.2285 - learning_rate: 8.5700e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2466 - val_accuracy: 0.8962 - val_loss: 0.2516 - learning_rate: 8.5700e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2507\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0004285000031813979.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2507 - val_accuracy: 0.9021 - val_loss: 0.2387 - learning_rate: 8.5700e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.2134 - val_accuracy: 0.9218 - val_loss: 0.1867 - learning_rate: 4.2850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2081 - val_accuracy: 0.9187 - val_loss: 0.1942 - learning_rate: 4.2850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.1965 - val_accuracy: 0.9215 - val_loss: 0.1857 - learning_rate: 4.2850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.1992 - val_accuracy: 0.9164 - val_loss: 0.2067 - learning_rate: 4.2850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2001 - val_accuracy: 0.9240 - val_loss: 0.1890 - learning_rate: 4.2850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9179 - loss: 0.2009 - val_accuracy: 0.9245 - val_loss: 0.1841 - learning_rate: 4.2850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9227 - loss: 0.1937 - val_accuracy: 0.9147 - val_loss: 0.2099 - learning_rate: 4.2850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.1943 - val_accuracy: 0.9267 - val_loss: 0.1769 - learning_rate: 4.2850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.1913 - val_accuracy: 0.9204 - val_loss: 0.2003 - learning_rate: 4.2850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.1933 - val_accuracy: 0.9223 - val_loss: 0.1823 - learning_rate: 4.2850e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.1944 - val_accuracy: 0.9288 - val_loss: 0.1735 - learning_rate: 4.2850e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.1888 - val_accuracy: 0.9250 - val_loss: 0.1811 - learning_rate: 4.2850e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.1854 - val_accuracy: 0.9304 - val_loss: 0.1803 - learning_rate: 4.2850e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1863 - val_accuracy: 0.9296 - val_loss: 0.1649 - learning_rate: 4.2850e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.1912 - val_accuracy: 0.9255 - val_loss: 0.1734 - learning_rate: 4.2850e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.1861 - val_accuracy: 0.9255 - val_loss: 0.1859 - learning_rate: 4.2850e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9276 - loss: 0.1816 - val_accuracy: 0.9231 - val_loss: 0.1871 - learning_rate: 4.2850e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.1819 - val_accuracy: 0.9189 - val_loss: 0.2034 - learning_rate: 4.2850e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2552/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.1881\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00021425000159069896.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.1881 - val_accuracy: 0.9291 - val_loss: 0.1729 - learning_rate: 4.2850e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9373 - loss: 0.1587 - val_accuracy: 0.9347 - val_loss: 0.1569 - learning_rate: 2.1425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 0.1577 - val_accuracy: 0.9347 - val_loss: 0.1604 - learning_rate: 2.1425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9357 - loss: 0.1569 - val_accuracy: 0.9399 - val_loss: 0.1487 - learning_rate: 2.1425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1548 - val_accuracy: 0.9358 - val_loss: 0.1541 - learning_rate: 2.1425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.1576 - val_accuracy: 0.9323 - val_loss: 0.1651 - learning_rate: 2.1425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 0.1536 - val_accuracy: 0.9315 - val_loss: 0.1637 - learning_rate: 2.1425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.1547 - val_accuracy: 0.9328 - val_loss: 0.1729 - learning_rate: 2.1425e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2558/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1504\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00010712500079534948.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9403 - loss: 0.1504 - val_accuracy: 0.9286 - val_loss: 0.1797 - learning_rate: 2.1425e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.1420 - val_accuracy: 0.9420 - val_loss: 0.1463 - learning_rate: 1.0713e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.1396 - val_accuracy: 0.9416 - val_loss: 0.1451 - learning_rate: 1.0713e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1396 - val_accuracy: 0.9407 - val_loss: 0.1488 - learning_rate: 1.0713e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1377 - val_accuracy: 0.9416 - val_loss: 0.1416 - learning_rate: 1.0713e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.1389 - val_accuracy: 0.9406 - val_loss: 0.1473 - learning_rate: 1.0713e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1394 - val_accuracy: 0.9420 - val_loss: 0.1417 - learning_rate: 1.0713e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1348 - val_accuracy: 0.9410 - val_loss: 0.1454 - learning_rate: 1.0713e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.1380 - val_accuracy: 0.9418 - val_loss: 0.1437 - learning_rate: 1.0713e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1390\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.356250039767474e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1389 - val_accuracy: 0.9420 - val_loss: 0.1447 - learning_rate: 1.0713e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1322 - val_accuracy: 0.9422 - val_loss: 0.1440 - learning_rate: 5.3563e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9503 - loss: 0.1254 - val_accuracy: 0.9455 - val_loss: 0.1369 - learning_rate: 5.3563e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9503 - loss: 0.1282 - val_accuracy: 0.9430 - val_loss: 0.1380 - learning_rate: 5.3563e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9487 - loss: 0.1267 - val_accuracy: 0.9452 - val_loss: 0.1376 - learning_rate: 5.3563e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1278 - val_accuracy: 0.9436 - val_loss: 0.1382 - learning_rate: 5.3563e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.1289 - val_accuracy: 0.9442 - val_loss: 0.1377 - learning_rate: 5.3563e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1286\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.678125019883737e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1286 - val_accuracy: 0.9438 - val_loss: 0.1375 - learning_rate: 5.3563e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9503 - loss: 0.1249 - val_accuracy: 0.9453 - val_loss: 0.1367 - learning_rate: 2.6781e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.1283 - val_accuracy: 0.9455 - val_loss: 0.1357 - learning_rate: 2.6781e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9505 - loss: 0.1236 - val_accuracy: 0.9454 - val_loss: 0.1339 - learning_rate: 2.6781e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.1237 - val_accuracy: 0.9438 - val_loss: 0.1368 - learning_rate: 2.6781e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1237 - val_accuracy: 0.9460 - val_loss: 0.1360 - learning_rate: 2.6781e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1261 - val_accuracy: 0.9460 - val_loss: 0.1349 - learning_rate: 2.6781e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1227 - val_accuracy: 0.9449 - val_loss: 0.1382 - learning_rate: 2.6781e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2551/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1247\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.3390625099418685e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1247 - val_accuracy: 0.9453 - val_loss: 0.1391 - learning_rate: 2.6781e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1192 - val_accuracy: 0.9452 - val_loss: 0.1356 - learning_rate: 1.3391e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9518 - loss: 0.1217 - val_accuracy: 0.9465 - val_loss: 0.1356 - learning_rate: 1.3391e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1223 - val_accuracy: 0.9471 - val_loss: 0.1340 - learning_rate: 1.3391e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.1214 - val_accuracy: 0.9450 - val_loss: 0.1356 - learning_rate: 1.3391e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2552/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1206\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.695312549709342e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1206 - val_accuracy: 0.9459 - val_loss: 0.1344 - learning_rate: 1.3391e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1219 - val_accuracy: 0.9465 - val_loss: 0.1345 - learning_rate: 6.6953e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9535 - loss: 0.1170 - val_accuracy: 0.9467 - val_loss: 0.1343 - learning_rate: 6.6953e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.1202 - val_accuracy: 0.9466 - val_loss: 0.1342 - learning_rate: 6.6953e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1188 - val_accuracy: 0.9461 - val_loss: 0.1342 - learning_rate: 6.6953e-06\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "11223  0.788532  36.806779  21.534552  33.941677  27.531361   5.235675   \n",
      "55861  1.299422  35.374199  17.264809  31.089427  22.556688   7.370416   \n",
      "17877  2.015660  34.002530  34.336128  45.340977  33.294839  21.415500   \n",
      "49056  0.672499  36.063187  45.654569  30.798606  24.901538   7.288939   \n",
      "54094  0.712792  36.322550  29.853384  31.056774  22.402436   7.123851   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "16220  1.352000  34.672196  41.145900  43.411919  34.175684   5.316750   \n",
      "85639  0.728323  35.027891  17.345244  42.090562  30.931943   5.235675   \n",
      "47918  0.725538  38.317685  35.133672  31.123532  25.055251   6.630873   \n",
      "24643  0.594160  35.561028  22.106232  38.654349  33.083665  15.419500   \n",
      "69640  0.805844  37.630012  16.062116  32.131847  24.733769   5.356766   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "11223   6.855948   9.546750  0.0     0.0           1.0  \n",
      "55861   9.998500   7.657750  0.0     0.0           1.0  \n",
      "17877  10.737750   8.848750  0.0     1.0           0.0  \n",
      "49056   6.288505   5.070579  0.0     0.0           0.0  \n",
      "54094   9.095000   5.358000  0.0     0.0           1.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "16220  14.228500  26.679540  0.0     1.0           1.0  \n",
      "85639   6.573424   5.602664  0.0     1.0           1.0  \n",
      "47918   6.125916   5.686500  0.0     0.0           0.0  \n",
      "24643  23.674250  13.202000  0.0     0.0           0.0  \n",
      "69640  13.448250   5.809816  0.0     1.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "11223  0.788532  36.806779  21.534552  33.941677  27.531361   5.235675   \n",
      "55861  1.299422  35.374199  17.264809  31.089427  22.556688   7.370416   \n",
      "17877  2.015660  34.002530  34.336128  45.340977  33.294839  21.415500   \n",
      "49056  0.672499  36.063187  45.654569  30.798606  24.901538   7.288939   \n",
      "54094  0.712792  36.322550  29.853384  31.056774  22.402436   7.123851   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "16220  1.352000  34.672196  41.145900  43.411919  34.175684   5.316750   \n",
      "85639  0.728323  35.027891  17.345244  42.090562  30.931943   5.235675   \n",
      "47918  0.725538  38.317685  35.133672  31.123532  25.055251   6.630873   \n",
      "24643  0.594160  35.561028  22.106232  38.654349  33.083665  15.419500   \n",
      "69640  0.805844  37.630012  16.062116  32.131847  24.733769   5.356766   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "11223   6.855948   9.546750  0.0     0.0           1.0  \n",
      "55861   9.998500   7.657750  0.0     0.0           0.0  \n",
      "17877  10.737750   8.848750  0.0     1.0           0.0  \n",
      "49056   6.288505   5.070579  0.0     0.0           1.0  \n",
      "54094   9.095000   5.358000  0.0     0.0           0.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "16220  14.228500  26.679540  0.0     1.0           0.0  \n",
      "85639   6.573424   5.602664  0.0     1.0           1.0  \n",
      "47918   6.125916   5.686500  0.0     0.0           0.0  \n",
      "24643  23.674250  13.202000  0.0     0.0           0.0  \n",
      "69640  13.448250   5.809816  0.0     1.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5187\n",
      "  Base Rate: 0.5062\n",
      "  Selection Rate: 0.5109\n",
      "  Disparate Impact: 1.0339\n",
      "  Statistical Parity Difference: 0.0198\n",
      "  Between Group Coefficient of Variation: 0.8991\n",
      "  Between Group Generalized Entropy Index: 0.4042\n",
      "  Between Group Theil Index: 0.5903\n",
      "  Mean Difference: 0.0198\n",
      "  Smoothed Empirical Differential Fairness: 0.7291\n",
      "  Consistency: 0.9506\n",
      "  Average Absolute Odds Difference: 0.0575\n",
      "  Average Odds Difference: 0.0488\n",
      "  Average Predictive Value Difference: 0.2149\n",
      "  Between All Groups Coefficient of Variation: 0.1433\n",
      "  Between All Groups Generalized Entropy Index: 0.0103\n",
      "  Between All Groups Theil Index: 0.0104\n",
      "  Coefficient of Variation: 0.6905\n",
      "  Differential Fairness Bias Amplification: -0.2930\n",
      "  Equal Opportunity Difference: -0.0087\n",
      "  Equalized Odds Difference: 0.1063\n",
      "  Error Rate: 0.4813\n",
      "  Error Rate Difference: 0.0082\n",
      "  Error Rate Ratio: 1.0155\n",
      "  False Discovery Rate: 0.4756\n",
      "  False Discovery Rate Difference: -0.1637\n",
      "  False Discovery Rate Ratio: 0.7070\n",
      "  False Negative Rate: 0.4707\n",
      "  False Negative Rate Difference: 0.0087\n",
      "  False Negative Rate Ratio: 1.0196\n",
      "  False Omission Rate: 0.4872\n",
      "  False Omission Rate Difference: 0.2661\n",
      "  False Omission Rate Ratio: 1.5415\n",
      "  False Positive Rate: 0.4921\n",
      "  False Positive Rate Difference: 0.1063\n",
      "  False Positive Rate Ratio: 1.1753\n",
      "  Generalized Entropy Index: 0.2384\n",
      "  Generalized Equalized Odds Difference: 0.1063\n",
      "  Generalized False Negative Rate: 0.4707\n",
      "  Generalized False Positive Rate: 0.4921\n",
      "  Generalized True Negative Rate: 0.5079\n",
      "  Generalized True Positive Rate: 0.5293\n",
      "  Negative Predictive Value: 0.5128\n",
      "  Number of False Negatives: 2442.0000\n",
      "  Number of False Positives: 2490.0000\n",
      "  Number of Generalized False Negatives: 2442.0000\n",
      "  Number of Generalized False Positives: 2490.0000\n",
      "  Number of Generalized True Negatives: 2570.0000\n",
      "  Number of Generalized True Positives: 2746.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5060.0000\n",
      "  Number of Positives: 5188.0000\n",
      "  Number of Predicted Negatives: 5012.0000\n",
      "  Number of Predicted Positives: 5236.0000\n",
      "  Number of True Negatives: 2570.0000\n",
      "  Number of True Positives: 2746.0000\n",
      "  Positive Predictive Value: 0.5244\n",
      "  Power: 2746.0000\n",
      "  Precision: 0.5244\n",
      "  Recall: 0.5293\n",
      "  Sensitivity: 0.5293\n",
      "  Specificity: 0.5079\n",
      "  Theil Index: 0.3306\n",
      "  True Negative Rate: 0.5079\n",
      "  True Positive Rate: 0.5293\n",
      "  True Positive Rate Difference: -0.0087\n",
      "  Accuracy: 0.5187\n",
      "  Base Rate: 0.5062\n",
      "  Selection Rate: 0.5109\n",
      "  Disparate Impact: 1.0339\n",
      "  Statistical Parity Difference: 0.0198\n",
      "  Between Group Coefficient of Variation: 0.8991\n",
      "  Between Group Generalized Entropy Index: 0.4042\n",
      "  Between Group Theil Index: 0.5903\n",
      "  Mean Difference: 0.0198\n",
      "  Smoothed Empirical Differential Fairness: 0.7291\n",
      "  Consistency: 0.9506\n",
      "  Average Absolute Odds Difference: 0.0575\n",
      "  Average Odds Difference: 0.0488\n",
      "  Average Predictive Value Difference: 0.2149\n",
      "  Between All Groups Coefficient of Variation: 0.1433\n",
      "  Between All Groups Generalized Entropy Index: 0.0103\n",
      "  Between All Groups Theil Index: 0.0104\n",
      "  Coefficient of Variation: 0.6905\n",
      "  Differential Fairness Bias Amplification: -0.2930\n",
      "  Equal Opportunity Difference: -0.0087\n",
      "  Equalized Odds Difference: 0.1063\n",
      "  Error Rate: 0.4813\n",
      "  Error Rate Difference: 0.0082\n",
      "  Error Rate Ratio: 1.0155\n",
      "  False Discovery Rate: 0.4756\n",
      "  False Discovery Rate Difference: -0.1637\n",
      "  False Discovery Rate Ratio: 0.7070\n",
      "  False Negative Rate: 0.4707\n",
      "  False Negative Rate Difference: 0.0087\n",
      "  False Negative Rate Ratio: 1.0196\n",
      "  False Omission Rate: 0.4872\n",
      "  False Omission Rate Difference: 0.2661\n",
      "  False Omission Rate Ratio: 1.5415\n",
      "  False Positive Rate: 0.4921\n",
      "  False Positive Rate Difference: 0.1063\n",
      "  False Positive Rate Ratio: 1.1753\n",
      "  Generalized Entropy Index: 0.2384\n",
      "  Generalized Equalized Odds Difference: 0.1063\n",
      "  Generalized False Negative Rate: 0.4707\n",
      "  Generalized False Positive Rate: 0.4921\n",
      "  Generalized True Negative Rate: 0.5079\n",
      "  Generalized True Positive Rate: 0.5293\n",
      "  Negative Predictive Value: 0.5128\n",
      "  Number of False Negatives: 2442.0000\n",
      "  Number of False Positives: 2490.0000\n",
      "  Number of Generalized False Negatives: 2442.0000\n",
      "  Number of Generalized False Positives: 2490.0000\n",
      "  Number of Generalized True Negatives: 2570.0000\n",
      "  Number of Generalized True Positives: 2746.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5060.0000\n",
      "  Number of Positives: 5188.0000\n",
      "  Number of Predicted Negatives: 5012.0000\n",
      "  Number of Predicted Positives: 5236.0000\n",
      "  Number of True Negatives: 2570.0000\n",
      "  Number of True Positives: 2746.0000\n",
      "  Positive Predictive Value: 0.5244\n",
      "  Power: 2746.0000\n",
      "  Precision: 0.5244\n",
      "  Recall: 0.5293\n",
      "  Sensitivity: 0.5293\n",
      "  Specificity: 0.5079\n",
      "  Theil Index: 0.3306\n",
      "  True Negative Rate: 0.5079\n",
      "  True Positive Rate: 0.5293\n",
      "  True Positive Rate Difference: -0.0087\n",
      "  Accuracy: 0.5158\n",
      "  Base Rate: 0.5073\n",
      "  Selection Rate: 0.5122\n",
      "  Disparate Impact: 1.1232\n",
      "  Statistical Parity Difference: 0.0700\n",
      "  Between Group Coefficient of Variation: 0.8698\n",
      "  Between Group Generalized Entropy Index: 0.3783\n",
      "  Between Group Theil Index: 0.5626\n",
      "  Mean Difference: 0.0700\n",
      "  Smoothed Empirical Differential Fairness: 0.7773\n",
      "  Consistency: 0.9508\n",
      "  Average Absolute Odds Difference: 0.0844\n",
      "  Average Odds Difference: 0.0844\n",
      "  Average Predictive Value Difference: 0.1899\n",
      "  Between All Groups Coefficient of Variation: 0.1290\n",
      "  Between All Groups Generalized Entropy Index: 0.0083\n",
      "  Between All Groups Theil Index: 0.0084\n",
      "  Coefficient of Variation: 0.6924\n",
      "  Differential Fairness Bias Amplification: -0.2644\n",
      "  Equal Opportunity Difference: 0.0805\n",
      "  Equalized Odds Difference: 0.0884\n",
      "  Error Rate: 0.4842\n",
      "  Error Rate Difference: -0.0470\n",
      "  Error Rate Ratio: 0.9128\n",
      "  False Discovery Rate: 0.4774\n",
      "  False Discovery Rate Difference: -0.1875\n",
      "  False Discovery Rate Ratio: 0.6641\n",
      "  False Negative Rate: 0.4724\n",
      "  False Negative Rate Difference: -0.0805\n",
      "  False Negative Rate Ratio: 0.8285\n",
      "  False Omission Rate: 0.4913\n",
      "  False Omission Rate Difference: 0.1924\n",
      "  False Omission Rate Ratio: 1.3739\n",
      "  False Positive Rate: 0.4963\n",
      "  False Positive Rate Difference: 0.0884\n",
      "  False Positive Rate Ratio: 1.1468\n",
      "  Generalized Entropy Index: 0.2397\n",
      "  Generalized Equalized Odds Difference: 0.0884\n",
      "  Generalized False Negative Rate: 0.4724\n",
      "  Generalized False Positive Rate: 0.4963\n",
      "  Generalized True Negative Rate: 0.5037\n",
      "  Generalized True Positive Rate: 0.5276\n",
      "  Negative Predictive Value: 0.5087\n",
      "  Number of False Negatives: 2456.0000\n",
      "  Number of False Positives: 2506.0000\n",
      "  Number of Generalized False Negatives: 2456.0000\n",
      "  Number of Generalized False Positives: 2506.0000\n",
      "  Number of Generalized True Negatives: 2543.0000\n",
      "  Number of Generalized True Positives: 2743.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5049.0000\n",
      "  Number of Positives: 5199.0000\n",
      "  Number of Predicted Negatives: 4999.0000\n",
      "  Number of Predicted Positives: 5249.0000\n",
      "  Number of True Negatives: 2543.0000\n",
      "  Number of True Positives: 2743.0000\n",
      "  Positive Predictive Value: 0.5226\n",
      "  Power: 2743.0000\n",
      "  Precision: 0.5226\n",
      "  Recall: 0.5276\n",
      "  Sensitivity: 0.5276\n",
      "  Specificity: 0.5037\n",
      "  Theil Index: 0.3325\n",
      "  True Negative Rate: 0.5037\n",
      "  True Positive Rate: 0.5276\n",
      "  True Positive Rate Difference: 0.0805\n",
      "  Accuracy: 0.5158\n",
      "  Base Rate: 0.5073\n",
      "  Selection Rate: 0.5122\n",
      "  Disparate Impact: 1.1232\n",
      "  Statistical Parity Difference: 0.0700\n",
      "  Between Group Coefficient of Variation: 0.8698\n",
      "  Between Group Generalized Entropy Index: 0.3783\n",
      "  Between Group Theil Index: 0.5626\n",
      "  Mean Difference: 0.0700\n",
      "  Smoothed Empirical Differential Fairness: 0.7773\n",
      "  Consistency: 0.9508\n",
      "  Average Absolute Odds Difference: 0.0844\n",
      "  Average Odds Difference: 0.0844\n",
      "  Average Predictive Value Difference: 0.1899\n",
      "  Between All Groups Coefficient of Variation: 0.1290\n",
      "  Between All Groups Generalized Entropy Index: 0.0083\n",
      "  Between All Groups Theil Index: 0.0084\n",
      "  Coefficient of Variation: 0.6924\n",
      "  Differential Fairness Bias Amplification: -0.2644\n",
      "  Equal Opportunity Difference: 0.0805\n",
      "  Equalized Odds Difference: 0.0884\n",
      "  Error Rate: 0.4842\n",
      "  Error Rate Difference: -0.0470\n",
      "  Error Rate Ratio: 0.9128\n",
      "  False Discovery Rate: 0.4774\n",
      "  False Discovery Rate Difference: -0.1875\n",
      "  False Discovery Rate Ratio: 0.6641\n",
      "  False Negative Rate: 0.4724\n",
      "  False Negative Rate Difference: -0.0805\n",
      "  False Negative Rate Ratio: 0.8285\n",
      "  False Omission Rate: 0.4913\n",
      "  False Omission Rate Difference: 0.1924\n",
      "  False Omission Rate Ratio: 1.3739\n",
      "  False Positive Rate: 0.4963\n",
      "  False Positive Rate Difference: 0.0884\n",
      "  False Positive Rate Ratio: 1.1468\n",
      "  Generalized Entropy Index: 0.2397\n",
      "  Generalized Equalized Odds Difference: 0.0884\n",
      "  Generalized False Negative Rate: 0.4724\n",
      "  Generalized False Positive Rate: 0.4963\n",
      "  Generalized True Negative Rate: 0.5037\n",
      "  Generalized True Positive Rate: 0.5276\n",
      "  Negative Predictive Value: 0.5087\n",
      "  Number of False Negatives: 2456.0000\n",
      "  Number of False Positives: 2506.0000\n",
      "  Number of Generalized False Negatives: 2456.0000\n",
      "  Number of Generalized False Positives: 2506.0000\n",
      "  Number of Generalized True Negatives: 2543.0000\n",
      "  Number of Generalized True Positives: 2743.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5049.0000\n",
      "  Number of Positives: 5199.0000\n",
      "  Number of Predicted Negatives: 4999.0000\n",
      "  Number of Predicted Positives: 5249.0000\n",
      "  Number of True Negatives: 2543.0000\n",
      "  Number of True Positives: 2743.0000\n",
      "  Positive Predictive Value: 0.5226\n",
      "  Power: 2743.0000\n",
      "  Precision: 0.5226\n",
      "  Recall: 0.5276\n",
      "  Sensitivity: 0.5276\n",
      "  Specificity: 0.5037\n",
      "  Theil Index: 0.3325\n",
      "  True Negative Rate: 0.5037\n",
      "  True Positive Rate: 0.5276\n",
      "  True Positive Rate Difference: 0.0805\n"
     ]
    }
   ],
   "source": [
    "for config in protected_attribute_configs:\n",
    "    protected_attribute_names = config[\"protected_attribute_names\"]\n",
    "    privileged_protected_attributes = config[\"privileged_protected_attributes\"]\n",
    "    unprivileged_protected_attributes = config[\"unprivileged_protected_attributes\"]\n",
    "    sensitive_attribute = config[\"sensitive_attribute\"]\n",
    "    desc = config[\"desc\"]\n",
    "\n",
    "    print(\"Protected Attribute Names:\", protected_attribute_names)\n",
    "    print(\"Privileged Protected Attributes:\", privileged_protected_attributes)\n",
    "    print(\"Unprivileged Protected Attributes:\", unprivileged_protected_attributes)\n",
    "    print(\"Sensitive Attribute:\", sensitive_attribute)\n",
    "    print(\"Description:\", desc)\n",
    "\n",
    "    # Creating BinaryLabelDataset\n",
    "    print(\"Creating BinaryLabelDataset...\")\n",
    "    binary_dataset = BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=['Emotion_Type'],\n",
    "        protected_attribute_names=protected_attribute_names\n",
    "    )\n",
    "    print(\"BinaryLabelDataset created.\\n\")\n",
    "\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_bld = BinaryLabelDataset(df=pred_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "\n",
    "    compute_fairness_metrics_CM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"LSTM model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"LSTM model-CM-{desc}\")\n",
    "    \n",
    "    reweighing = Reweighing(\n",
    "        privileged_groups=privileged_protected_attributes,\n",
    "        unprivileged_groups=unprivileged_protected_attributes\n",
    "    )\n",
    "    reweighed_dataset = reweighing.fit_transform(binary_dataset)\n",
    "\n",
    "    dir_remover = DisparateImpactRemover(repair_level=0.1, sensitive_attribute=sensitive_attribute)\n",
    "    dir_processed = dir_remover.fit_transform(binary_dataset)\n",
    "    \n",
    "    # Perform a 70%-15%-15% split for training, validation, and test sets\n",
    "    train_dir, temp_dir = dir_processed.split([0.8], shuffle=True)\n",
    "    val_dir, test_dir = temp_dir.split([0.5], shuffle=True)\n",
    "    \n",
    "    # Perform the same split on the reweighted dataset\n",
    "    train_reweighed, temp_reweighed = reweighed_dataset.split([0.8], shuffle=True)\n",
    "    val_reweighed, test_reweighed = temp_reweighed.split([0.5], shuffle=True)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    train_dir_df = train_dir.convert_to_dataframe()[0]\n",
    "    val_dir_df = val_dir.convert_to_dataframe()[0]\n",
    "    test_dir_df = test_dir.convert_to_dataframe()[0]\n",
    "    \n",
    "    train_reweighed_df = train_reweighed.convert_to_dataframe()[0]\n",
    "    val_reweighed_df = val_reweighed.convert_to_dataframe()[0]\n",
    "    test_reweighed_df = test_reweighed.convert_to_dataframe()[0]\n",
    "\n",
    "    dir_weights = train_dir.instance_weights\n",
    "    rw_weights = train_reweighed.instance_weights\n",
    "    \n",
    "    def prepare_data_for_lstm(dataset, weights):\n",
    "        features = dataset.drop(columns=['Emotion', 'Emotion_Type'])\n",
    "        labels = dataset['Emotion']\n",
    "        features_reshaped = np.expand_dims(features.values, axis=2)\n",
    "        return features_reshaped, labels, weights\n",
    "    \n",
    "    # Prepare data for LSTM model with train, validation, and test splits\n",
    "    X_train_dir, y_train_dir, train_weights_dir = prepare_data_for_lstm(train_dir_df, dir_weights)\n",
    "    X_val_dir, y_val_dir, _ = prepare_data_for_lstm(val_dir_df, dir_weights)\n",
    "    X_test_dir, y_test_dir, _ = prepare_data_for_lstm(test_dir_df, dir_weights)\n",
    "    \n",
    "    X_train_reweighed, y_train_reweighed, train_weights_rw = prepare_data_for_lstm(train_reweighed_df, rw_weights)\n",
    "    X_val_reweighed, y_val_reweighed, _ = prepare_data_for_lstm(val_reweighed_df, rw_weights)\n",
    "    X_test_reweighed, y_test_reweighed, _ = prepare_data_for_lstm(test_reweighed_df, rw_weights)\n",
    "\n",
    "    lstm_dir = build_lstm_model(X_train_dir.shape[1:], num_classes)\n",
    "    lstm_dir.fit(\n",
    "        X_train_dir, y_train_dir, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_dir, y_val_dir), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_dir = np.argmax(lstm_dir.predict(X_test_dir), axis=1)\n",
    "    \n",
    "    lstm_reweighed = build_lstm_model(X_train_reweighed.shape[1:], num_classes)\n",
    "    lstm_reweighed.fit(\n",
    "        X_train_reweighed, y_train_reweighed, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_reweighed, y_val_reweighed), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_reweighed = np.argmax(lstm_reweighed.predict(X_test_reweighed), axis=1)\n",
    "\n",
    "    pred_reweighed_df = test_reweighed_df.copy()\n",
    "    pred_reweighed_df['Emotion'] = y_pred_reweighed\n",
    "    \n",
    "    pred_dir_df = test_dir_df.copy()\n",
    "    pred_dir_df['Emotion'] = y_pred_dir\n",
    "    \n",
    "    pred_reweighed_df['Emotion_Type'] = pred_reweighed_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    pred_dir_df['Emotion_Type'] = pred_dir_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    \n",
    "    pred_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    pred_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    print(pred_dir_df)\n",
    "    \n",
    "    pred_reweighed_bld = BinaryLabelDataset(df=pred_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_dir_bld = BinaryLabelDataset(df=pred_dir_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    \n",
    "    test_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    print(test_dir_df)\n",
    "    test_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    test_dir = BinaryLabelDataset(df=test_dir_df, label_names=['Emotion_Type'], protected_attribute_names=test_dir.protected_attribute_names)\n",
    "    test_reweighed = BinaryLabelDataset(df=test_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=test_reweighed.protected_attribute_names)\n",
    "    \n",
    "    compute_fairness_metrics_CM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"LSTM DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"LSTM DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_CM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"LSTM Reweighed model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"LSTM Reweighed model-CM-{desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07097e7",
   "metadata": {
    "papermill": {
     "duration": 16.889295,
     "end_time": "2025-02-25T09:52:57.410058",
     "exception": false,
     "start_time": "2025-02-25T09:52:40.520763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb89bad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T09:53:31.180969Z",
     "iopub.status.busy": "2025-02-25T09:53:31.180632Z",
     "iopub.status.idle": "2025-02-25T10:05:20.698828Z",
     "shell.execute_reply": "2025-02-25T10:05:20.697754Z"
    },
    "papermill": {
     "duration": 734.532579,
     "end_time": "2025-02-25T10:05:28.820000",
     "exception": false,
     "start_time": "2025-02-25T09:53:14.287421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.5267 - loss: 1.3513 - val_accuracy: 0.7554 - val_loss: 0.6446 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.6295 - val_accuracy: 0.8238 - val_loss: 0.4621 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4944 - val_accuracy: 0.8453 - val_loss: 0.4050 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.4334 - val_accuracy: 0.8495 - val_loss: 0.3897 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.4031 - val_accuracy: 0.8746 - val_loss: 0.3345 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3753 - val_accuracy: 0.8568 - val_loss: 0.3601 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.3522 - val_accuracy: 0.8528 - val_loss: 0.3840 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8689 - loss: 0.3446 - val_accuracy: 0.8357 - val_loss: 0.4247 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.3381 - val_accuracy: 0.8820 - val_loss: 0.3092 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3260 - val_accuracy: 0.8825 - val_loss: 0.2942 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.3137 - val_accuracy: 0.8856 - val_loss: 0.2885 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.3137 - val_accuracy: 0.8872 - val_loss: 0.2857 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.2994 - val_accuracy: 0.8731 - val_loss: 0.3172 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2935 - val_accuracy: 0.8999 - val_loss: 0.2498 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2921 - val_accuracy: 0.8854 - val_loss: 0.2999 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8891 - loss: 0.2920 - val_accuracy: 0.8921 - val_loss: 0.2731 - learning_rate: 9.5500e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2849 - val_accuracy: 0.9048 - val_loss: 0.2383 - learning_rate: 9.5500e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2773 - val_accuracy: 0.8930 - val_loss: 0.2725 - learning_rate: 9.5500e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2712 - val_accuracy: 0.8932 - val_loss: 0.2707 - learning_rate: 9.5500e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2789 - val_accuracy: 0.8999 - val_loss: 0.2559 - learning_rate: 9.5500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.2737 - val_accuracy: 0.8945 - val_loss: 0.2648 - learning_rate: 9.5500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2701\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2701 - val_accuracy: 0.9054 - val_loss: 0.2393 - learning_rate: 9.5500e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2292 - val_accuracy: 0.9150 - val_loss: 0.2103 - learning_rate: 4.7750e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2236 - val_accuracy: 0.9140 - val_loss: 0.2091 - learning_rate: 4.7750e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2224 - val_accuracy: 0.9157 - val_loss: 0.2096 - learning_rate: 4.7750e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2137 - val_accuracy: 0.9072 - val_loss: 0.2267 - learning_rate: 4.7750e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2148 - val_accuracy: 0.9165 - val_loss: 0.2060 - learning_rate: 4.7750e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2144 - val_accuracy: 0.9170 - val_loss: 0.1992 - learning_rate: 4.7750e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2113 - val_accuracy: 0.9168 - val_loss: 0.2036 - learning_rate: 4.7750e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2050 - val_accuracy: 0.9203 - val_loss: 0.2023 - learning_rate: 4.7750e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2048 - val_accuracy: 0.9119 - val_loss: 0.2157 - learning_rate: 4.7750e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2021 - val_accuracy: 0.9241 - val_loss: 0.1883 - learning_rate: 4.7750e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2014 - val_accuracy: 0.9225 - val_loss: 0.1859 - learning_rate: 4.7750e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2026 - val_accuracy: 0.9214 - val_loss: 0.1876 - learning_rate: 4.7750e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.1972 - val_accuracy: 0.9178 - val_loss: 0.2007 - learning_rate: 4.7750e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.1979 - val_accuracy: 0.9145 - val_loss: 0.2075 - learning_rate: 4.7750e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.1951 - val_accuracy: 0.9205 - val_loss: 0.1906 - learning_rate: 4.7750e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.1978 - val_accuracy: 0.9247 - val_loss: 0.1817 - learning_rate: 4.7750e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.1949 - val_accuracy: 0.9206 - val_loss: 0.1906 - learning_rate: 4.7750e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.1912 - val_accuracy: 0.9117 - val_loss: 0.2105 - learning_rate: 4.7750e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.1959 - val_accuracy: 0.9251 - val_loss: 0.1767 - learning_rate: 4.7750e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.1950 - val_accuracy: 0.9187 - val_loss: 0.1937 - learning_rate: 4.7750e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.1882 - val_accuracy: 0.9239 - val_loss: 0.1861 - learning_rate: 4.7750e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.1880 - val_accuracy: 0.9251 - val_loss: 0.1796 - learning_rate: 4.7750e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.1948 - val_accuracy: 0.9228 - val_loss: 0.1810 - learning_rate: 4.7750e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2229/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.1904\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.1904 - val_accuracy: 0.9234 - val_loss: 0.1908 - learning_rate: 4.7750e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1629 - val_accuracy: 0.9307 - val_loss: 0.1686 - learning_rate: 2.3875e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1649 - val_accuracy: 0.9343 - val_loss: 0.1588 - learning_rate: 2.3875e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1597 - val_accuracy: 0.9230 - val_loss: 0.1880 - learning_rate: 2.3875e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.1600 - val_accuracy: 0.9276 - val_loss: 0.1687 - learning_rate: 2.3875e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1592 - val_accuracy: 0.9321 - val_loss: 0.1607 - learning_rate: 2.3875e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.1527 - val_accuracy: 0.9324 - val_loss: 0.1607 - learning_rate: 2.3875e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2232/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1556\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1556 - val_accuracy: 0.9288 - val_loss: 0.1683 - learning_rate: 2.3875e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1448 - val_accuracy: 0.9374 - val_loss: 0.1514 - learning_rate: 1.1937e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1436 - val_accuracy: 0.9374 - val_loss: 0.1492 - learning_rate: 1.1937e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.1392 - val_accuracy: 0.9383 - val_loss: 0.1466 - learning_rate: 1.1937e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1390 - val_accuracy: 0.9379 - val_loss: 0.1486 - learning_rate: 1.1937e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1363 - val_accuracy: 0.9390 - val_loss: 0.1477 - learning_rate: 1.1937e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1379 - val_accuracy: 0.9361 - val_loss: 0.1515 - learning_rate: 1.1937e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1345 - val_accuracy: 0.9379 - val_loss: 0.1442 - learning_rate: 1.1937e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1339 - val_accuracy: 0.9404 - val_loss: 0.1409 - learning_rate: 1.1937e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1371 - val_accuracy: 0.9377 - val_loss: 0.1463 - learning_rate: 1.1937e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1358 - val_accuracy: 0.9395 - val_loss: 0.1440 - learning_rate: 1.1937e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1315 - val_accuracy: 0.9401 - val_loss: 0.1438 - learning_rate: 1.1937e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1288 - val_accuracy: 0.9397 - val_loss: 0.1470 - learning_rate: 1.1937e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2234/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1297\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1297 - val_accuracy: 0.9406 - val_loss: 0.1445 - learning_rate: 1.1937e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1269 - val_accuracy: 0.9411 - val_loss: 0.1401 - learning_rate: 5.9687e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1260 - val_accuracy: 0.9413 - val_loss: 0.1382 - learning_rate: 5.9687e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1219 - val_accuracy: 0.9427 - val_loss: 0.1379 - learning_rate: 5.9687e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1235 - val_accuracy: 0.9429 - val_loss: 0.1364 - learning_rate: 5.9687e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1251 - val_accuracy: 0.9419 - val_loss: 0.1396 - learning_rate: 5.9687e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1245 - val_accuracy: 0.9396 - val_loss: 0.1457 - learning_rate: 5.9687e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1236 - val_accuracy: 0.9434 - val_loss: 0.1388 - learning_rate: 5.9687e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1222 - val_accuracy: 0.9444 - val_loss: 0.1341 - learning_rate: 5.9687e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1241 - val_accuracy: 0.9425 - val_loss: 0.1365 - learning_rate: 5.9687e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1197 - val_accuracy: 0.9441 - val_loss: 0.1345 - learning_rate: 5.9687e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1214 - val_accuracy: 0.9448 - val_loss: 0.1344 - learning_rate: 5.9687e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1201 - val_accuracy: 0.9431 - val_loss: 0.1359 - learning_rate: 5.9687e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1193\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1193 - val_accuracy: 0.9433 - val_loss: 0.1355 - learning_rate: 5.9687e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1175 - val_accuracy: 0.9448 - val_loss: 0.1329 - learning_rate: 2.9844e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1155 - val_accuracy: 0.9451 - val_loss: 0.1330 - learning_rate: 2.9844e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1164 - val_accuracy: 0.9456 - val_loss: 0.1325 - learning_rate: 2.9844e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.1186 - val_accuracy: 0.9456 - val_loss: 0.1323 - learning_rate: 2.9844e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1177 - val_accuracy: 0.9450 - val_loss: 0.1322 - learning_rate: 2.9844e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1161 - val_accuracy: 0.9445 - val_loss: 0.1339 - learning_rate: 2.9844e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1162 - val_accuracy: 0.9448 - val_loss: 0.1333 - learning_rate: 2.9844e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1136 - val_accuracy: 0.9460 - val_loss: 0.1319 - learning_rate: 2.9844e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1119 - val_accuracy: 0.9467 - val_loss: 0.1307 - learning_rate: 2.9844e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1164 - val_accuracy: 0.9461 - val_loss: 0.1308 - learning_rate: 2.9844e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1136 - val_accuracy: 0.9465 - val_loss: 0.1312 - learning_rate: 2.9844e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1133 - val_accuracy: 0.9454 - val_loss: 0.1315 - learning_rate: 2.9844e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1165 - val_accuracy: 0.9462 - val_loss: 0.1315 - learning_rate: 2.9844e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2234/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1135\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.4921874935680535e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1135 - val_accuracy: 0.9450 - val_loss: 0.1332 - learning_rate: 2.9844e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1134 - val_accuracy: 0.9469 - val_loss: 0.1293 - learning_rate: 1.4922e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1119 - val_accuracy: 0.9465 - val_loss: 0.1291 - learning_rate: 1.4922e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1095 - val_accuracy: 0.9466 - val_loss: 0.1304 - learning_rate: 1.4922e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1112 - val_accuracy: 0.9461 - val_loss: 0.1295 - learning_rate: 1.4922e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1123 - val_accuracy: 0.9469 - val_loss: 0.1297 - learning_rate: 1.4922e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1106 - val_accuracy: 0.9474 - val_loss: 0.1293 - learning_rate: 1.4922e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2230/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1117\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.460937467840267e-06.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1117 - val_accuracy: 0.9465 - val_loss: 0.1297 - learning_rate: 1.4922e-05\n",
      "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy: 0.9498\n",
      "Precision: 0.9506\n",
      "Recall: 0.9498\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      2402\n",
      "           1       0.89      0.89      0.89       722\n",
      "           2       0.96      0.96      0.96      1686\n",
      "           3       0.96      0.96      0.96      2795\n",
      "           4       0.96      0.95      0.96      2574\n",
      "           5       0.92      0.89      0.91       415\n",
      "           6       0.95      0.98      0.97       678\n",
      "           7       0.98      0.93      0.95      1027\n",
      "           8       0.76      0.84      0.80       424\n",
      "           9       0.94      0.98      0.96       474\n",
      "          10       0.94      1.00      0.97       411\n",
      "          11       1.00      1.00      1.00       441\n",
      "          12       0.92      0.98      0.95       469\n",
      "          13       0.96      1.00      0.98       412\n",
      "          14       1.00      1.00      1.00       442\n",
      "\n",
      "    accuracy                           0.95     15372\n",
      "   macro avg       0.94      0.95      0.95     15372\n",
      "weighted avg       0.95      0.95      0.95     15372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "def build_rnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # RNN Layer with 128 units\n",
    "    model.add(SimpleRNN(128, input_shape=input_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.000955)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load data\n",
    "X = df.drop(columns=['Emotion'])\n",
    "y = df['Emotion']\n",
    "\n",
    "# Splitting Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  \n",
    "\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build and train RNN model\n",
    "rnn_model = build_rnn_model(input_shape, num_classes)\n",
    "history = rnn_model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=100, batch_size=32, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions on test data\n",
    "predictions = rnn_model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "pred_df = X_test.copy()\n",
    "pred_df['Emotion'] = predicted_labels\n",
    "pred_df['Emotion_Type'] = pred_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "y_pred = pred_df['Emotion'].values\n",
    "pred_df.drop(columns=['Emotion'], inplace=True)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = tf.math.confusion_matrix(y_test, predicted_labels).numpy()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- ROC CURVE FOR MULTI-CLASS TEST DATA ---\n",
    "n_classes = len(np.unique(y_test))  \n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], predictions[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve for Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3613d",
   "metadata": {
    "papermill": {
     "duration": 18.555956,
     "end_time": "2025-02-25T10:06:06.070994",
     "exception": false,
     "start_time": "2025-02-25T10:05:47.515038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN - Preprocessing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0543c9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T10:06:42.542542Z",
     "iopub.status.busy": "2025-02-25T10:06:42.542179Z",
     "iopub.status.idle": "2025-02-25T11:23:42.986169Z",
     "shell.execute_reply": "2025-02-25T11:23:42.985273Z"
    },
    "papermill": {
     "duration": 4649.644825,
     "end_time": "2025-02-25T11:23:53.835168",
     "exception": false,
     "start_time": "2025-02-25T10:06:24.190343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected Attribute Names: ['GENDER']\n",
      "Privileged Protected Attributes: [{'GENDER': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1}]\n",
      "Sensitive Attribute: GENDER\n",
      "Description: GENDER Mitigation\n",
      "  Accuracy: 0.5135\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5118\n",
      "  Disparate Impact: 0.8116\n",
      "  Statistical Parity Difference: -0.1056\n",
      "  Between Group Coefficient of Variation: 0.1212\n",
      "  Between Group Generalized Entropy Index: 0.0073\n",
      "  Between Group Theil Index: 0.0074\n",
      "  Mean Difference: -0.1056\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1122\n",
      "  Average Odds Difference: -0.1122\n",
      "  Average Predictive Value Difference: 0.1431\n",
      "  Between All Groups Coefficient of Variation: 0.1212\n",
      "  Between All Groups Generalized Entropy Index: 0.0073\n",
      "  Between All Groups Theil Index: 0.0074\n",
      "  Coefficient of Variation: 0.6939\n",
      "  Differential Fairness Bias Amplification: -0.0714\n",
      "  Equal Opportunity Difference: -0.0918\n",
      "  Equalized Odds Difference: 0.1326\n",
      "  Error Rate: 0.4865\n",
      "  Error Rate Difference: -0.0191\n",
      "  Error Rate Ratio: 0.9614\n",
      "  False Discovery Rate: 0.4802\n",
      "  False Discovery Rate Difference: -0.1628\n",
      "  False Discovery Rate Ratio: 0.7021\n",
      "  False Negative Rate: 0.4750\n",
      "  False Negative Rate Difference: 0.0918\n",
      "  False Negative Rate Ratio: 1.2152\n",
      "  False Omission Rate: 0.4931\n",
      "  False Omission Rate Difference: 0.1233\n",
      "  False Omission Rate Ratio: 1.2868\n",
      "  False Positive Rate: 0.4983\n",
      "  False Positive Rate Difference: -0.1326\n",
      "  False Positive Rate Ratio: 0.7589\n",
      "  Generalized Entropy Index: 0.2408\n",
      "  Generalized Equalized Odds Difference: 0.1326\n",
      "  Generalized False Negative Rate: 0.4750\n",
      "  Generalized False Positive Rate: 0.4983\n",
      "  Generalized True Negative Rate: 0.5017\n",
      "  Generalized True Positive Rate: 0.5250\n",
      "  Negative Predictive Value: 0.5069\n",
      "  Number of False Negatives: 3700.0000\n",
      "  Number of False Positives: 3778.0000\n",
      "  Number of Generalized False Negatives: 3700.0000\n",
      "  Number of Generalized False Positives: 3778.0000\n",
      "  Number of Generalized True Negatives: 3804.0000\n",
      "  Number of Generalized True Positives: 4090.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7504.0000\n",
      "  Number of Predicted Positives: 7868.0000\n",
      "  Number of True Negatives: 3804.0000\n",
      "  Number of True Positives: 4090.0000\n",
      "  Positive Predictive Value: 0.5198\n",
      "  Power: 4090.0000\n",
      "  Precision: 0.5198\n",
      "  Recall: 0.5250\n",
      "  Sensitivity: 0.5250\n",
      "  Specificity: 0.5017\n",
      "  Theil Index: 0.3339\n",
      "  True Negative Rate: 0.5017\n",
      "  True Positive Rate: 0.5250\n",
      "  True Positive Rate Difference: -0.0918\n",
      "  Accuracy: 0.5135\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5118\n",
      "  Disparate Impact: 0.8116\n",
      "  Statistical Parity Difference: -0.1056\n",
      "  Between Group Coefficient of Variation: 0.1212\n",
      "  Between Group Generalized Entropy Index: 0.0073\n",
      "  Between Group Theil Index: 0.0074\n",
      "  Mean Difference: -0.1056\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1122\n",
      "  Average Odds Difference: -0.1122\n",
      "  Average Predictive Value Difference: 0.1431\n",
      "  Between All Groups Coefficient of Variation: 0.1212\n",
      "  Between All Groups Generalized Entropy Index: 0.0073\n",
      "  Between All Groups Theil Index: 0.0074\n",
      "  Coefficient of Variation: 0.6939\n",
      "  Differential Fairness Bias Amplification: -0.0714\n",
      "  Equal Opportunity Difference: -0.0918\n",
      "  Equalized Odds Difference: 0.1326\n",
      "  Error Rate: 0.4865\n",
      "  Error Rate Difference: -0.0191\n",
      "  Error Rate Ratio: 0.9614\n",
      "  False Discovery Rate: 0.4802\n",
      "  False Discovery Rate Difference: -0.1628\n",
      "  False Discovery Rate Ratio: 0.7021\n",
      "  False Negative Rate: 0.4750\n",
      "  False Negative Rate Difference: 0.0918\n",
      "  False Negative Rate Ratio: 1.2152\n",
      "  False Omission Rate: 0.4931\n",
      "  False Omission Rate Difference: 0.1233\n",
      "  False Omission Rate Ratio: 1.2868\n",
      "  False Positive Rate: 0.4983\n",
      "  False Positive Rate Difference: -0.1326\n",
      "  False Positive Rate Ratio: 0.7589\n",
      "  Generalized Entropy Index: 0.2408\n",
      "  Generalized Equalized Odds Difference: 0.1326\n",
      "  Generalized False Negative Rate: 0.4750\n",
      "  Generalized False Positive Rate: 0.4983\n",
      "  Generalized True Negative Rate: 0.5017\n",
      "  Generalized True Positive Rate: 0.5250\n",
      "  Negative Predictive Value: 0.5069\n",
      "  Number of False Negatives: 3700.0000\n",
      "  Number of False Positives: 3778.0000\n",
      "  Number of Generalized False Negatives: 3700.0000\n",
      "  Number of Generalized False Positives: 3778.0000\n",
      "  Number of Generalized True Negatives: 3804.0000\n",
      "  Number of Generalized True Positives: 4090.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7504.0000\n",
      "  Number of Predicted Positives: 7868.0000\n",
      "  Number of True Negatives: 3804.0000\n",
      "  Number of True Positives: 4090.0000\n",
      "  Positive Predictive Value: 0.5198\n",
      "  Power: 4090.0000\n",
      "  Precision: 0.5198\n",
      "  Recall: 0.5250\n",
      "  Sensitivity: 0.5250\n",
      "  Specificity: 0.5017\n",
      "  Theil Index: 0.3339\n",
      "  True Negative Rate: 0.5017\n",
      "  True Positive Rate: 0.5250\n",
      "  True Positive Rate Difference: -0.0918\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.4452 - loss: 1.7031 - val_accuracy: 0.7015 - val_loss: 0.8276 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7077 - loss: 0.8053 - val_accuracy: 0.7949 - val_loss: 0.5708 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.6419 - val_accuracy: 0.7864 - val_loss: 0.5841 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.5677 - val_accuracy: 0.8024 - val_loss: 0.5180 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.5280 - val_accuracy: 0.8280 - val_loss: 0.4380 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4990 - val_accuracy: 0.8372 - val_loss: 0.4132 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4762 - val_accuracy: 0.8421 - val_loss: 0.4031 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4515 - val_accuracy: 0.8415 - val_loss: 0.4132 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.4401 - val_accuracy: 0.8508 - val_loss: 0.3838 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4330 - val_accuracy: 0.8658 - val_loss: 0.3411 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.4164 - val_accuracy: 0.8569 - val_loss: 0.3617 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.4059 - val_accuracy: 0.8532 - val_loss: 0.3645 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.4016 - val_accuracy: 0.8411 - val_loss: 0.4073 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3995 - val_accuracy: 0.8608 - val_loss: 0.3714 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3944\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3944 - val_accuracy: 0.8483 - val_loss: 0.3791 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3342 - val_accuracy: 0.8948 - val_loss: 0.2721 - learning_rate: 4.7750e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.3234 - val_accuracy: 0.8870 - val_loss: 0.2822 - learning_rate: 4.7750e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.3159 - val_accuracy: 0.8967 - val_loss: 0.2607 - learning_rate: 4.7750e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.3075 - val_accuracy: 0.8917 - val_loss: 0.2693 - learning_rate: 4.7750e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.3084 - val_accuracy: 0.8819 - val_loss: 0.2918 - learning_rate: 4.7750e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.3049 - val_accuracy: 0.8920 - val_loss: 0.2736 - learning_rate: 4.7750e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.2997 - val_accuracy: 0.8906 - val_loss: 0.2735 - learning_rate: 4.7750e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.3003 - val_accuracy: 0.8967 - val_loss: 0.2599 - learning_rate: 4.7750e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.2932 - val_accuracy: 0.8906 - val_loss: 0.2694 - learning_rate: 4.7750e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2902 - val_accuracy: 0.8950 - val_loss: 0.2638 - learning_rate: 4.7750e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2936 - val_accuracy: 0.8867 - val_loss: 0.2783 - learning_rate: 4.7750e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.2888 - val_accuracy: 0.8963 - val_loss: 0.2620 - learning_rate: 4.7750e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2877\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2877 - val_accuracy: 0.8695 - val_loss: 0.3415 - learning_rate: 4.7750e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2611 - val_accuracy: 0.9051 - val_loss: 0.2379 - learning_rate: 2.3875e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2520 - val_accuracy: 0.9112 - val_loss: 0.2211 - learning_rate: 2.3875e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2441 - val_accuracy: 0.9113 - val_loss: 0.2187 - learning_rate: 2.3875e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2495 - val_accuracy: 0.9088 - val_loss: 0.2258 - learning_rate: 2.3875e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9014 - loss: 0.2498 - val_accuracy: 0.9058 - val_loss: 0.2367 - learning_rate: 2.3875e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2479 - val_accuracy: 0.9030 - val_loss: 0.2379 - learning_rate: 2.3875e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2445 - val_accuracy: 0.9108 - val_loss: 0.2218 - learning_rate: 2.3875e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2552/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2454\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2454 - val_accuracy: 0.9100 - val_loss: 0.2247 - learning_rate: 2.3875e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2305 - val_accuracy: 0.9152 - val_loss: 0.2099 - learning_rate: 1.1937e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2214 - val_accuracy: 0.9188 - val_loss: 0.2009 - learning_rate: 1.1937e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2231 - val_accuracy: 0.9175 - val_loss: 0.2027 - learning_rate: 1.1937e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2227 - val_accuracy: 0.9184 - val_loss: 0.2015 - learning_rate: 1.1937e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2185 - val_accuracy: 0.9188 - val_loss: 0.1999 - learning_rate: 1.1937e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2165 - val_accuracy: 0.9196 - val_loss: 0.1988 - learning_rate: 1.1937e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2178 - val_accuracy: 0.9161 - val_loss: 0.2057 - learning_rate: 1.1937e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2203 - val_accuracy: 0.9163 - val_loss: 0.2038 - learning_rate: 1.1937e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2158 - val_accuracy: 0.9170 - val_loss: 0.2023 - learning_rate: 1.1937e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2189 - val_accuracy: 0.9200 - val_loss: 0.1991 - learning_rate: 1.1937e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2132 - val_accuracy: 0.9198 - val_loss: 0.1986 - learning_rate: 1.1937e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2151 - val_accuracy: 0.9209 - val_loss: 0.2017 - learning_rate: 1.1937e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2152 - val_accuracy: 0.9179 - val_loss: 0.1987 - learning_rate: 1.1937e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2125 - val_accuracy: 0.9221 - val_loss: 0.1931 - learning_rate: 1.1937e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2123 - val_accuracy: 0.9233 - val_loss: 0.1927 - learning_rate: 1.1937e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2131 - val_accuracy: 0.9207 - val_loss: 0.1943 - learning_rate: 1.1937e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2109 - val_accuracy: 0.9219 - val_loss: 0.1957 - learning_rate: 1.1937e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2105 - val_accuracy: 0.9182 - val_loss: 0.2016 - learning_rate: 1.1937e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2134 - val_accuracy: 0.9203 - val_loss: 0.1937 - learning_rate: 1.1937e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2078\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2078 - val_accuracy: 0.9191 - val_loss: 0.1976 - learning_rate: 1.1937e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2005 - val_accuracy: 0.9243 - val_loss: 0.1872 - learning_rate: 5.9687e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.1978 - val_accuracy: 0.9246 - val_loss: 0.1862 - learning_rate: 5.9687e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.1981 - val_accuracy: 0.9250 - val_loss: 0.1842 - learning_rate: 5.9687e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.1972 - val_accuracy: 0.9233 - val_loss: 0.1863 - learning_rate: 5.9687e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.1990 - val_accuracy: 0.9257 - val_loss: 0.1877 - learning_rate: 5.9687e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.1936 - val_accuracy: 0.9275 - val_loss: 0.1834 - learning_rate: 5.9687e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.1941 - val_accuracy: 0.9252 - val_loss: 0.1857 - learning_rate: 5.9687e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.1952 - val_accuracy: 0.9255 - val_loss: 0.1820 - learning_rate: 5.9687e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.1932 - val_accuracy: 0.9251 - val_loss: 0.1856 - learning_rate: 5.9687e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.1968 - val_accuracy: 0.9275 - val_loss: 0.1823 - learning_rate: 5.9687e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.1982 - val_accuracy: 0.9280 - val_loss: 0.1794 - learning_rate: 5.9687e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.1979 - val_accuracy: 0.9259 - val_loss: 0.1839 - learning_rate: 5.9687e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.1986 - val_accuracy: 0.9260 - val_loss: 0.1835 - learning_rate: 5.9687e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.1916 - val_accuracy: 0.9267 - val_loss: 0.1844 - learning_rate: 5.9687e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.1943 - val_accuracy: 0.9272 - val_loss: 0.1805 - learning_rate: 5.9687e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2548/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.1939\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.1939 - val_accuracy: 0.9274 - val_loss: 0.1820 - learning_rate: 5.9687e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1847 - val_accuracy: 0.9304 - val_loss: 0.1773 - learning_rate: 2.9844e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1870 - val_accuracy: 0.9288 - val_loss: 0.1793 - learning_rate: 2.9844e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.1866 - val_accuracy: 0.9283 - val_loss: 0.1798 - learning_rate: 2.9844e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1882 - val_accuracy: 0.9281 - val_loss: 0.1762 - learning_rate: 2.9844e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.1826 - val_accuracy: 0.9306 - val_loss: 0.1750 - learning_rate: 2.9844e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.1860 - val_accuracy: 0.9301 - val_loss: 0.1765 - learning_rate: 2.9844e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.1851 - val_accuracy: 0.9315 - val_loss: 0.1759 - learning_rate: 2.9844e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.1869 - val_accuracy: 0.9257 - val_loss: 0.1849 - learning_rate: 2.9844e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.1848 - val_accuracy: 0.9302 - val_loss: 0.1773 - learning_rate: 2.9844e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.1829\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.4921874935680535e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.1829 - val_accuracy: 0.9281 - val_loss: 0.1766 - learning_rate: 2.9844e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1830 - val_accuracy: 0.9307 - val_loss: 0.1755 - learning_rate: 1.4922e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.1800 - val_accuracy: 0.9299 - val_loss: 0.1756 - learning_rate: 1.4922e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.1803 - val_accuracy: 0.9306 - val_loss: 0.1742 - learning_rate: 1.4922e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.1835 - val_accuracy: 0.9314 - val_loss: 0.1737 - learning_rate: 1.4922e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.1839 - val_accuracy: 0.9308 - val_loss: 0.1747 - learning_rate: 1.4922e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1831 - val_accuracy: 0.9328 - val_loss: 0.1724 - learning_rate: 1.4922e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.1866 - val_accuracy: 0.9321 - val_loss: 0.1734 - learning_rate: 1.4922e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.1819 - val_accuracy: 0.9310 - val_loss: 0.1738 - learning_rate: 1.4922e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1827 - val_accuracy: 0.9324 - val_loss: 0.1729 - learning_rate: 1.4922e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1811 - val_accuracy: 0.9321 - val_loss: 0.1728 - learning_rate: 1.4922e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.1830\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.460937467840267e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.1830 - val_accuracy: 0.9325 - val_loss: 0.1730 - learning_rate: 1.4922e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1813 - val_accuracy: 0.9317 - val_loss: 0.1726 - learning_rate: 7.4609e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1796 - val_accuracy: 0.9328 - val_loss: 0.1720 - learning_rate: 7.4609e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1802 - val_accuracy: 0.9328 - val_loss: 0.1714 - learning_rate: 7.4609e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1790 - val_accuracy: 0.9328 - val_loss: 0.1730 - learning_rate: 7.4609e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1802 - val_accuracy: 0.9322 - val_loss: 0.1725 - learning_rate: 7.4609e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.1804 - val_accuracy: 0.9330 - val_loss: 0.1712 - learning_rate: 7.4609e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.1802 - val_accuracy: 0.9334 - val_loss: 0.1710 - learning_rate: 7.4609e-06\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.4717 - loss: 1.6288 - val_accuracy: 0.7163 - val_loss: 0.7960 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.7469 - val_accuracy: 0.7615 - val_loss: 0.6625 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.6239 - val_accuracy: 0.8074 - val_loss: 0.5027 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.5619 - val_accuracy: 0.8014 - val_loss: 0.5283 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5098 - val_accuracy: 0.8299 - val_loss: 0.4502 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.4771 - val_accuracy: 0.8257 - val_loss: 0.4586 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4619 - val_accuracy: 0.8500 - val_loss: 0.4057 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4542 - val_accuracy: 0.8299 - val_loss: 0.4380 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.4344 - val_accuracy: 0.8514 - val_loss: 0.3932 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.4147 - val_accuracy: 0.8487 - val_loss: 0.3829 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.4100 - val_accuracy: 0.8347 - val_loss: 0.4180 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.3997 - val_accuracy: 0.8538 - val_loss: 0.3645 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.3987 - val_accuracy: 0.8433 - val_loss: 0.3907 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3896 - val_accuracy: 0.8353 - val_loss: 0.4399 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3865 - val_accuracy: 0.8619 - val_loss: 0.3596 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3790 - val_accuracy: 0.8464 - val_loss: 0.3751 - learning_rate: 9.5500e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8554 - loss: 0.3759 - val_accuracy: 0.8654 - val_loss: 0.3455 - learning_rate: 9.5500e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3671 - val_accuracy: 0.8655 - val_loss: 0.3411 - learning_rate: 9.5500e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3649 - val_accuracy: 0.8732 - val_loss: 0.3190 - learning_rate: 9.5500e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3658 - val_accuracy: 0.8569 - val_loss: 0.3600 - learning_rate: 9.5500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.3598 - val_accuracy: 0.8679 - val_loss: 0.3471 - learning_rate: 9.5500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.3514 - val_accuracy: 0.8677 - val_loss: 0.3289 - learning_rate: 9.5500e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.3495 - val_accuracy: 0.8711 - val_loss: 0.3222 - learning_rate: 9.5500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3481 - val_accuracy: 0.8782 - val_loss: 0.3065 - learning_rate: 9.5500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.3426 - val_accuracy: 0.8674 - val_loss: 0.3419 - learning_rate: 9.5500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3509 - val_accuracy: 0.8675 - val_loss: 0.3315 - learning_rate: 9.5500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3480 - val_accuracy: 0.8585 - val_loss: 0.3569 - learning_rate: 9.5500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3386 - val_accuracy: 0.8590 - val_loss: 0.3576 - learning_rate: 9.5500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.3427\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.3427 - val_accuracy: 0.8629 - val_loss: 0.3437 - learning_rate: 9.5500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2885 - val_accuracy: 0.8933 - val_loss: 0.2686 - learning_rate: 4.7750e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2791 - val_accuracy: 0.8971 - val_loss: 0.2545 - learning_rate: 4.7750e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.2723 - val_accuracy: 0.8816 - val_loss: 0.2941 - learning_rate: 4.7750e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2705 - val_accuracy: 0.8913 - val_loss: 0.2679 - learning_rate: 4.7750e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.2702 - val_accuracy: 0.8965 - val_loss: 0.2520 - learning_rate: 4.7750e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2657 - val_accuracy: 0.8983 - val_loss: 0.2549 - learning_rate: 4.7750e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.2672 - val_accuracy: 0.8958 - val_loss: 0.2526 - learning_rate: 4.7750e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2679 - val_accuracy: 0.8826 - val_loss: 0.2877 - learning_rate: 4.7750e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2576 - val_accuracy: 0.9012 - val_loss: 0.2486 - learning_rate: 4.7750e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.2539 - val_accuracy: 0.8996 - val_loss: 0.2458 - learning_rate: 4.7750e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2521 - val_accuracy: 0.8870 - val_loss: 0.2973 - learning_rate: 4.7750e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2573 - val_accuracy: 0.8986 - val_loss: 0.2486 - learning_rate: 4.7750e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9014 - loss: 0.2498 - val_accuracy: 0.8959 - val_loss: 0.2652 - learning_rate: 4.7750e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.2537 - val_accuracy: 0.8966 - val_loss: 0.2576 - learning_rate: 4.7750e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2550/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2540\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2540 - val_accuracy: 0.8954 - val_loss: 0.2554 - learning_rate: 4.7750e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2207 - val_accuracy: 0.9122 - val_loss: 0.2145 - learning_rate: 2.3875e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2198 - val_accuracy: 0.9146 - val_loss: 0.2099 - learning_rate: 2.3875e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2177 - val_accuracy: 0.9139 - val_loss: 0.2117 - learning_rate: 2.3875e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2118 - val_accuracy: 0.9189 - val_loss: 0.2082 - learning_rate: 2.3875e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2126 - val_accuracy: 0.8978 - val_loss: 0.2580 - learning_rate: 2.3875e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2116 - val_accuracy: 0.9109 - val_loss: 0.2174 - learning_rate: 2.3875e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2077 - val_accuracy: 0.9142 - val_loss: 0.2150 - learning_rate: 2.3875e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2111 - val_accuracy: 0.9184 - val_loss: 0.2069 - learning_rate: 2.3875e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2070 - val_accuracy: 0.9123 - val_loss: 0.2185 - learning_rate: 2.3875e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2056 - val_accuracy: 0.9215 - val_loss: 0.1997 - learning_rate: 2.3875e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2055 - val_accuracy: 0.9155 - val_loss: 0.2138 - learning_rate: 2.3875e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2067 - val_accuracy: 0.9168 - val_loss: 0.2020 - learning_rate: 2.3875e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2042 - val_accuracy: 0.9214 - val_loss: 0.1987 - learning_rate: 2.3875e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2027 - val_accuracy: 0.9202 - val_loss: 0.1997 - learning_rate: 2.3875e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2041 - val_accuracy: 0.9248 - val_loss: 0.1929 - learning_rate: 2.3875e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2057 - val_accuracy: 0.9159 - val_loss: 0.2117 - learning_rate: 2.3875e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.1987 - val_accuracy: 0.9146 - val_loss: 0.2088 - learning_rate: 2.3875e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2013 - val_accuracy: 0.9185 - val_loss: 0.2069 - learning_rate: 2.3875e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2026 - val_accuracy: 0.9177 - val_loss: 0.2066 - learning_rate: 2.3875e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2558/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.1981\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.1981 - val_accuracy: 0.9118 - val_loss: 0.2225 - learning_rate: 2.3875e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.1824 - val_accuracy: 0.9273 - val_loss: 0.1835 - learning_rate: 1.1937e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1802 - val_accuracy: 0.9265 - val_loss: 0.1863 - learning_rate: 1.1937e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1783 - val_accuracy: 0.9275 - val_loss: 0.1815 - learning_rate: 1.1937e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1815 - val_accuracy: 0.9295 - val_loss: 0.1829 - learning_rate: 1.1937e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.1736 - val_accuracy: 0.9292 - val_loss: 0.1835 - learning_rate: 1.1937e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.1767 - val_accuracy: 0.9247 - val_loss: 0.1864 - learning_rate: 1.1937e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.1784 - val_accuracy: 0.9269 - val_loss: 0.1831 - learning_rate: 1.1937e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1770 - val_accuracy: 0.9318 - val_loss: 0.1780 - learning_rate: 1.1937e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.1770 - val_accuracy: 0.9286 - val_loss: 0.1825 - learning_rate: 1.1937e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1732 - val_accuracy: 0.9316 - val_loss: 0.1782 - learning_rate: 1.1937e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.1757 - val_accuracy: 0.9322 - val_loss: 0.1741 - learning_rate: 1.1937e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.1736 - val_accuracy: 0.9310 - val_loss: 0.1770 - learning_rate: 1.1937e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1734 - val_accuracy: 0.9288 - val_loss: 0.1833 - learning_rate: 1.1937e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1749 - val_accuracy: 0.9301 - val_loss: 0.1820 - learning_rate: 1.1937e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1721 - val_accuracy: 0.9321 - val_loss: 0.1744 - learning_rate: 1.1937e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.1723\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.1723 - val_accuracy: 0.9306 - val_loss: 0.1765 - learning_rate: 1.1937e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.1638 - val_accuracy: 0.9347 - val_loss: 0.1699 - learning_rate: 5.9687e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1621 - val_accuracy: 0.9332 - val_loss: 0.1703 - learning_rate: 5.9687e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1616 - val_accuracy: 0.9352 - val_loss: 0.1688 - learning_rate: 5.9687e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.1559 - val_accuracy: 0.9366 - val_loss: 0.1668 - learning_rate: 5.9687e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1603 - val_accuracy: 0.9335 - val_loss: 0.1718 - learning_rate: 5.9687e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.1633 - val_accuracy: 0.9363 - val_loss: 0.1679 - learning_rate: 5.9687e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1559 - val_accuracy: 0.9367 - val_loss: 0.1667 - learning_rate: 5.9687e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.1569 - val_accuracy: 0.9370 - val_loss: 0.1670 - learning_rate: 5.9687e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1596 - val_accuracy: 0.9368 - val_loss: 0.1660 - learning_rate: 5.9687e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1610 - val_accuracy: 0.9369 - val_loss: 0.1646 - learning_rate: 5.9687e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1578 - val_accuracy: 0.9342 - val_loss: 0.1722 - learning_rate: 5.9687e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1580 - val_accuracy: 0.9360 - val_loss: 0.1675 - learning_rate: 5.9687e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1587 - val_accuracy: 0.9375 - val_loss: 0.1648 - learning_rate: 5.9687e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.1597 - val_accuracy: 0.9353 - val_loss: 0.1698 - learning_rate: 5.9687e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2544/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9379 - loss: 0.1573\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9379 - loss: 0.1573 - val_accuracy: 0.9368 - val_loss: 0.1662 - learning_rate: 5.9687e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1534 - val_accuracy: 0.9378 - val_loss: 0.1631 - learning_rate: 2.9844e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1519 - val_accuracy: 0.9387 - val_loss: 0.1622 - learning_rate: 2.9844e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.1539 - val_accuracy: 0.9368 - val_loss: 0.1638 - learning_rate: 2.9844e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.1499 - val_accuracy: 0.9393 - val_loss: 0.1599 - learning_rate: 2.9844e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1512 - val_accuracy: 0.9375 - val_loss: 0.1614 - learning_rate: 2.9844e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "  Accuracy: 0.5060\n",
      "  Base Rate: 0.4985\n",
      "  Selection Rate: 0.5085\n",
      "  Disparate Impact: 0.7829\n",
      "  Statistical Parity Difference: -0.1228\n",
      "  Between Group Coefficient of Variation: 0.1334\n",
      "  Between Group Generalized Entropy Index: 0.0089\n",
      "  Between Group Theil Index: 0.0090\n",
      "  Mean Difference: -0.1228\n",
      "  Smoothed Empirical Differential Fairness: 0.2990\n",
      "  Consistency: 0.9531\n",
      "  Average Absolute Odds Difference: 0.1276\n",
      "  Average Odds Difference: -0.1276\n",
      "  Average Predictive Value Difference: 0.1511\n",
      "  Between All Groups Coefficient of Variation: 0.1334\n",
      "  Between All Groups Generalized Entropy Index: 0.0089\n",
      "  Between All Groups Theil Index: 0.0090\n",
      "  Coefficient of Variation: 0.6958\n",
      "  Differential Fairness Bias Amplification: -0.0503\n",
      "  Equal Opportunity Difference: -0.1091\n",
      "  Equalized Odds Difference: 0.1462\n",
      "  Error Rate: 0.4940\n",
      "  Error Rate Difference: -0.0183\n",
      "  Error Rate Ratio: 0.9635\n",
      "  False Discovery Rate: 0.4955\n",
      "  False Discovery Rate Difference: -0.1693\n",
      "  False Discovery Rate Ratio: 0.6997\n",
      "  False Negative Rate: 0.4854\n",
      "  False Negative Rate Difference: 0.1091\n",
      "  False Negative Rate Ratio: 1.2556\n",
      "  False Omission Rate: 0.4924\n",
      "  False Omission Rate Difference: 0.1328\n",
      "  False Omission Rate Ratio: 1.3143\n",
      "  False Positive Rate: 0.5024\n",
      "  False Positive Rate Difference: -0.1462\n",
      "  False Positive Rate Ratio: 0.7388\n",
      "  Generalized Entropy Index: 0.2421\n",
      "  Generalized Equalized Odds Difference: 0.1462\n",
      "  Generalized False Negative Rate: 0.4854\n",
      "  Generalized False Positive Rate: 0.5024\n",
      "  Generalized True Negative Rate: 0.4976\n",
      "  Generalized True Positive Rate: 0.5146\n",
      "  Negative Predictive Value: 0.5076\n",
      "  Number of False Negatives: 2480.0000\n",
      "  Number of False Positives: 2582.0000\n",
      "  Number of Generalized False Negatives: 2480.0000\n",
      "  Number of Generalized False Positives: 2582.0000\n",
      "  Number of Generalized True Negatives: 2557.0000\n",
      "  Number of Generalized True Positives: 2629.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5139.0000\n",
      "  Number of Positives: 5109.0000\n",
      "  Number of Predicted Negatives: 5037.0000\n",
      "  Number of Predicted Positives: 5211.0000\n",
      "  Number of True Negatives: 2557.0000\n",
      "  Number of True Positives: 2629.0000\n",
      "  Positive Predictive Value: 0.5045\n",
      "  Power: 2629.0000\n",
      "  Precision: 0.5045\n",
      "  Recall: 0.5146\n",
      "  Sensitivity: 0.5146\n",
      "  Specificity: 0.4976\n",
      "  Theil Index: 0.3359\n",
      "  True Negative Rate: 0.4976\n",
      "  True Positive Rate: 0.5146\n",
      "  True Positive Rate Difference: -0.1091\n",
      "  Accuracy: 0.5060\n",
      "  Base Rate: 0.4985\n",
      "  Selection Rate: 0.5085\n",
      "  Disparate Impact: 0.7829\n",
      "  Statistical Parity Difference: -0.1228\n",
      "  Between Group Coefficient of Variation: 0.1334\n",
      "  Between Group Generalized Entropy Index: 0.0089\n",
      "  Between Group Theil Index: 0.0090\n",
      "  Mean Difference: -0.1228\n",
      "  Smoothed Empirical Differential Fairness: 0.2990\n",
      "  Consistency: 0.9531\n",
      "  Average Absolute Odds Difference: 0.1276\n",
      "  Average Odds Difference: -0.1276\n",
      "  Average Predictive Value Difference: 0.1511\n",
      "  Between All Groups Coefficient of Variation: 0.1334\n",
      "  Between All Groups Generalized Entropy Index: 0.0089\n",
      "  Between All Groups Theil Index: 0.0090\n",
      "  Coefficient of Variation: 0.6958\n",
      "  Differential Fairness Bias Amplification: -0.0503\n",
      "  Equal Opportunity Difference: -0.1091\n",
      "  Equalized Odds Difference: 0.1462\n",
      "  Error Rate: 0.4940\n",
      "  Error Rate Difference: -0.0183\n",
      "  Error Rate Ratio: 0.9635\n",
      "  False Discovery Rate: 0.4955\n",
      "  False Discovery Rate Difference: -0.1693\n",
      "  False Discovery Rate Ratio: 0.6997\n",
      "  False Negative Rate: 0.4854\n",
      "  False Negative Rate Difference: 0.1091\n",
      "  False Negative Rate Ratio: 1.2556\n",
      "  False Omission Rate: 0.4924\n",
      "  False Omission Rate Difference: 0.1328\n",
      "  False Omission Rate Ratio: 1.3143\n",
      "  False Positive Rate: 0.5024\n",
      "  False Positive Rate Difference: -0.1462\n",
      "  False Positive Rate Ratio: 0.7388\n",
      "  Generalized Entropy Index: 0.2421\n",
      "  Generalized Equalized Odds Difference: 0.1462\n",
      "  Generalized False Negative Rate: 0.4854\n",
      "  Generalized False Positive Rate: 0.5024\n",
      "  Generalized True Negative Rate: 0.4976\n",
      "  Generalized True Positive Rate: 0.5146\n",
      "  Negative Predictive Value: 0.5076\n",
      "  Number of False Negatives: 2480.0000\n",
      "  Number of False Positives: 2582.0000\n",
      "  Number of Generalized False Negatives: 2480.0000\n",
      "  Number of Generalized False Positives: 2582.0000\n",
      "  Number of Generalized True Negatives: 2557.0000\n",
      "  Number of Generalized True Positives: 2629.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5139.0000\n",
      "  Number of Positives: 5109.0000\n",
      "  Number of Predicted Negatives: 5037.0000\n",
      "  Number of Predicted Positives: 5211.0000\n",
      "  Number of True Negatives: 2557.0000\n",
      "  Number of True Positives: 2629.0000\n",
      "  Positive Predictive Value: 0.5045\n",
      "  Power: 2629.0000\n",
      "  Precision: 0.5045\n",
      "  Recall: 0.5146\n",
      "  Sensitivity: 0.5146\n",
      "  Specificity: 0.4976\n",
      "  Theil Index: 0.3359\n",
      "  True Negative Rate: 0.4976\n",
      "  True Positive Rate: 0.5146\n",
      "  True Positive Rate Difference: -0.1091\n",
      "  Accuracy: 0.5218\n",
      "  Base Rate: 0.5076\n",
      "  Selection Rate: 0.5120\n",
      "  Disparate Impact: 0.7901\n",
      "  Statistical Parity Difference: -0.1191\n",
      "  Between Group Coefficient of Variation: 0.1348\n",
      "  Between Group Generalized Entropy Index: 0.0091\n",
      "  Between Group Theil Index: 0.0092\n",
      "  Mean Difference: -0.1191\n",
      "  Smoothed Empirical Differential Fairness: 0.3151\n",
      "  Consistency: 0.9523\n",
      "  Average Absolute Odds Difference: 0.1296\n",
      "  Average Odds Difference: -0.1296\n",
      "  Average Predictive Value Difference: 0.1595\n",
      "  Between All Groups Coefficient of Variation: 0.1348\n",
      "  Between All Groups Generalized Entropy Index: 0.0091\n",
      "  Between All Groups Theil Index: 0.0092\n",
      "  Coefficient of Variation: 0.6885\n",
      "  Differential Fairness Bias Amplification: -0.0719\n",
      "  Equal Opportunity Difference: -0.1052\n",
      "  Equalized Odds Difference: 0.1540\n",
      "  Error Rate: 0.4782\n",
      "  Error Rate Difference: -0.0226\n",
      "  Error Rate Ratio: 0.9537\n",
      "  False Discovery Rate: 0.4713\n",
      "  False Discovery Rate Difference: -0.1829\n",
      "  False Discovery Rate Ratio: 0.6650\n",
      "  False Negative Rate: 0.4667\n",
      "  False Negative Rate Difference: 0.1052\n",
      "  False Negative Rate Ratio: 1.2566\n",
      "  False Omission Rate: 0.4855\n",
      "  False Omission Rate Difference: 0.1361\n",
      "  False Omission Rate Ratio: 1.3287\n",
      "  False Positive Rate: 0.4901\n",
      "  False Positive Rate Difference: -0.1540\n",
      "  False Positive Rate Ratio: 0.7200\n",
      "  Generalized Entropy Index: 0.2370\n",
      "  Generalized Equalized Odds Difference: 0.1540\n",
      "  Generalized False Negative Rate: 0.4667\n",
      "  Generalized False Positive Rate: 0.4901\n",
      "  Generalized True Negative Rate: 0.5099\n",
      "  Generalized True Positive Rate: 0.5333\n",
      "  Negative Predictive Value: 0.5145\n",
      "  Number of False Negatives: 2428.0000\n",
      "  Number of False Positives: 2473.0000\n",
      "  Number of Generalized False Negatives: 2428.0000\n",
      "  Number of Generalized False Positives: 2473.0000\n",
      "  Number of Generalized True Negatives: 2573.0000\n",
      "  Number of Generalized True Positives: 2774.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5046.0000\n",
      "  Number of Positives: 5202.0000\n",
      "  Number of Predicted Negatives: 5001.0000\n",
      "  Number of Predicted Positives: 5247.0000\n",
      "  Number of True Negatives: 2573.0000\n",
      "  Number of True Positives: 2774.0000\n",
      "  Positive Predictive Value: 0.5287\n",
      "  Power: 2774.0000\n",
      "  Precision: 0.5287\n",
      "  Recall: 0.5333\n",
      "  Sensitivity: 0.5333\n",
      "  Specificity: 0.5099\n",
      "  Theil Index: 0.3287\n",
      "  True Negative Rate: 0.5099\n",
      "  True Positive Rate: 0.5333\n",
      "  True Positive Rate Difference: -0.1052\n",
      "  Accuracy: 0.5218\n",
      "  Base Rate: 0.5076\n",
      "  Selection Rate: 0.5120\n",
      "  Disparate Impact: 0.7901\n",
      "  Statistical Parity Difference: -0.1191\n",
      "  Between Group Coefficient of Variation: 0.1348\n",
      "  Between Group Generalized Entropy Index: 0.0091\n",
      "  Between Group Theil Index: 0.0092\n",
      "  Mean Difference: -0.1191\n",
      "  Smoothed Empirical Differential Fairness: 0.3151\n",
      "  Consistency: 0.9523\n",
      "  Average Absolute Odds Difference: 0.1296\n",
      "  Average Odds Difference: -0.1296\n",
      "  Average Predictive Value Difference: 0.1595\n",
      "  Between All Groups Coefficient of Variation: 0.1348\n",
      "  Between All Groups Generalized Entropy Index: 0.0091\n",
      "  Between All Groups Theil Index: 0.0092\n",
      "  Coefficient of Variation: 0.6885\n",
      "  Differential Fairness Bias Amplification: -0.0719\n",
      "  Equal Opportunity Difference: -0.1052\n",
      "  Equalized Odds Difference: 0.1540\n",
      "  Error Rate: 0.4782\n",
      "  Error Rate Difference: -0.0226\n",
      "  Error Rate Ratio: 0.9537\n",
      "  False Discovery Rate: 0.4713\n",
      "  False Discovery Rate Difference: -0.1829\n",
      "  False Discovery Rate Ratio: 0.6650\n",
      "  False Negative Rate: 0.4667\n",
      "  False Negative Rate Difference: 0.1052\n",
      "  False Negative Rate Ratio: 1.2566\n",
      "  False Omission Rate: 0.4855\n",
      "  False Omission Rate Difference: 0.1361\n",
      "  False Omission Rate Ratio: 1.3287\n",
      "  False Positive Rate: 0.4901\n",
      "  False Positive Rate Difference: -0.1540\n",
      "  False Positive Rate Ratio: 0.7200\n",
      "  Generalized Entropy Index: 0.2370\n",
      "  Generalized Equalized Odds Difference: 0.1540\n",
      "  Generalized False Negative Rate: 0.4667\n",
      "  Generalized False Positive Rate: 0.4901\n",
      "  Generalized True Negative Rate: 0.5099\n",
      "  Generalized True Positive Rate: 0.5333\n",
      "  Negative Predictive Value: 0.5145\n",
      "  Number of False Negatives: 2428.0000\n",
      "  Number of False Positives: 2473.0000\n",
      "  Number of Generalized False Negatives: 2428.0000\n",
      "  Number of Generalized False Positives: 2473.0000\n",
      "  Number of Generalized True Negatives: 2573.0000\n",
      "  Number of Generalized True Positives: 2774.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5046.0000\n",
      "  Number of Positives: 5202.0000\n",
      "  Number of Predicted Negatives: 5001.0000\n",
      "  Number of Predicted Positives: 5247.0000\n",
      "  Number of True Negatives: 2573.0000\n",
      "  Number of True Positives: 2774.0000\n",
      "  Positive Predictive Value: 0.5287\n",
      "  Power: 2774.0000\n",
      "  Precision: 0.5287\n",
      "  Recall: 0.5333\n",
      "  Sensitivity: 0.5333\n",
      "  Specificity: 0.5099\n",
      "  Theil Index: 0.3287\n",
      "  True Negative Rate: 0.5099\n",
      "  True Positive Rate: 0.5333\n",
      "  True Positive Rate Difference: -0.1052\n",
      "Protected Attribute Names: ['AGE']\n",
      "Privileged Protected Attributes: [{'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE Mitigation\n",
      "  Accuracy: 0.5135\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5118\n",
      "  Disparate Impact: 1.1638\n",
      "  Statistical Parity Difference: 0.0813\n",
      "  Between Group Coefficient of Variation: 0.0350\n",
      "  Between Group Generalized Entropy Index: 0.0006\n",
      "  Between Group Theil Index: 0.0006\n",
      "  Mean Difference: 0.0813\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1286\n",
      "  Average Odds Difference: 0.0811\n",
      "  Average Predictive Value Difference: -0.0270\n",
      "  Between All Groups Coefficient of Variation: 0.0350\n",
      "  Between All Groups Generalized Entropy Index: 0.0006\n",
      "  Between All Groups Theil Index: 0.0006\n",
      "  Coefficient of Variation: 0.6939\n",
      "  Differential Fairness Bias Amplification: 0.1592\n",
      "  Equal Opportunity Difference: 0.2097\n",
      "  Equalized Odds Difference: 0.2097\n",
      "  Error Rate: 0.4865\n",
      "  Error Rate Difference: -0.1287\n",
      "  Error Rate Ratio: 0.7482\n",
      "  False Discovery Rate: 0.4802\n",
      "  False Discovery Rate Difference: -0.1045\n",
      "  False Discovery Rate Ratio: 0.7921\n",
      "  False Negative Rate: 0.4750\n",
      "  False Negative Rate Difference: -0.2097\n",
      "  False Negative Rate Ratio: 0.5922\n",
      "  False Omission Rate: 0.4931\n",
      "  False Omission Rate Difference: -0.1585\n",
      "  False Omission Rate Ratio: 0.6946\n",
      "  False Positive Rate: 0.4983\n",
      "  False Positive Rate Difference: -0.0475\n",
      "  False Positive Rate Ratio: 0.9064\n",
      "  Generalized Entropy Index: 0.2408\n",
      "  Generalized Equalized Odds Difference: 0.2097\n",
      "  Generalized False Negative Rate: 0.4750\n",
      "  Generalized False Positive Rate: 0.4983\n",
      "  Generalized True Negative Rate: 0.5017\n",
      "  Generalized True Positive Rate: 0.5250\n",
      "  Negative Predictive Value: 0.5069\n",
      "  Number of False Negatives: 3700.0000\n",
      "  Number of False Positives: 3778.0000\n",
      "  Number of Generalized False Negatives: 3700.0000\n",
      "  Number of Generalized False Positives: 3778.0000\n",
      "  Number of Generalized True Negatives: 3804.0000\n",
      "  Number of Generalized True Positives: 4090.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7504.0000\n",
      "  Number of Predicted Positives: 7868.0000\n",
      "  Number of True Negatives: 3804.0000\n",
      "  Number of True Positives: 4090.0000\n",
      "  Positive Predictive Value: 0.5198\n",
      "  Power: 4090.0000\n",
      "  Precision: 0.5198\n",
      "  Recall: 0.5250\n",
      "  Sensitivity: 0.5250\n",
      "  Specificity: 0.5017\n",
      "  Theil Index: 0.3339\n",
      "  True Negative Rate: 0.5017\n",
      "  True Positive Rate: 0.5250\n",
      "  True Positive Rate Difference: 0.2097\n",
      "  Accuracy: 0.5135\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5118\n",
      "  Disparate Impact: 1.1638\n",
      "  Statistical Parity Difference: 0.0813\n",
      "  Between Group Coefficient of Variation: 0.0350\n",
      "  Between Group Generalized Entropy Index: 0.0006\n",
      "  Between Group Theil Index: 0.0006\n",
      "  Mean Difference: 0.0813\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1286\n",
      "  Average Odds Difference: 0.0811\n",
      "  Average Predictive Value Difference: -0.0270\n",
      "  Between All Groups Coefficient of Variation: 0.0350\n",
      "  Between All Groups Generalized Entropy Index: 0.0006\n",
      "  Between All Groups Theil Index: 0.0006\n",
      "  Coefficient of Variation: 0.6939\n",
      "  Differential Fairness Bias Amplification: 0.1592\n",
      "  Equal Opportunity Difference: 0.2097\n",
      "  Equalized Odds Difference: 0.2097\n",
      "  Error Rate: 0.4865\n",
      "  Error Rate Difference: -0.1287\n",
      "  Error Rate Ratio: 0.7482\n",
      "  False Discovery Rate: 0.4802\n",
      "  False Discovery Rate Difference: -0.1045\n",
      "  False Discovery Rate Ratio: 0.7921\n",
      "  False Negative Rate: 0.4750\n",
      "  False Negative Rate Difference: -0.2097\n",
      "  False Negative Rate Ratio: 0.5922\n",
      "  False Omission Rate: 0.4931\n",
      "  False Omission Rate Difference: -0.1585\n",
      "  False Omission Rate Ratio: 0.6946\n",
      "  False Positive Rate: 0.4983\n",
      "  False Positive Rate Difference: -0.0475\n",
      "  False Positive Rate Ratio: 0.9064\n",
      "  Generalized Entropy Index: 0.2408\n",
      "  Generalized Equalized Odds Difference: 0.2097\n",
      "  Generalized False Negative Rate: 0.4750\n",
      "  Generalized False Positive Rate: 0.4983\n",
      "  Generalized True Negative Rate: 0.5017\n",
      "  Generalized True Positive Rate: 0.5250\n",
      "  Negative Predictive Value: 0.5069\n",
      "  Number of False Negatives: 3700.0000\n",
      "  Number of False Positives: 3778.0000\n",
      "  Number of Generalized False Negatives: 3700.0000\n",
      "  Number of Generalized False Positives: 3778.0000\n",
      "  Number of Generalized True Negatives: 3804.0000\n",
      "  Number of Generalized True Positives: 4090.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7504.0000\n",
      "  Number of Predicted Positives: 7868.0000\n",
      "  Number of True Negatives: 3804.0000\n",
      "  Number of True Positives: 4090.0000\n",
      "  Positive Predictive Value: 0.5198\n",
      "  Power: 4090.0000\n",
      "  Precision: 0.5198\n",
      "  Recall: 0.5250\n",
      "  Sensitivity: 0.5250\n",
      "  Specificity: 0.5017\n",
      "  Theil Index: 0.3339\n",
      "  True Negative Rate: 0.5017\n",
      "  True Positive Rate: 0.5250\n",
      "  True Positive Rate Difference: 0.2097\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.4402 - loss: 1.7176 - val_accuracy: 0.7045 - val_loss: 0.7955 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7072 - loss: 0.8061 - val_accuracy: 0.7886 - val_loss: 0.5681 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.6496 - val_accuracy: 0.7938 - val_loss: 0.5429 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 0.5805 - val_accuracy: 0.8289 - val_loss: 0.4642 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.5400 - val_accuracy: 0.8124 - val_loss: 0.4781 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.5027 - val_accuracy: 0.8192 - val_loss: 0.4744 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.4848 - val_accuracy: 0.8258 - val_loss: 0.4429 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.4703 - val_accuracy: 0.8515 - val_loss: 0.3906 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4584 - val_accuracy: 0.8379 - val_loss: 0.4144 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.4388 - val_accuracy: 0.8363 - val_loss: 0.4194 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4286 - val_accuracy: 0.8496 - val_loss: 0.3827 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4247 - val_accuracy: 0.8529 - val_loss: 0.3824 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.4188 - val_accuracy: 0.8564 - val_loss: 0.3642 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.4055 - val_accuracy: 0.8553 - val_loss: 0.3799 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.4029 - val_accuracy: 0.8630 - val_loss: 0.3528 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8465 - loss: 0.3968 - val_accuracy: 0.8301 - val_loss: 0.4568 - learning_rate: 9.5500e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.4032 - val_accuracy: 0.8586 - val_loss: 0.3626 - learning_rate: 9.5500e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3885 - val_accuracy: 0.8669 - val_loss: 0.3297 - learning_rate: 9.5500e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3716 - val_accuracy: 0.8286 - val_loss: 0.4265 - learning_rate: 9.5500e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3787 - val_accuracy: 0.8680 - val_loss: 0.3301 - learning_rate: 9.5500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.3764 - val_accuracy: 0.8638 - val_loss: 0.3564 - learning_rate: 9.5500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3753 - val_accuracy: 0.8726 - val_loss: 0.3282 - learning_rate: 9.5500e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3773 - val_accuracy: 0.8785 - val_loss: 0.3167 - learning_rate: 9.5500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3732 - val_accuracy: 0.8635 - val_loss: 0.3512 - learning_rate: 9.5500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3680 - val_accuracy: 0.8528 - val_loss: 0.3840 - learning_rate: 9.5500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.3681 - val_accuracy: 0.8377 - val_loss: 0.3996 - learning_rate: 9.5500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3641 - val_accuracy: 0.8435 - val_loss: 0.3874 - learning_rate: 9.5500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.3643 - val_accuracy: 0.8745 - val_loss: 0.3114 - learning_rate: 9.5500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3535 - val_accuracy: 0.8574 - val_loss: 0.3667 - learning_rate: 9.5500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3511 - val_accuracy: 0.8558 - val_loss: 0.3664 - learning_rate: 9.5500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3479 - val_accuracy: 0.8706 - val_loss: 0.3239 - learning_rate: 9.5500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3524 - val_accuracy: 0.8715 - val_loss: 0.3147 - learning_rate: 9.5500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2549/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3506\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3506 - val_accuracy: 0.8743 - val_loss: 0.3210 - learning_rate: 9.5500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8803 - loss: 0.3062 - val_accuracy: 0.8952 - val_loss: 0.2620 - learning_rate: 4.7750e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2908 - val_accuracy: 0.8953 - val_loss: 0.2664 - learning_rate: 4.7750e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2876 - val_accuracy: 0.8801 - val_loss: 0.2973 - learning_rate: 4.7750e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2919 - val_accuracy: 0.8967 - val_loss: 0.2622 - learning_rate: 4.7750e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.2850 - val_accuracy: 0.8992 - val_loss: 0.2588 - learning_rate: 4.7750e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2767 - val_accuracy: 0.8997 - val_loss: 0.2525 - learning_rate: 4.7750e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.2802 - val_accuracy: 0.9012 - val_loss: 0.2485 - learning_rate: 4.7750e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.2738 - val_accuracy: 0.9012 - val_loss: 0.2493 - learning_rate: 4.7750e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2806 - val_accuracy: 0.8972 - val_loss: 0.2545 - learning_rate: 4.7750e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2764 - val_accuracy: 0.8990 - val_loss: 0.2627 - learning_rate: 4.7750e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2700 - val_accuracy: 0.8981 - val_loss: 0.2521 - learning_rate: 4.7750e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2762\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2762 - val_accuracy: 0.8994 - val_loss: 0.2532 - learning_rate: 4.7750e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2465 - val_accuracy: 0.9080 - val_loss: 0.2295 - learning_rate: 2.3875e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2436 - val_accuracy: 0.9125 - val_loss: 0.2198 - learning_rate: 2.3875e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.2370 - val_accuracy: 0.9100 - val_loss: 0.2298 - learning_rate: 2.3875e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2361 - val_accuracy: 0.9004 - val_loss: 0.2398 - learning_rate: 2.3875e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2316 - val_accuracy: 0.9093 - val_loss: 0.2201 - learning_rate: 2.3875e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2343 - val_accuracy: 0.9133 - val_loss: 0.2201 - learning_rate: 2.3875e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2552/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2303\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2303 - val_accuracy: 0.9084 - val_loss: 0.2270 - learning_rate: 2.3875e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2164 - val_accuracy: 0.9130 - val_loss: 0.2178 - learning_rate: 1.1937e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2142 - val_accuracy: 0.9169 - val_loss: 0.2057 - learning_rate: 1.1937e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2100 - val_accuracy: 0.9134 - val_loss: 0.2162 - learning_rate: 1.1937e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2123 - val_accuracy: 0.9104 - val_loss: 0.2168 - learning_rate: 1.1937e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2150 - val_accuracy: 0.9167 - val_loss: 0.2073 - learning_rate: 1.1937e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2110 - val_accuracy: 0.9174 - val_loss: 0.2048 - learning_rate: 1.1937e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2106 - val_accuracy: 0.9170 - val_loss: 0.2047 - learning_rate: 1.1937e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2097 - val_accuracy: 0.9182 - val_loss: 0.2019 - learning_rate: 1.1937e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2080 - val_accuracy: 0.9177 - val_loss: 0.2048 - learning_rate: 1.1937e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2118 - val_accuracy: 0.9168 - val_loss: 0.2037 - learning_rate: 1.1937e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2076 - val_accuracy: 0.9202 - val_loss: 0.2008 - learning_rate: 1.1937e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2021 - val_accuracy: 0.9165 - val_loss: 0.2068 - learning_rate: 1.1937e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2077 - val_accuracy: 0.9213 - val_loss: 0.1965 - learning_rate: 1.1937e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2095 - val_accuracy: 0.9169 - val_loss: 0.2098 - learning_rate: 1.1937e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2049 - val_accuracy: 0.9180 - val_loss: 0.2027 - learning_rate: 1.1937e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2053 - val_accuracy: 0.9173 - val_loss: 0.2049 - learning_rate: 1.1937e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2030 - val_accuracy: 0.9194 - val_loss: 0.2006 - learning_rate: 1.1937e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2041 - val_accuracy: 0.9199 - val_loss: 0.1955 - learning_rate: 1.1937e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2039 - val_accuracy: 0.9187 - val_loss: 0.2049 - learning_rate: 1.1937e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.1980 - val_accuracy: 0.9199 - val_loss: 0.2006 - learning_rate: 1.1937e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2018 - val_accuracy: 0.9198 - val_loss: 0.1991 - learning_rate: 1.1937e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2034 - val_accuracy: 0.9192 - val_loss: 0.1994 - learning_rate: 1.1937e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2556/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.1980\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.1980 - val_accuracy: 0.9140 - val_loss: 0.2110 - learning_rate: 1.1937e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.1933 - val_accuracy: 0.9225 - val_loss: 0.1918 - learning_rate: 5.9687e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.1916 - val_accuracy: 0.9219 - val_loss: 0.1977 - learning_rate: 5.9687e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.1898 - val_accuracy: 0.9230 - val_loss: 0.1915 - learning_rate: 5.9687e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.1907 - val_accuracy: 0.9207 - val_loss: 0.1920 - learning_rate: 5.9687e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1860 - val_accuracy: 0.9243 - val_loss: 0.1916 - learning_rate: 5.9687e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.1862 - val_accuracy: 0.9222 - val_loss: 0.1957 - learning_rate: 5.9687e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.1874 - val_accuracy: 0.9235 - val_loss: 0.1903 - learning_rate: 5.9687e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.1898 - val_accuracy: 0.9237 - val_loss: 0.1894 - learning_rate: 5.9687e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.1884 - val_accuracy: 0.9241 - val_loss: 0.1921 - learning_rate: 5.9687e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.1889 - val_accuracy: 0.9242 - val_loss: 0.1881 - learning_rate: 5.9687e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.1861 - val_accuracy: 0.9226 - val_loss: 0.1924 - learning_rate: 5.9687e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1868 - val_accuracy: 0.9226 - val_loss: 0.1907 - learning_rate: 5.9687e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.1872 - val_accuracy: 0.9252 - val_loss: 0.1883 - learning_rate: 5.9687e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.1877 - val_accuracy: 0.9236 - val_loss: 0.1922 - learning_rate: 5.9687e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2555/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.1871\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.1871 - val_accuracy: 0.9227 - val_loss: 0.1931 - learning_rate: 5.9687e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1798 - val_accuracy: 0.9263 - val_loss: 0.1864 - learning_rate: 2.9844e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.1820 - val_accuracy: 0.9253 - val_loss: 0.1860 - learning_rate: 2.9844e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1810 - val_accuracy: 0.9268 - val_loss: 0.1880 - learning_rate: 2.9844e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1791 - val_accuracy: 0.9254 - val_loss: 0.1891 - learning_rate: 2.9844e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1821 - val_accuracy: 0.9266 - val_loss: 0.1849 - learning_rate: 2.9844e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1771 - val_accuracy: 0.9253 - val_loss: 0.1861 - learning_rate: 2.9844e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1856 - val_accuracy: 0.9260 - val_loss: 0.1854 - learning_rate: 2.9844e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1775 - val_accuracy: 0.9256 - val_loss: 0.1848 - learning_rate: 2.9844e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.1812 - val_accuracy: 0.9263 - val_loss: 0.1842 - learning_rate: 2.9844e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1772 - val_accuracy: 0.9249 - val_loss: 0.1855 - learning_rate: 2.9844e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.4543 - loss: 1.6618 - val_accuracy: 0.7178 - val_loss: 0.7584 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7148 - loss: 0.7755 - val_accuracy: 0.7842 - val_loss: 0.5950 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.6374 - val_accuracy: 0.7875 - val_loss: 0.5535 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.5579 - val_accuracy: 0.8145 - val_loss: 0.4970 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.5182 - val_accuracy: 0.8140 - val_loss: 0.4813 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4806 - val_accuracy: 0.8256 - val_loss: 0.4397 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4624 - val_accuracy: 0.8501 - val_loss: 0.3944 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.4464 - val_accuracy: 0.8559 - val_loss: 0.3727 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.4295 - val_accuracy: 0.8550 - val_loss: 0.3694 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.4148 - val_accuracy: 0.8477 - val_loss: 0.3998 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8453 - loss: 0.4047 - val_accuracy: 0.8665 - val_loss: 0.3440 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.3995 - val_accuracy: 0.8409 - val_loss: 0.4170 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3929 - val_accuracy: 0.8609 - val_loss: 0.3683 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3923 - val_accuracy: 0.8484 - val_loss: 0.4051 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8554 - loss: 0.3776 - val_accuracy: 0.8666 - val_loss: 0.3337 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3770 - val_accuracy: 0.8703 - val_loss: 0.3212 - learning_rate: 9.5500e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3672 - val_accuracy: 0.8750 - val_loss: 0.3191 - learning_rate: 9.5500e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3669 - val_accuracy: 0.8506 - val_loss: 0.3663 - learning_rate: 9.5500e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3672 - val_accuracy: 0.8731 - val_loss: 0.3245 - learning_rate: 9.5500e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3540 - val_accuracy: 0.8759 - val_loss: 0.3127 - learning_rate: 9.5500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.3562 - val_accuracy: 0.8781 - val_loss: 0.3102 - learning_rate: 9.5500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.3569 - val_accuracy: 0.8777 - val_loss: 0.3256 - learning_rate: 9.5500e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.3460 - val_accuracy: 0.8567 - val_loss: 0.3589 - learning_rate: 9.5500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3513 - val_accuracy: 0.8705 - val_loss: 0.3172 - learning_rate: 9.5500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.3478 - val_accuracy: 0.8716 - val_loss: 0.3201 - learning_rate: 9.5500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.3415\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.3415 - val_accuracy: 0.8822 - val_loss: 0.3221 - learning_rate: 9.5500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.2856 - val_accuracy: 0.8867 - val_loss: 0.2864 - learning_rate: 4.7750e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.2769 - val_accuracy: 0.9030 - val_loss: 0.2498 - learning_rate: 4.7750e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2751 - val_accuracy: 0.9030 - val_loss: 0.2444 - learning_rate: 4.7750e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2723 - val_accuracy: 0.9001 - val_loss: 0.2508 - learning_rate: 4.7750e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2706 - val_accuracy: 0.8975 - val_loss: 0.2630 - learning_rate: 4.7750e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2707 - val_accuracy: 0.8930 - val_loss: 0.2645 - learning_rate: 4.7750e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.2736 - val_accuracy: 0.8966 - val_loss: 0.2601 - learning_rate: 4.7750e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2650\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2650 - val_accuracy: 0.9007 - val_loss: 0.2511 - learning_rate: 4.7750e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2348 - val_accuracy: 0.9127 - val_loss: 0.2186 - learning_rate: 2.3875e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2306 - val_accuracy: 0.9113 - val_loss: 0.2243 - learning_rate: 2.3875e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.2266 - val_accuracy: 0.9118 - val_loss: 0.2173 - learning_rate: 2.3875e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2284 - val_accuracy: 0.9015 - val_loss: 0.2410 - learning_rate: 2.3875e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2248 - val_accuracy: 0.9184 - val_loss: 0.2038 - learning_rate: 2.3875e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2223 - val_accuracy: 0.9153 - val_loss: 0.2085 - learning_rate: 2.3875e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2190 - val_accuracy: 0.9168 - val_loss: 0.2041 - learning_rate: 2.3875e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2180 - val_accuracy: 0.9147 - val_loss: 0.2155 - learning_rate: 2.3875e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2204 - val_accuracy: 0.9188 - val_loss: 0.2063 - learning_rate: 2.3875e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2561/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2177\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2177 - val_accuracy: 0.9164 - val_loss: 0.2093 - learning_rate: 2.3875e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2019 - val_accuracy: 0.9228 - val_loss: 0.1925 - learning_rate: 1.1937e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.1955 - val_accuracy: 0.9247 - val_loss: 0.1865 - learning_rate: 1.1937e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.1997 - val_accuracy: 0.9231 - val_loss: 0.1926 - learning_rate: 1.1937e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.1966 - val_accuracy: 0.9247 - val_loss: 0.1868 - learning_rate: 1.1937e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.1970 - val_accuracy: 0.9244 - val_loss: 0.1877 - learning_rate: 1.1937e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.1927 - val_accuracy: 0.9264 - val_loss: 0.1840 - learning_rate: 1.1937e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.1957 - val_accuracy: 0.9242 - val_loss: 0.1915 - learning_rate: 1.1937e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.1897 - val_accuracy: 0.9252 - val_loss: 0.1865 - learning_rate: 1.1937e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1940 - val_accuracy: 0.9267 - val_loss: 0.1855 - learning_rate: 1.1937e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.1919 - val_accuracy: 0.9225 - val_loss: 0.1911 - learning_rate: 1.1937e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1933\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1933 - val_accuracy: 0.9222 - val_loss: 0.1896 - learning_rate: 1.1937e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.1799 - val_accuracy: 0.9295 - val_loss: 0.1763 - learning_rate: 5.9687e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.1801 - val_accuracy: 0.9276 - val_loss: 0.1776 - learning_rate: 5.9687e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.1806 - val_accuracy: 0.9294 - val_loss: 0.1763 - learning_rate: 5.9687e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1794 - val_accuracy: 0.9307 - val_loss: 0.1751 - learning_rate: 5.9687e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1775 - val_accuracy: 0.9314 - val_loss: 0.1742 - learning_rate: 5.9687e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.1775 - val_accuracy: 0.9306 - val_loss: 0.1734 - learning_rate: 5.9687e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.1782 - val_accuracy: 0.9324 - val_loss: 0.1738 - learning_rate: 5.9687e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.1774 - val_accuracy: 0.9350 - val_loss: 0.1706 - learning_rate: 5.9687e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9299 - loss: 0.1761 - val_accuracy: 0.9330 - val_loss: 0.1731 - learning_rate: 5.9687e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.1744 - val_accuracy: 0.9328 - val_loss: 0.1703 - learning_rate: 5.9687e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.1762 - val_accuracy: 0.9298 - val_loss: 0.1739 - learning_rate: 5.9687e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9314 - loss: 0.1730 - val_accuracy: 0.9310 - val_loss: 0.1751 - learning_rate: 5.9687e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.1750 - val_accuracy: 0.9293 - val_loss: 0.1754 - learning_rate: 5.9687e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.1765 - val_accuracy: 0.9322 - val_loss: 0.1703 - learning_rate: 5.9687e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1713\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1713 - val_accuracy: 0.9316 - val_loss: 0.1712 - learning_rate: 5.9687e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.1700 - val_accuracy: 0.9315 - val_loss: 0.1690 - learning_rate: 2.9844e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.1675 - val_accuracy: 0.9347 - val_loss: 0.1657 - learning_rate: 2.9844e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1675 - val_accuracy: 0.9350 - val_loss: 0.1663 - learning_rate: 2.9844e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.1689 - val_accuracy: 0.9351 - val_loss: 0.1658 - learning_rate: 2.9844e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.1651 - val_accuracy: 0.9351 - val_loss: 0.1669 - learning_rate: 2.9844e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.1701 - val_accuracy: 0.9335 - val_loss: 0.1675 - learning_rate: 2.9844e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.1682 - val_accuracy: 0.9357 - val_loss: 0.1650 - learning_rate: 2.9844e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.1698 - val_accuracy: 0.9327 - val_loss: 0.1683 - learning_rate: 2.9844e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.1647 - val_accuracy: 0.9336 - val_loss: 0.1659 - learning_rate: 2.9844e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.1642 - val_accuracy: 0.9341 - val_loss: 0.1676 - learning_rate: 2.9844e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1664 - val_accuracy: 0.9340 - val_loss: 0.1677 - learning_rate: 2.9844e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.1673\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.4921874935680535e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.1673 - val_accuracy: 0.9351 - val_loss: 0.1667 - learning_rate: 2.9844e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1643 - val_accuracy: 0.9370 - val_loss: 0.1642 - learning_rate: 1.4922e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1628 - val_accuracy: 0.9351 - val_loss: 0.1644 - learning_rate: 1.4922e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.1671 - val_accuracy: 0.9361 - val_loss: 0.1647 - learning_rate: 1.4922e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.1582 - val_accuracy: 0.9355 - val_loss: 0.1637 - learning_rate: 1.4922e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1644 - val_accuracy: 0.9362 - val_loss: 0.1636 - learning_rate: 1.4922e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.1662 - val_accuracy: 0.9368 - val_loss: 0.1636 - learning_rate: 1.4922e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1614 - val_accuracy: 0.9366 - val_loss: 0.1632 - learning_rate: 1.4922e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.1652 - val_accuracy: 0.9364 - val_loss: 0.1639 - learning_rate: 1.4922e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.1628 - val_accuracy: 0.9350 - val_loss: 0.1651 - learning_rate: 1.4922e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1611 - val_accuracy: 0.9360 - val_loss: 0.1630 - learning_rate: 1.4922e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.1629 - val_accuracy: 0.9363 - val_loss: 0.1641 - learning_rate: 1.4922e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.1652 - val_accuracy: 0.9355 - val_loss: 0.1629 - learning_rate: 1.4922e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1632 - val_accuracy: 0.9357 - val_loss: 0.1628 - learning_rate: 1.4922e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1620 - val_accuracy: 0.9369 - val_loss: 0.1626 - learning_rate: 1.4922e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1639 - val_accuracy: 0.9372 - val_loss: 0.1633 - learning_rate: 1.4922e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1631 - val_accuracy: 0.9365 - val_loss: 0.1633 - learning_rate: 1.4922e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1649 - val_accuracy: 0.9361 - val_loss: 0.1639 - learning_rate: 1.4922e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.1646 - val_accuracy: 0.9367 - val_loss: 0.1622 - learning_rate: 1.4922e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "  Accuracy: 0.5157\n",
      "  Base Rate: 0.5035\n",
      "  Selection Rate: 0.5190\n",
      "  Disparate Impact: 1.1706\n",
      "  Statistical Parity Difference: 0.0858\n",
      "  Between Group Coefficient of Variation: 0.0328\n",
      "  Between Group Generalized Entropy Index: 0.0005\n",
      "  Between Group Theil Index: 0.0005\n",
      "  Mean Difference: 0.0858\n",
      "  Smoothed Empirical Differential Fairness: 0.0004\n",
      "  Consistency: 0.9484\n",
      "  Average Absolute Odds Difference: 0.0938\n",
      "  Average Odds Difference: 0.0851\n",
      "  Average Predictive Value Difference: -0.0167\n",
      "  Between All Groups Coefficient of Variation: 0.0328\n",
      "  Between All Groups Generalized Entropy Index: 0.0005\n",
      "  Between All Groups Theil Index: 0.0005\n",
      "  Coefficient of Variation: 0.6851\n",
      "  Differential Fairness Bias Amplification: 0.1891\n",
      "  Equal Opportunity Difference: 0.1789\n",
      "  Equalized Odds Difference: 0.1789\n",
      "  Error Rate: 0.4843\n",
      "  Error Rate Difference: -0.0944\n",
      "  Error Rate Ratio: 0.8118\n",
      "  False Discovery Rate: 0.4815\n",
      "  False Discovery Rate Difference: -0.0801\n",
      "  False Discovery Rate Ratio: 0.8393\n",
      "  False Negative Rate: 0.4655\n",
      "  False Negative Rate Difference: -0.1789\n",
      "  False Negative Rate Ratio: 0.6412\n",
      "  False Omission Rate: 0.4873\n",
      "  False Omission Rate Difference: -0.1135\n",
      "  False Omission Rate Ratio: 0.7754\n",
      "  False Positive Rate: 0.5033\n",
      "  False Positive Rate Difference: -0.0087\n",
      "  False Positive Rate Ratio: 0.9829\n",
      "  Generalized Entropy Index: 0.2347\n",
      "  Generalized Equalized Odds Difference: 0.1789\n",
      "  Generalized False Negative Rate: 0.4655\n",
      "  Generalized False Positive Rate: 0.5033\n",
      "  Generalized True Negative Rate: 0.4967\n",
      "  Generalized True Positive Rate: 0.5345\n",
      "  Negative Predictive Value: 0.5127\n",
      "  Number of False Negatives: 2402.0000\n",
      "  Number of False Positives: 2561.0000\n",
      "  Number of Generalized False Negatives: 2402.0000\n",
      "  Number of Generalized False Positives: 2561.0000\n",
      "  Number of Generalized True Negatives: 2527.0000\n",
      "  Number of Generalized True Positives: 2758.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5088.0000\n",
      "  Number of Positives: 5160.0000\n",
      "  Number of Predicted Negatives: 4929.0000\n",
      "  Number of Predicted Positives: 5319.0000\n",
      "  Number of True Negatives: 2527.0000\n",
      "  Number of True Positives: 2758.0000\n",
      "  Positive Predictive Value: 0.5185\n",
      "  Power: 2758.0000\n",
      "  Precision: 0.5185\n",
      "  Recall: 0.5345\n",
      "  Sensitivity: 0.5345\n",
      "  Specificity: 0.4967\n",
      "  Theil Index: 0.3257\n",
      "  True Negative Rate: 0.4967\n",
      "  True Positive Rate: 0.5345\n",
      "  True Positive Rate Difference: 0.1789\n",
      "  Accuracy: 0.5157\n",
      "  Base Rate: 0.5035\n",
      "  Selection Rate: 0.5190\n",
      "  Disparate Impact: 1.1706\n",
      "  Statistical Parity Difference: 0.0858\n",
      "  Between Group Coefficient of Variation: 0.0328\n",
      "  Between Group Generalized Entropy Index: 0.0005\n",
      "  Between Group Theil Index: 0.0005\n",
      "  Mean Difference: 0.0858\n",
      "  Smoothed Empirical Differential Fairness: 0.0004\n",
      "  Consistency: 0.9484\n",
      "  Average Absolute Odds Difference: 0.0938\n",
      "  Average Odds Difference: 0.0851\n",
      "  Average Predictive Value Difference: -0.0167\n",
      "  Between All Groups Coefficient of Variation: 0.0328\n",
      "  Between All Groups Generalized Entropy Index: 0.0005\n",
      "  Between All Groups Theil Index: 0.0005\n",
      "  Coefficient of Variation: 0.6851\n",
      "  Differential Fairness Bias Amplification: 0.1891\n",
      "  Equal Opportunity Difference: 0.1789\n",
      "  Equalized Odds Difference: 0.1789\n",
      "  Error Rate: 0.4843\n",
      "  Error Rate Difference: -0.0944\n",
      "  Error Rate Ratio: 0.8118\n",
      "  False Discovery Rate: 0.4815\n",
      "  False Discovery Rate Difference: -0.0801\n",
      "  False Discovery Rate Ratio: 0.8393\n",
      "  False Negative Rate: 0.4655\n",
      "  False Negative Rate Difference: -0.1789\n",
      "  False Negative Rate Ratio: 0.6412\n",
      "  False Omission Rate: 0.4873\n",
      "  False Omission Rate Difference: -0.1135\n",
      "  False Omission Rate Ratio: 0.7754\n",
      "  False Positive Rate: 0.5033\n",
      "  False Positive Rate Difference: -0.0087\n",
      "  False Positive Rate Ratio: 0.9829\n",
      "  Generalized Entropy Index: 0.2347\n",
      "  Generalized Equalized Odds Difference: 0.1789\n",
      "  Generalized False Negative Rate: 0.4655\n",
      "  Generalized False Positive Rate: 0.5033\n",
      "  Generalized True Negative Rate: 0.4967\n",
      "  Generalized True Positive Rate: 0.5345\n",
      "  Negative Predictive Value: 0.5127\n",
      "  Number of False Negatives: 2402.0000\n",
      "  Number of False Positives: 2561.0000\n",
      "  Number of Generalized False Negatives: 2402.0000\n",
      "  Number of Generalized False Positives: 2561.0000\n",
      "  Number of Generalized True Negatives: 2527.0000\n",
      "  Number of Generalized True Positives: 2758.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5088.0000\n",
      "  Number of Positives: 5160.0000\n",
      "  Number of Predicted Negatives: 4929.0000\n",
      "  Number of Predicted Positives: 5319.0000\n",
      "  Number of True Negatives: 2527.0000\n",
      "  Number of True Positives: 2758.0000\n",
      "  Positive Predictive Value: 0.5185\n",
      "  Power: 2758.0000\n",
      "  Precision: 0.5185\n",
      "  Recall: 0.5345\n",
      "  Sensitivity: 0.5345\n",
      "  Specificity: 0.4967\n",
      "  Theil Index: 0.3257\n",
      "  True Negative Rate: 0.4967\n",
      "  True Positive Rate: 0.5345\n",
      "  True Positive Rate Difference: 0.1789\n",
      "  Accuracy: 0.5141\n",
      "  Base Rate: 0.5030\n",
      "  Selection Rate: 0.5203\n",
      "  Disparate Impact: 1.1355\n",
      "  Statistical Parity Difference: 0.0687\n",
      "  Between Group Coefficient of Variation: 0.0270\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0687\n",
      "  Smoothed Empirical Differential Fairness: 0.0024\n",
      "  Consistency: 0.9536\n",
      "  Average Absolute Odds Difference: 0.1268\n",
      "  Average Odds Difference: 0.0682\n",
      "  Average Predictive Value Difference: -0.0195\n",
      "  Between All Groups Coefficient of Variation: 0.0270\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6850\n",
      "  Differential Fairness Bias Amplification: 0.1477\n",
      "  Equal Opportunity Difference: 0.1950\n",
      "  Equalized Odds Difference: 0.1950\n",
      "  Error Rate: 0.4859\n",
      "  Error Rate Difference: -0.1270\n",
      "  Error Rate Ratio: 0.7509\n",
      "  False Discovery Rate: 0.4835\n",
      "  False Discovery Rate Difference: -0.1100\n",
      "  False Discovery Rate Ratio: 0.7828\n",
      "  False Negative Rate: 0.4658\n",
      "  False Negative Rate Difference: -0.1950\n",
      "  False Negative Rate Ratio: 0.6122\n",
      "  False Omission Rate: 0.4884\n",
      "  False Omission Rate Difference: -0.1490\n",
      "  False Omission Rate Ratio: 0.7097\n",
      "  False Positive Rate: 0.5062\n",
      "  False Positive Rate Difference: -0.0586\n",
      "  False Positive Rate Ratio: 0.8868\n",
      "  Generalized Entropy Index: 0.2346\n",
      "  Generalized Equalized Odds Difference: 0.1950\n",
      "  Generalized False Negative Rate: 0.4658\n",
      "  Generalized False Positive Rate: 0.5062\n",
      "  Generalized True Negative Rate: 0.4938\n",
      "  Generalized True Positive Rate: 0.5342\n",
      "  Negative Predictive Value: 0.5116\n",
      "  Number of False Negatives: 2401.0000\n",
      "  Number of False Positives: 2578.0000\n",
      "  Number of Generalized False Negatives: 2401.0000\n",
      "  Number of Generalized False Positives: 2578.0000\n",
      "  Number of Generalized True Negatives: 2515.0000\n",
      "  Number of Generalized True Positives: 2754.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5093.0000\n",
      "  Number of Positives: 5155.0000\n",
      "  Number of Predicted Negatives: 4916.0000\n",
      "  Number of Predicted Positives: 5332.0000\n",
      "  Number of True Negatives: 2515.0000\n",
      "  Number of True Positives: 2754.0000\n",
      "  Positive Predictive Value: 0.5165\n",
      "  Power: 2754.0000\n",
      "  Precision: 0.5165\n",
      "  Recall: 0.5342\n",
      "  Sensitivity: 0.5342\n",
      "  Specificity: 0.4938\n",
      "  Theil Index: 0.3257\n",
      "  True Negative Rate: 0.4938\n",
      "  True Positive Rate: 0.5342\n",
      "  True Positive Rate Difference: 0.1950\n",
      "  Accuracy: 0.5141\n",
      "  Base Rate: 0.5030\n",
      "  Selection Rate: 0.5203\n",
      "  Disparate Impact: 1.1355\n",
      "  Statistical Parity Difference: 0.0687\n",
      "  Between Group Coefficient of Variation: 0.0270\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0687\n",
      "  Smoothed Empirical Differential Fairness: 0.0024\n",
      "  Consistency: 0.9536\n",
      "  Average Absolute Odds Difference: 0.1268\n",
      "  Average Odds Difference: 0.0682\n",
      "  Average Predictive Value Difference: -0.0195\n",
      "  Between All Groups Coefficient of Variation: 0.0270\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6850\n",
      "  Differential Fairness Bias Amplification: 0.1477\n",
      "  Equal Opportunity Difference: 0.1950\n",
      "  Equalized Odds Difference: 0.1950\n",
      "  Error Rate: 0.4859\n",
      "  Error Rate Difference: -0.1270\n",
      "  Error Rate Ratio: 0.7509\n",
      "  False Discovery Rate: 0.4835\n",
      "  False Discovery Rate Difference: -0.1100\n",
      "  False Discovery Rate Ratio: 0.7828\n",
      "  False Negative Rate: 0.4658\n",
      "  False Negative Rate Difference: -0.1950\n",
      "  False Negative Rate Ratio: 0.6122\n",
      "  False Omission Rate: 0.4884\n",
      "  False Omission Rate Difference: -0.1490\n",
      "  False Omission Rate Ratio: 0.7097\n",
      "  False Positive Rate: 0.5062\n",
      "  False Positive Rate Difference: -0.0586\n",
      "  False Positive Rate Ratio: 0.8868\n",
      "  Generalized Entropy Index: 0.2346\n",
      "  Generalized Equalized Odds Difference: 0.1950\n",
      "  Generalized False Negative Rate: 0.4658\n",
      "  Generalized False Positive Rate: 0.5062\n",
      "  Generalized True Negative Rate: 0.4938\n",
      "  Generalized True Positive Rate: 0.5342\n",
      "  Negative Predictive Value: 0.5116\n",
      "  Number of False Negatives: 2401.0000\n",
      "  Number of False Positives: 2578.0000\n",
      "  Number of Generalized False Negatives: 2401.0000\n",
      "  Number of Generalized False Positives: 2578.0000\n",
      "  Number of Generalized True Negatives: 2515.0000\n",
      "  Number of Generalized True Positives: 2754.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5093.0000\n",
      "  Number of Positives: 5155.0000\n",
      "  Number of Predicted Negatives: 4916.0000\n",
      "  Number of Predicted Positives: 5332.0000\n",
      "  Number of True Negatives: 2515.0000\n",
      "  Number of True Positives: 2754.0000\n",
      "  Positive Predictive Value: 0.5165\n",
      "  Power: 2754.0000\n",
      "  Precision: 0.5165\n",
      "  Recall: 0.5342\n",
      "  Sensitivity: 0.5342\n",
      "  Specificity: 0.4938\n",
      "  Theil Index: 0.3257\n",
      "  True Negative Rate: 0.4938\n",
      "  True Positive Rate: 0.5342\n",
      "  True Positive Rate Difference: 0.1950\n",
      "Protected Attribute Names: ['GENDER', 'AGE']\n",
      "Privileged Protected Attributes: [{'GENDER': 0, 'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1, 'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE&GENDER Mitigation\n",
      "  Accuracy: 0.5135\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5118\n",
      "  Disparate Impact: 1.1063\n",
      "  Statistical Parity Difference: 0.0605\n",
      "  Between Group Coefficient of Variation: 0.8831\n",
      "  Between Group Generalized Entropy Index: 0.3899\n",
      "  Between Group Theil Index: 0.5757\n",
      "  Mean Difference: 0.0605\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0817\n",
      "  Average Odds Difference: 0.0817\n",
      "  Average Predictive Value Difference: 0.1841\n",
      "  Between All Groups Coefficient of Variation: 0.1306\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0087\n",
      "  Coefficient of Variation: 0.6939\n",
      "  Differential Fairness Bias Amplification: -0.1925\n",
      "  Equal Opportunity Difference: 0.0607\n",
      "  Equalized Odds Difference: 0.1027\n",
      "  Error Rate: 0.4865\n",
      "  Error Rate Difference: -0.0245\n",
      "  Error Rate Ratio: 0.9554\n",
      "  False Discovery Rate: 0.4802\n",
      "  False Discovery Rate Difference: -0.1644\n",
      "  False Discovery Rate Ratio: 0.7136\n",
      "  False Negative Rate: 0.4750\n",
      "  False Negative Rate Difference: -0.0607\n",
      "  False Negative Rate Ratio: 0.8731\n",
      "  False Omission Rate: 0.4931\n",
      "  False Omission Rate Difference: 0.2039\n",
      "  False Omission Rate Ratio: 1.3952\n",
      "  False Positive Rate: 0.4983\n",
      "  False Positive Rate Difference: 0.1027\n",
      "  False Positive Rate Ratio: 1.1683\n",
      "  Generalized Entropy Index: 0.2408\n",
      "  Generalized Equalized Odds Difference: 0.1027\n",
      "  Generalized False Negative Rate: 0.4750\n",
      "  Generalized False Positive Rate: 0.4983\n",
      "  Generalized True Negative Rate: 0.5017\n",
      "  Generalized True Positive Rate: 0.5250\n",
      "  Negative Predictive Value: 0.5069\n",
      "  Number of False Negatives: 3700.0000\n",
      "  Number of False Positives: 3778.0000\n",
      "  Number of Generalized False Negatives: 3700.0000\n",
      "  Number of Generalized False Positives: 3778.0000\n",
      "  Number of Generalized True Negatives: 3804.0000\n",
      "  Number of Generalized True Positives: 4090.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7504.0000\n",
      "  Number of Predicted Positives: 7868.0000\n",
      "  Number of True Negatives: 3804.0000\n",
      "  Number of True Positives: 4090.0000\n",
      "  Positive Predictive Value: 0.5198\n",
      "  Power: 4090.0000\n",
      "  Precision: 0.5198\n",
      "  Recall: 0.5250\n",
      "  Sensitivity: 0.5250\n",
      "  Specificity: 0.5017\n",
      "  Theil Index: 0.3339\n",
      "  True Negative Rate: 0.5017\n",
      "  True Positive Rate: 0.5250\n",
      "  True Positive Rate Difference: 0.0607\n",
      "  Accuracy: 0.5135\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5118\n",
      "  Disparate Impact: 1.1063\n",
      "  Statistical Parity Difference: 0.0605\n",
      "  Between Group Coefficient of Variation: 0.8831\n",
      "  Between Group Generalized Entropy Index: 0.3899\n",
      "  Between Group Theil Index: 0.5757\n",
      "  Mean Difference: 0.0605\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0817\n",
      "  Average Odds Difference: 0.0817\n",
      "  Average Predictive Value Difference: 0.1841\n",
      "  Between All Groups Coefficient of Variation: 0.1306\n",
      "  Between All Groups Generalized Entropy Index: 0.0085\n",
      "  Between All Groups Theil Index: 0.0087\n",
      "  Coefficient of Variation: 0.6939\n",
      "  Differential Fairness Bias Amplification: -0.1925\n",
      "  Equal Opportunity Difference: 0.0607\n",
      "  Equalized Odds Difference: 0.1027\n",
      "  Error Rate: 0.4865\n",
      "  Error Rate Difference: -0.0245\n",
      "  Error Rate Ratio: 0.9554\n",
      "  False Discovery Rate: 0.4802\n",
      "  False Discovery Rate Difference: -0.1644\n",
      "  False Discovery Rate Ratio: 0.7136\n",
      "  False Negative Rate: 0.4750\n",
      "  False Negative Rate Difference: -0.0607\n",
      "  False Negative Rate Ratio: 0.8731\n",
      "  False Omission Rate: 0.4931\n",
      "  False Omission Rate Difference: 0.2039\n",
      "  False Omission Rate Ratio: 1.3952\n",
      "  False Positive Rate: 0.4983\n",
      "  False Positive Rate Difference: 0.1027\n",
      "  False Positive Rate Ratio: 1.1683\n",
      "  Generalized Entropy Index: 0.2408\n",
      "  Generalized Equalized Odds Difference: 0.1027\n",
      "  Generalized False Negative Rate: 0.4750\n",
      "  Generalized False Positive Rate: 0.4983\n",
      "  Generalized True Negative Rate: 0.5017\n",
      "  Generalized True Positive Rate: 0.5250\n",
      "  Negative Predictive Value: 0.5069\n",
      "  Number of False Negatives: 3700.0000\n",
      "  Number of False Positives: 3778.0000\n",
      "  Number of Generalized False Negatives: 3700.0000\n",
      "  Number of Generalized False Positives: 3778.0000\n",
      "  Number of Generalized True Negatives: 3804.0000\n",
      "  Number of Generalized True Positives: 4090.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7504.0000\n",
      "  Number of Predicted Positives: 7868.0000\n",
      "  Number of True Negatives: 3804.0000\n",
      "  Number of True Positives: 4090.0000\n",
      "  Positive Predictive Value: 0.5198\n",
      "  Power: 4090.0000\n",
      "  Precision: 0.5198\n",
      "  Recall: 0.5250\n",
      "  Sensitivity: 0.5250\n",
      "  Specificity: 0.5017\n",
      "  Theil Index: 0.3339\n",
      "  True Negative Rate: 0.5017\n",
      "  True Positive Rate: 0.5250\n",
      "  True Positive Rate Difference: 0.0607\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.4373 - loss: 1.7121 - val_accuracy: 0.7073 - val_loss: 0.8024 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.7913 - val_accuracy: 0.7691 - val_loss: 0.6113 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.6395 - val_accuracy: 0.8163 - val_loss: 0.5017 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.5702 - val_accuracy: 0.8230 - val_loss: 0.4791 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.5265 - val_accuracy: 0.8412 - val_loss: 0.4271 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.5041 - val_accuracy: 0.8150 - val_loss: 0.4851 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4754 - val_accuracy: 0.8361 - val_loss: 0.4292 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.4695 - val_accuracy: 0.8356 - val_loss: 0.4262 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.4533 - val_accuracy: 0.8510 - val_loss: 0.3829 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.4416 - val_accuracy: 0.8545 - val_loss: 0.3696 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8384 - loss: 0.4252 - val_accuracy: 0.8648 - val_loss: 0.3499 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4221 - val_accuracy: 0.8619 - val_loss: 0.3557 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.4079 - val_accuracy: 0.8582 - val_loss: 0.3597 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.4062 - val_accuracy: 0.8473 - val_loss: 0.3845 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3956 - val_accuracy: 0.8538 - val_loss: 0.3683 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3991 - val_accuracy: 0.8745 - val_loss: 0.3280 - learning_rate: 9.5500e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.3854 - val_accuracy: 0.8675 - val_loss: 0.3394 - learning_rate: 9.5500e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3769 - val_accuracy: 0.8614 - val_loss: 0.3504 - learning_rate: 9.5500e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3712 - val_accuracy: 0.8526 - val_loss: 0.3645 - learning_rate: 9.5500e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8543 - loss: 0.3762 - val_accuracy: 0.8512 - val_loss: 0.3926 - learning_rate: 9.5500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2559/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.3701\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.3701 - val_accuracy: 0.8332 - val_loss: 0.4414 - learning_rate: 9.5500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3214 - val_accuracy: 0.8902 - val_loss: 0.2794 - learning_rate: 4.7750e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3064 - val_accuracy: 0.8851 - val_loss: 0.2954 - learning_rate: 4.7750e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3047 - val_accuracy: 0.8857 - val_loss: 0.2807 - learning_rate: 4.7750e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.3040 - val_accuracy: 0.8882 - val_loss: 0.2809 - learning_rate: 4.7750e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3021 - val_accuracy: 0.8815 - val_loss: 0.2978 - learning_rate: 4.7750e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2950 - val_accuracy: 0.8960 - val_loss: 0.2619 - learning_rate: 4.7750e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2916 - val_accuracy: 0.8969 - val_loss: 0.2694 - learning_rate: 4.7750e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.2924 - val_accuracy: 0.8889 - val_loss: 0.2771 - learning_rate: 4.7750e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2905 - val_accuracy: 0.8870 - val_loss: 0.2808 - learning_rate: 4.7750e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2860 - val_accuracy: 0.8985 - val_loss: 0.2514 - learning_rate: 4.7750e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2832 - val_accuracy: 0.8902 - val_loss: 0.2748 - learning_rate: 4.7750e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.2834 - val_accuracy: 0.8964 - val_loss: 0.2577 - learning_rate: 4.7750e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2803 - val_accuracy: 0.8959 - val_loss: 0.2597 - learning_rate: 4.7750e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2836 - val_accuracy: 0.8976 - val_loss: 0.2586 - learning_rate: 4.7750e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.2758\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.2758 - val_accuracy: 0.8940 - val_loss: 0.2582 - learning_rate: 4.7750e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2516 - val_accuracy: 0.9006 - val_loss: 0.2492 - learning_rate: 2.3875e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.2476 - val_accuracy: 0.9081 - val_loss: 0.2321 - learning_rate: 2.3875e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.2458 - val_accuracy: 0.9041 - val_loss: 0.2463 - learning_rate: 2.3875e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2402 - val_accuracy: 0.9067 - val_loss: 0.2378 - learning_rate: 2.3875e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.2392 - val_accuracy: 0.9095 - val_loss: 0.2300 - learning_rate: 2.3875e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2405 - val_accuracy: 0.9120 - val_loss: 0.2257 - learning_rate: 2.3875e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2391 - val_accuracy: 0.9083 - val_loss: 0.2293 - learning_rate: 2.3875e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2334 - val_accuracy: 0.9047 - val_loss: 0.2350 - learning_rate: 2.3875e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.2355 - val_accuracy: 0.9108 - val_loss: 0.2252 - learning_rate: 2.3875e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2374 - val_accuracy: 0.9064 - val_loss: 0.2289 - learning_rate: 2.3875e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2311 - val_accuracy: 0.9108 - val_loss: 0.2282 - learning_rate: 2.3875e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2322 - val_accuracy: 0.9040 - val_loss: 0.2369 - learning_rate: 2.3875e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2303 - val_accuracy: 0.9091 - val_loss: 0.2252 - learning_rate: 2.3875e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2299\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2299 - val_accuracy: 0.9094 - val_loss: 0.2288 - learning_rate: 2.3875e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2158 - val_accuracy: 0.9182 - val_loss: 0.2068 - learning_rate: 1.1937e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2069 - val_accuracy: 0.9157 - val_loss: 0.2158 - learning_rate: 1.1937e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2063 - val_accuracy: 0.9195 - val_loss: 0.2057 - learning_rate: 1.1937e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2134 - val_accuracy: 0.9181 - val_loss: 0.2067 - learning_rate: 1.1937e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2124 - val_accuracy: 0.9134 - val_loss: 0.2161 - learning_rate: 1.1937e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2057 - val_accuracy: 0.9186 - val_loss: 0.2084 - learning_rate: 1.1937e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2059 - val_accuracy: 0.9224 - val_loss: 0.1988 - learning_rate: 1.1937e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2082 - val_accuracy: 0.9207 - val_loss: 0.2044 - learning_rate: 1.1937e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2079 - val_accuracy: 0.9234 - val_loss: 0.1982 - learning_rate: 1.1937e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2051 - val_accuracy: 0.9189 - val_loss: 0.2063 - learning_rate: 1.1937e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2061 - val_accuracy: 0.9231 - val_loss: 0.2038 - learning_rate: 1.1937e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2028 - val_accuracy: 0.9193 - val_loss: 0.2032 - learning_rate: 1.1937e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2017 - val_accuracy: 0.9225 - val_loss: 0.1988 - learning_rate: 1.1937e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2548/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2042\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2042 - val_accuracy: 0.9207 - val_loss: 0.2031 - learning_rate: 1.1937e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.1951 - val_accuracy: 0.9269 - val_loss: 0.1930 - learning_rate: 5.9687e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.1923 - val_accuracy: 0.9249 - val_loss: 0.1939 - learning_rate: 5.9687e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.1924 - val_accuracy: 0.9257 - val_loss: 0.1926 - learning_rate: 5.9687e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.1896 - val_accuracy: 0.9230 - val_loss: 0.1935 - learning_rate: 5.9687e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.1888 - val_accuracy: 0.9254 - val_loss: 0.1922 - learning_rate: 5.9687e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.1902 - val_accuracy: 0.9251 - val_loss: 0.1907 - learning_rate: 5.9687e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.1873 - val_accuracy: 0.9255 - val_loss: 0.1915 - learning_rate: 5.9687e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.1892 - val_accuracy: 0.9255 - val_loss: 0.1926 - learning_rate: 5.9687e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.1902 - val_accuracy: 0.9277 - val_loss: 0.1905 - learning_rate: 5.9687e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1887 - val_accuracy: 0.9251 - val_loss: 0.1946 - learning_rate: 5.9687e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.1859 - val_accuracy: 0.9249 - val_loss: 0.1922 - learning_rate: 5.9687e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.1906 - val_accuracy: 0.9223 - val_loss: 0.1952 - learning_rate: 5.9687e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.1868 - val_accuracy: 0.9260 - val_loss: 0.1906 - learning_rate: 5.9687e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2550/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.1853\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.1853 - val_accuracy: 0.9270 - val_loss: 0.1904 - learning_rate: 5.9687e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1819 - val_accuracy: 0.9259 - val_loss: 0.1891 - learning_rate: 2.9844e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1844 - val_accuracy: 0.9279 - val_loss: 0.1859 - learning_rate: 2.9844e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.1830 - val_accuracy: 0.9276 - val_loss: 0.1848 - learning_rate: 2.9844e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1781 - val_accuracy: 0.9271 - val_loss: 0.1868 - learning_rate: 2.9844e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9312 - loss: 0.1746 - val_accuracy: 0.9280 - val_loss: 0.1853 - learning_rate: 2.9844e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.1798 - val_accuracy: 0.9275 - val_loss: 0.1858 - learning_rate: 2.9844e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.1778 - val_accuracy: 0.9264 - val_loss: 0.1863 - learning_rate: 2.9844e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2546/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1756\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.4921874935680535e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1757 - val_accuracy: 0.9280 - val_loss: 0.1866 - learning_rate: 2.9844e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1771 - val_accuracy: 0.9276 - val_loss: 0.1846 - learning_rate: 1.4922e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.1771 - val_accuracy: 0.9291 - val_loss: 0.1835 - learning_rate: 1.4922e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1746 - val_accuracy: 0.9290 - val_loss: 0.1829 - learning_rate: 1.4922e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9301 - loss: 0.1770 - val_accuracy: 0.9292 - val_loss: 0.1856 - learning_rate: 1.4922e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.1796 - val_accuracy: 0.9302 - val_loss: 0.1827 - learning_rate: 1.4922e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1775 - val_accuracy: 0.9293 - val_loss: 0.1833 - learning_rate: 1.4922e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.1752 - val_accuracy: 0.9289 - val_loss: 0.1846 - learning_rate: 1.4922e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1757 - val_accuracy: 0.9290 - val_loss: 0.1833 - learning_rate: 1.4922e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1768 - val_accuracy: 0.9294 - val_loss: 0.1828 - learning_rate: 1.4922e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1772 - val_accuracy: 0.9301 - val_loss: 0.1825 - learning_rate: 1.4922e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1750 - val_accuracy: 0.9303 - val_loss: 0.1828 - learning_rate: 1.4922e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1750 - val_accuracy: 0.9296 - val_loss: 0.1842 - learning_rate: 1.4922e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1748 - val_accuracy: 0.9281 - val_loss: 0.1829 - learning_rate: 1.4922e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.1731 - val_accuracy: 0.9309 - val_loss: 0.1826 - learning_rate: 1.4922e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.4362 - loss: 1.7172 - val_accuracy: 0.7029 - val_loss: 0.8433 - learning_rate: 9.5500e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7082 - loss: 0.8115 - val_accuracy: 0.7752 - val_loss: 0.6214 - learning_rate: 9.5500e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.6554 - val_accuracy: 0.7841 - val_loss: 0.5618 - learning_rate: 9.5500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.5839 - val_accuracy: 0.8043 - val_loss: 0.6016 - learning_rate: 9.5500e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.5317 - val_accuracy: 0.8115 - val_loss: 0.4961 - learning_rate: 9.5500e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.5008 - val_accuracy: 0.8415 - val_loss: 0.4126 - learning_rate: 9.5500e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8213 - loss: 0.4748 - val_accuracy: 0.8491 - val_loss: 0.4031 - learning_rate: 9.5500e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.4574 - val_accuracy: 0.8571 - val_loss: 0.3758 - learning_rate: 9.5500e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4445 - val_accuracy: 0.8496 - val_loss: 0.3865 - learning_rate: 9.5500e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.4330 - val_accuracy: 0.8432 - val_loss: 0.4019 - learning_rate: 9.5500e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4159 - val_accuracy: 0.8620 - val_loss: 0.3484 - learning_rate: 9.5500e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.4108 - val_accuracy: 0.8420 - val_loss: 0.4235 - learning_rate: 9.5500e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.4143 - val_accuracy: 0.8655 - val_loss: 0.3473 - learning_rate: 9.5500e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.4048 - val_accuracy: 0.8627 - val_loss: 0.3549 - learning_rate: 9.5500e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3960 - val_accuracy: 0.8699 - val_loss: 0.3369 - learning_rate: 9.5500e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.3901 - val_accuracy: 0.8610 - val_loss: 0.3559 - learning_rate: 9.5500e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3798 - val_accuracy: 0.8800 - val_loss: 0.3144 - learning_rate: 9.5500e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3776 - val_accuracy: 0.8711 - val_loss: 0.3437 - learning_rate: 9.5500e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3775 - val_accuracy: 0.8515 - val_loss: 0.3879 - learning_rate: 9.5500e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3710 - val_accuracy: 0.8578 - val_loss: 0.3619 - learning_rate: 9.5500e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3626 - val_accuracy: 0.8804 - val_loss: 0.3127 - learning_rate: 9.5500e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3667 - val_accuracy: 0.8453 - val_loss: 0.3904 - learning_rate: 9.5500e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3651 - val_accuracy: 0.8627 - val_loss: 0.3562 - learning_rate: 9.5500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3602 - val_accuracy: 0.8763 - val_loss: 0.3136 - learning_rate: 9.5500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3477 - val_accuracy: 0.8849 - val_loss: 0.3003 - learning_rate: 9.5500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.3512 - val_accuracy: 0.8844 - val_loss: 0.2940 - learning_rate: 9.5500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3493 - val_accuracy: 0.8704 - val_loss: 0.3278 - learning_rate: 9.5500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.3446 - val_accuracy: 0.8863 - val_loss: 0.2939 - learning_rate: 9.5500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3452 - val_accuracy: 0.8748 - val_loss: 0.3122 - learning_rate: 9.5500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3433 - val_accuracy: 0.8862 - val_loss: 0.2934 - learning_rate: 9.5500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.3421 - val_accuracy: 0.8827 - val_loss: 0.2908 - learning_rate: 9.5500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3368 - val_accuracy: 0.8857 - val_loss: 0.2948 - learning_rate: 9.5500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3398 - val_accuracy: 0.8721 - val_loss: 0.3206 - learning_rate: 9.5500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3474 - val_accuracy: 0.8149 - val_loss: 0.5011 - learning_rate: 9.5500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.3366 - val_accuracy: 0.8760 - val_loss: 0.3047 - learning_rate: 9.5500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2547/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3383\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0004774999979417771.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3383 - val_accuracy: 0.8729 - val_loss: 0.3080 - learning_rate: 9.5500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.2825 - val_accuracy: 0.8993 - val_loss: 0.2491 - learning_rate: 4.7750e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2727 - val_accuracy: 0.9037 - val_loss: 0.2378 - learning_rate: 4.7750e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2655 - val_accuracy: 0.9052 - val_loss: 0.2407 - learning_rate: 4.7750e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2702 - val_accuracy: 0.8916 - val_loss: 0.2706 - learning_rate: 4.7750e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.2671 - val_accuracy: 0.9048 - val_loss: 0.2355 - learning_rate: 4.7750e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2629 - val_accuracy: 0.9056 - val_loss: 0.2360 - learning_rate: 4.7750e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2563 - val_accuracy: 0.8984 - val_loss: 0.2516 - learning_rate: 4.7750e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2630 - val_accuracy: 0.8961 - val_loss: 0.2575 - learning_rate: 4.7750e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2575 - val_accuracy: 0.9077 - val_loss: 0.2350 - learning_rate: 4.7750e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2560 - val_accuracy: 0.9040 - val_loss: 0.2358 - learning_rate: 4.7750e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2522 - val_accuracy: 0.9058 - val_loss: 0.2312 - learning_rate: 4.7750e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2514 - val_accuracy: 0.9100 - val_loss: 0.2231 - learning_rate: 4.7750e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2521 - val_accuracy: 0.9087 - val_loss: 0.2315 - learning_rate: 4.7750e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2530 - val_accuracy: 0.9048 - val_loss: 0.2314 - learning_rate: 4.7750e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2500 - val_accuracy: 0.9050 - val_loss: 0.2319 - learning_rate: 4.7750e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2491 - val_accuracy: 0.9040 - val_loss: 0.2485 - learning_rate: 4.7750e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2544/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2511\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00023874999897088856.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2511 - val_accuracy: 0.9044 - val_loss: 0.2466 - learning_rate: 4.7750e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2206 - val_accuracy: 0.9145 - val_loss: 0.2073 - learning_rate: 2.3875e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2138 - val_accuracy: 0.9185 - val_loss: 0.2034 - learning_rate: 2.3875e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2106 - val_accuracy: 0.9179 - val_loss: 0.2026 - learning_rate: 2.3875e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2112 - val_accuracy: 0.9118 - val_loss: 0.2117 - learning_rate: 2.3875e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2068 - val_accuracy: 0.9189 - val_loss: 0.2007 - learning_rate: 2.3875e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2084 - val_accuracy: 0.9159 - val_loss: 0.1994 - learning_rate: 2.3875e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2082 - val_accuracy: 0.9177 - val_loss: 0.1987 - learning_rate: 2.3875e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2064 - val_accuracy: 0.9184 - val_loss: 0.2023 - learning_rate: 2.3875e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2051 - val_accuracy: 0.9215 - val_loss: 0.1939 - learning_rate: 2.3875e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2026 - val_accuracy: 0.9165 - val_loss: 0.2034 - learning_rate: 2.3875e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2084 - val_accuracy: 0.9237 - val_loss: 0.1919 - learning_rate: 2.3875e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2034 - val_accuracy: 0.9202 - val_loss: 0.1989 - learning_rate: 2.3875e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2016 - val_accuracy: 0.9185 - val_loss: 0.2029 - learning_rate: 2.3875e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2020 - val_accuracy: 0.9133 - val_loss: 0.2123 - learning_rate: 2.3875e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2017 - val_accuracy: 0.9231 - val_loss: 0.1960 - learning_rate: 2.3875e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2545/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2045\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.00011937499948544428.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2045 - val_accuracy: 0.9139 - val_loss: 0.2128 - learning_rate: 2.3875e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.1858 - val_accuracy: 0.9281 - val_loss: 0.1792 - learning_rate: 1.1937e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.1831 - val_accuracy: 0.9288 - val_loss: 0.1772 - learning_rate: 1.1937e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.1829 - val_accuracy: 0.9290 - val_loss: 0.1789 - learning_rate: 1.1937e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.1790 - val_accuracy: 0.9263 - val_loss: 0.1752 - learning_rate: 1.1937e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.1818 - val_accuracy: 0.9298 - val_loss: 0.1736 - learning_rate: 1.1937e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.1793 - val_accuracy: 0.9323 - val_loss: 0.1717 - learning_rate: 1.1937e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1791 - val_accuracy: 0.9245 - val_loss: 0.1865 - learning_rate: 1.1937e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1788 - val_accuracy: 0.9291 - val_loss: 0.1737 - learning_rate: 1.1937e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.1773 - val_accuracy: 0.9278 - val_loss: 0.1821 - learning_rate: 1.1937e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.1753 - val_accuracy: 0.9231 - val_loss: 0.1857 - learning_rate: 1.1937e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1820\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 5.968749974272214e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1820 - val_accuracy: 0.9281 - val_loss: 0.1740 - learning_rate: 1.1937e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1674 - val_accuracy: 0.9336 - val_loss: 0.1661 - learning_rate: 5.9687e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.1651 - val_accuracy: 0.9321 - val_loss: 0.1660 - learning_rate: 5.9687e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.1682 - val_accuracy: 0.9302 - val_loss: 0.1721 - learning_rate: 5.9687e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.1654 - val_accuracy: 0.9317 - val_loss: 0.1675 - learning_rate: 5.9687e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9312 - loss: 0.1674 - val_accuracy: 0.9347 - val_loss: 0.1663 - learning_rate: 5.9687e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.1628 - val_accuracy: 0.9335 - val_loss: 0.1665 - learning_rate: 5.9687e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.1651 - val_accuracy: 0.9324 - val_loss: 0.1648 - learning_rate: 5.9687e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.1633 - val_accuracy: 0.9347 - val_loss: 0.1639 - learning_rate: 5.9687e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1629 - val_accuracy: 0.9333 - val_loss: 0.1661 - learning_rate: 5.9687e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.1634 - val_accuracy: 0.9317 - val_loss: 0.1699 - learning_rate: 5.9687e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1631 - val_accuracy: 0.9315 - val_loss: 0.1647 - learning_rate: 5.9687e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.1645 - val_accuracy: 0.9330 - val_loss: 0.1691 - learning_rate: 5.9687e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2545/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1626\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.984374987136107e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1626 - val_accuracy: 0.9325 - val_loss: 0.1667 - learning_rate: 5.9687e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.1608 - val_accuracy: 0.9364 - val_loss: 0.1603 - learning_rate: 2.9844e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1568 - val_accuracy: 0.9351 - val_loss: 0.1634 - learning_rate: 2.9844e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1588 - val_accuracy: 0.9356 - val_loss: 0.1611 - learning_rate: 2.9844e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1590 - val_accuracy: 0.9356 - val_loss: 0.1591 - learning_rate: 2.9844e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.1587 - val_accuracy: 0.9366 - val_loss: 0.1600 - learning_rate: 2.9844e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1564 - val_accuracy: 0.9379 - val_loss: 0.1582 - learning_rate: 2.9844e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1552 - val_accuracy: 0.9365 - val_loss: 0.1606 - learning_rate: 2.9844e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "  Accuracy: 0.5199\n",
      "  Base Rate: 0.5004\n",
      "  Selection Rate: 0.5142\n",
      "  Disparate Impact: 1.0338\n",
      "  Statistical Parity Difference: 0.0197\n",
      "  Between Group Coefficient of Variation: 0.8860\n",
      "  Between Group Generalized Entropy Index: 0.3925\n",
      "  Between Group Theil Index: 0.5776\n",
      "  Mean Difference: 0.0197\n",
      "  Smoothed Empirical Differential Fairness: 0.7415\n",
      "  Consistency: 0.9524\n",
      "  Average Absolute Odds Difference: 0.0636\n",
      "  Average Odds Difference: 0.0489\n",
      "  Average Predictive Value Difference: 0.2098\n",
      "  Between All Groups Coefficient of Variation: 0.1297\n",
      "  Between All Groups Generalized Entropy Index: 0.0084\n",
      "  Between All Groups Theil Index: 0.0085\n",
      "  Coefficient of Variation: 0.6833\n",
      "  Differential Fairness Bias Amplification: -0.3306\n",
      "  Equal Opportunity Difference: -0.0147\n",
      "  Equalized Odds Difference: 0.1125\n",
      "  Error Rate: 0.4801\n",
      "  Error Rate Difference: 0.0157\n",
      "  Error Rate Ratio: 1.0298\n",
      "  False Discovery Rate: 0.4803\n",
      "  False Discovery Rate Difference: -0.1522\n",
      "  False Discovery Rate Ratio: 0.7257\n",
      "  False Negative Rate: 0.4659\n",
      "  False Negative Rate Difference: 0.0147\n",
      "  False Negative Rate Ratio: 1.0334\n",
      "  False Omission Rate: 0.4799\n",
      "  False Omission Rate Difference: 0.2674\n",
      "  False Omission Rate Ratio: 1.5455\n",
      "  False Positive Rate: 0.4943\n",
      "  False Positive Rate Difference: 0.1125\n",
      "  False Positive Rate Ratio: 1.1863\n",
      "  Generalized Entropy Index: 0.2334\n",
      "  Generalized Equalized Odds Difference: 0.1125\n",
      "  Generalized False Negative Rate: 0.4659\n",
      "  Generalized False Positive Rate: 0.4943\n",
      "  Generalized True Negative Rate: 0.5057\n",
      "  Generalized True Positive Rate: 0.5341\n",
      "  Negative Predictive Value: 0.5201\n",
      "  Number of False Negatives: 2389.0000\n",
      "  Number of False Positives: 2531.0000\n",
      "  Number of Generalized False Negatives: 2389.0000\n",
      "  Number of Generalized False Positives: 2531.0000\n",
      "  Number of Generalized True Negatives: 2589.0000\n",
      "  Number of Generalized True Positives: 2739.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5120.0000\n",
      "  Number of Positives: 5128.0000\n",
      "  Number of Predicted Negatives: 4978.0000\n",
      "  Number of Predicted Positives: 5270.0000\n",
      "  Number of True Negatives: 2589.0000\n",
      "  Number of True Positives: 2739.0000\n",
      "  Positive Predictive Value: 0.5197\n",
      "  Power: 2739.0000\n",
      "  Precision: 0.5197\n",
      "  Recall: 0.5341\n",
      "  Sensitivity: 0.5341\n",
      "  Specificity: 0.5057\n",
      "  Theil Index: 0.3239\n",
      "  True Negative Rate: 0.5057\n",
      "  True Positive Rate: 0.5341\n",
      "  True Positive Rate Difference: -0.0147\n",
      "  Accuracy: 0.5199\n",
      "  Base Rate: 0.5004\n",
      "  Selection Rate: 0.5142\n",
      "  Disparate Impact: 1.0338\n",
      "  Statistical Parity Difference: 0.0197\n",
      "  Between Group Coefficient of Variation: 0.8860\n",
      "  Between Group Generalized Entropy Index: 0.3925\n",
      "  Between Group Theil Index: 0.5776\n",
      "  Mean Difference: 0.0197\n",
      "  Smoothed Empirical Differential Fairness: 0.7415\n",
      "  Consistency: 0.9524\n",
      "  Average Absolute Odds Difference: 0.0636\n",
      "  Average Odds Difference: 0.0489\n",
      "  Average Predictive Value Difference: 0.2098\n",
      "  Between All Groups Coefficient of Variation: 0.1297\n",
      "  Between All Groups Generalized Entropy Index: 0.0084\n",
      "  Between All Groups Theil Index: 0.0085\n",
      "  Coefficient of Variation: 0.6833\n",
      "  Differential Fairness Bias Amplification: -0.3306\n",
      "  Equal Opportunity Difference: -0.0147\n",
      "  Equalized Odds Difference: 0.1125\n",
      "  Error Rate: 0.4801\n",
      "  Error Rate Difference: 0.0157\n",
      "  Error Rate Ratio: 1.0298\n",
      "  False Discovery Rate: 0.4803\n",
      "  False Discovery Rate Difference: -0.1522\n",
      "  False Discovery Rate Ratio: 0.7257\n",
      "  False Negative Rate: 0.4659\n",
      "  False Negative Rate Difference: 0.0147\n",
      "  False Negative Rate Ratio: 1.0334\n",
      "  False Omission Rate: 0.4799\n",
      "  False Omission Rate Difference: 0.2674\n",
      "  False Omission Rate Ratio: 1.5455\n",
      "  False Positive Rate: 0.4943\n",
      "  False Positive Rate Difference: 0.1125\n",
      "  False Positive Rate Ratio: 1.1863\n",
      "  Generalized Entropy Index: 0.2334\n",
      "  Generalized Equalized Odds Difference: 0.1125\n",
      "  Generalized False Negative Rate: 0.4659\n",
      "  Generalized False Positive Rate: 0.4943\n",
      "  Generalized True Negative Rate: 0.5057\n",
      "  Generalized True Positive Rate: 0.5341\n",
      "  Negative Predictive Value: 0.5201\n",
      "  Number of False Negatives: 2389.0000\n",
      "  Number of False Positives: 2531.0000\n",
      "  Number of Generalized False Negatives: 2389.0000\n",
      "  Number of Generalized False Positives: 2531.0000\n",
      "  Number of Generalized True Negatives: 2589.0000\n",
      "  Number of Generalized True Positives: 2739.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5120.0000\n",
      "  Number of Positives: 5128.0000\n",
      "  Number of Predicted Negatives: 4978.0000\n",
      "  Number of Predicted Positives: 5270.0000\n",
      "  Number of True Negatives: 2589.0000\n",
      "  Number of True Positives: 2739.0000\n",
      "  Positive Predictive Value: 0.5197\n",
      "  Power: 2739.0000\n",
      "  Precision: 0.5197\n",
      "  Recall: 0.5341\n",
      "  Sensitivity: 0.5341\n",
      "  Specificity: 0.5057\n",
      "  Theil Index: 0.3239\n",
      "  True Negative Rate: 0.5057\n",
      "  True Positive Rate: 0.5341\n",
      "  True Positive Rate Difference: -0.0147\n",
      "  Accuracy: 0.5218\n",
      "  Base Rate: 0.5117\n",
      "  Selection Rate: 0.5231\n",
      "  Disparate Impact: 1.0642\n",
      "  Statistical Parity Difference: 0.0372\n",
      "  Between Group Coefficient of Variation: 0.8660\n",
      "  Between Group Generalized Entropy Index: 0.3750\n",
      "  Between Group Theil Index: 0.5585\n",
      "  Mean Difference: 0.0372\n",
      "  Smoothed Empirical Differential Fairness: 0.6201\n",
      "  Consistency: 0.9514\n",
      "  Average Absolute Odds Difference: 0.0540\n",
      "  Average Odds Difference: 0.0540\n",
      "  Average Predictive Value Difference: 0.1757\n",
      "  Between All Groups Coefficient of Variation: 0.1300\n",
      "  Between All Groups Generalized Entropy Index: 0.0084\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6836\n",
      "  Differential Fairness Bias Amplification: -0.1896\n",
      "  Equal Opportunity Difference: 0.0250\n",
      "  Equalized Odds Difference: 0.0830\n",
      "  Error Rate: 0.4782\n",
      "  Error Rate Difference: -0.0122\n",
      "  Error Rate Ratio: 0.9769\n",
      "  False Discovery Rate: 0.4680\n",
      "  False Discovery Rate Difference: -0.1486\n",
      "  False Discovery Rate Ratio: 0.7300\n",
      "  False Negative Rate: 0.4561\n",
      "  False Negative Rate Difference: -0.0250\n",
      "  False Negative Rate Ratio: 0.9442\n",
      "  False Omission Rate: 0.4895\n",
      "  False Omission Rate Difference: 0.2028\n",
      "  False Omission Rate Ratio: 1.4037\n",
      "  False Positive Rate: 0.5014\n",
      "  False Positive Rate Difference: 0.0830\n",
      "  False Positive Rate Ratio: 1.1374\n",
      "  Generalized Entropy Index: 0.2337\n",
      "  Generalized Equalized Odds Difference: 0.0830\n",
      "  Generalized False Negative Rate: 0.4561\n",
      "  Generalized False Positive Rate: 0.5014\n",
      "  Generalized True Negative Rate: 0.4986\n",
      "  Generalized True Positive Rate: 0.5439\n",
      "  Negative Predictive Value: 0.5105\n",
      "  Number of False Negatives: 2392.0000\n",
      "  Number of False Positives: 2509.0000\n",
      "  Number of Generalized False Negatives: 2392.0000\n",
      "  Number of Generalized False Positives: 2509.0000\n",
      "  Number of Generalized True Negatives: 2495.0000\n",
      "  Number of Generalized True Positives: 2852.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5004.0000\n",
      "  Number of Positives: 5244.0000\n",
      "  Number of Predicted Negatives: 4887.0000\n",
      "  Number of Predicted Positives: 5361.0000\n",
      "  Number of True Negatives: 2495.0000\n",
      "  Number of True Positives: 2852.0000\n",
      "  Positive Predictive Value: 0.5320\n",
      "  Power: 2852.0000\n",
      "  Precision: 0.5320\n",
      "  Recall: 0.5439\n",
      "  Sensitivity: 0.5439\n",
      "  Specificity: 0.4986\n",
      "  Theil Index: 0.3242\n",
      "  True Negative Rate: 0.4986\n",
      "  True Positive Rate: 0.5439\n",
      "  True Positive Rate Difference: 0.0250\n",
      "  Accuracy: 0.5218\n",
      "  Base Rate: 0.5117\n",
      "  Selection Rate: 0.5231\n",
      "  Disparate Impact: 1.0642\n",
      "  Statistical Parity Difference: 0.0372\n",
      "  Between Group Coefficient of Variation: 0.8660\n",
      "  Between Group Generalized Entropy Index: 0.3750\n",
      "  Between Group Theil Index: 0.5585\n",
      "  Mean Difference: 0.0372\n",
      "  Smoothed Empirical Differential Fairness: 0.6201\n",
      "  Consistency: 0.9514\n",
      "  Average Absolute Odds Difference: 0.0540\n",
      "  Average Odds Difference: 0.0540\n",
      "  Average Predictive Value Difference: 0.1757\n",
      "  Between All Groups Coefficient of Variation: 0.1300\n",
      "  Between All Groups Generalized Entropy Index: 0.0084\n",
      "  Between All Groups Theil Index: 0.0086\n",
      "  Coefficient of Variation: 0.6836\n",
      "  Differential Fairness Bias Amplification: -0.1896\n",
      "  Equal Opportunity Difference: 0.0250\n",
      "  Equalized Odds Difference: 0.0830\n",
      "  Error Rate: 0.4782\n",
      "  Error Rate Difference: -0.0122\n",
      "  Error Rate Ratio: 0.9769\n",
      "  False Discovery Rate: 0.4680\n",
      "  False Discovery Rate Difference: -0.1486\n",
      "  False Discovery Rate Ratio: 0.7300\n",
      "  False Negative Rate: 0.4561\n",
      "  False Negative Rate Difference: -0.0250\n",
      "  False Negative Rate Ratio: 0.9442\n",
      "  False Omission Rate: 0.4895\n",
      "  False Omission Rate Difference: 0.2028\n",
      "  False Omission Rate Ratio: 1.4037\n",
      "  False Positive Rate: 0.5014\n",
      "  False Positive Rate Difference: 0.0830\n",
      "  False Positive Rate Ratio: 1.1374\n",
      "  Generalized Entropy Index: 0.2337\n",
      "  Generalized Equalized Odds Difference: 0.0830\n",
      "  Generalized False Negative Rate: 0.4561\n",
      "  Generalized False Positive Rate: 0.5014\n",
      "  Generalized True Negative Rate: 0.4986\n",
      "  Generalized True Positive Rate: 0.5439\n",
      "  Negative Predictive Value: 0.5105\n",
      "  Number of False Negatives: 2392.0000\n",
      "  Number of False Positives: 2509.0000\n",
      "  Number of Generalized False Negatives: 2392.0000\n",
      "  Number of Generalized False Positives: 2509.0000\n",
      "  Number of Generalized True Negatives: 2495.0000\n",
      "  Number of Generalized True Positives: 2852.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5004.0000\n",
      "  Number of Positives: 5244.0000\n",
      "  Number of Predicted Negatives: 4887.0000\n",
      "  Number of Predicted Positives: 5361.0000\n",
      "  Number of True Negatives: 2495.0000\n",
      "  Number of True Positives: 2852.0000\n",
      "  Positive Predictive Value: 0.5320\n",
      "  Power: 2852.0000\n",
      "  Precision: 0.5320\n",
      "  Recall: 0.5439\n",
      "  Sensitivity: 0.5439\n",
      "  Specificity: 0.4986\n",
      "  Theil Index: 0.3242\n",
      "  True Negative Rate: 0.4986\n",
      "  True Positive Rate: 0.5439\n",
      "  True Positive Rate Difference: 0.0250\n"
     ]
    }
   ],
   "source": [
    "for config in protected_attribute_configs:\n",
    "    protected_attribute_names = config[\"protected_attribute_names\"]\n",
    "    privileged_protected_attributes = config[\"privileged_protected_attributes\"]\n",
    "    unprivileged_protected_attributes = config[\"unprivileged_protected_attributes\"]\n",
    "    sensitive_attribute = config[\"sensitive_attribute\"]\n",
    "    desc = config[\"desc\"]\n",
    "\n",
    "    print(\"Protected Attribute Names:\", protected_attribute_names)\n",
    "    print(\"Privileged Protected Attributes:\", privileged_protected_attributes)\n",
    "    print(\"Unprivileged Protected Attributes:\", unprivileged_protected_attributes)\n",
    "    print(\"Sensitive Attribute:\", sensitive_attribute)\n",
    "    print(\"Description:\", desc)\n",
    "\n",
    "    binary_dataset = BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=['Emotion_Type'],\n",
    "        protected_attribute_names=protected_attribute_names\n",
    "    )\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_bld = BinaryLabelDataset(df=pred_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "\n",
    "    compute_fairness_metrics_CM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RNN model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RNN model-CM-{desc}\")\n",
    "    \n",
    "    reweighing = Reweighing(\n",
    "        privileged_groups=privileged_protected_attributes,\n",
    "        unprivileged_groups=unprivileged_protected_attributes\n",
    "    )\n",
    "    reweighed_dataset = reweighing.fit_transform(binary_dataset)\n",
    "    dir_remover = DisparateImpactRemover(repair_level=0.1, sensitive_attribute=sensitive_attribute)\n",
    "    dir_processed = dir_remover.fit_transform(binary_dataset)\n",
    "    \n",
    "    train_dir, temp_dir = dir_processed.split([0.8], shuffle=True)\n",
    "    val_dir, test_dir = temp_dir.split([0.5], shuffle=True)\n",
    "    train_reweighed, temp_reweighed = reweighed_dataset.split([0.8], shuffle=True)\n",
    "    val_reweighed, test_reweighed = temp_reweighed.split([0.5], shuffle=True)\n",
    "    \n",
    "    train_dir_df = train_dir.convert_to_dataframe()[0]\n",
    "    val_dir_df = val_dir.convert_to_dataframe()[0]\n",
    "    test_dir_df = test_dir.convert_to_dataframe()[0]\n",
    "    train_reweighed_df = train_reweighed.convert_to_dataframe()[0]\n",
    "    val_reweighed_df = val_reweighed.convert_to_dataframe()[0]\n",
    "    test_reweighed_df = test_reweighed.convert_to_dataframe()[0]\n",
    "    \n",
    "    dir_weights = train_dir.instance_weights\n",
    "    rw_weights = train_reweighed.instance_weights\n",
    "    \n",
    "    def prepare_data_for_rnn(dataset, weights):\n",
    "        features = dataset.drop(columns=['Emotion', 'Emotion_Type'])\n",
    "        labels = dataset['Emotion']\n",
    "        features_reshaped = np.expand_dims(features.values, axis=2)\n",
    "        return features_reshaped, labels, weights\n",
    "    \n",
    "    X_train_dir, y_train_dir, train_weights_dir = prepare_data_for_rnn(train_dir_df, dir_weights)\n",
    "    X_val_dir, y_val_dir, _ = prepare_data_for_rnn(val_dir_df, dir_weights)\n",
    "    X_test_dir, y_test_dir, _ = prepare_data_for_rnn(test_dir_df, dir_weights)\n",
    "    X_train_reweighed, y_train_reweighed, train_weights_rw = prepare_data_for_rnn(train_reweighed_df, rw_weights)\n",
    "    X_val_reweighed, y_val_reweighed, _ = prepare_data_for_rnn(val_reweighed_df, rw_weights)\n",
    "    X_test_reweighed, y_test_reweighed, _ = prepare_data_for_rnn(test_reweighed_df, rw_weights)\n",
    "    \n",
    "    rnn_dir = build_rnn_model(X_train_dir.shape[1:], num_classes)\n",
    "    rnn_dir.fit(\n",
    "        X_train_dir, y_train_dir, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_dir, y_val_dir), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_dir = np.argmax(rnn_dir.predict(X_test_dir), axis=1)\n",
    "    \n",
    "    rnn_reweighed = build_rnn_model(X_train_reweighed.shape[1:], num_classes)\n",
    "    rnn_reweighed.fit(\n",
    "        X_train_reweighed, y_train_reweighed, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_reweighed, y_val_reweighed), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_reweighed = np.argmax(rnn_reweighed.predict(X_test_reweighed), axis=1)\n",
    "    \n",
    "    pred_reweighed_df = test_reweighed_df.copy()\n",
    "    pred_reweighed_df['Emotion'] = y_pred_reweighed\n",
    "    pred_dir_df = test_dir_df.copy()\n",
    "    pred_dir_df['Emotion'] = y_pred_dir\n",
    "    \n",
    "    pred_reweighed_df['Emotion_Type'] = pred_reweighed_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    pred_dir_df['Emotion_Type'] = pred_dir_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    \n",
    "    pred_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    pred_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    pred_reweighed_bld = BinaryLabelDataset(df=pred_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_dir_bld = BinaryLabelDataset(df=pred_dir_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    \n",
    "    test_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    test_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    test_dir = BinaryLabelDataset(df=test_dir_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    test_reweighed = BinaryLabelDataset(df=test_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    \n",
    "    compute_fairness_metrics_CM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RNN DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RNN DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_CM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RNN Reweighed model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RNN Reweighed model-CM-{desc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e8923",
   "metadata": {
    "papermill": {
     "duration": 22.568762,
     "end_time": "2025-02-25T11:24:39.343976",
     "exception": false,
     "start_time": "2025-02-25T11:24:16.775214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0b93aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T11:25:26.610052Z",
     "iopub.status.busy": "2025-02-25T11:25:26.609682Z",
     "iopub.status.idle": "2025-02-25T11:33:30.092008Z",
     "shell.execute_reply": "2025-02-25T11:33:30.091136Z"
    },
    "papermill": {
     "duration": 506.912169,
     "end_time": "2025-02-25T11:33:30.093864",
     "exception": false,
     "start_time": "2025-02-25T11:25:03.181695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.4173 - loss: 1.8230 - val_accuracy: 0.6535 - val_loss: 0.9641 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6893 - loss: 0.8442 - val_accuracy: 0.7957 - val_loss: 0.6219 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7438 - loss: 0.6898 - val_accuracy: 0.8026 - val_loss: 0.5546 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.6245 - val_accuracy: 0.8080 - val_loss: 0.5301 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7855 - loss: 0.5772 - val_accuracy: 0.8335 - val_loss: 0.4755 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.5457 - val_accuracy: 0.8353 - val_loss: 0.4582 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.5203 - val_accuracy: 0.8488 - val_loss: 0.4326 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.5059 - val_accuracy: 0.8336 - val_loss: 0.4421 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4948 - val_accuracy: 0.8517 - val_loss: 0.4171 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4861 - val_accuracy: 0.8569 - val_loss: 0.3949 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4686 - val_accuracy: 0.8504 - val_loss: 0.4164 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4669 - val_accuracy: 0.8537 - val_loss: 0.4035 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.4555 - val_accuracy: 0.8569 - val_loss: 0.3810 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4534 - val_accuracy: 0.8631 - val_loss: 0.3846 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.4417 - val_accuracy: 0.8681 - val_loss: 0.3688 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4343 - val_accuracy: 0.8587 - val_loss: 0.3784 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.4248 - val_accuracy: 0.8631 - val_loss: 0.3644 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4270 - val_accuracy: 0.8652 - val_loss: 0.3736 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.4260 - val_accuracy: 0.8659 - val_loss: 0.3673 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4175 - val_accuracy: 0.8676 - val_loss: 0.3485 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4086 - val_accuracy: 0.8620 - val_loss: 0.3592 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.4050 - val_accuracy: 0.8658 - val_loss: 0.3533 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.4066 - val_accuracy: 0.8653 - val_loss: 0.3568 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4066 - val_accuracy: 0.8741 - val_loss: 0.3375 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.4023 - val_accuracy: 0.8618 - val_loss: 0.3583 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4091 - val_accuracy: 0.8651 - val_loss: 0.3625 - learning_rate: 4.9700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.3928 - val_accuracy: 0.8711 - val_loss: 0.3442 - learning_rate: 4.9700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3923 - val_accuracy: 0.8723 - val_loss: 0.3634 - learning_rate: 4.9700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2224/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3869\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3869 - val_accuracy: 0.8779 - val_loss: 0.3432 - learning_rate: 4.9700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3708 - val_accuracy: 0.8865 - val_loss: 0.3089 - learning_rate: 2.4850e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3580 - val_accuracy: 0.8876 - val_loss: 0.3071 - learning_rate: 2.4850e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3626 - val_accuracy: 0.8875 - val_loss: 0.3065 - learning_rate: 2.4850e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.3543 - val_accuracy: 0.8873 - val_loss: 0.3135 - learning_rate: 2.4850e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.3567 - val_accuracy: 0.8871 - val_loss: 0.3156 - learning_rate: 2.4850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3560 - val_accuracy: 0.8922 - val_loss: 0.3047 - learning_rate: 2.4850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.3510 - val_accuracy: 0.8818 - val_loss: 0.3112 - learning_rate: 2.4850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3519 - val_accuracy: 0.8842 - val_loss: 0.3117 - learning_rate: 2.4850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3573 - val_accuracy: 0.8908 - val_loss: 0.2949 - learning_rate: 2.4850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3539 - val_accuracy: 0.8962 - val_loss: 0.2951 - learning_rate: 2.4850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3440 - val_accuracy: 0.8929 - val_loss: 0.2976 - learning_rate: 2.4850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3507 - val_accuracy: 0.8883 - val_loss: 0.3038 - learning_rate: 2.4850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3507 - val_accuracy: 0.8953 - val_loss: 0.2941 - learning_rate: 2.4850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.3439 - val_accuracy: 0.8960 - val_loss: 0.2880 - learning_rate: 2.4850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3421 - val_accuracy: 0.8957 - val_loss: 0.2861 - learning_rate: 2.4850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8680 - loss: 0.3449 - val_accuracy: 0.8851 - val_loss: 0.2979 - learning_rate: 2.4850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.3338 - val_accuracy: 0.8942 - val_loss: 0.2941 - learning_rate: 2.4850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.3421 - val_accuracy: 0.8884 - val_loss: 0.2918 - learning_rate: 2.4850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3421 - val_accuracy: 0.8925 - val_loss: 0.2881 - learning_rate: 2.4850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2234/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3445\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3445 - val_accuracy: 0.8961 - val_loss: 0.2879 - learning_rate: 2.4850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3263 - val_accuracy: 0.8964 - val_loss: 0.2802 - learning_rate: 1.2425e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3297 - val_accuracy: 0.8958 - val_loss: 0.2843 - learning_rate: 1.2425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.3231 - val_accuracy: 0.8942 - val_loss: 0.2813 - learning_rate: 1.2425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3259 - val_accuracy: 0.8972 - val_loss: 0.2811 - learning_rate: 1.2425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3211 - val_accuracy: 0.9021 - val_loss: 0.2745 - learning_rate: 1.2425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8767 - loss: 0.3203 - val_accuracy: 0.8970 - val_loss: 0.2821 - learning_rate: 1.2425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.3239 - val_accuracy: 0.8999 - val_loss: 0.2783 - learning_rate: 1.2425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3183 - val_accuracy: 0.8959 - val_loss: 0.2836 - learning_rate: 1.2425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.3218 - val_accuracy: 0.8992 - val_loss: 0.2713 - learning_rate: 1.2425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.3218 - val_accuracy: 0.9002 - val_loss: 0.2739 - learning_rate: 1.2425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.3229 - val_accuracy: 0.9031 - val_loss: 0.2708 - learning_rate: 1.2425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.3213 - val_accuracy: 0.8983 - val_loss: 0.2712 - learning_rate: 1.2425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.3195 - val_accuracy: 0.9007 - val_loss: 0.2717 - learning_rate: 1.2425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3243 - val_accuracy: 0.8988 - val_loss: 0.2753 - learning_rate: 1.2425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8763 - loss: 0.3232 - val_accuracy: 0.8996 - val_loss: 0.2735 - learning_rate: 1.2425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2230/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.3189\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.3189 - val_accuracy: 0.9018 - val_loss: 0.2803 - learning_rate: 1.2425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.3110 - val_accuracy: 0.9015 - val_loss: 0.2693 - learning_rate: 6.2125e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.3113 - val_accuracy: 0.9026 - val_loss: 0.2683 - learning_rate: 6.2125e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.3162 - val_accuracy: 0.9037 - val_loss: 0.2674 - learning_rate: 6.2125e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3077 - val_accuracy: 0.9051 - val_loss: 0.2621 - learning_rate: 6.2125e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.3171 - val_accuracy: 0.9034 - val_loss: 0.2652 - learning_rate: 6.2125e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3076 - val_accuracy: 0.9024 - val_loss: 0.2692 - learning_rate: 6.2125e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.3100 - val_accuracy: 0.9033 - val_loss: 0.2620 - learning_rate: 6.2125e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3135 - val_accuracy: 0.9057 - val_loss: 0.2619 - learning_rate: 6.2125e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3107 - val_accuracy: 0.9040 - val_loss: 0.2645 - learning_rate: 6.2125e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.3105 - val_accuracy: 0.9056 - val_loss: 0.2609 - learning_rate: 6.2125e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.3130 - val_accuracy: 0.9050 - val_loss: 0.2606 - learning_rate: 6.2125e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.3097 - val_accuracy: 0.9052 - val_loss: 0.2604 - learning_rate: 6.2125e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3047 - val_accuracy: 0.9044 - val_loss: 0.2655 - learning_rate: 6.2125e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3076 - val_accuracy: 0.9048 - val_loss: 0.2634 - learning_rate: 6.2125e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3093 - val_accuracy: 0.9040 - val_loss: 0.2618 - learning_rate: 6.2125e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.3088 - val_accuracy: 0.9031 - val_loss: 0.2643 - learning_rate: 6.2125e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2233/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3102\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.3102 - val_accuracy: 0.9006 - val_loss: 0.2651 - learning_rate: 6.2125e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.3059 - val_accuracy: 0.9052 - val_loss: 0.2580 - learning_rate: 3.1063e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3057 - val_accuracy: 0.9073 - val_loss: 0.2562 - learning_rate: 3.1063e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3034 - val_accuracy: 0.9053 - val_loss: 0.2589 - learning_rate: 3.1063e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.3032 - val_accuracy: 0.9065 - val_loss: 0.2633 - learning_rate: 3.1063e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.3037 - val_accuracy: 0.9044 - val_loss: 0.2625 - learning_rate: 3.1063e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3032 - val_accuracy: 0.9050 - val_loss: 0.2577 - learning_rate: 3.1063e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2236/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.3021\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.5531250028288923e-05.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.3021 - val_accuracy: 0.9068 - val_loss: 0.2574 - learning_rate: 3.1063e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3079 - val_accuracy: 0.9064 - val_loss: 0.2555 - learning_rate: 1.5531e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.2998 - val_accuracy: 0.9065 - val_loss: 0.2569 - learning_rate: 1.5531e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.3035 - val_accuracy: 0.9065 - val_loss: 0.2566 - learning_rate: 1.5531e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.3022 - val_accuracy: 0.9065 - val_loss: 0.2572 - learning_rate: 1.5531e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.3050 - val_accuracy: 0.9045 - val_loss: 0.2571 - learning_rate: 1.5531e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2221/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3023\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 7.765625014144462e-06.\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3023 - val_accuracy: 0.9063 - val_loss: 0.2573 - learning_rate: 1.5531e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2995 - val_accuracy: 0.9068 - val_loss: 0.2567 - learning_rate: 7.7656e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3024 - val_accuracy: 0.9054 - val_loss: 0.2590 - learning_rate: 7.7656e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3052 - val_accuracy: 0.9067 - val_loss: 0.2568 - learning_rate: 7.7656e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.3003 - val_accuracy: 0.9065 - val_loss: 0.2566 - learning_rate: 7.7656e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2242/2242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2994 - val_accuracy: 0.9085 - val_loss: 0.2517 - learning_rate: 7.7656e-06\n",
      "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy: 0.9079\n",
      "Precision: 0.9088\n",
      "Recall: 0.9079\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      2402\n",
      "           1       0.90      0.69      0.78       722\n",
      "           2       0.94      0.92      0.93      1686\n",
      "           3       0.93      0.93      0.93      2795\n",
      "           4       0.94      0.92      0.93      2574\n",
      "           5       0.84      0.87      0.86       415\n",
      "           6       0.95      0.86      0.90       678\n",
      "           7       0.95      0.90      0.92      1027\n",
      "           8       0.78      0.42      0.55       424\n",
      "           9       0.86      0.96      0.91       474\n",
      "          10       0.86      0.91      0.89       411\n",
      "          11       0.95      1.00      0.97       441\n",
      "          12       0.92      0.93      0.93       469\n",
      "          13       0.91      0.99      0.95       412\n",
      "          14       1.00      1.00      1.00       442\n",
      "\n",
      "    accuracy                           0.91     15372\n",
      "   macro avg       0.90      0.89      0.89     15372\n",
      "weighted avg       0.91      0.91      0.91     15372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build a CNN model with fixed hyperparameters (without tuning)\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First Conv1D layer\n",
    "    x = Conv1D(\n",
    "        filters=64,  # Fixed filter count\n",
    "        kernel_size=7,  # Fixed kernel size\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=32,  # Fixed filter count\n",
    "        kernel_size=5,  # Fixed kernel size\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # Flatten and Dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.1)(x)  # Fixed dropout value\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)  # Fixed dense layer size\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Fixed learning rate\n",
    "    optimizer = Adam(learning_rate=0.000497)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Load data\n",
    "X = df.drop(columns=['Emotion'])\n",
    "y = df['Emotion']\n",
    "\n",
    "# Splitting Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  \n",
    "\n",
    "# Reshape input for CNN\n",
    "X_train_cnn = np.expand_dims(X_train, axis=-1)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=-1)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "input_shape = (X_train_cnn.shape[1], 1)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Build and train CNN model\n",
    "cnn_model = build_cnn_model(input_shape, num_classes)\n",
    "history = cnn_model.fit(\n",
    "    X_train_cnn, y_train, \n",
    "    epochs=100, batch_size=32, \n",
    "    validation_data=(X_val_cnn, y_val), \n",
    "    callbacks=[\n",
    "        reduce_lr\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions on test data\n",
    "predictions = cnn_model.predict(X_test_cnn)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "pred_df = X_test.copy()\n",
    "pred_df = pd.DataFrame(pred_df, columns=df.drop(columns=['Emotion']).columns)\n",
    "pred_df['Emotion'] = predicted_labels\n",
    "pred_df['Emotion_Type'] = pred_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "pred_df.drop(columns=['Emotion'], inplace=True)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df['Emotion_Type'] = (test_df['Emotion_Type'] == 1).astype(float)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = tf.math.confusion_matrix(y_test, predicted_labels).numpy()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- ROC CURVE FOR MULTI-CLASS TEST DATA ---\n",
    "n_classes = len(np.unique(y_test))  \n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], predictions[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve for Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d013278",
   "metadata": {
    "papermill": {
     "duration": 24.65487,
     "end_time": "2025-02-25T11:34:19.379789",
     "exception": false,
     "start_time": "2025-02-25T11:33:54.724919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### CNN - Preprocessing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c44befba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T11:35:08.252133Z",
     "iopub.status.busy": "2025-02-25T11:35:08.251734Z",
     "iopub.status.idle": "2025-02-25T12:24:22.685627Z",
     "shell.execute_reply": "2025-02-25T12:24:22.684611Z"
    },
    "papermill": {
     "duration": 2978.552622,
     "end_time": "2025-02-25T12:24:22.687080",
     "exception": false,
     "start_time": "2025-02-25T11:34:44.134458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected Attribute Names: ['GENDER']\n",
      "Privileged Protected Attributes: [{'GENDER': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1}]\n",
      "Sensitive Attribute: GENDER\n",
      "Description: GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 0.7598\n",
      "  Statistical Parity Difference: -0.1445\n",
      "  Between Group Coefficient of Variation: 0.1373\n",
      "  Between Group Generalized Entropy Index: 0.0094\n",
      "  Between Group Theil Index: 0.0095\n",
      "  Mean Difference: -0.1445\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1437\n",
      "  Average Odds Difference: -0.1437\n",
      "  Average Predictive Value Difference: 0.1334\n",
      "  Between All Groups Coefficient of Variation: 0.1373\n",
      "  Between All Groups Generalized Entropy Index: 0.0094\n",
      "  Between All Groups Theil Index: 0.0095\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.0226\n",
      "  Equal Opportunity Difference: -0.0918\n",
      "  Equalized Odds Difference: 0.1956\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0554\n",
      "  Error Rate Ratio: 0.8982\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1859\n",
      "  False Discovery Rate Ratio: 0.6818\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: 0.0918\n",
      "  False Negative Rate Ratio: 1.2107\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.0809\n",
      "  False Omission Rate Ratio: 1.1671\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.1956\n",
      "  False Positive Rate Ratio: 0.6900\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.1956\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: -0.0918\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 0.7598\n",
      "  Statistical Parity Difference: -0.1445\n",
      "  Between Group Coefficient of Variation: 0.1373\n",
      "  Between Group Generalized Entropy Index: 0.0094\n",
      "  Between Group Theil Index: 0.0095\n",
      "  Mean Difference: -0.1445\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1437\n",
      "  Average Odds Difference: -0.1437\n",
      "  Average Predictive Value Difference: 0.1334\n",
      "  Between All Groups Coefficient of Variation: 0.1373\n",
      "  Between All Groups Generalized Entropy Index: 0.0094\n",
      "  Between All Groups Theil Index: 0.0095\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.0226\n",
      "  Equal Opportunity Difference: -0.0918\n",
      "  Equalized Odds Difference: 0.1956\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0554\n",
      "  Error Rate Ratio: 0.8982\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1859\n",
      "  False Discovery Rate Ratio: 0.6818\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: 0.0918\n",
      "  False Negative Rate Ratio: 1.2107\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.0809\n",
      "  False Omission Rate Ratio: 1.1671\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.1956\n",
      "  False Positive Rate Ratio: 0.6900\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.1956\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: -0.0918\n",
      "Epoch 1/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.3957 - loss: 1.8580 - val_accuracy: 0.6098 - val_loss: 1.1131 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 1.0914 - val_accuracy: 0.7165 - val_loss: 0.8275 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6724 - loss: 0.9207 - val_accuracy: 0.7421 - val_loss: 0.7543 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.8355 - val_accuracy: 0.7633 - val_loss: 0.7223 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.7821 - val_accuracy: 0.7684 - val_loss: 0.6774 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.7449 - val_accuracy: 0.7841 - val_loss: 0.6248 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.7135 - val_accuracy: 0.7811 - val_loss: 0.6092 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.6885 - val_accuracy: 0.8034 - val_loss: 0.5721 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.6771 - val_accuracy: 0.7886 - val_loss: 0.5955 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.6618 - val_accuracy: 0.8051 - val_loss: 0.5718 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.6455 - val_accuracy: 0.8124 - val_loss: 0.5452 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7652 - loss: 0.6423 - val_accuracy: 0.8091 - val_loss: 0.5524 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7693 - loss: 0.6308 - val_accuracy: 0.8159 - val_loss: 0.5284 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7751 - loss: 0.6112 - val_accuracy: 0.8172 - val_loss: 0.5298 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.6034 - val_accuracy: 0.8216 - val_loss: 0.5192 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7801 - loss: 0.5971 - val_accuracy: 0.8139 - val_loss: 0.5354 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.5991 - val_accuracy: 0.8195 - val_loss: 0.5096 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.5873 - val_accuracy: 0.8290 - val_loss: 0.4914 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7863 - loss: 0.5798 - val_accuracy: 0.8253 - val_loss: 0.5161 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.5779 - val_accuracy: 0.8132 - val_loss: 0.5327 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.5737 - val_accuracy: 0.8383 - val_loss: 0.4887 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.5671 - val_accuracy: 0.8374 - val_loss: 0.4877 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.5640 - val_accuracy: 0.8242 - val_loss: 0.5160 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.5640 - val_accuracy: 0.8259 - val_loss: 0.5105 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.5664 - val_accuracy: 0.8229 - val_loss: 0.4869 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.5538 - val_accuracy: 0.8260 - val_loss: 0.4917 - learning_rate: 4.9700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.5516 - val_accuracy: 0.8326 - val_loss: 0.4758 - learning_rate: 4.9700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.5508 - val_accuracy: 0.8367 - val_loss: 0.4698 - learning_rate: 4.9700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5463 - val_accuracy: 0.8372 - val_loss: 0.4716 - learning_rate: 4.9700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.5406 - val_accuracy: 0.8326 - val_loss: 0.4772 - learning_rate: 4.9700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.5485 - val_accuracy: 0.8334 - val_loss: 0.4708 - learning_rate: 4.9700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.5408 - val_accuracy: 0.8200 - val_loss: 0.4870 - learning_rate: 4.9700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.5370\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.5370 - val_accuracy: 0.8264 - val_loss: 0.4727 - learning_rate: 4.9700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.5170 - val_accuracy: 0.8474 - val_loss: 0.4427 - learning_rate: 2.4850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.5062 - val_accuracy: 0.8427 - val_loss: 0.4443 - learning_rate: 2.4850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.5061 - val_accuracy: 0.8453 - val_loss: 0.4398 - learning_rate: 2.4850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.5037 - val_accuracy: 0.8470 - val_loss: 0.4337 - learning_rate: 2.4850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4999 - val_accuracy: 0.8525 - val_loss: 0.4252 - learning_rate: 2.4850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.5022 - val_accuracy: 0.8507 - val_loss: 0.4346 - learning_rate: 2.4850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4952 - val_accuracy: 0.8448 - val_loss: 0.4225 - learning_rate: 2.4850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4999 - val_accuracy: 0.8551 - val_loss: 0.4196 - learning_rate: 2.4850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.5032 - val_accuracy: 0.8586 - val_loss: 0.4150 - learning_rate: 2.4850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4970 - val_accuracy: 0.8528 - val_loss: 0.4200 - learning_rate: 2.4850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4924 - val_accuracy: 0.8540 - val_loss: 0.4265 - learning_rate: 2.4850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.4905 - val_accuracy: 0.8612 - val_loss: 0.4125 - learning_rate: 2.4850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4932 - val_accuracy: 0.8467 - val_loss: 0.4286 - learning_rate: 2.4850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4900 - val_accuracy: 0.8571 - val_loss: 0.4276 - learning_rate: 2.4850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4863 - val_accuracy: 0.8578 - val_loss: 0.4160 - learning_rate: 2.4850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4907 - val_accuracy: 0.8572 - val_loss: 0.4215 - learning_rate: 2.4850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2537/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.4887\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.4887 - val_accuracy: 0.8479 - val_loss: 0.4316 - learning_rate: 2.4850e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4792 - val_accuracy: 0.8575 - val_loss: 0.4079 - learning_rate: 1.2425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4718 - val_accuracy: 0.8617 - val_loss: 0.3968 - learning_rate: 1.2425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.4734 - val_accuracy: 0.8546 - val_loss: 0.4162 - learning_rate: 1.2425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.4702 - val_accuracy: 0.8611 - val_loss: 0.4086 - learning_rate: 1.2425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4734 - val_accuracy: 0.8631 - val_loss: 0.4024 - learning_rate: 1.2425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4651 - val_accuracy: 0.8631 - val_loss: 0.4004 - learning_rate: 1.2425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2554/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4680\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4680 - val_accuracy: 0.8587 - val_loss: 0.4045 - learning_rate: 1.2425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.4674 - val_accuracy: 0.8640 - val_loss: 0.3952 - learning_rate: 6.2125e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.4599 - val_accuracy: 0.8623 - val_loss: 0.3956 - learning_rate: 6.2125e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4660 - val_accuracy: 0.8645 - val_loss: 0.3972 - learning_rate: 6.2125e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4588 - val_accuracy: 0.8667 - val_loss: 0.3958 - learning_rate: 6.2125e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.4529 - val_accuracy: 0.8675 - val_loss: 0.3935 - learning_rate: 6.2125e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4584 - val_accuracy: 0.8669 - val_loss: 0.3954 - learning_rate: 6.2125e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4557 - val_accuracy: 0.8636 - val_loss: 0.3966 - learning_rate: 6.2125e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4592 - val_accuracy: 0.8661 - val_loss: 0.3908 - learning_rate: 6.2125e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4592 - val_accuracy: 0.8656 - val_loss: 0.3962 - learning_rate: 6.2125e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4556 - val_accuracy: 0.8665 - val_loss: 0.3926 - learning_rate: 6.2125e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.4580 - val_accuracy: 0.8646 - val_loss: 0.4001 - learning_rate: 6.2125e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8294 - loss: 0.4527 - val_accuracy: 0.8662 - val_loss: 0.3872 - learning_rate: 6.2125e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4532 - val_accuracy: 0.8710 - val_loss: 0.3896 - learning_rate: 6.2125e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8288 - loss: 0.4573 - val_accuracy: 0.8662 - val_loss: 0.3897 - learning_rate: 6.2125e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4499 - val_accuracy: 0.8671 - val_loss: 0.3856 - learning_rate: 6.2125e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4614 - val_accuracy: 0.8662 - val_loss: 0.3937 - learning_rate: 6.2125e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4571 - val_accuracy: 0.8641 - val_loss: 0.3923 - learning_rate: 6.2125e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.4538 - val_accuracy: 0.8700 - val_loss: 0.3857 - learning_rate: 6.2125e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.4539 - val_accuracy: 0.8668 - val_loss: 0.3933 - learning_rate: 6.2125e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.4527 - val_accuracy: 0.8663 - val_loss: 0.3834 - learning_rate: 6.2125e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.4523 - val_accuracy: 0.8651 - val_loss: 0.3852 - learning_rate: 6.2125e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4562 - val_accuracy: 0.8653 - val_loss: 0.3946 - learning_rate: 6.2125e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4537 - val_accuracy: 0.8679 - val_loss: 0.3783 - learning_rate: 6.2125e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4555 - val_accuracy: 0.8643 - val_loss: 0.3834 - learning_rate: 6.2125e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.4524 - val_accuracy: 0.8633 - val_loss: 0.3848 - learning_rate: 6.2125e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4582 - val_accuracy: 0.8676 - val_loss: 0.3819 - learning_rate: 6.2125e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4474 - val_accuracy: 0.8652 - val_loss: 0.3866 - learning_rate: 6.2125e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4516\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4516 - val_accuracy: 0.8675 - val_loss: 0.3849 - learning_rate: 6.2125e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8303 - loss: 0.4512 - val_accuracy: 0.8707 - val_loss: 0.3804 - learning_rate: 3.1063e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4458 - val_accuracy: 0.8695 - val_loss: 0.3785 - learning_rate: 3.1063e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4444 - val_accuracy: 0.8688 - val_loss: 0.3819 - learning_rate: 3.1063e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4492 - val_accuracy: 0.8681 - val_loss: 0.3849 - learning_rate: 3.1063e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.4535\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.5531250028288923e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.4535 - val_accuracy: 0.8689 - val_loss: 0.3805 - learning_rate: 3.1063e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.4503 - val_accuracy: 0.8700 - val_loss: 0.3750 - learning_rate: 1.5531e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4515 - val_accuracy: 0.8715 - val_loss: 0.3748 - learning_rate: 1.5531e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4414 - val_accuracy: 0.8709 - val_loss: 0.3793 - learning_rate: 1.5531e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4484 - val_accuracy: 0.8705 - val_loss: 0.3795 - learning_rate: 1.5531e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.4495 - val_accuracy: 0.8710 - val_loss: 0.3828 - learning_rate: 1.5531e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4457 - val_accuracy: 0.8668 - val_loss: 0.3838 - learning_rate: 1.5531e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4463\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 7.765625014144462e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4463 - val_accuracy: 0.8723 - val_loss: 0.3771 - learning_rate: 1.5531e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4438 - val_accuracy: 0.8704 - val_loss: 0.3797 - learning_rate: 7.7656e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.4441 - val_accuracy: 0.8679 - val_loss: 0.3850 - learning_rate: 7.7656e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4494 - val_accuracy: 0.8694 - val_loss: 0.3814 - learning_rate: 7.7656e-06\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.4135 - loss: 1.8118 - val_accuracy: 0.6342 - val_loss: 1.0932 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 1.0869 - val_accuracy: 0.7042 - val_loss: 0.8672 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6711 - loss: 0.9179 - val_accuracy: 0.7226 - val_loss: 0.7888 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.8324 - val_accuracy: 0.7530 - val_loss: 0.7049 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7746 - val_accuracy: 0.7575 - val_loss: 0.6881 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.7466 - val_accuracy: 0.7747 - val_loss: 0.6478 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.7170 - val_accuracy: 0.7733 - val_loss: 0.6262 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7446 - loss: 0.6948 - val_accuracy: 0.7699 - val_loss: 0.6406 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7511 - loss: 0.6750 - val_accuracy: 0.7883 - val_loss: 0.6077 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.6618 - val_accuracy: 0.7984 - val_loss: 0.5686 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7610 - loss: 0.6451 - val_accuracy: 0.8034 - val_loss: 0.5719 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.6421 - val_accuracy: 0.8004 - val_loss: 0.5434 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.6202 - val_accuracy: 0.8113 - val_loss: 0.5420 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.6124 - val_accuracy: 0.8079 - val_loss: 0.5308 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.6072 - val_accuracy: 0.8126 - val_loss: 0.5309 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.5936 - val_accuracy: 0.8110 - val_loss: 0.5139 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.5959 - val_accuracy: 0.7917 - val_loss: 0.5722 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.5907 - val_accuracy: 0.8190 - val_loss: 0.4972 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7784 - loss: 0.5890 - val_accuracy: 0.8161 - val_loss: 0.5154 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.5768 - val_accuracy: 0.8079 - val_loss: 0.5272 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.5700 - val_accuracy: 0.8207 - val_loss: 0.4890 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.5718 - val_accuracy: 0.8272 - val_loss: 0.4962 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7868 - loss: 0.5618 - val_accuracy: 0.8216 - val_loss: 0.4993 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.5606 - val_accuracy: 0.8223 - val_loss: 0.4877 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.5600 - val_accuracy: 0.8118 - val_loss: 0.5186 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.5505 - val_accuracy: 0.8217 - val_loss: 0.4925 - learning_rate: 4.9700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5451 - val_accuracy: 0.8208 - val_loss: 0.4882 - learning_rate: 4.9700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.5500 - val_accuracy: 0.8227 - val_loss: 0.4835 - learning_rate: 4.9700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.5444 - val_accuracy: 0.8262 - val_loss: 0.4699 - learning_rate: 4.9700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.5435 - val_accuracy: 0.8270 - val_loss: 0.4831 - learning_rate: 4.9700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.5390 - val_accuracy: 0.8350 - val_loss: 0.4740 - learning_rate: 4.9700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.5421 - val_accuracy: 0.8285 - val_loss: 0.4705 - learning_rate: 4.9700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.5329 - val_accuracy: 0.8263 - val_loss: 0.4701 - learning_rate: 4.9700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2545/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.5310\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.5311 - val_accuracy: 0.8253 - val_loss: 0.4724 - learning_rate: 4.9700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.5112 - val_accuracy: 0.8465 - val_loss: 0.4364 - learning_rate: 2.4850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.5088 - val_accuracy: 0.8417 - val_loss: 0.4488 - learning_rate: 2.4850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.5027 - val_accuracy: 0.8411 - val_loss: 0.4315 - learning_rate: 2.4850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.5016 - val_accuracy: 0.8454 - val_loss: 0.4313 - learning_rate: 2.4850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.4933 - val_accuracy: 0.8388 - val_loss: 0.4285 - learning_rate: 2.4850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.5061 - val_accuracy: 0.8404 - val_loss: 0.4395 - learning_rate: 2.4850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.5004 - val_accuracy: 0.8425 - val_loss: 0.4364 - learning_rate: 2.4850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.4965 - val_accuracy: 0.8438 - val_loss: 0.4281 - learning_rate: 2.4850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.4946 - val_accuracy: 0.8307 - val_loss: 0.4532 - learning_rate: 2.4850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4956 - val_accuracy: 0.8547 - val_loss: 0.4122 - learning_rate: 2.4850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4950 - val_accuracy: 0.8413 - val_loss: 0.4309 - learning_rate: 2.4850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4889 - val_accuracy: 0.8387 - val_loss: 0.4368 - learning_rate: 2.4850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.4831 - val_accuracy: 0.8398 - val_loss: 0.4149 - learning_rate: 2.4850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4881 - val_accuracy: 0.8448 - val_loss: 0.4269 - learning_rate: 2.4850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2546/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4867\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4867 - val_accuracy: 0.8424 - val_loss: 0.4346 - learning_rate: 2.4850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4820 - val_accuracy: 0.8530 - val_loss: 0.4122 - learning_rate: 1.2425e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4637 - val_accuracy: 0.8516 - val_loss: 0.4118 - learning_rate: 1.2425e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.4657 - val_accuracy: 0.8504 - val_loss: 0.4145 - learning_rate: 1.2425e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.4670 - val_accuracy: 0.8503 - val_loss: 0.4086 - learning_rate: 1.2425e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.4670 - val_accuracy: 0.8544 - val_loss: 0.4009 - learning_rate: 1.2425e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.4580 - val_accuracy: 0.8537 - val_loss: 0.4136 - learning_rate: 1.2425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.4659 - val_accuracy: 0.8568 - val_loss: 0.3995 - learning_rate: 1.2425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4670 - val_accuracy: 0.8532 - val_loss: 0.4074 - learning_rate: 1.2425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4664 - val_accuracy: 0.8554 - val_loss: 0.4016 - learning_rate: 1.2425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4567 - val_accuracy: 0.8581 - val_loss: 0.3953 - learning_rate: 1.2425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4658 - val_accuracy: 0.8560 - val_loss: 0.4050 - learning_rate: 1.2425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.4646 - val_accuracy: 0.8477 - val_loss: 0.4109 - learning_rate: 1.2425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.4638 - val_accuracy: 0.8582 - val_loss: 0.3951 - learning_rate: 1.2425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.4611 - val_accuracy: 0.8453 - val_loss: 0.4070 - learning_rate: 1.2425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4572 - val_accuracy: 0.8547 - val_loss: 0.3952 - learning_rate: 1.2425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.4621 - val_accuracy: 0.8548 - val_loss: 0.3929 - learning_rate: 1.2425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4559 - val_accuracy: 0.8602 - val_loss: 0.3927 - learning_rate: 1.2425e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4527 - val_accuracy: 0.8573 - val_loss: 0.3940 - learning_rate: 1.2425e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.4586 - val_accuracy: 0.8608 - val_loss: 0.3923 - learning_rate: 1.2425e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4609 - val_accuracy: 0.8587 - val_loss: 0.3945 - learning_rate: 1.2425e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4541 - val_accuracy: 0.8569 - val_loss: 0.3916 - learning_rate: 1.2425e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.4607 - val_accuracy: 0.8532 - val_loss: 0.3943 - learning_rate: 1.2425e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.4556 - val_accuracy: 0.8607 - val_loss: 0.3875 - learning_rate: 1.2425e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.4500 - val_accuracy: 0.8562 - val_loss: 0.3959 - learning_rate: 1.2425e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4548 - val_accuracy: 0.8551 - val_loss: 0.3959 - learning_rate: 1.2425e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4530 - val_accuracy: 0.8598 - val_loss: 0.3898 - learning_rate: 1.2425e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4499 - val_accuracy: 0.8567 - val_loss: 0.3954 - learning_rate: 1.2425e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.4584 - val_accuracy: 0.8563 - val_loss: 0.3850 - learning_rate: 1.2425e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.4539 - val_accuracy: 0.8576 - val_loss: 0.3980 - learning_rate: 1.2425e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4532 - val_accuracy: 0.8613 - val_loss: 0.3863 - learning_rate: 1.2425e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8294 - loss: 0.4515 - val_accuracy: 0.8549 - val_loss: 0.3953 - learning_rate: 1.2425e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4512 - val_accuracy: 0.8592 - val_loss: 0.3910 - learning_rate: 1.2425e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m2543/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4539\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4539 - val_accuracy: 0.8581 - val_loss: 0.3874 - learning_rate: 1.2425e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4481 - val_accuracy: 0.8621 - val_loss: 0.3788 - learning_rate: 6.2125e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.4449 - val_accuracy: 0.8643 - val_loss: 0.3814 - learning_rate: 6.2125e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4374 - val_accuracy: 0.8619 - val_loss: 0.3862 - learning_rate: 6.2125e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.4421 - val_accuracy: 0.8647 - val_loss: 0.3770 - learning_rate: 6.2125e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4454 - val_accuracy: 0.8654 - val_loss: 0.3823 - learning_rate: 6.2125e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.4462 - val_accuracy: 0.8687 - val_loss: 0.3781 - learning_rate: 6.2125e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4401 - val_accuracy: 0.8665 - val_loss: 0.3791 - learning_rate: 6.2125e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4462 - val_accuracy: 0.8663 - val_loss: 0.3797 - learning_rate: 6.2125e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2538/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4399\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4399 - val_accuracy: 0.8634 - val_loss: 0.3822 - learning_rate: 6.2125e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4439 - val_accuracy: 0.8659 - val_loss: 0.3777 - learning_rate: 3.1063e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.4432 - val_accuracy: 0.8666 - val_loss: 0.3756 - learning_rate: 3.1063e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4407 - val_accuracy: 0.8675 - val_loss: 0.3735 - learning_rate: 3.1063e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4367 - val_accuracy: 0.8647 - val_loss: 0.3756 - learning_rate: 3.1063e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4375 - val_accuracy: 0.8653 - val_loss: 0.3810 - learning_rate: 3.1063e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4369 - val_accuracy: 0.8655 - val_loss: 0.3765 - learning_rate: 3.1063e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4395 - val_accuracy: 0.8656 - val_loss: 0.3777 - learning_rate: 3.1063e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.4385 - val_accuracy: 0.8675 - val_loss: 0.3728 - learning_rate: 3.1063e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4357 - val_accuracy: 0.8646 - val_loss: 0.3733 - learning_rate: 3.1063e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "23373  0.773760  36.118992  23.952529  41.529143  28.532619   7.740000   \n",
      "68962  0.778693  36.696599   6.615936  31.481888  22.437499   6.373703   \n",
      "79496  0.520780  35.702485  47.145696  46.188097  28.528304   6.507750   \n",
      "59187  0.714085  37.378185  13.314312  30.107391  23.264847  10.080750   \n",
      "44838  0.668801  37.407194  36.480888  32.711198  24.975669   6.336430   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "66252  0.785113  36.469051  10.459896  30.930133  22.363873   6.301289   \n",
      "73034  0.699560  36.650955   6.509472  33.727502  25.368301   7.363964   \n",
      "89474 -0.465601  35.974870  14.000304  32.673381  23.674151   5.470085   \n",
      "48345  0.846040  36.826144  43.747128  31.917447  25.024732   7.586719   \n",
      "54817  0.691978  36.564337  18.829944  31.307653  22.549689   6.944706   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "23373   7.679792  24.413500  0.0     1.0           1.0  \n",
      "68962  10.491500   5.226577  0.0     0.0           1.0  \n",
      "79496   5.234750   6.754250  0.0     1.0           0.0  \n",
      "59187   5.768500   4.677508  0.0     0.0           1.0  \n",
      "44838  10.080750   8.426665  0.0     0.0           0.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "66252  13.530500   8.125680  0.0     0.0           1.0  \n",
      "73034   8.930750   6.706159  0.0     0.0           1.0  \n",
      "89474  14.787577   4.794912  0.0     1.0           0.0  \n",
      "48345   7.165000  49.489233  0.0     0.0           0.0  \n",
      "54817   9.916500   5.378450  0.0     0.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt   emg_coru  \\\n",
      "23373  0.773760  36.118992  23.952529  41.529143  28.532619   7.740000   \n",
      "68962  0.778693  36.696599   6.615936  31.481888  22.437499   6.373703   \n",
      "79496  0.520780  35.702485  47.145696  46.188097  28.528304   6.507750   \n",
      "59187  0.714085  37.378185  13.314312  30.107391  23.264847  10.080750   \n",
      "44838  0.668801  37.407194  36.480888  32.711198  24.975669   6.336430   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "66252  0.785113  36.469051  10.459896  30.930133  22.363873   6.301289   \n",
      "73034  0.699560  36.650955   6.509472  33.727502  25.368301   7.363964   \n",
      "89474 -0.465601  35.974870  14.000304  32.673381  23.674151   5.470085   \n",
      "48345  0.846040  36.826144  43.747128  31.917447  25.024732   7.586719   \n",
      "54817  0.691978  36.564337  18.829944  31.307653  22.549689   6.944706   \n",
      "\n",
      "        emg_trap   emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "23373   7.679792  24.413500  0.0     1.0           1.0  \n",
      "68962  10.491500   5.226577  0.0     0.0           0.0  \n",
      "79496   5.234750   6.754250  0.0     1.0           0.0  \n",
      "59187   5.768500   4.677508  0.0     0.0           0.0  \n",
      "44838  10.080750   8.426665  0.0     0.0           0.0  \n",
      "...          ...        ...  ...     ...           ...  \n",
      "66252  13.530500   8.125680  0.0     0.0           1.0  \n",
      "73034   8.930750   6.706159  0.0     0.0           1.0  \n",
      "89474  14.787577   4.794912  0.0     1.0           0.0  \n",
      "48345   7.165000  49.489233  0.0     0.0           0.0  \n",
      "54817   9.916500   5.378450  0.0     0.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.4802\n",
      "  Base Rate: 0.5049\n",
      "  Selection Rate: 0.5272\n",
      "  Disparate Impact: 0.7637\n",
      "  Statistical Parity Difference: -0.1398\n",
      "  Between Group Coefficient of Variation: 0.1332\n",
      "  Between Group Generalized Entropy Index: 0.0089\n",
      "  Between Group Theil Index: 0.0090\n",
      "  Mean Difference: -0.1398\n",
      "  Smoothed Empirical Differential Fairness: 0.2738\n",
      "  Consistency: 0.9527\n",
      "  Average Absolute Odds Difference: 0.1379\n",
      "  Average Odds Difference: -0.1379\n",
      "  Average Predictive Value Difference: 0.1291\n",
      "  Between All Groups Coefficient of Variation: 0.1332\n",
      "  Between All Groups Generalized Entropy Index: 0.0089\n",
      "  Between All Groups Theil Index: 0.0090\n",
      "  Coefficient of Variation: 0.7049\n",
      "  Differential Fairness Bias Amplification: 0.0205\n",
      "  Equal Opportunity Difference: -0.1062\n",
      "  Equalized Odds Difference: 0.1696\n",
      "  Error Rate: 0.5198\n",
      "  Error Rate Difference: -0.0342\n",
      "  Error Rate Ratio: 0.9362\n",
      "  False Discovery Rate: 0.5142\n",
      "  False Discovery Rate Difference: -0.1613\n",
      "  False Discovery Rate Ratio: 0.7208\n",
      "  False Negative Rate: 0.4927\n",
      "  False Negative Rate Difference: 0.1062\n",
      "  False Negative Rate Ratio: 1.2431\n",
      "  False Omission Rate: 0.5261\n",
      "  False Omission Rate Difference: 0.0970\n",
      "  False Omission Rate Ratio: 1.2045\n",
      "  False Positive Rate: 0.5475\n",
      "  False Positive Rate Difference: -0.1696\n",
      "  False Positive Rate Ratio: 0.7239\n",
      "  Generalized Entropy Index: 0.2484\n",
      "  Generalized Equalized Odds Difference: 0.1696\n",
      "  Generalized False Negative Rate: 0.4927\n",
      "  Generalized False Positive Rate: 0.5475\n",
      "  Generalized True Negative Rate: 0.4525\n",
      "  Generalized True Positive Rate: 0.5073\n",
      "  Negative Predictive Value: 0.4739\n",
      "  Number of False Negatives: 2549.0000\n",
      "  Number of False Positives: 2778.0000\n",
      "  Number of Generalized False Negatives: 2549.0000\n",
      "  Number of Generalized False Positives: 2778.0000\n",
      "  Number of Generalized True Negatives: 2296.0000\n",
      "  Number of Generalized True Positives: 2625.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5074.0000\n",
      "  Number of Positives: 5174.0000\n",
      "  Number of Predicted Negatives: 4845.0000\n",
      "  Number of Predicted Positives: 5403.0000\n",
      "  Number of True Negatives: 2296.0000\n",
      "  Number of True Positives: 2625.0000\n",
      "  Positive Predictive Value: 0.4858\n",
      "  Power: 2625.0000\n",
      "  Precision: 0.4858\n",
      "  Recall: 0.5073\n",
      "  Sensitivity: 0.5073\n",
      "  Specificity: 0.4525\n",
      "  Theil Index: 0.3455\n",
      "  True Negative Rate: 0.4525\n",
      "  True Positive Rate: 0.5073\n",
      "  True Positive Rate Difference: -0.1062\n",
      "  Accuracy: 0.4802\n",
      "  Base Rate: 0.5049\n",
      "  Selection Rate: 0.5272\n",
      "  Disparate Impact: 0.7637\n",
      "  Statistical Parity Difference: -0.1398\n",
      "  Between Group Coefficient of Variation: 0.1332\n",
      "  Between Group Generalized Entropy Index: 0.0089\n",
      "  Between Group Theil Index: 0.0090\n",
      "  Mean Difference: -0.1398\n",
      "  Smoothed Empirical Differential Fairness: 0.2738\n",
      "  Consistency: 0.9527\n",
      "  Average Absolute Odds Difference: 0.1379\n",
      "  Average Odds Difference: -0.1379\n",
      "  Average Predictive Value Difference: 0.1291\n",
      "  Between All Groups Coefficient of Variation: 0.1332\n",
      "  Between All Groups Generalized Entropy Index: 0.0089\n",
      "  Between All Groups Theil Index: 0.0090\n",
      "  Coefficient of Variation: 0.7049\n",
      "  Differential Fairness Bias Amplification: 0.0205\n",
      "  Equal Opportunity Difference: -0.1062\n",
      "  Equalized Odds Difference: 0.1696\n",
      "  Error Rate: 0.5198\n",
      "  Error Rate Difference: -0.0342\n",
      "  Error Rate Ratio: 0.9362\n",
      "  False Discovery Rate: 0.5142\n",
      "  False Discovery Rate Difference: -0.1613\n",
      "  False Discovery Rate Ratio: 0.7208\n",
      "  False Negative Rate: 0.4927\n",
      "  False Negative Rate Difference: 0.1062\n",
      "  False Negative Rate Ratio: 1.2431\n",
      "  False Omission Rate: 0.5261\n",
      "  False Omission Rate Difference: 0.0970\n",
      "  False Omission Rate Ratio: 1.2045\n",
      "  False Positive Rate: 0.5475\n",
      "  False Positive Rate Difference: -0.1696\n",
      "  False Positive Rate Ratio: 0.7239\n",
      "  Generalized Entropy Index: 0.2484\n",
      "  Generalized Equalized Odds Difference: 0.1696\n",
      "  Generalized False Negative Rate: 0.4927\n",
      "  Generalized False Positive Rate: 0.5475\n",
      "  Generalized True Negative Rate: 0.4525\n",
      "  Generalized True Positive Rate: 0.5073\n",
      "  Negative Predictive Value: 0.4739\n",
      "  Number of False Negatives: 2549.0000\n",
      "  Number of False Positives: 2778.0000\n",
      "  Number of Generalized False Negatives: 2549.0000\n",
      "  Number of Generalized False Positives: 2778.0000\n",
      "  Number of Generalized True Negatives: 2296.0000\n",
      "  Number of Generalized True Positives: 2625.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5074.0000\n",
      "  Number of Positives: 5174.0000\n",
      "  Number of Predicted Negatives: 4845.0000\n",
      "  Number of Predicted Positives: 5403.0000\n",
      "  Number of True Negatives: 2296.0000\n",
      "  Number of True Positives: 2625.0000\n",
      "  Positive Predictive Value: 0.4858\n",
      "  Power: 2625.0000\n",
      "  Precision: 0.4858\n",
      "  Recall: 0.5073\n",
      "  Sensitivity: 0.5073\n",
      "  Specificity: 0.4525\n",
      "  Theil Index: 0.3455\n",
      "  True Negative Rate: 0.4525\n",
      "  True Positive Rate: 0.5073\n",
      "  True Positive Rate Difference: -0.1062\n",
      "  Accuracy: 0.5039\n",
      "  Base Rate: 0.5058\n",
      "  Selection Rate: 0.5112\n",
      "  Disparate Impact: 0.7794\n",
      "  Statistical Parity Difference: -0.1257\n",
      "  Between Group Coefficient of Variation: 0.1265\n",
      "  Between Group Generalized Entropy Index: 0.0080\n",
      "  Between Group Theil Index: 0.0081\n",
      "  Mean Difference: -0.1257\n",
      "  Smoothed Empirical Differential Fairness: 0.2652\n",
      "  Consistency: 0.9495\n",
      "  Average Absolute Odds Difference: 0.1293\n",
      "  Average Odds Difference: -0.1293\n",
      "  Average Predictive Value Difference: 0.1321\n",
      "  Between All Groups Coefficient of Variation: 0.1265\n",
      "  Between All Groups Generalized Entropy Index: 0.0080\n",
      "  Between All Groups Theil Index: 0.0081\n",
      "  Coefficient of Variation: 0.7005\n",
      "  Differential Fairness Bias Amplification: -0.0089\n",
      "  Equal Opportunity Difference: -0.1139\n",
      "  Equalized Odds Difference: 0.1447\n",
      "  Error Rate: 0.4961\n",
      "  Error Rate Difference: -0.0143\n",
      "  Error Rate Ratio: 0.9716\n",
      "  False Discovery Rate: 0.4906\n",
      "  False Discovery Rate Difference: -0.1473\n",
      "  False Discovery Rate Ratio: 0.7323\n",
      "  False Negative Rate: 0.4850\n",
      "  False Negative Rate Difference: 0.1139\n",
      "  False Negative Rate Ratio: 1.2682\n",
      "  False Omission Rate: 0.5019\n",
      "  False Omission Rate Difference: 0.1170\n",
      "  False Omission Rate Ratio: 1.2660\n",
      "  False Positive Rate: 0.5074\n",
      "  False Positive Rate Difference: -0.1447\n",
      "  False Positive Rate Ratio: 0.7441\n",
      "  Generalized Entropy Index: 0.2453\n",
      "  Generalized Equalized Odds Difference: 0.1447\n",
      "  Generalized False Negative Rate: 0.4850\n",
      "  Generalized False Positive Rate: 0.5074\n",
      "  Generalized True Negative Rate: 0.4926\n",
      "  Generalized True Positive Rate: 0.5150\n",
      "  Negative Predictive Value: 0.4981\n",
      "  Number of False Negatives: 2514.0000\n",
      "  Number of False Positives: 2570.0000\n",
      "  Number of Generalized False Negatives: 2514.0000\n",
      "  Number of Generalized False Positives: 2570.0000\n",
      "  Number of Generalized True Negatives: 2495.0000\n",
      "  Number of Generalized True Positives: 2669.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5065.0000\n",
      "  Number of Positives: 5183.0000\n",
      "  Number of Predicted Negatives: 5009.0000\n",
      "  Number of Predicted Positives: 5239.0000\n",
      "  Number of True Negatives: 2495.0000\n",
      "  Number of True Positives: 2669.0000\n",
      "  Positive Predictive Value: 0.5094\n",
      "  Power: 2669.0000\n",
      "  Precision: 0.5094\n",
      "  Recall: 0.5150\n",
      "  Sensitivity: 0.5150\n",
      "  Specificity: 0.4926\n",
      "  Theil Index: 0.3403\n",
      "  True Negative Rate: 0.4926\n",
      "  True Positive Rate: 0.5150\n",
      "  True Positive Rate Difference: -0.1139\n",
      "  Accuracy: 0.5039\n",
      "  Base Rate: 0.5058\n",
      "  Selection Rate: 0.5112\n",
      "  Disparate Impact: 0.7794\n",
      "  Statistical Parity Difference: -0.1257\n",
      "  Between Group Coefficient of Variation: 0.1265\n",
      "  Between Group Generalized Entropy Index: 0.0080\n",
      "  Between Group Theil Index: 0.0081\n",
      "  Mean Difference: -0.1257\n",
      "  Smoothed Empirical Differential Fairness: 0.2652\n",
      "  Consistency: 0.9495\n",
      "  Average Absolute Odds Difference: 0.1293\n",
      "  Average Odds Difference: -0.1293\n",
      "  Average Predictive Value Difference: 0.1321\n",
      "  Between All Groups Coefficient of Variation: 0.1265\n",
      "  Between All Groups Generalized Entropy Index: 0.0080\n",
      "  Between All Groups Theil Index: 0.0081\n",
      "  Coefficient of Variation: 0.7005\n",
      "  Differential Fairness Bias Amplification: -0.0089\n",
      "  Equal Opportunity Difference: -0.1139\n",
      "  Equalized Odds Difference: 0.1447\n",
      "  Error Rate: 0.4961\n",
      "  Error Rate Difference: -0.0143\n",
      "  Error Rate Ratio: 0.9716\n",
      "  False Discovery Rate: 0.4906\n",
      "  False Discovery Rate Difference: -0.1473\n",
      "  False Discovery Rate Ratio: 0.7323\n",
      "  False Negative Rate: 0.4850\n",
      "  False Negative Rate Difference: 0.1139\n",
      "  False Negative Rate Ratio: 1.2682\n",
      "  False Omission Rate: 0.5019\n",
      "  False Omission Rate Difference: 0.1170\n",
      "  False Omission Rate Ratio: 1.2660\n",
      "  False Positive Rate: 0.5074\n",
      "  False Positive Rate Difference: -0.1447\n",
      "  False Positive Rate Ratio: 0.7441\n",
      "  Generalized Entropy Index: 0.2453\n",
      "  Generalized Equalized Odds Difference: 0.1447\n",
      "  Generalized False Negative Rate: 0.4850\n",
      "  Generalized False Positive Rate: 0.5074\n",
      "  Generalized True Negative Rate: 0.4926\n",
      "  Generalized True Positive Rate: 0.5150\n",
      "  Negative Predictive Value: 0.4981\n",
      "  Number of False Negatives: 2514.0000\n",
      "  Number of False Positives: 2570.0000\n",
      "  Number of Generalized False Negatives: 2514.0000\n",
      "  Number of Generalized False Positives: 2570.0000\n",
      "  Number of Generalized True Negatives: 2495.0000\n",
      "  Number of Generalized True Positives: 2669.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5065.0000\n",
      "  Number of Positives: 5183.0000\n",
      "  Number of Predicted Negatives: 5009.0000\n",
      "  Number of Predicted Positives: 5239.0000\n",
      "  Number of True Negatives: 2495.0000\n",
      "  Number of True Positives: 2669.0000\n",
      "  Positive Predictive Value: 0.5094\n",
      "  Power: 2669.0000\n",
      "  Precision: 0.5094\n",
      "  Recall: 0.5150\n",
      "  Sensitivity: 0.5150\n",
      "  Specificity: 0.4926\n",
      "  Theil Index: 0.3403\n",
      "  True Negative Rate: 0.4926\n",
      "  True Positive Rate: 0.5150\n",
      "  True Positive Rate Difference: -0.1139\n",
      "Protected Attribute Names: ['AGE']\n",
      "Privileged Protected Attributes: [{'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.1753\n",
      "  Statistical Parity Difference: 0.0907\n",
      "  Between Group Coefficient of Variation: 0.0378\n",
      "  Between Group Generalized Entropy Index: 0.0007\n",
      "  Between Group Theil Index: 0.0007\n",
      "  Mean Difference: 0.0907\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1167\n",
      "  Average Odds Difference: 0.0900\n",
      "  Average Predictive Value Difference: -0.0270\n",
      "  Between All Groups Coefficient of Variation: 0.0378\n",
      "  Between All Groups Generalized Entropy Index: 0.0007\n",
      "  Between All Groups Theil Index: 0.0007\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.1915\n",
      "  Equal Opportunity Difference: 0.2068\n",
      "  Equalized Odds Difference: 0.2068\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.1164\n",
      "  Error Rate Ratio: 0.7849\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.0935\n",
      "  False Discovery Rate Ratio: 0.8241\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.2068\n",
      "  False Negative Rate Ratio: 0.6046\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: -0.1475\n",
      "  False Omission Rate Ratio: 0.7325\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.0267\n",
      "  False Positive Rate Ratio: 0.9523\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.2068\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.2068\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.1753\n",
      "  Statistical Parity Difference: 0.0907\n",
      "  Between Group Coefficient of Variation: 0.0378\n",
      "  Between Group Generalized Entropy Index: 0.0007\n",
      "  Between Group Theil Index: 0.0007\n",
      "  Mean Difference: 0.0907\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1167\n",
      "  Average Odds Difference: 0.0900\n",
      "  Average Predictive Value Difference: -0.0270\n",
      "  Between All Groups Coefficient of Variation: 0.0378\n",
      "  Between All Groups Generalized Entropy Index: 0.0007\n",
      "  Between All Groups Theil Index: 0.0007\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.1915\n",
      "  Equal Opportunity Difference: 0.2068\n",
      "  Equalized Odds Difference: 0.2068\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.1164\n",
      "  Error Rate Ratio: 0.7849\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.0935\n",
      "  False Discovery Rate Ratio: 0.8241\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.2068\n",
      "  False Negative Rate Ratio: 0.6046\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: -0.1475\n",
      "  False Omission Rate Ratio: 0.7325\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.0267\n",
      "  False Positive Rate Ratio: 0.9523\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.2068\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.2068\n",
      "Epoch 1/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.3928 - loss: 1.8649 - val_accuracy: 0.6131 - val_loss: 1.0940 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6039 - loss: 1.1234 - val_accuracy: 0.7104 - val_loss: 0.8489 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6612 - loss: 0.9413 - val_accuracy: 0.7343 - val_loss: 0.7549 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.8490 - val_accuracy: 0.7578 - val_loss: 0.7005 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.7935 - val_accuracy: 0.7669 - val_loss: 0.6686 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.7476 - val_accuracy: 0.7717 - val_loss: 0.6510 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.7369 - val_accuracy: 0.7852 - val_loss: 0.5982 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.7137 - val_accuracy: 0.7900 - val_loss: 0.5794 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.6945 - val_accuracy: 0.7916 - val_loss: 0.5818 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7460 - loss: 0.6829 - val_accuracy: 0.8115 - val_loss: 0.5387 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.6678 - val_accuracy: 0.7922 - val_loss: 0.5554 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7584 - loss: 0.6461 - val_accuracy: 0.8001 - val_loss: 0.5404 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.6509 - val_accuracy: 0.8105 - val_loss: 0.5298 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.6412 - val_accuracy: 0.7968 - val_loss: 0.5655 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.6373 - val_accuracy: 0.8133 - val_loss: 0.5131 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.6229 - val_accuracy: 0.8128 - val_loss: 0.5160 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7674 - loss: 0.6204 - val_accuracy: 0.8173 - val_loss: 0.4999 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.6136 - val_accuracy: 0.8146 - val_loss: 0.5194 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7717 - loss: 0.6102 - val_accuracy: 0.8085 - val_loss: 0.5013 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.5985 - val_accuracy: 0.8262 - val_loss: 0.4785 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.5965 - val_accuracy: 0.8228 - val_loss: 0.4928 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.5995 - val_accuracy: 0.8115 - val_loss: 0.5014 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.5926 - val_accuracy: 0.8113 - val_loss: 0.4976 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.5861 - val_accuracy: 0.8122 - val_loss: 0.4978 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2560/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.5807\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.5807 - val_accuracy: 0.8225 - val_loss: 0.4804 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7895 - loss: 0.5575 - val_accuracy: 0.8345 - val_loss: 0.4479 - learning_rate: 2.4850e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.5495 - val_accuracy: 0.8438 - val_loss: 0.4444 - learning_rate: 2.4850e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.5346 - val_accuracy: 0.8443 - val_loss: 0.4359 - learning_rate: 2.4850e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7937 - loss: 0.5453 - val_accuracy: 0.8387 - val_loss: 0.4365 - learning_rate: 2.4850e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7943 - loss: 0.5406 - val_accuracy: 0.8370 - val_loss: 0.4349 - learning_rate: 2.4850e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.5379 - val_accuracy: 0.8488 - val_loss: 0.4190 - learning_rate: 2.4850e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.5363 - val_accuracy: 0.8459 - val_loss: 0.4373 - learning_rate: 2.4850e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.5327 - val_accuracy: 0.8440 - val_loss: 0.4319 - learning_rate: 2.4850e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.5335 - val_accuracy: 0.8440 - val_loss: 0.4370 - learning_rate: 2.4850e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.5370 - val_accuracy: 0.8416 - val_loss: 0.4324 - learning_rate: 2.4850e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.5271 - val_accuracy: 0.8467 - val_loss: 0.4188 - learning_rate: 2.4850e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.5311 - val_accuracy: 0.8453 - val_loss: 0.4287 - learning_rate: 2.4850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.5209 - val_accuracy: 0.8481 - val_loss: 0.4273 - learning_rate: 2.4850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8014 - loss: 0.5221 - val_accuracy: 0.8464 - val_loss: 0.4215 - learning_rate: 2.4850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.5253 - val_accuracy: 0.8514 - val_loss: 0.4161 - learning_rate: 2.4850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8015 - loss: 0.5208 - val_accuracy: 0.8479 - val_loss: 0.4124 - learning_rate: 2.4850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.5253 - val_accuracy: 0.8419 - val_loss: 0.4308 - learning_rate: 2.4850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.5151 - val_accuracy: 0.8505 - val_loss: 0.4191 - learning_rate: 2.4850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.5233 - val_accuracy: 0.8468 - val_loss: 0.4089 - learning_rate: 2.4850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.5104 - val_accuracy: 0.8463 - val_loss: 0.4175 - learning_rate: 2.4850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.5113 - val_accuracy: 0.8410 - val_loss: 0.4253 - learning_rate: 2.4850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.5178 - val_accuracy: 0.8576 - val_loss: 0.4047 - learning_rate: 2.4850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.5101 - val_accuracy: 0.8518 - val_loss: 0.4111 - learning_rate: 2.4850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.5135 - val_accuracy: 0.8567 - val_loss: 0.4024 - learning_rate: 2.4850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.5173 - val_accuracy: 0.8460 - val_loss: 0.4231 - learning_rate: 2.4850e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.5074 - val_accuracy: 0.8535 - val_loss: 0.4140 - learning_rate: 2.4850e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.5144 - val_accuracy: 0.8478 - val_loss: 0.4185 - learning_rate: 2.4850e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.5090 - val_accuracy: 0.8511 - val_loss: 0.4086 - learning_rate: 2.4850e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2545/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.5102\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.5102 - val_accuracy: 0.8391 - val_loss: 0.4233 - learning_rate: 2.4850e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.4977 - val_accuracy: 0.8564 - val_loss: 0.3885 - learning_rate: 1.2425e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.4901 - val_accuracy: 0.8581 - val_loss: 0.3868 - learning_rate: 1.2425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4945 - val_accuracy: 0.8581 - val_loss: 0.3881 - learning_rate: 1.2425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.4909 - val_accuracy: 0.8597 - val_loss: 0.3852 - learning_rate: 1.2425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4865 - val_accuracy: 0.8649 - val_loss: 0.3850 - learning_rate: 1.2425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4883 - val_accuracy: 0.8664 - val_loss: 0.3786 - learning_rate: 1.2425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4827 - val_accuracy: 0.8599 - val_loss: 0.3855 - learning_rate: 1.2425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4898 - val_accuracy: 0.8649 - val_loss: 0.3832 - learning_rate: 1.2425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.4884 - val_accuracy: 0.8614 - val_loss: 0.3830 - learning_rate: 1.2425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4818 - val_accuracy: 0.8630 - val_loss: 0.3803 - learning_rate: 1.2425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2543/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.4806\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.4806 - val_accuracy: 0.8618 - val_loss: 0.3834 - learning_rate: 1.2425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4746 - val_accuracy: 0.8645 - val_loss: 0.3769 - learning_rate: 6.2125e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4744 - val_accuracy: 0.8651 - val_loss: 0.3752 - learning_rate: 6.2125e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4782 - val_accuracy: 0.8678 - val_loss: 0.3787 - learning_rate: 6.2125e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.4714 - val_accuracy: 0.8687 - val_loss: 0.3742 - learning_rate: 6.2125e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4759 - val_accuracy: 0.8652 - val_loss: 0.3734 - learning_rate: 6.2125e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4742 - val_accuracy: 0.8698 - val_loss: 0.3716 - learning_rate: 6.2125e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.4762 - val_accuracy: 0.8682 - val_loss: 0.3747 - learning_rate: 6.2125e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4724 - val_accuracy: 0.8699 - val_loss: 0.3713 - learning_rate: 6.2125e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.4755 - val_accuracy: 0.8699 - val_loss: 0.3730 - learning_rate: 6.2125e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4766 - val_accuracy: 0.8652 - val_loss: 0.3693 - learning_rate: 6.2125e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.4730 - val_accuracy: 0.8709 - val_loss: 0.3673 - learning_rate: 6.2125e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4753 - val_accuracy: 0.8663 - val_loss: 0.3745 - learning_rate: 6.2125e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4755 - val_accuracy: 0.8648 - val_loss: 0.3758 - learning_rate: 6.2125e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4787 - val_accuracy: 0.8673 - val_loss: 0.3728 - learning_rate: 6.2125e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4804 - val_accuracy: 0.8669 - val_loss: 0.3728 - learning_rate: 6.2125e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4704\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4704 - val_accuracy: 0.8699 - val_loss: 0.3712 - learning_rate: 6.2125e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4701 - val_accuracy: 0.8692 - val_loss: 0.3692 - learning_rate: 3.1063e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4634 - val_accuracy: 0.8696 - val_loss: 0.3686 - learning_rate: 3.1063e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4660 - val_accuracy: 0.8692 - val_loss: 0.3727 - learning_rate: 3.1063e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.4625 - val_accuracy: 0.8725 - val_loss: 0.3644 - learning_rate: 3.1063e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.4680 - val_accuracy: 0.8687 - val_loss: 0.3655 - learning_rate: 3.1063e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4637 - val_accuracy: 0.8712 - val_loss: 0.3660 - learning_rate: 3.1063e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4645 - val_accuracy: 0.8702 - val_loss: 0.3675 - learning_rate: 3.1063e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.4741 - val_accuracy: 0.8685 - val_loss: 0.3668 - learning_rate: 3.1063e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.4662 - val_accuracy: 0.8718 - val_loss: 0.3635 - learning_rate: 3.1063e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8204 - loss: 0.4691 - val_accuracy: 0.8724 - val_loss: 0.3622 - learning_rate: 3.1063e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4628 - val_accuracy: 0.8678 - val_loss: 0.3674 - learning_rate: 3.1063e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4689 - val_accuracy: 0.8709 - val_loss: 0.3646 - learning_rate: 3.1063e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.4644 - val_accuracy: 0.8728 - val_loss: 0.3634 - learning_rate: 3.1063e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.4591 - val_accuracy: 0.8714 - val_loss: 0.3619 - learning_rate: 3.1063e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.4620 - val_accuracy: 0.8713 - val_loss: 0.3610 - learning_rate: 3.1063e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.4581 - val_accuracy: 0.8702 - val_loss: 0.3676 - learning_rate: 3.1063e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.4598 - val_accuracy: 0.8713 - val_loss: 0.3624 - learning_rate: 3.1063e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4601 - val_accuracy: 0.8699 - val_loss: 0.3633 - learning_rate: 3.1063e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.4615 - val_accuracy: 0.8746 - val_loss: 0.3625 - learning_rate: 3.1063e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.4211 - loss: 1.8062 - val_accuracy: 0.6153 - val_loss: 1.0581 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6276 - loss: 1.0633 - val_accuracy: 0.7157 - val_loss: 0.8169 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6781 - loss: 0.9044 - val_accuracy: 0.7414 - val_loss: 0.7359 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.8301 - val_accuracy: 0.7545 - val_loss: 0.6816 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.7801 - val_accuracy: 0.7727 - val_loss: 0.6386 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.7434 - val_accuracy: 0.7878 - val_loss: 0.6058 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.7168 - val_accuracy: 0.7913 - val_loss: 0.5933 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.7022 - val_accuracy: 0.7933 - val_loss: 0.5691 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7476 - loss: 0.6830 - val_accuracy: 0.7979 - val_loss: 0.5770 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7537 - loss: 0.6586 - val_accuracy: 0.7858 - val_loss: 0.5613 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.6596 - val_accuracy: 0.8004 - val_loss: 0.5406 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7631 - loss: 0.6388 - val_accuracy: 0.7985 - val_loss: 0.5630 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.6291 - val_accuracy: 0.8210 - val_loss: 0.5246 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.6241 - val_accuracy: 0.8069 - val_loss: 0.5237 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.6202 - val_accuracy: 0.8097 - val_loss: 0.5084 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7691 - loss: 0.6219 - val_accuracy: 0.8078 - val_loss: 0.5222 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7751 - loss: 0.6045 - val_accuracy: 0.8207 - val_loss: 0.4911 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7721 - loss: 0.6082 - val_accuracy: 0.8093 - val_loss: 0.5113 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7779 - loss: 0.5977 - val_accuracy: 0.7990 - val_loss: 0.5276 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.5934 - val_accuracy: 0.7909 - val_loss: 0.5446 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.5867 - val_accuracy: 0.8233 - val_loss: 0.5120 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7807 - loss: 0.5808 - val_accuracy: 0.8260 - val_loss: 0.4788 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.5681 - val_accuracy: 0.8288 - val_loss: 0.4874 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.5720 - val_accuracy: 0.8230 - val_loss: 0.4662 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7867 - loss: 0.5684 - val_accuracy: 0.8213 - val_loss: 0.4799 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.5670 - val_accuracy: 0.8252 - val_loss: 0.4750 - learning_rate: 4.9700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.5628 - val_accuracy: 0.8346 - val_loss: 0.4643 - learning_rate: 4.9700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7908 - loss: 0.5635 - val_accuracy: 0.8361 - val_loss: 0.4575 - learning_rate: 4.9700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.5527 - val_accuracy: 0.8281 - val_loss: 0.4553 - learning_rate: 4.9700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.5483 - val_accuracy: 0.8207 - val_loss: 0.4669 - learning_rate: 4.9700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.5498 - val_accuracy: 0.8375 - val_loss: 0.4553 - learning_rate: 4.9700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.5478 - val_accuracy: 0.8342 - val_loss: 0.4495 - learning_rate: 4.9700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.5442 - val_accuracy: 0.8393 - val_loss: 0.4697 - learning_rate: 4.9700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.5415 - val_accuracy: 0.8336 - val_loss: 0.4436 - learning_rate: 4.9700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.5417 - val_accuracy: 0.8384 - val_loss: 0.4580 - learning_rate: 4.9700e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.5376 - val_accuracy: 0.8308 - val_loss: 0.4583 - learning_rate: 4.9700e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.5350 - val_accuracy: 0.8303 - val_loss: 0.4636 - learning_rate: 4.9700e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.5369 - val_accuracy: 0.8327 - val_loss: 0.4585 - learning_rate: 4.9700e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.5323 - val_accuracy: 0.8454 - val_loss: 0.4419 - learning_rate: 4.9700e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.5300 - val_accuracy: 0.8407 - val_loss: 0.4357 - learning_rate: 4.9700e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.5277 - val_accuracy: 0.8407 - val_loss: 0.4505 - learning_rate: 4.9700e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.5226 - val_accuracy: 0.8334 - val_loss: 0.4423 - learning_rate: 4.9700e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.5318 - val_accuracy: 0.8355 - val_loss: 0.4422 - learning_rate: 4.9700e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.5287 - val_accuracy: 0.8427 - val_loss: 0.4345 - learning_rate: 4.9700e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.5274 - val_accuracy: 0.8324 - val_loss: 0.4542 - learning_rate: 4.9700e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.5220 - val_accuracy: 0.8373 - val_loss: 0.4296 - learning_rate: 4.9700e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.5185 - val_accuracy: 0.8459 - val_loss: 0.4205 - learning_rate: 4.9700e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.5138 - val_accuracy: 0.8350 - val_loss: 0.4353 - learning_rate: 4.9700e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.5161 - val_accuracy: 0.8452 - val_loss: 0.4275 - learning_rate: 4.9700e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.5113 - val_accuracy: 0.8509 - val_loss: 0.4192 - learning_rate: 4.9700e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.5143 - val_accuracy: 0.8435 - val_loss: 0.4361 - learning_rate: 4.9700e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.5120 - val_accuracy: 0.8469 - val_loss: 0.4283 - learning_rate: 4.9700e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.5101 - val_accuracy: 0.8328 - val_loss: 0.4556 - learning_rate: 4.9700e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.5132 - val_accuracy: 0.8385 - val_loss: 0.4377 - learning_rate: 4.9700e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2550/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.5058\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.5058 - val_accuracy: 0.8460 - val_loss: 0.4283 - learning_rate: 4.9700e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4896 - val_accuracy: 0.8611 - val_loss: 0.4029 - learning_rate: 2.4850e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4795 - val_accuracy: 0.8555 - val_loss: 0.4072 - learning_rate: 2.4850e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4820 - val_accuracy: 0.8584 - val_loss: 0.3918 - learning_rate: 2.4850e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.4772 - val_accuracy: 0.8507 - val_loss: 0.4173 - learning_rate: 2.4850e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4853 - val_accuracy: 0.8588 - val_loss: 0.4011 - learning_rate: 2.4850e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.4709 - val_accuracy: 0.8667 - val_loss: 0.3898 - learning_rate: 2.4850e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4707 - val_accuracy: 0.8651 - val_loss: 0.4044 - learning_rate: 2.4850e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.4724 - val_accuracy: 0.8587 - val_loss: 0.3863 - learning_rate: 2.4850e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.4709 - val_accuracy: 0.8548 - val_loss: 0.3935 - learning_rate: 2.4850e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.4740 - val_accuracy: 0.8598 - val_loss: 0.3869 - learning_rate: 2.4850e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4759 - val_accuracy: 0.8679 - val_loss: 0.3830 - learning_rate: 2.4850e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.4658 - val_accuracy: 0.8615 - val_loss: 0.3940 - learning_rate: 2.4850e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.4704 - val_accuracy: 0.8649 - val_loss: 0.3909 - learning_rate: 2.4850e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4716 - val_accuracy: 0.8606 - val_loss: 0.3965 - learning_rate: 2.4850e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4682 - val_accuracy: 0.8706 - val_loss: 0.3828 - learning_rate: 2.4850e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4671 - val_accuracy: 0.8605 - val_loss: 0.3810 - learning_rate: 2.4850e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4694 - val_accuracy: 0.8636 - val_loss: 0.3884 - learning_rate: 2.4850e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.4656 - val_accuracy: 0.8638 - val_loss: 0.3796 - learning_rate: 2.4850e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.4646 - val_accuracy: 0.8659 - val_loss: 0.3780 - learning_rate: 2.4850e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4775 - val_accuracy: 0.8599 - val_loss: 0.3854 - learning_rate: 2.4850e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.4726 - val_accuracy: 0.8713 - val_loss: 0.3824 - learning_rate: 2.4850e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4737 - val_accuracy: 0.8591 - val_loss: 0.3880 - learning_rate: 2.4850e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4640 - val_accuracy: 0.8711 - val_loss: 0.3819 - learning_rate: 2.4850e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m2541/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4681\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4681 - val_accuracy: 0.8644 - val_loss: 0.3820 - learning_rate: 2.4850e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.4507 - val_accuracy: 0.8688 - val_loss: 0.3713 - learning_rate: 1.2425e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4487 - val_accuracy: 0.8712 - val_loss: 0.3717 - learning_rate: 1.2425e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4486 - val_accuracy: 0.8664 - val_loss: 0.3776 - learning_rate: 1.2425e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.4525 - val_accuracy: 0.8682 - val_loss: 0.3777 - learning_rate: 1.2425e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.4500 - val_accuracy: 0.8730 - val_loss: 0.3684 - learning_rate: 1.2425e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.4475 - val_accuracy: 0.8712 - val_loss: 0.3675 - learning_rate: 1.2425e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4530 - val_accuracy: 0.8740 - val_loss: 0.3628 - learning_rate: 1.2425e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.4480 - val_accuracy: 0.8748 - val_loss: 0.3670 - learning_rate: 1.2425e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4523 - val_accuracy: 0.8671 - val_loss: 0.3834 - learning_rate: 1.2425e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4508 - val_accuracy: 0.8690 - val_loss: 0.3679 - learning_rate: 1.2425e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4526 - val_accuracy: 0.8673 - val_loss: 0.3719 - learning_rate: 1.2425e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m2546/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4520\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4520 - val_accuracy: 0.8716 - val_loss: 0.3698 - learning_rate: 1.2425e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.4427 - val_accuracy: 0.8702 - val_loss: 0.3613 - learning_rate: 6.2125e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4398 - val_accuracy: 0.8749 - val_loss: 0.3583 - learning_rate: 6.2125e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4433 - val_accuracy: 0.8730 - val_loss: 0.3652 - learning_rate: 6.2125e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.4389 - val_accuracy: 0.8736 - val_loss: 0.3639 - learning_rate: 6.2125e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4399 - val_accuracy: 0.8747 - val_loss: 0.3613 - learning_rate: 6.2125e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.4374 - val_accuracy: 0.8743 - val_loss: 0.3618 - learning_rate: 6.2125e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2545/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4402\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4402 - val_accuracy: 0.8757 - val_loss: 0.3582 - learning_rate: 6.2125e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.4368 - val_accuracy: 0.8752 - val_loss: 0.3626 - learning_rate: 3.1063e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4357 - val_accuracy: 0.8755 - val_loss: 0.3589 - learning_rate: 3.1063e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "85412  0.741540  36.084208  17.544672  41.786270  30.788211  5.152500   \n",
      "65906  0.938123  36.700181  10.302216  31.272081  22.384338  6.138250   \n",
      "81669  0.967600  35.910297  29.583857  40.745113  27.044061  6.138250   \n",
      "63143  0.734340  35.973710  23.821248  36.321587  31.215906  7.159219   \n",
      "30850  0.882180  36.593486  27.089640  34.792241  22.377894  9.852254   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "46241  0.712792  35.215756  37.099872  31.482180  25.210549  6.425325   \n",
      "59018  0.705631  36.777746  13.240219  29.697385  23.282389  7.411245   \n",
      "7378   0.874820  36.853888  29.104296  29.778306  24.323595  7.436731   \n",
      "14808  0.686916  35.812459  31.126487  43.462084  34.173772  6.425325   \n",
      "80132  0.067556  35.525234  46.420866  47.381586  28.702278  5.522032   \n",
      "\n",
      "        emg_trap  emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "85412   6.646625  5.522250  0.0     1.0           1.0  \n",
      "65906  14.310750  7.411250  0.0     0.0           1.0  \n",
      "81669  18.789095  4.742019  0.0     1.0           0.0  \n",
      "63143   9.657291  6.184203  1.0     1.0           1.0  \n",
      "30850  25.193750  4.865000  0.0     0.0           1.0  \n",
      "...          ...       ...  ...     ...           ...  \n",
      "46241  17.541090  4.865000  0.0     1.0           0.0  \n",
      "59018   6.001670  4.783000  0.0     0.0           1.0  \n",
      "7378    5.768500  8.992271  1.0     0.0           1.0  \n",
      "14808   9.916500  5.193750  0.0     1.0           1.0  \n",
      "80132  10.326660  7.123750  0.0     1.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "            ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "85412  0.741540  36.084208  17.544672  41.786270  30.788211  5.152500   \n",
      "65906  0.938123  36.700181  10.302216  31.272081  22.384338  6.138250   \n",
      "81669  0.967600  35.910297  29.583857  40.745113  27.044061  6.138250   \n",
      "63143  0.734340  35.973710  23.821248  36.321587  31.215906  7.159219   \n",
      "30850  0.882180  36.593486  27.089640  34.792241  22.377894  9.852254   \n",
      "...         ...        ...        ...        ...        ...       ...   \n",
      "46241  0.712792  35.215756  37.099872  31.482180  25.210549  6.425325   \n",
      "59018  0.705631  36.777746  13.240219  29.697385  23.282389  7.411245   \n",
      "7378   0.874820  36.853888  29.104296  29.778306  24.323595  7.436731   \n",
      "14808  0.686916  35.812459  31.126487  43.462084  34.173772  6.425325   \n",
      "80132  0.067556  35.525234  46.420866  47.381586  28.702278  5.522032   \n",
      "\n",
      "        emg_trap  emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "85412   6.646625  5.522250  0.0     1.0           1.0  \n",
      "65906  14.310750  7.411250  0.0     0.0           1.0  \n",
      "81669  18.789095  4.742019  0.0     1.0           0.0  \n",
      "63143   9.657291  6.184203  1.0     1.0           1.0  \n",
      "30850  25.193750  4.865000  0.0     0.0           0.0  \n",
      "...          ...       ...  ...     ...           ...  \n",
      "46241  17.541090  4.865000  0.0     1.0           1.0  \n",
      "59018   6.001670  4.783000  0.0     0.0           0.0  \n",
      "7378    5.768500  8.992271  1.0     0.0           1.0  \n",
      "14808   9.916500  5.193750  0.0     1.0           0.0  \n",
      "80132  10.326660  7.123750  0.0     1.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.5053\n",
      "  Base Rate: 0.4964\n",
      "  Selection Rate: 0.5241\n",
      "  Disparate Impact: 1.1296\n",
      "  Statistical Parity Difference: 0.0663\n",
      "  Between Group Coefficient of Variation: 0.0270\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0663\n",
      "  Smoothed Empirical Differential Fairness: 0.0090\n",
      "  Consistency: 0.9512\n",
      "  Average Absolute Odds Difference: 0.1033\n",
      "  Average Odds Difference: 0.0676\n",
      "  Average Predictive Value Difference: -0.0190\n",
      "  Between All Groups Coefficient of Variation: 0.0270\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6839\n",
      "  Differential Fairness Bias Amplification: 0.1368\n",
      "  Equal Opportunity Difference: 0.1710\n",
      "  Equalized Odds Difference: 0.1710\n",
      "  Error Rate: 0.4947\n",
      "  Error Rate Difference: -0.1022\n",
      "  Error Rate Ratio: 0.8011\n",
      "  False Discovery Rate: 0.4984\n",
      "  False Discovery Rate Difference: -0.0865\n",
      "  False Discovery Rate Ratio: 0.8325\n",
      "  False Negative Rate: 0.4704\n",
      "  False Negative Rate Difference: -0.1710\n",
      "  False Negative Rate Ratio: 0.6598\n",
      "  False Omission Rate: 0.4907\n",
      "  False Omission Rate Difference: -0.1245\n",
      "  False Omission Rate Ratio: 0.7566\n",
      "  False Positive Rate: 0.5187\n",
      "  False Positive Rate Difference: -0.0357\n",
      "  False Positive Rate Ratio: 0.9321\n",
      "  Generalized Entropy Index: 0.2338\n",
      "  Generalized Equalized Odds Difference: 0.1710\n",
      "  Generalized False Negative Rate: 0.4704\n",
      "  Generalized False Positive Rate: 0.5187\n",
      "  Generalized True Negative Rate: 0.4813\n",
      "  Generalized True Positive Rate: 0.5296\n",
      "  Negative Predictive Value: 0.5093\n",
      "  Number of False Negatives: 2393.0000\n",
      "  Number of False Positives: 2677.0000\n",
      "  Number of Generalized False Negatives: 2393.0000\n",
      "  Number of Generalized False Positives: 2677.0000\n",
      "  Number of Generalized True Negatives: 2484.0000\n",
      "  Number of Generalized True Positives: 2694.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5161.0000\n",
      "  Number of Positives: 5087.0000\n",
      "  Number of Predicted Negatives: 4877.0000\n",
      "  Number of Predicted Positives: 5371.0000\n",
      "  Number of True Negatives: 2484.0000\n",
      "  Number of True Positives: 2694.0000\n",
      "  Positive Predictive Value: 0.5016\n",
      "  Power: 2694.0000\n",
      "  Precision: 0.5016\n",
      "  Recall: 0.5296\n",
      "  Sensitivity: 0.5296\n",
      "  Specificity: 0.4813\n",
      "  Theil Index: 0.3250\n",
      "  True Negative Rate: 0.4813\n",
      "  True Positive Rate: 0.5296\n",
      "  True Positive Rate Difference: 0.1710\n",
      "  Accuracy: 0.5053\n",
      "  Base Rate: 0.4964\n",
      "  Selection Rate: 0.5241\n",
      "  Disparate Impact: 1.1296\n",
      "  Statistical Parity Difference: 0.0663\n",
      "  Between Group Coefficient of Variation: 0.0270\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0663\n",
      "  Smoothed Empirical Differential Fairness: 0.0090\n",
      "  Consistency: 0.9512\n",
      "  Average Absolute Odds Difference: 0.1033\n",
      "  Average Odds Difference: 0.0676\n",
      "  Average Predictive Value Difference: -0.0190\n",
      "  Between All Groups Coefficient of Variation: 0.0270\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6839\n",
      "  Differential Fairness Bias Amplification: 0.1368\n",
      "  Equal Opportunity Difference: 0.1710\n",
      "  Equalized Odds Difference: 0.1710\n",
      "  Error Rate: 0.4947\n",
      "  Error Rate Difference: -0.1022\n",
      "  Error Rate Ratio: 0.8011\n",
      "  False Discovery Rate: 0.4984\n",
      "  False Discovery Rate Difference: -0.0865\n",
      "  False Discovery Rate Ratio: 0.8325\n",
      "  False Negative Rate: 0.4704\n",
      "  False Negative Rate Difference: -0.1710\n",
      "  False Negative Rate Ratio: 0.6598\n",
      "  False Omission Rate: 0.4907\n",
      "  False Omission Rate Difference: -0.1245\n",
      "  False Omission Rate Ratio: 0.7566\n",
      "  False Positive Rate: 0.5187\n",
      "  False Positive Rate Difference: -0.0357\n",
      "  False Positive Rate Ratio: 0.9321\n",
      "  Generalized Entropy Index: 0.2338\n",
      "  Generalized Equalized Odds Difference: 0.1710\n",
      "  Generalized False Negative Rate: 0.4704\n",
      "  Generalized False Positive Rate: 0.5187\n",
      "  Generalized True Negative Rate: 0.4813\n",
      "  Generalized True Positive Rate: 0.5296\n",
      "  Negative Predictive Value: 0.5093\n",
      "  Number of False Negatives: 2393.0000\n",
      "  Number of False Positives: 2677.0000\n",
      "  Number of Generalized False Negatives: 2393.0000\n",
      "  Number of Generalized False Positives: 2677.0000\n",
      "  Number of Generalized True Negatives: 2484.0000\n",
      "  Number of Generalized True Positives: 2694.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5161.0000\n",
      "  Number of Positives: 5087.0000\n",
      "  Number of Predicted Negatives: 4877.0000\n",
      "  Number of Predicted Positives: 5371.0000\n",
      "  Number of True Negatives: 2484.0000\n",
      "  Number of True Positives: 2694.0000\n",
      "  Positive Predictive Value: 0.5016\n",
      "  Power: 2694.0000\n",
      "  Precision: 0.5016\n",
      "  Recall: 0.5296\n",
      "  Sensitivity: 0.5296\n",
      "  Specificity: 0.4813\n",
      "  Theil Index: 0.3250\n",
      "  True Negative Rate: 0.4813\n",
      "  True Positive Rate: 0.5296\n",
      "  True Positive Rate Difference: 0.1710\n",
      "  Accuracy: 0.4969\n",
      "  Base Rate: 0.5051\n",
      "  Selection Rate: 0.5256\n",
      "  Disparate Impact: 1.1654\n",
      "  Statistical Parity Difference: 0.0843\n",
      "  Between Group Coefficient of Variation: 0.0292\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0843\n",
      "  Smoothed Empirical Differential Fairness: 0.0164\n",
      "  Consistency: 0.9524\n",
      "  Average Absolute Odds Difference: 0.1284\n",
      "  Average Odds Difference: 0.0818\n",
      "  Average Predictive Value Difference: -0.0120\n",
      "  Between All Groups Coefficient of Variation: 0.0292\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6948\n",
      "  Differential Fairness Bias Amplification: 0.1721\n",
      "  Equal Opportunity Difference: 0.2102\n",
      "  Equalized Odds Difference: 0.2102\n",
      "  Error Rate: 0.5031\n",
      "  Error Rate Difference: -0.1305\n",
      "  Error Rate Ratio: 0.7527\n",
      "  False Discovery Rate: 0.4981\n",
      "  False Discovery Rate Difference: -0.1200\n",
      "  False Discovery Rate Ratio: 0.7708\n",
      "  False Negative Rate: 0.4778\n",
      "  False Negative Rate Difference: -0.2102\n",
      "  False Negative Rate Ratio: 0.5941\n",
      "  False Omission Rate: 0.5086\n",
      "  False Omission Rate Difference: -0.1441\n",
      "  False Omission Rate Ratio: 0.7290\n",
      "  False Positive Rate: 0.5290\n",
      "  False Positive Rate Difference: -0.0467\n",
      "  False Positive Rate Ratio: 0.9132\n",
      "  Generalized Entropy Index: 0.2414\n",
      "  Generalized Equalized Odds Difference: 0.2102\n",
      "  Generalized False Negative Rate: 0.4778\n",
      "  Generalized False Positive Rate: 0.5290\n",
      "  Generalized True Negative Rate: 0.4710\n",
      "  Generalized True Positive Rate: 0.5222\n",
      "  Negative Predictive Value: 0.4914\n",
      "  Number of False Negatives: 2473.0000\n",
      "  Number of False Positives: 2683.0000\n",
      "  Number of Generalized False Negatives: 2473.0000\n",
      "  Number of Generalized False Positives: 2683.0000\n",
      "  Number of Generalized True Negatives: 2389.0000\n",
      "  Number of Generalized True Positives: 2703.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5072.0000\n",
      "  Number of Positives: 5176.0000\n",
      "  Number of Predicted Negatives: 4862.0000\n",
      "  Number of Predicted Positives: 5386.0000\n",
      "  Number of True Negatives: 2389.0000\n",
      "  Number of True Positives: 2703.0000\n",
      "  Positive Predictive Value: 0.5019\n",
      "  Power: 2703.0000\n",
      "  Precision: 0.5019\n",
      "  Recall: 0.5222\n",
      "  Sensitivity: 0.5222\n",
      "  Specificity: 0.4710\n",
      "  Theil Index: 0.3354\n",
      "  True Negative Rate: 0.4710\n",
      "  True Positive Rate: 0.5222\n",
      "  True Positive Rate Difference: 0.2102\n",
      "  Accuracy: 0.4969\n",
      "  Base Rate: 0.5051\n",
      "  Selection Rate: 0.5256\n",
      "  Disparate Impact: 1.1654\n",
      "  Statistical Parity Difference: 0.0843\n",
      "  Between Group Coefficient of Variation: 0.0292\n",
      "  Between Group Generalized Entropy Index: 0.0004\n",
      "  Between Group Theil Index: 0.0004\n",
      "  Mean Difference: 0.0843\n",
      "  Smoothed Empirical Differential Fairness: 0.0164\n",
      "  Consistency: 0.9524\n",
      "  Average Absolute Odds Difference: 0.1284\n",
      "  Average Odds Difference: 0.0818\n",
      "  Average Predictive Value Difference: -0.0120\n",
      "  Between All Groups Coefficient of Variation: 0.0292\n",
      "  Between All Groups Generalized Entropy Index: 0.0004\n",
      "  Between All Groups Theil Index: 0.0004\n",
      "  Coefficient of Variation: 0.6948\n",
      "  Differential Fairness Bias Amplification: 0.1721\n",
      "  Equal Opportunity Difference: 0.2102\n",
      "  Equalized Odds Difference: 0.2102\n",
      "  Error Rate: 0.5031\n",
      "  Error Rate Difference: -0.1305\n",
      "  Error Rate Ratio: 0.7527\n",
      "  False Discovery Rate: 0.4981\n",
      "  False Discovery Rate Difference: -0.1200\n",
      "  False Discovery Rate Ratio: 0.7708\n",
      "  False Negative Rate: 0.4778\n",
      "  False Negative Rate Difference: -0.2102\n",
      "  False Negative Rate Ratio: 0.5941\n",
      "  False Omission Rate: 0.5086\n",
      "  False Omission Rate Difference: -0.1441\n",
      "  False Omission Rate Ratio: 0.7290\n",
      "  False Positive Rate: 0.5290\n",
      "  False Positive Rate Difference: -0.0467\n",
      "  False Positive Rate Ratio: 0.9132\n",
      "  Generalized Entropy Index: 0.2414\n",
      "  Generalized Equalized Odds Difference: 0.2102\n",
      "  Generalized False Negative Rate: 0.4778\n",
      "  Generalized False Positive Rate: 0.5290\n",
      "  Generalized True Negative Rate: 0.4710\n",
      "  Generalized True Positive Rate: 0.5222\n",
      "  Negative Predictive Value: 0.4914\n",
      "  Number of False Negatives: 2473.0000\n",
      "  Number of False Positives: 2683.0000\n",
      "  Number of Generalized False Negatives: 2473.0000\n",
      "  Number of Generalized False Positives: 2683.0000\n",
      "  Number of Generalized True Negatives: 2389.0000\n",
      "  Number of Generalized True Positives: 2703.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5072.0000\n",
      "  Number of Positives: 5176.0000\n",
      "  Number of Predicted Negatives: 4862.0000\n",
      "  Number of Predicted Positives: 5386.0000\n",
      "  Number of True Negatives: 2389.0000\n",
      "  Number of True Positives: 2703.0000\n",
      "  Positive Predictive Value: 0.5019\n",
      "  Power: 2703.0000\n",
      "  Precision: 0.5019\n",
      "  Recall: 0.5222\n",
      "  Sensitivity: 0.5222\n",
      "  Specificity: 0.4710\n",
      "  Theil Index: 0.3354\n",
      "  True Negative Rate: 0.4710\n",
      "  True Positive Rate: 0.5222\n",
      "  True Positive Rate Difference: 0.2102\n",
      "Protected Attribute Names: ['GENDER', 'AGE']\n",
      "Privileged Protected Attributes: [{'GENDER': 0, 'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1, 'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE&GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.0547\n",
      "  Statistical Parity Difference: 0.0332\n",
      "  Between Group Coefficient of Variation: 0.8839\n",
      "  Between Group Generalized Entropy Index: 0.3906\n",
      "  Between Group Theil Index: 0.5761\n",
      "  Mean Difference: 0.0332\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0678\n",
      "  Average Odds Difference: 0.0678\n",
      "  Average Predictive Value Difference: 0.1823\n",
      "  Between All Groups Coefficient of Variation: 0.1470\n",
      "  Between All Groups Generalized Entropy Index: 0.0108\n",
      "  Between All Groups Theil Index: 0.0110\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: -0.1613\n",
      "  Equal Opportunity Difference: 0.0554\n",
      "  Equalized Odds Difference: 0.0801\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0415\n",
      "  Error Rate Ratio: 0.9305\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1735\n",
      "  False Discovery Rate Ratio: 0.7150\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.0554\n",
      "  False Negative Rate Ratio: 0.8866\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.1911\n",
      "  False Omission Rate Ratio: 1.3305\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: 0.0801\n",
      "  False Positive Rate Ratio: 1.1160\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.0801\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.0554\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.0547\n",
      "  Statistical Parity Difference: 0.0332\n",
      "  Between Group Coefficient of Variation: 0.8839\n",
      "  Between Group Generalized Entropy Index: 0.3906\n",
      "  Between Group Theil Index: 0.5761\n",
      "  Mean Difference: 0.0332\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0678\n",
      "  Average Odds Difference: 0.0678\n",
      "  Average Predictive Value Difference: 0.1823\n",
      "  Between All Groups Coefficient of Variation: 0.1470\n",
      "  Between All Groups Generalized Entropy Index: 0.0108\n",
      "  Between All Groups Theil Index: 0.0110\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: -0.1613\n",
      "  Equal Opportunity Difference: 0.0554\n",
      "  Equalized Odds Difference: 0.0801\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0415\n",
      "  Error Rate Ratio: 0.9305\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1735\n",
      "  False Discovery Rate Ratio: 0.7150\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.0554\n",
      "  False Negative Rate Ratio: 0.8866\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.1911\n",
      "  False Omission Rate Ratio: 1.3305\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: 0.0801\n",
      "  False Positive Rate Ratio: 1.1160\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.0801\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.0554\n",
      "Epoch 1/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.4046 - loss: 1.8515 - val_accuracy: 0.6787 - val_loss: 1.0251 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 1.1021 - val_accuracy: 0.6846 - val_loss: 0.8846 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6646 - loss: 0.9386 - val_accuracy: 0.7129 - val_loss: 0.7829 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6936 - loss: 0.8420 - val_accuracy: 0.7397 - val_loss: 0.7168 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.7915 - val_accuracy: 0.7618 - val_loss: 0.6479 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7473 - val_accuracy: 0.7744 - val_loss: 0.6234 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.7173 - val_accuracy: 0.7753 - val_loss: 0.6310 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.7040 - val_accuracy: 0.7765 - val_loss: 0.5961 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.6863 - val_accuracy: 0.8004 - val_loss: 0.5623 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.6679 - val_accuracy: 0.7846 - val_loss: 0.6098 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7615 - loss: 0.6497 - val_accuracy: 0.8028 - val_loss: 0.5446 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7605 - loss: 0.6479 - val_accuracy: 0.7804 - val_loss: 0.5863 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.6315 - val_accuracy: 0.8104 - val_loss: 0.5394 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.6234 - val_accuracy: 0.8049 - val_loss: 0.5351 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.6189 - val_accuracy: 0.8147 - val_loss: 0.5106 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.6045 - val_accuracy: 0.8186 - val_loss: 0.5012 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.6018 - val_accuracy: 0.8011 - val_loss: 0.5348 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.5935 - val_accuracy: 0.8172 - val_loss: 0.5074 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.5932 - val_accuracy: 0.8206 - val_loss: 0.4980 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7813 - loss: 0.5858 - val_accuracy: 0.8348 - val_loss: 0.4850 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.5809 - val_accuracy: 0.8108 - val_loss: 0.5051 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.5754 - val_accuracy: 0.8277 - val_loss: 0.4869 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.5732 - val_accuracy: 0.8228 - val_loss: 0.4943 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.5701 - val_accuracy: 0.8236 - val_loss: 0.4862 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.5745 - val_accuracy: 0.8190 - val_loss: 0.4765 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.5591 - val_accuracy: 0.8243 - val_loss: 0.4837 - learning_rate: 4.9700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.5602 - val_accuracy: 0.8315 - val_loss: 0.4742 - learning_rate: 4.9700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: 0.5624 - val_accuracy: 0.8228 - val_loss: 0.4754 - learning_rate: 4.9700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.5550 - val_accuracy: 0.8281 - val_loss: 0.4758 - learning_rate: 4.9700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7967 - loss: 0.5425 - val_accuracy: 0.8319 - val_loss: 0.4696 - learning_rate: 4.9700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5470 - val_accuracy: 0.8290 - val_loss: 0.4668 - learning_rate: 4.9700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.5432 - val_accuracy: 0.8376 - val_loss: 0.4590 - learning_rate: 4.9700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.5422 - val_accuracy: 0.8326 - val_loss: 0.4657 - learning_rate: 4.9700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.5423 - val_accuracy: 0.8244 - val_loss: 0.4942 - learning_rate: 4.9700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.5385 - val_accuracy: 0.8299 - val_loss: 0.4647 - learning_rate: 4.9700e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.5427 - val_accuracy: 0.8405 - val_loss: 0.4337 - learning_rate: 4.9700e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8015 - loss: 0.5362 - val_accuracy: 0.8340 - val_loss: 0.4434 - learning_rate: 4.9700e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.5287 - val_accuracy: 0.8313 - val_loss: 0.4760 - learning_rate: 4.9700e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.5283 - val_accuracy: 0.8394 - val_loss: 0.4506 - learning_rate: 4.9700e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.5263 - val_accuracy: 0.8391 - val_loss: 0.4512 - learning_rate: 4.9700e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2547/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.5322\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.5322 - val_accuracy: 0.8323 - val_loss: 0.4490 - learning_rate: 4.9700e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.5055 - val_accuracy: 0.8454 - val_loss: 0.4164 - learning_rate: 2.4850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4938 - val_accuracy: 0.8524 - val_loss: 0.4162 - learning_rate: 2.4850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.4948 - val_accuracy: 0.8528 - val_loss: 0.4088 - learning_rate: 2.4850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4909 - val_accuracy: 0.8522 - val_loss: 0.4105 - learning_rate: 2.4850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4929 - val_accuracy: 0.8513 - val_loss: 0.4107 - learning_rate: 2.4850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4868 - val_accuracy: 0.8523 - val_loss: 0.4134 - learning_rate: 2.4850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.4852 - val_accuracy: 0.8544 - val_loss: 0.3952 - learning_rate: 2.4850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.4885 - val_accuracy: 0.8539 - val_loss: 0.4023 - learning_rate: 2.4850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.4906 - val_accuracy: 0.8599 - val_loss: 0.3947 - learning_rate: 2.4850e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4853 - val_accuracy: 0.8540 - val_loss: 0.4131 - learning_rate: 2.4850e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4848 - val_accuracy: 0.8544 - val_loss: 0.3971 - learning_rate: 2.4850e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4853 - val_accuracy: 0.8567 - val_loss: 0.4066 - learning_rate: 2.4850e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4841 - val_accuracy: 0.8532 - val_loss: 0.3947 - learning_rate: 2.4850e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4797\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4797 - val_accuracy: 0.8596 - val_loss: 0.4005 - learning_rate: 2.4850e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4702 - val_accuracy: 0.8585 - val_loss: 0.3968 - learning_rate: 1.2425e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4680 - val_accuracy: 0.8586 - val_loss: 0.3901 - learning_rate: 1.2425e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4637 - val_accuracy: 0.8578 - val_loss: 0.3881 - learning_rate: 1.2425e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4676 - val_accuracy: 0.8616 - val_loss: 0.3893 - learning_rate: 1.2425e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.4633 - val_accuracy: 0.8636 - val_loss: 0.3836 - learning_rate: 1.2425e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4641 - val_accuracy: 0.8586 - val_loss: 0.3954 - learning_rate: 1.2425e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4669 - val_accuracy: 0.8612 - val_loss: 0.3847 - learning_rate: 1.2425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4612 - val_accuracy: 0.8632 - val_loss: 0.3829 - learning_rate: 1.2425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4607 - val_accuracy: 0.8654 - val_loss: 0.3819 - learning_rate: 1.2425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.4613 - val_accuracy: 0.8629 - val_loss: 0.3791 - learning_rate: 1.2425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.4645 - val_accuracy: 0.8637 - val_loss: 0.3826 - learning_rate: 1.2425e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.4598 - val_accuracy: 0.8675 - val_loss: 0.3665 - learning_rate: 1.2425e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4542 - val_accuracy: 0.8651 - val_loss: 0.3746 - learning_rate: 1.2425e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.4629 - val_accuracy: 0.8664 - val_loss: 0.3757 - learning_rate: 1.2425e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4644 - val_accuracy: 0.8606 - val_loss: 0.3818 - learning_rate: 1.2425e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.4563 - val_accuracy: 0.8560 - val_loss: 0.3864 - learning_rate: 1.2425e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2535/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4618\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4617 - val_accuracy: 0.8596 - val_loss: 0.3856 - learning_rate: 1.2425e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.4510 - val_accuracy: 0.8650 - val_loss: 0.3648 - learning_rate: 6.2125e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4511 - val_accuracy: 0.8653 - val_loss: 0.3686 - learning_rate: 6.2125e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4466 - val_accuracy: 0.8686 - val_loss: 0.3676 - learning_rate: 6.2125e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4502 - val_accuracy: 0.8693 - val_loss: 0.3671 - learning_rate: 6.2125e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4530 - val_accuracy: 0.8693 - val_loss: 0.3638 - learning_rate: 6.2125e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4523 - val_accuracy: 0.8695 - val_loss: 0.3653 - learning_rate: 6.2125e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4477 - val_accuracy: 0.8645 - val_loss: 0.3760 - learning_rate: 6.2125e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4528 - val_accuracy: 0.8705 - val_loss: 0.3641 - learning_rate: 6.2125e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.4483 - val_accuracy: 0.8687 - val_loss: 0.3648 - learning_rate: 6.2125e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4402 - val_accuracy: 0.8694 - val_loss: 0.3633 - learning_rate: 6.2125e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4482 - val_accuracy: 0.8718 - val_loss: 0.3659 - learning_rate: 6.2125e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4495 - val_accuracy: 0.8666 - val_loss: 0.3698 - learning_rate: 6.2125e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4439 - val_accuracy: 0.8683 - val_loss: 0.3684 - learning_rate: 6.2125e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4464 - val_accuracy: 0.8670 - val_loss: 0.3713 - learning_rate: 6.2125e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2537/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4489\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4488 - val_accuracy: 0.8683 - val_loss: 0.3664 - learning_rate: 6.2125e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4420 - val_accuracy: 0.8681 - val_loss: 0.3629 - learning_rate: 3.1063e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8339 - loss: 0.4372 - val_accuracy: 0.8693 - val_loss: 0.3573 - learning_rate: 3.1063e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4399 - val_accuracy: 0.8692 - val_loss: 0.3643 - learning_rate: 3.1063e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4400 - val_accuracy: 0.8697 - val_loss: 0.3606 - learning_rate: 3.1063e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.4361 - val_accuracy: 0.8692 - val_loss: 0.3697 - learning_rate: 3.1063e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4447 - val_accuracy: 0.8722 - val_loss: 0.3596 - learning_rate: 3.1063e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2533/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4366\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.5531250028288923e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4366 - val_accuracy: 0.8699 - val_loss: 0.3653 - learning_rate: 3.1063e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.4377 - val_accuracy: 0.8695 - val_loss: 0.3656 - learning_rate: 1.5531e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.4405 - val_accuracy: 0.8691 - val_loss: 0.3687 - learning_rate: 1.5531e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.4346 - val_accuracy: 0.8725 - val_loss: 0.3585 - learning_rate: 1.5531e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4395 - val_accuracy: 0.8702 - val_loss: 0.3653 - learning_rate: 1.5531e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.4388\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 7.765625014144462e-06.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.4388 - val_accuracy: 0.8695 - val_loss: 0.3664 - learning_rate: 1.5531e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.4360 - val_accuracy: 0.8726 - val_loss: 0.3559 - learning_rate: 7.7656e-06\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.4309 - loss: 1.7739 - val_accuracy: 0.6871 - val_loss: 0.9660 - learning_rate: 4.9700e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6373 - loss: 1.0383 - val_accuracy: 0.7220 - val_loss: 0.7974 - learning_rate: 4.9700e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6825 - loss: 0.8864 - val_accuracy: 0.7288 - val_loss: 0.7402 - learning_rate: 4.9700e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8048 - val_accuracy: 0.7527 - val_loss: 0.6736 - learning_rate: 4.9700e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.7572 - val_accuracy: 0.7830 - val_loss: 0.6204 - learning_rate: 4.9700e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.7157 - val_accuracy: 0.7909 - val_loss: 0.6005 - learning_rate: 4.9700e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.6933 - val_accuracy: 0.7907 - val_loss: 0.5817 - learning_rate: 4.9700e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.6779 - val_accuracy: 0.7989 - val_loss: 0.5559 - learning_rate: 4.9700e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7543 - loss: 0.6609 - val_accuracy: 0.7990 - val_loss: 0.5566 - learning_rate: 4.9700e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7586 - loss: 0.6445 - val_accuracy: 0.8104 - val_loss: 0.5275 - learning_rate: 4.9700e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.6367 - val_accuracy: 0.7912 - val_loss: 0.5532 - learning_rate: 4.9700e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7702 - loss: 0.6196 - val_accuracy: 0.7843 - val_loss: 0.5848 - learning_rate: 4.9700e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7709 - loss: 0.6082 - val_accuracy: 0.8004 - val_loss: 0.5489 - learning_rate: 4.9700e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.6073 - val_accuracy: 0.8174 - val_loss: 0.5208 - learning_rate: 4.9700e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.6028 - val_accuracy: 0.8125 - val_loss: 0.5114 - learning_rate: 4.9700e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7804 - loss: 0.5923 - val_accuracy: 0.8177 - val_loss: 0.5076 - learning_rate: 4.9700e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.5858 - val_accuracy: 0.8214 - val_loss: 0.4953 - learning_rate: 4.9700e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.5781 - val_accuracy: 0.8115 - val_loss: 0.5038 - learning_rate: 4.9700e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.5765 - val_accuracy: 0.8183 - val_loss: 0.4875 - learning_rate: 4.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7871 - loss: 0.5722 - val_accuracy: 0.8161 - val_loss: 0.5096 - learning_rate: 4.9700e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7899 - loss: 0.5651 - val_accuracy: 0.8256 - val_loss: 0.4875 - learning_rate: 4.9700e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: 0.5655 - val_accuracy: 0.8171 - val_loss: 0.4832 - learning_rate: 4.9700e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.5587 - val_accuracy: 0.8303 - val_loss: 0.4609 - learning_rate: 4.9700e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: 0.5599 - val_accuracy: 0.8176 - val_loss: 0.4972 - learning_rate: 4.9700e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.5518 - val_accuracy: 0.8322 - val_loss: 0.4641 - learning_rate: 4.9700e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.5490 - val_accuracy: 0.8345 - val_loss: 0.4539 - learning_rate: 4.9700e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5433 - val_accuracy: 0.8364 - val_loss: 0.4570 - learning_rate: 4.9700e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.5457 - val_accuracy: 0.8325 - val_loss: 0.4511 - learning_rate: 4.9700e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.5410 - val_accuracy: 0.8187 - val_loss: 0.4850 - learning_rate: 4.9700e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.5399 - val_accuracy: 0.8288 - val_loss: 0.4547 - learning_rate: 4.9700e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.5398 - val_accuracy: 0.8366 - val_loss: 0.4324 - learning_rate: 4.9700e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.5351 - val_accuracy: 0.8289 - val_loss: 0.4642 - learning_rate: 4.9700e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.5393 - val_accuracy: 0.8378 - val_loss: 0.4439 - learning_rate: 4.9700e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.5309 - val_accuracy: 0.8369 - val_loss: 0.4498 - learning_rate: 4.9700e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.5265 - val_accuracy: 0.8454 - val_loss: 0.4348 - learning_rate: 4.9700e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2542/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.5268\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00024850000045262277.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.5268 - val_accuracy: 0.8422 - val_loss: 0.4432 - learning_rate: 4.9700e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.5048 - val_accuracy: 0.8482 - val_loss: 0.4142 - learning_rate: 2.4850e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4941 - val_accuracy: 0.8497 - val_loss: 0.4093 - learning_rate: 2.4850e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4913 - val_accuracy: 0.8487 - val_loss: 0.4116 - learning_rate: 2.4850e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4934 - val_accuracy: 0.8515 - val_loss: 0.4148 - learning_rate: 2.4850e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4849 - val_accuracy: 0.8528 - val_loss: 0.4059 - learning_rate: 2.4850e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4868 - val_accuracy: 0.8513 - val_loss: 0.3982 - learning_rate: 2.4850e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4876 - val_accuracy: 0.8529 - val_loss: 0.4036 - learning_rate: 2.4850e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4873 - val_accuracy: 0.8529 - val_loss: 0.4012 - learning_rate: 2.4850e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.4803 - val_accuracy: 0.8436 - val_loss: 0.4209 - learning_rate: 2.4850e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.4781 - val_accuracy: 0.8533 - val_loss: 0.3995 - learning_rate: 2.4850e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4788 - val_accuracy: 0.8515 - val_loss: 0.3951 - learning_rate: 2.4850e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4791 - val_accuracy: 0.8526 - val_loss: 0.4065 - learning_rate: 2.4850e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4807 - val_accuracy: 0.8491 - val_loss: 0.4123 - learning_rate: 2.4850e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4818 - val_accuracy: 0.8553 - val_loss: 0.4040 - learning_rate: 2.4850e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4774 - val_accuracy: 0.8569 - val_loss: 0.3919 - learning_rate: 2.4850e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4819 - val_accuracy: 0.8557 - val_loss: 0.3939 - learning_rate: 2.4850e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4776 - val_accuracy: 0.8528 - val_loss: 0.3955 - learning_rate: 2.4850e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4760 - val_accuracy: 0.8515 - val_loss: 0.3995 - learning_rate: 2.4850e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.4720 - val_accuracy: 0.8565 - val_loss: 0.4036 - learning_rate: 2.4850e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.4719 - val_accuracy: 0.8601 - val_loss: 0.3828 - learning_rate: 2.4850e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4709 - val_accuracy: 0.8594 - val_loss: 0.3872 - learning_rate: 2.4850e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4737 - val_accuracy: 0.8517 - val_loss: 0.4007 - learning_rate: 2.4850e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4804 - val_accuracy: 0.8573 - val_loss: 0.3925 - learning_rate: 2.4850e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.4725 - val_accuracy: 0.8597 - val_loss: 0.3867 - learning_rate: 2.4850e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4663\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012425000022631139.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4663 - val_accuracy: 0.8567 - val_loss: 0.4030 - learning_rate: 2.4850e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.4545 - val_accuracy: 0.8664 - val_loss: 0.3743 - learning_rate: 1.2425e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.4577 - val_accuracy: 0.8632 - val_loss: 0.3735 - learning_rate: 1.2425e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.4516 - val_accuracy: 0.8620 - val_loss: 0.3753 - learning_rate: 1.2425e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.4489 - val_accuracy: 0.8602 - val_loss: 0.3887 - learning_rate: 1.2425e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.4531 - val_accuracy: 0.8630 - val_loss: 0.3734 - learning_rate: 1.2425e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4528 - val_accuracy: 0.8618 - val_loss: 0.3710 - learning_rate: 1.2425e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4504 - val_accuracy: 0.8640 - val_loss: 0.3702 - learning_rate: 1.2425e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.4473 - val_accuracy: 0.8649 - val_loss: 0.3702 - learning_rate: 1.2425e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.4462 - val_accuracy: 0.8643 - val_loss: 0.3672 - learning_rate: 1.2425e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.4545 - val_accuracy: 0.8657 - val_loss: 0.3666 - learning_rate: 1.2425e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4457 - val_accuracy: 0.8602 - val_loss: 0.3780 - learning_rate: 1.2425e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4500 - val_accuracy: 0.8649 - val_loss: 0.3721 - learning_rate: 1.2425e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.4532 - val_accuracy: 0.8649 - val_loss: 0.3653 - learning_rate: 1.2425e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.4483 - val_accuracy: 0.8596 - val_loss: 0.3684 - learning_rate: 1.2425e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.4425 - val_accuracy: 0.8612 - val_loss: 0.3771 - learning_rate: 1.2425e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4418 - val_accuracy: 0.8631 - val_loss: 0.3681 - learning_rate: 1.2425e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4423 - val_accuracy: 0.8650 - val_loss: 0.3643 - learning_rate: 1.2425e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4453 - val_accuracy: 0.8676 - val_loss: 0.3665 - learning_rate: 1.2425e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.4458 - val_accuracy: 0.8665 - val_loss: 0.3688 - learning_rate: 1.2425e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.4446 - val_accuracy: 0.8652 - val_loss: 0.3706 - learning_rate: 1.2425e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4390 - val_accuracy: 0.8628 - val_loss: 0.3710 - learning_rate: 1.2425e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4390 - val_accuracy: 0.8671 - val_loss: 0.3626 - learning_rate: 1.2425e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4399 - val_accuracy: 0.8667 - val_loss: 0.3590 - learning_rate: 1.2425e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.4453 - val_accuracy: 0.8661 - val_loss: 0.3719 - learning_rate: 1.2425e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4372 - val_accuracy: 0.8619 - val_loss: 0.3701 - learning_rate: 1.2425e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4458 - val_accuracy: 0.8669 - val_loss: 0.3674 - learning_rate: 1.2425e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.4360 - val_accuracy: 0.8682 - val_loss: 0.3638 - learning_rate: 1.2425e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m2553/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4410\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.212500011315569e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4410 - val_accuracy: 0.8666 - val_loss: 0.3673 - learning_rate: 1.2425e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4305 - val_accuracy: 0.8691 - val_loss: 0.3606 - learning_rate: 6.2125e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.4332 - val_accuracy: 0.8684 - val_loss: 0.3506 - learning_rate: 6.2125e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4321 - val_accuracy: 0.8673 - val_loss: 0.3560 - learning_rate: 6.2125e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4324 - val_accuracy: 0.8660 - val_loss: 0.3599 - learning_rate: 6.2125e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4349 - val_accuracy: 0.8673 - val_loss: 0.3660 - learning_rate: 6.2125e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.4292 - val_accuracy: 0.8676 - val_loss: 0.3584 - learning_rate: 6.2125e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2557/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.4304\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.1062500056577846e-05.\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.4304 - val_accuracy: 0.8693 - val_loss: 0.3554 - learning_rate: 6.2125e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.4309 - val_accuracy: 0.8694 - val_loss: 0.3575 - learning_rate: 3.1063e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.4261 - val_accuracy: 0.8695 - val_loss: 0.3521 - learning_rate: 3.1063e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4283 - val_accuracy: 0.8660 - val_loss: 0.3603 - learning_rate: 3.1063e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m2562/2562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.4298 - val_accuracy: 0.8675 - val_loss: 0.3538 - learning_rate: 3.1063e-05\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "             ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "78577   0.869040  38.220811  46.244577  47.084943  29.287747  7.574129   \n",
      "74955   1.010320  36.709851  11.650560  35.043901  24.536954  5.768148   \n",
      "14820   0.490279  36.332341  31.110117  45.165482  34.173766  6.301919   \n",
      "55651   0.905180  36.903541  17.280418  31.311913  22.556688  6.507750   \n",
      "61380   1.053020  36.351480  15.167033  30.348253  23.226284  6.343500   \n",
      "...          ...        ...        ...        ...        ...       ...   \n",
      "101362  0.920110  35.956885  30.360600  41.567856  27.099330  6.109799   \n",
      "16169  -0.888680  35.658573  41.369736  43.411919  34.176032  5.891764   \n",
      "63736   0.757340  36.344829  22.391568  33.979162  30.998548  7.366675   \n",
      "77344   1.065648  34.059813  31.869983  47.639704  28.740841  6.795421   \n",
      "96475   1.253844  35.278110  40.684770  43.371535  33.838538  5.070703   \n",
      "\n",
      "         emg_trap  emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "78577    5.882901  6.179250  0.0     1.0           0.0  \n",
      "74955    6.001670  5.481250  0.0     0.0           1.0  \n",
      "14820    9.998500  5.563178  0.0     1.0           1.0  \n",
      "55651    9.957500  7.493949  0.0     0.0           0.0  \n",
      "61380    5.961497  5.852392  0.0     0.0           1.0  \n",
      "...           ...       ...  ...     ...           ...  \n",
      "101362  23.209481  4.942229  0.0     1.0           0.0  \n",
      "16169   14.054993  5.686500  0.0     1.0           1.0  \n",
      "63736    7.660929  5.566404  1.0     1.0           0.0  \n",
      "77344    6.240601  5.522250  0.0     1.0           0.0  \n",
      "96475   12.324769  7.393334  0.0     1.0           1.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "             ecg        bvp        gsr        rsp        skt  emg_coru  \\\n",
      "78577   0.869040  38.220811  46.244577  47.084943  29.287747  7.574129   \n",
      "74955   1.010320  36.709851  11.650560  35.043901  24.536954  5.768148   \n",
      "14820   0.490279  36.332341  31.110117  45.165482  34.173766  6.301919   \n",
      "55651   0.905180  36.903541  17.280418  31.311913  22.556688  6.507750   \n",
      "61380   1.053020  36.351480  15.167033  30.348253  23.226284  6.343500   \n",
      "...          ...        ...        ...        ...        ...       ...   \n",
      "101362  0.920110  35.956885  30.360600  41.567856  27.099330  6.109799   \n",
      "16169  -0.888680  35.658573  41.369736  43.411919  34.176032  5.891764   \n",
      "63736   0.757340  36.344829  22.391568  33.979162  30.998548  7.366675   \n",
      "77344   1.065648  34.059813  31.869983  47.639704  28.740841  6.795421   \n",
      "96475   1.253844  35.278110  40.684770  43.371535  33.838538  5.070703   \n",
      "\n",
      "         emg_trap  emg_zygo  AGE  GENDER  Emotion_Type  \n",
      "78577    5.882901  6.179250  0.0     1.0           0.0  \n",
      "74955    6.001670  5.481250  0.0     0.0           0.0  \n",
      "14820    9.998500  5.563178  0.0     1.0           0.0  \n",
      "55651    9.957500  7.493949  0.0     0.0           0.0  \n",
      "61380    5.961497  5.852392  0.0     0.0           1.0  \n",
      "...           ...       ...  ...     ...           ...  \n",
      "101362  23.209481  4.942229  0.0     1.0           0.0  \n",
      "16169   14.054993  5.686500  0.0     1.0           0.0  \n",
      "63736    7.660929  5.566404  1.0     1.0           0.0  \n",
      "77344    6.240601  5.522250  0.0     1.0           1.0  \n",
      "96475   12.324769  7.393334  0.0     1.0           0.0  \n",
      "\n",
      "[10248 rows x 11 columns]\n",
      "  Accuracy: 0.4840\n",
      "  Base Rate: 0.5116\n",
      "  Selection Rate: 0.5374\n",
      "  Disparate Impact: 0.9801\n",
      "  Statistical Parity Difference: -0.0123\n",
      "  Between Group Coefficient of Variation: 0.8744\n",
      "  Between Group Generalized Entropy Index: 0.3823\n",
      "  Between Group Theil Index: 0.5658\n",
      "  Mean Difference: -0.0123\n",
      "  Smoothed Empirical Differential Fairness: 0.6382\n",
      "  Consistency: 0.9512\n",
      "  Average Absolute Odds Difference: 0.0136\n",
      "  Average Odds Difference: 0.0136\n",
      "  Average Predictive Value Difference: 0.1775\n",
      "  Between All Groups Coefficient of Variation: 0.1547\n",
      "  Between All Groups Generalized Entropy Index: 0.0120\n",
      "  Between All Groups Theil Index: 0.0121\n",
      "  Coefficient of Variation: 0.6998\n",
      "  Differential Fairness Bias Amplification: -0.1699\n",
      "  Equal Opportunity Difference: 0.0031\n",
      "  Equalized Odds Difference: 0.0241\n",
      "  Error Rate: 0.5160\n",
      "  Error Rate Difference: -0.0350\n",
      "  Error Rate Ratio: 0.9386\n",
      "  False Discovery Rate: 0.5041\n",
      "  False Discovery Rate Difference: -0.1741\n",
      "  False Discovery Rate Ratio: 0.6996\n",
      "  False Negative Rate: 0.4791\n",
      "  False Negative Rate Difference: -0.0031\n",
      "  False Negative Rate Ratio: 0.9930\n",
      "  False Omission Rate: 0.5298\n",
      "  False Omission Rate Difference: 0.1808\n",
      "  False Omission Rate Ratio: 1.3256\n",
      "  False Positive Rate: 0.5546\n",
      "  False Positive Rate Difference: 0.0241\n",
      "  False Positive Rate Ratio: 1.0354\n",
      "  Generalized Entropy Index: 0.2449\n",
      "  Generalized Equalized Odds Difference: 0.0241\n",
      "  Generalized False Negative Rate: 0.4791\n",
      "  Generalized False Positive Rate: 0.5546\n",
      "  Generalized True Negative Rate: 0.4454\n",
      "  Generalized True Positive Rate: 0.5209\n",
      "  Negative Predictive Value: 0.4702\n",
      "  Number of False Negatives: 2512.0000\n",
      "  Number of False Positives: 2776.0000\n",
      "  Number of Generalized False Negatives: 2512.0000\n",
      "  Number of Generalized False Positives: 2776.0000\n",
      "  Number of Generalized True Negatives: 2229.0000\n",
      "  Number of Generalized True Positives: 2731.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5005.0000\n",
      "  Number of Positives: 5243.0000\n",
      "  Number of Predicted Negatives: 4741.0000\n",
      "  Number of Predicted Positives: 5507.0000\n",
      "  Number of True Negatives: 2229.0000\n",
      "  Number of True Positives: 2731.0000\n",
      "  Positive Predictive Value: 0.4959\n",
      "  Power: 2731.0000\n",
      "  Precision: 0.4959\n",
      "  Recall: 0.5209\n",
      "  Sensitivity: 0.5209\n",
      "  Specificity: 0.4454\n",
      "  Theil Index: 0.3407\n",
      "  True Negative Rate: 0.4454\n",
      "  True Positive Rate: 0.5209\n",
      "  True Positive Rate Difference: 0.0031\n",
      "  Accuracy: 0.4840\n",
      "  Base Rate: 0.5116\n",
      "  Selection Rate: 0.5374\n",
      "  Disparate Impact: 0.9801\n",
      "  Statistical Parity Difference: -0.0123\n",
      "  Between Group Coefficient of Variation: 0.8744\n",
      "  Between Group Generalized Entropy Index: 0.3823\n",
      "  Between Group Theil Index: 0.5658\n",
      "  Mean Difference: -0.0123\n",
      "  Smoothed Empirical Differential Fairness: 0.6382\n",
      "  Consistency: 0.9512\n",
      "  Average Absolute Odds Difference: 0.0136\n",
      "  Average Odds Difference: 0.0136\n",
      "  Average Predictive Value Difference: 0.1775\n",
      "  Between All Groups Coefficient of Variation: 0.1547\n",
      "  Between All Groups Generalized Entropy Index: 0.0120\n",
      "  Between All Groups Theil Index: 0.0121\n",
      "  Coefficient of Variation: 0.6998\n",
      "  Differential Fairness Bias Amplification: -0.1699\n",
      "  Equal Opportunity Difference: 0.0031\n",
      "  Equalized Odds Difference: 0.0241\n",
      "  Error Rate: 0.5160\n",
      "  Error Rate Difference: -0.0350\n",
      "  Error Rate Ratio: 0.9386\n",
      "  False Discovery Rate: 0.5041\n",
      "  False Discovery Rate Difference: -0.1741\n",
      "  False Discovery Rate Ratio: 0.6996\n",
      "  False Negative Rate: 0.4791\n",
      "  False Negative Rate Difference: -0.0031\n",
      "  False Negative Rate Ratio: 0.9930\n",
      "  False Omission Rate: 0.5298\n",
      "  False Omission Rate Difference: 0.1808\n",
      "  False Omission Rate Ratio: 1.3256\n",
      "  False Positive Rate: 0.5546\n",
      "  False Positive Rate Difference: 0.0241\n",
      "  False Positive Rate Ratio: 1.0354\n",
      "  Generalized Entropy Index: 0.2449\n",
      "  Generalized Equalized Odds Difference: 0.0241\n",
      "  Generalized False Negative Rate: 0.4791\n",
      "  Generalized False Positive Rate: 0.5546\n",
      "  Generalized True Negative Rate: 0.4454\n",
      "  Generalized True Positive Rate: 0.5209\n",
      "  Negative Predictive Value: 0.4702\n",
      "  Number of False Negatives: 2512.0000\n",
      "  Number of False Positives: 2776.0000\n",
      "  Number of Generalized False Negatives: 2512.0000\n",
      "  Number of Generalized False Positives: 2776.0000\n",
      "  Number of Generalized True Negatives: 2229.0000\n",
      "  Number of Generalized True Positives: 2731.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5005.0000\n",
      "  Number of Positives: 5243.0000\n",
      "  Number of Predicted Negatives: 4741.0000\n",
      "  Number of Predicted Positives: 5507.0000\n",
      "  Number of True Negatives: 2229.0000\n",
      "  Number of True Positives: 2731.0000\n",
      "  Positive Predictive Value: 0.4959\n",
      "  Power: 2731.0000\n",
      "  Precision: 0.4959\n",
      "  Recall: 0.5209\n",
      "  Sensitivity: 0.5209\n",
      "  Specificity: 0.4454\n",
      "  Theil Index: 0.3407\n",
      "  True Negative Rate: 0.4454\n",
      "  True Positive Rate: 0.5209\n",
      "  True Positive Rate Difference: 0.0031\n",
      "  Accuracy: 0.4921\n",
      "  Base Rate: 0.5101\n",
      "  Selection Rate: 0.5391\n",
      "  Disparate Impact: 0.9757\n",
      "  Statistical Parity Difference: -0.0150\n",
      "  Between Group Coefficient of Variation: 0.8841\n",
      "  Between Group Generalized Entropy Index: 0.3908\n",
      "  Between Group Theil Index: 0.5746\n",
      "  Mean Difference: -0.0150\n",
      "  Smoothed Empirical Differential Fairness: 0.7167\n",
      "  Consistency: 0.9522\n",
      "  Average Absolute Odds Difference: 0.0720\n",
      "  Average Odds Difference: 0.0321\n",
      "  Average Predictive Value Difference: 0.2214\n",
      "  Between All Groups Coefficient of Variation: 0.1492\n",
      "  Between All Groups Generalized Entropy Index: 0.0111\n",
      "  Between All Groups Theil Index: 0.0112\n",
      "  Coefficient of Variation: 0.6920\n",
      "  Differential Fairness Bias Amplification: -0.2731\n",
      "  Equal Opportunity Difference: -0.0399\n",
      "  Equalized Odds Difference: 0.1041\n",
      "  Error Rate: 0.5079\n",
      "  Error Rate Difference: 0.0120\n",
      "  Error Rate Ratio: 1.0215\n",
      "  False Discovery Rate: 0.4979\n",
      "  False Discovery Rate Difference: -0.1628\n",
      "  False Discovery Rate Ratio: 0.7171\n",
      "  False Negative Rate: 0.4694\n",
      "  False Negative Rate Difference: 0.0399\n",
      "  False Negative Rate Ratio: 1.0914\n",
      "  False Omission Rate: 0.5196\n",
      "  False Omission Rate Difference: 0.2799\n",
      "  False Omission Rate Ratio: 1.5251\n",
      "  False Positive Rate: 0.5480\n",
      "  False Positive Rate Difference: 0.1041\n",
      "  False Positive Rate Ratio: 1.1562\n",
      "  Generalized Entropy Index: 0.2395\n",
      "  Generalized Equalized Odds Difference: 0.1041\n",
      "  Generalized False Negative Rate: 0.4694\n",
      "  Generalized False Positive Rate: 0.5480\n",
      "  Generalized True Negative Rate: 0.4520\n",
      "  Generalized True Positive Rate: 0.5306\n",
      "  Negative Predictive Value: 0.4804\n",
      "  Number of False Negatives: 2454.0000\n",
      "  Number of False Positives: 2751.0000\n",
      "  Number of Generalized False Negatives: 2454.0000\n",
      "  Number of Generalized False Positives: 2751.0000\n",
      "  Number of Generalized True Negatives: 2269.0000\n",
      "  Number of Generalized True Positives: 2774.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5020.0000\n",
      "  Number of Positives: 5228.0000\n",
      "  Number of Predicted Negatives: 4723.0000\n",
      "  Number of Predicted Positives: 5525.0000\n",
      "  Number of True Negatives: 2269.0000\n",
      "  Number of True Positives: 2774.0000\n",
      "  Positive Predictive Value: 0.5021\n",
      "  Power: 2774.0000\n",
      "  Precision: 0.5021\n",
      "  Recall: 0.5306\n",
      "  Sensitivity: 0.5306\n",
      "  Specificity: 0.4520\n",
      "  Theil Index: 0.3331\n",
      "  True Negative Rate: 0.4520\n",
      "  True Positive Rate: 0.5306\n",
      "  True Positive Rate Difference: -0.0399\n",
      "  Accuracy: 0.4921\n",
      "  Base Rate: 0.5101\n",
      "  Selection Rate: 0.5391\n",
      "  Disparate Impact: 0.9757\n",
      "  Statistical Parity Difference: -0.0150\n",
      "  Between Group Coefficient of Variation: 0.8841\n",
      "  Between Group Generalized Entropy Index: 0.3908\n",
      "  Between Group Theil Index: 0.5746\n",
      "  Mean Difference: -0.0150\n",
      "  Smoothed Empirical Differential Fairness: 0.7167\n",
      "  Consistency: 0.9522\n",
      "  Average Absolute Odds Difference: 0.0720\n",
      "  Average Odds Difference: 0.0321\n",
      "  Average Predictive Value Difference: 0.2214\n",
      "  Between All Groups Coefficient of Variation: 0.1492\n",
      "  Between All Groups Generalized Entropy Index: 0.0111\n",
      "  Between All Groups Theil Index: 0.0112\n",
      "  Coefficient of Variation: 0.6920\n",
      "  Differential Fairness Bias Amplification: -0.2731\n",
      "  Equal Opportunity Difference: -0.0399\n",
      "  Equalized Odds Difference: 0.1041\n",
      "  Error Rate: 0.5079\n",
      "  Error Rate Difference: 0.0120\n",
      "  Error Rate Ratio: 1.0215\n",
      "  False Discovery Rate: 0.4979\n",
      "  False Discovery Rate Difference: -0.1628\n",
      "  False Discovery Rate Ratio: 0.7171\n",
      "  False Negative Rate: 0.4694\n",
      "  False Negative Rate Difference: 0.0399\n",
      "  False Negative Rate Ratio: 1.0914\n",
      "  False Omission Rate: 0.5196\n",
      "  False Omission Rate Difference: 0.2799\n",
      "  False Omission Rate Ratio: 1.5251\n",
      "  False Positive Rate: 0.5480\n",
      "  False Positive Rate Difference: 0.1041\n",
      "  False Positive Rate Ratio: 1.1562\n",
      "  Generalized Entropy Index: 0.2395\n",
      "  Generalized Equalized Odds Difference: 0.1041\n",
      "  Generalized False Negative Rate: 0.4694\n",
      "  Generalized False Positive Rate: 0.5480\n",
      "  Generalized True Negative Rate: 0.4520\n",
      "  Generalized True Positive Rate: 0.5306\n",
      "  Negative Predictive Value: 0.4804\n",
      "  Number of False Negatives: 2454.0000\n",
      "  Number of False Positives: 2751.0000\n",
      "  Number of Generalized False Negatives: 2454.0000\n",
      "  Number of Generalized False Positives: 2751.0000\n",
      "  Number of Generalized True Negatives: 2269.0000\n",
      "  Number of Generalized True Positives: 2774.0000\n",
      "  Number of Instances: 10248.0000\n",
      "  Number of Negatives: 5020.0000\n",
      "  Number of Positives: 5228.0000\n",
      "  Number of Predicted Negatives: 4723.0000\n",
      "  Number of Predicted Positives: 5525.0000\n",
      "  Number of True Negatives: 2269.0000\n",
      "  Number of True Positives: 2774.0000\n",
      "  Positive Predictive Value: 0.5021\n",
      "  Power: 2774.0000\n",
      "  Precision: 0.5021\n",
      "  Recall: 0.5306\n",
      "  Sensitivity: 0.5306\n",
      "  Specificity: 0.4520\n",
      "  Theil Index: 0.3331\n",
      "  True Negative Rate: 0.4520\n",
      "  True Positive Rate: 0.5306\n",
      "  True Positive Rate Difference: -0.0399\n"
     ]
    }
   ],
   "source": [
    "for config in protected_attribute_configs:\n",
    "    protected_attribute_names = config[\"protected_attribute_names\"]\n",
    "    privileged_protected_attributes = config[\"privileged_protected_attributes\"]\n",
    "    unprivileged_protected_attributes = config[\"unprivileged_protected_attributes\"]\n",
    "    sensitive_attribute = config[\"sensitive_attribute\"]\n",
    "    desc = config[\"desc\"]\n",
    "\n",
    "    print(\"Protected Attribute Names:\", protected_attribute_names)\n",
    "    print(\"Privileged Protected Attributes:\", privileged_protected_attributes)\n",
    "    print(\"Unprivileged Protected Attributes:\", unprivileged_protected_attributes)\n",
    "    print(\"Sensitive Attribute:\", sensitive_attribute)\n",
    "    print(\"Description:\", desc)\n",
    "\n",
    "    # Creating BinaryLabelDataset\n",
    "    print(\"Creating BinaryLabelDataset...\")\n",
    "    binary_dataset = BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=['Emotion_Type'],\n",
    "        protected_attribute_names=protected_attribute_names\n",
    "    )\n",
    "    print(\"BinaryLabelDataset created.\\n\")\n",
    "\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_bld = BinaryLabelDataset(df=pred_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "\n",
    "    compute_fairness_metrics_CM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"CNN model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"CNN model-CM-{desc}\")\n",
    "    \n",
    "    reweighing = Reweighing(\n",
    "        privileged_groups=privileged_protected_attributes,\n",
    "        unprivileged_groups=unprivileged_protected_attributes\n",
    "    )\n",
    "    reweighed_dataset = reweighing.fit_transform(binary_dataset)\n",
    "\n",
    "    dir_remover = DisparateImpactRemover(repair_level=0.1, sensitive_attribute=sensitive_attribute)\n",
    "    dir_processed = dir_remover.fit_transform(binary_dataset)\n",
    "    \n",
    "    train_dir, temp_dir = dir_processed.split([0.8], shuffle=True)\n",
    "    val_dir, test_dir = temp_dir.split([0.5], shuffle=True)\n",
    "    \n",
    "    train_reweighed, temp_reweighed = reweighed_dataset.split([0.8], shuffle=True)\n",
    "    val_reweighed, test_reweighed = temp_reweighed.split([0.5], shuffle=True)\n",
    "\n",
    "    train_dir_df = train_dir.convert_to_dataframe()[0]\n",
    "    val_dir_df = val_dir.convert_to_dataframe()[0]\n",
    "    test_dir_df = test_dir.convert_to_dataframe()[0]\n",
    "    \n",
    "    train_reweighed_df = train_reweighed.convert_to_dataframe()[0]\n",
    "    val_reweighed_df = val_reweighed.convert_to_dataframe()[0]\n",
    "    test_reweighed_df = test_reweighed.convert_to_dataframe()[0]\n",
    "\n",
    "    dir_weights = train_dir.instance_weights\n",
    "    rw_weights = train_reweighed.instance_weights\n",
    "    \n",
    "    def prepare_data_for_cnn(dataset, weights):\n",
    "        features = dataset.drop(columns=['Emotion', 'Emotion_Type'])\n",
    "        labels = dataset['Emotion']\n",
    "        features_reshaped = np.expand_dims(features.values, axis=2)\n",
    "        return features_reshaped, labels, weights\n",
    "    \n",
    "    X_train_dir, y_train_dir, train_weights_dir = prepare_data_for_cnn(train_dir_df, dir_weights)\n",
    "    X_val_dir, y_val_dir, _ = prepare_data_for_cnn(val_dir_df, dir_weights)\n",
    "    X_test_dir, y_test_dir, _ = prepare_data_for_cnn(test_dir_df, dir_weights)\n",
    "    \n",
    "    X_train_reweighed, y_train_reweighed, train_weights_rw = prepare_data_for_cnn(train_reweighed_df, rw_weights)\n",
    "    X_val_reweighed, y_val_reweighed, _ = prepare_data_for_cnn(val_reweighed_df, rw_weights)\n",
    "    X_test_reweighed, y_test_reweighed, _ = prepare_data_for_cnn(test_reweighed_df, rw_weights)\n",
    "\n",
    "    cnn_dir = build_cnn_model(X_train_dir.shape[1:], num_classes)\n",
    "    cnn_dir.fit(\n",
    "        X_train_dir, y_train_dir, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_dir, y_val_dir), \n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_dir = np.argmax(cnn_dir.predict(X_test_dir), axis=1)\n",
    "    \n",
    "    cnn_reweighed = build_cnn_model(X_train_reweighed.shape[1:], num_classes)\n",
    "    cnn_reweighed.fit(\n",
    "        X_train_reweighed, y_train_reweighed, \n",
    "        epochs=100, batch_size=32, \n",
    "        validation_data=(X_val_reweighed, y_val_reweighed), \n",
    "        callbacks=[reduce_lr], \n",
    "        verbose=1\n",
    "    )\n",
    "    y_pred_reweighed = np.argmax(cnn_reweighed.predict(X_test_reweighed), axis=1)\n",
    "\n",
    "    pred_reweighed_df = test_reweighed_df.copy()\n",
    "    pred_reweighed_df['Emotion'] = y_pred_reweighed\n",
    "    \n",
    "    pred_dir_df = test_dir_df.copy()\n",
    "    pred_dir_df['Emotion'] = y_pred_dir\n",
    "    \n",
    "    pred_reweighed_df['Emotion_Type'] = pred_reweighed_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    pred_dir_df['Emotion_Type'] = pred_dir_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    \n",
    "    pred_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    pred_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    print(pred_dir_df)\n",
    "    \n",
    "    pred_reweighed_bld = BinaryLabelDataset(df=pred_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_dir_bld = BinaryLabelDataset(df=pred_dir_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    \n",
    "    test_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    print(test_dir_df)\n",
    "    test_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    test_dir = BinaryLabelDataset(df=test_dir_df, label_names=['Emotion_Type'], protected_attribute_names=test_dir.protected_attribute_names)\n",
    "    test_reweighed = BinaryLabelDataset(df=test_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=test_reweighed.protected_attribute_names)\n",
    "    \n",
    "    compute_fairness_metrics_CM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"CNN DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"CNN DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_CM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"CNN Reweighed model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"CNN Reweighed model-CM-{desc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5dbdf",
   "metadata": {
    "papermill": {
     "duration": 26.543063,
     "end_time": "2025-02-25T12:25:15.864649",
     "exception": false,
     "start_time": "2025-02-25T12:24:49.321586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9feb3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T12:26:07.909576Z",
     "iopub.status.busy": "2025-02-25T12:26:07.909256Z",
     "iopub.status.idle": "2025-02-25T12:26:23.583294Z",
     "shell.execute_reply": "2025-02-25T12:26:23.582417Z"
    },
    "papermill": {
     "duration": 41.845122,
     "end_time": "2025-02-25T12:26:23.585114",
     "exception": false,
     "start_time": "2025-02-25T12:25:41.739992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9812\n",
      "Test Accuracy: 0.9826\n",
      "Test Precision: 0.9826\n",
      "Test Recall: 0.9826\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2449\n",
      "           1       0.98      0.96      0.97       727\n",
      "           2       0.99      0.99      0.99      1676\n",
      "           3       0.98      0.98      0.98      2763\n",
      "           4       0.98      0.98      0.98      2582\n",
      "           5       0.99      0.96      0.97       445\n",
      "           6       0.98      0.98      0.98       644\n",
      "           7       0.99      0.97      0.98       990\n",
      "           8       0.94      0.94      0.94       420\n",
      "           9       0.97      0.99      0.98       443\n",
      "          10       0.98      1.00      0.99       430\n",
      "          11       0.99      1.00      1.00       444\n",
      "          12       0.99      0.99      0.99       473\n",
      "          13       0.98      0.99      0.99       442\n",
      "          14       1.00      1.00      1.00       444\n",
      "\n",
      "    accuracy                           0.98     15372\n",
      "   macro avg       0.98      0.98      0.98     15372\n",
      "weighted avg       0.98      0.98      0.98     15372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X = df.drop(columns=['Emotion'])\n",
    "y = df['Emotion']\n",
    "\n",
    "# Split data into 85% train and 15% test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "\n",
    "# Stratified K-Fold (n=5) - 4 parts train, 1 part validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_indices, val_indices = next(skf.split(X_train_full, y_train_full))\n",
    "\n",
    "X_train, X_val = X_train_full.iloc[train_indices], X_train_full.iloc[val_indices]\n",
    "y_train, y_val = y_train_full.iloc[train_indices], y_train_full.iloc[val_indices]\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Print validation accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Predictions on test data\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "y_test_proba = rf_model.predict_proba(X_test)  # Probabilities for ROC Curve\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# --- ROC CURVE FOR MULTI-CLASS TEST DATA ---\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  # Binarize labels\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve for Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da4f40",
   "metadata": {
    "papermill": {
     "duration": 27.154673,
     "end_time": "2025-02-25T12:27:17.587376",
     "exception": false,
     "start_time": "2025-02-25T12:26:50.432703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RF - Preprocessing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1609f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T12:28:12.306020Z",
     "iopub.status.busy": "2025-02-25T12:28:12.305631Z",
     "iopub.status.idle": "2025-02-25T12:32:03.475155Z",
     "shell.execute_reply": "2025-02-25T12:32:03.474022Z"
    },
    "papermill": {
     "duration": 258.990519,
     "end_time": "2025-02-25T12:32:03.476715",
     "exception": false,
     "start_time": "2025-02-25T12:27:44.486196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected Attribute Names: ['GENDER']\n",
      "Privileged Protected Attributes: [{'GENDER': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1}]\n",
      "Sensitive Attribute: GENDER\n",
      "Description: GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 0.7598\n",
      "  Statistical Parity Difference: -0.1445\n",
      "  Between Group Coefficient of Variation: 0.1373\n",
      "  Between Group Generalized Entropy Index: 0.0094\n",
      "  Between Group Theil Index: 0.0095\n",
      "  Mean Difference: -0.1445\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1437\n",
      "  Average Odds Difference: -0.1437\n",
      "  Average Predictive Value Difference: 0.1334\n",
      "  Between All Groups Coefficient of Variation: 0.1373\n",
      "  Between All Groups Generalized Entropy Index: 0.0094\n",
      "  Between All Groups Theil Index: 0.0095\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.0226\n",
      "  Equal Opportunity Difference: -0.0918\n",
      "  Equalized Odds Difference: 0.1956\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0554\n",
      "  Error Rate Ratio: 0.8982\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1859\n",
      "  False Discovery Rate Ratio: 0.6818\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: 0.0918\n",
      "  False Negative Rate Ratio: 1.2107\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.0809\n",
      "  False Omission Rate Ratio: 1.1671\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.1956\n",
      "  False Positive Rate Ratio: 0.6900\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.1956\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: -0.0918\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 0.7598\n",
      "  Statistical Parity Difference: -0.1445\n",
      "  Between Group Coefficient of Variation: 0.1373\n",
      "  Between Group Generalized Entropy Index: 0.0094\n",
      "  Between Group Theil Index: 0.0095\n",
      "  Mean Difference: -0.1445\n",
      "  Smoothed Empirical Differential Fairness: 0.2866\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1437\n",
      "  Average Odds Difference: -0.1437\n",
      "  Average Predictive Value Difference: 0.1334\n",
      "  Between All Groups Coefficient of Variation: 0.1373\n",
      "  Between All Groups Generalized Entropy Index: 0.0094\n",
      "  Between All Groups Theil Index: 0.0095\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.0226\n",
      "  Equal Opportunity Difference: -0.0918\n",
      "  Equalized Odds Difference: 0.1956\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0554\n",
      "  Error Rate Ratio: 0.8982\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1859\n",
      "  False Discovery Rate Ratio: 0.6818\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: 0.0918\n",
      "  False Negative Rate Ratio: 1.2107\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.0809\n",
      "  False Omission Rate Ratio: 1.1671\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.1956\n",
      "  False Positive Rate Ratio: 0.6900\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.1956\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: -0.0918\n",
      "  Accuracy: 0.5048\n",
      "  Base Rate: 0.5049\n",
      "  Selection Rate: 0.5126\n",
      "  Disparate Impact: 0.8195\n",
      "  Statistical Parity Difference: -0.1009\n",
      "  Between Group Coefficient of Variation: 0.1214\n",
      "  Between Group Generalized Entropy Index: 0.0074\n",
      "  Between Group Theil Index: 0.0074\n",
      "  Mean Difference: -0.1009\n",
      "  Smoothed Empirical Differential Fairness: 0.2976\n",
      "  Consistency: 0.9572\n",
      "  Average Absolute Odds Difference: 0.1051\n",
      "  Average Odds Difference: -0.1051\n",
      "  Average Predictive Value Difference: 0.1468\n",
      "  Between All Groups Coefficient of Variation: 0.1214\n",
      "  Between All Groups Generalized Entropy Index: 0.0074\n",
      "  Between All Groups Theil Index: 0.0074\n",
      "  Coefficient of Variation: 0.6983\n",
      "  Differential Fairness Bias Amplification: -0.0916\n",
      "  Equal Opportunity Difference: -0.0858\n",
      "  Equalized Odds Difference: 0.1243\n",
      "  Error Rate: 0.4952\n",
      "  Error Rate Difference: -0.0190\n",
      "  Error Rate Ratio: 0.9623\n",
      "  False Discovery Rate: 0.4905\n",
      "  False Discovery Rate Difference: -0.1656\n",
      "  False Discovery Rate Ratio: 0.7035\n",
      "  False Negative Rate: 0.4828\n",
      "  False Negative Rate Difference: 0.0858\n",
      "  False Negative Rate Ratio: 1.1963\n",
      "  False Omission Rate: 0.5001\n",
      "  False Omission Rate Difference: 0.1280\n",
      "  False Omission Rate Ratio: 1.2946\n",
      "  False Positive Rate: 0.5078\n",
      "  False Positive Rate Difference: -0.1243\n",
      "  False Positive Rate Ratio: 0.7764\n",
      "  Generalized Entropy Index: 0.2438\n",
      "  Generalized Equalized Odds Difference: 0.1243\n",
      "  Generalized False Negative Rate: 0.4828\n",
      "  Generalized False Positive Rate: 0.5078\n",
      "  Generalized True Negative Rate: 0.4922\n",
      "  Generalized True Positive Rate: 0.5172\n",
      "  Negative Predictive Value: 0.4999\n",
      "  Number of False Negatives: 3747.0000\n",
      "  Number of False Positives: 3865.0000\n",
      "  Number of Generalized False Negatives: 3747.0000\n",
      "  Number of Generalized False Positives: 3865.0000\n",
      "  Number of Generalized True Negatives: 3746.0000\n",
      "  Number of Generalized True Positives: 4014.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7611.0000\n",
      "  Number of Positives: 7761.0000\n",
      "  Number of Predicted Negatives: 7493.0000\n",
      "  Number of Predicted Positives: 7879.0000\n",
      "  Number of True Negatives: 3746.0000\n",
      "  Number of True Positives: 4014.0000\n",
      "  Positive Predictive Value: 0.5095\n",
      "  Power: 4014.0000\n",
      "  Precision: 0.5095\n",
      "  Recall: 0.5172\n",
      "  Sensitivity: 0.5172\n",
      "  Specificity: 0.4922\n",
      "  Theil Index: 0.3383\n",
      "  True Negative Rate: 0.4922\n",
      "  True Positive Rate: 0.5172\n",
      "  True Positive Rate Difference: -0.0858\n",
      "  Accuracy: 0.5048\n",
      "  Base Rate: 0.5049\n",
      "  Selection Rate: 0.5126\n",
      "  Disparate Impact: 0.8195\n",
      "  Statistical Parity Difference: -0.1009\n",
      "  Between Group Coefficient of Variation: 0.1214\n",
      "  Between Group Generalized Entropy Index: 0.0074\n",
      "  Between Group Theil Index: 0.0074\n",
      "  Mean Difference: -0.1009\n",
      "  Smoothed Empirical Differential Fairness: 0.2976\n",
      "  Consistency: 0.9572\n",
      "  Average Absolute Odds Difference: 0.1051\n",
      "  Average Odds Difference: -0.1051\n",
      "  Average Predictive Value Difference: 0.1468\n",
      "  Between All Groups Coefficient of Variation: 0.1214\n",
      "  Between All Groups Generalized Entropy Index: 0.0074\n",
      "  Between All Groups Theil Index: 0.0074\n",
      "  Coefficient of Variation: 0.6983\n",
      "  Differential Fairness Bias Amplification: -0.0916\n",
      "  Equal Opportunity Difference: -0.0858\n",
      "  Equalized Odds Difference: 0.1243\n",
      "  Error Rate: 0.4952\n",
      "  Error Rate Difference: -0.0190\n",
      "  Error Rate Ratio: 0.9623\n",
      "  False Discovery Rate: 0.4905\n",
      "  False Discovery Rate Difference: -0.1656\n",
      "  False Discovery Rate Ratio: 0.7035\n",
      "  False Negative Rate: 0.4828\n",
      "  False Negative Rate Difference: 0.0858\n",
      "  False Negative Rate Ratio: 1.1963\n",
      "  False Omission Rate: 0.5001\n",
      "  False Omission Rate Difference: 0.1280\n",
      "  False Omission Rate Ratio: 1.2946\n",
      "  False Positive Rate: 0.5078\n",
      "  False Positive Rate Difference: -0.1243\n",
      "  False Positive Rate Ratio: 0.7764\n",
      "  Generalized Entropy Index: 0.2438\n",
      "  Generalized Equalized Odds Difference: 0.1243\n",
      "  Generalized False Negative Rate: 0.4828\n",
      "  Generalized False Positive Rate: 0.5078\n",
      "  Generalized True Negative Rate: 0.4922\n",
      "  Generalized True Positive Rate: 0.5172\n",
      "  Negative Predictive Value: 0.4999\n",
      "  Number of False Negatives: 3747.0000\n",
      "  Number of False Positives: 3865.0000\n",
      "  Number of Generalized False Negatives: 3747.0000\n",
      "  Number of Generalized False Positives: 3865.0000\n",
      "  Number of Generalized True Negatives: 3746.0000\n",
      "  Number of Generalized True Positives: 4014.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7611.0000\n",
      "  Number of Positives: 7761.0000\n",
      "  Number of Predicted Negatives: 7493.0000\n",
      "  Number of Predicted Positives: 7879.0000\n",
      "  Number of True Negatives: 3746.0000\n",
      "  Number of True Positives: 4014.0000\n",
      "  Positive Predictive Value: 0.5095\n",
      "  Power: 4014.0000\n",
      "  Precision: 0.5095\n",
      "  Recall: 0.5172\n",
      "  Sensitivity: 0.5172\n",
      "  Specificity: 0.4922\n",
      "  Theil Index: 0.3383\n",
      "  True Negative Rate: 0.4922\n",
      "  True Positive Rate: 0.5172\n",
      "  True Positive Rate Difference: -0.0858\n",
      "  Accuracy: 0.5121\n",
      "  Base Rate: 0.5067\n",
      "  Selection Rate: 0.5189\n",
      "  Disparate Impact: 0.8037\n",
      "  Statistical Parity Difference: -0.1121\n",
      "  Between Group Coefficient of Variation: 0.1245\n",
      "  Between Group Generalized Entropy Index: 0.0078\n",
      "  Between Group Theil Index: 0.0078\n",
      "  Mean Difference: -0.1121\n",
      "  Smoothed Empirical Differential Fairness: 0.2900\n",
      "  Consistency: 0.9559\n",
      "  Average Absolute Odds Difference: 0.1188\n",
      "  Average Odds Difference: -0.1188\n",
      "  Average Predictive Value Difference: 0.1444\n",
      "  Between All Groups Coefficient of Variation: 0.1245\n",
      "  Between All Groups Generalized Entropy Index: 0.0078\n",
      "  Between All Groups Theil Index: 0.0078\n",
      "  Coefficient of Variation: 0.6900\n",
      "  Differential Fairness Bias Amplification: -0.0578\n",
      "  Equal Opportunity Difference: -0.0891\n",
      "  Equalized Odds Difference: 0.1485\n",
      "  Error Rate: 0.4879\n",
      "  Error Rate Difference: -0.0304\n",
      "  Error Rate Ratio: 0.9395\n",
      "  False Discovery Rate: 0.4819\n",
      "  False Discovery Rate Difference: -0.1733\n",
      "  False Discovery Rate Ratio: 0.6866\n",
      "  False Negative Rate: 0.4694\n",
      "  False Negative Rate Difference: 0.0891\n",
      "  False Negative Rate Ratio: 1.2112\n",
      "  False Omission Rate: 0.4944\n",
      "  False Omission Rate Difference: 0.1155\n",
      "  False Omission Rate Ratio: 1.2662\n",
      "  False Positive Rate: 0.5069\n",
      "  False Positive Rate Difference: -0.1485\n",
      "  False Positive Rate Ratio: 0.7374\n",
      "  Generalized Entropy Index: 0.2380\n",
      "  Generalized Equalized Odds Difference: 0.1485\n",
      "  Generalized False Negative Rate: 0.4694\n",
      "  Generalized False Positive Rate: 0.5069\n",
      "  Generalized True Negative Rate: 0.4931\n",
      "  Generalized True Positive Rate: 0.5306\n",
      "  Negative Predictive Value: 0.5056\n",
      "  Number of False Negatives: 3656.0000\n",
      "  Number of False Positives: 3844.0000\n",
      "  Number of Generalized False Negatives: 3656.0000\n",
      "  Number of Generalized False Positives: 3844.0000\n",
      "  Number of Generalized True Negatives: 3739.0000\n",
      "  Number of Generalized True Positives: 4133.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7583.0000\n",
      "  Number of Positives: 7789.0000\n",
      "  Number of Predicted Negatives: 7395.0000\n",
      "  Number of Predicted Positives: 7977.0000\n",
      "  Number of True Negatives: 3739.0000\n",
      "  Number of True Positives: 4133.0000\n",
      "  Positive Predictive Value: 0.5181\n",
      "  Power: 4133.0000\n",
      "  Precision: 0.5181\n",
      "  Recall: 0.5306\n",
      "  Sensitivity: 0.5306\n",
      "  Specificity: 0.4931\n",
      "  Theil Index: 0.3303\n",
      "  True Negative Rate: 0.4931\n",
      "  True Positive Rate: 0.5306\n",
      "  True Positive Rate Difference: -0.0891\n",
      "  Accuracy: 0.5121\n",
      "  Base Rate: 0.5067\n",
      "  Selection Rate: 0.5189\n",
      "  Disparate Impact: 0.8037\n",
      "  Statistical Parity Difference: -0.1121\n",
      "  Between Group Coefficient of Variation: 0.1245\n",
      "  Between Group Generalized Entropy Index: 0.0078\n",
      "  Between Group Theil Index: 0.0078\n",
      "  Mean Difference: -0.1121\n",
      "  Smoothed Empirical Differential Fairness: 0.2900\n",
      "  Consistency: 0.9559\n",
      "  Average Absolute Odds Difference: 0.1188\n",
      "  Average Odds Difference: -0.1188\n",
      "  Average Predictive Value Difference: 0.1444\n",
      "  Between All Groups Coefficient of Variation: 0.1245\n",
      "  Between All Groups Generalized Entropy Index: 0.0078\n",
      "  Between All Groups Theil Index: 0.0078\n",
      "  Coefficient of Variation: 0.6900\n",
      "  Differential Fairness Bias Amplification: -0.0578\n",
      "  Equal Opportunity Difference: -0.0891\n",
      "  Equalized Odds Difference: 0.1485\n",
      "  Error Rate: 0.4879\n",
      "  Error Rate Difference: -0.0304\n",
      "  Error Rate Ratio: 0.9395\n",
      "  False Discovery Rate: 0.4819\n",
      "  False Discovery Rate Difference: -0.1733\n",
      "  False Discovery Rate Ratio: 0.6866\n",
      "  False Negative Rate: 0.4694\n",
      "  False Negative Rate Difference: 0.0891\n",
      "  False Negative Rate Ratio: 1.2112\n",
      "  False Omission Rate: 0.4944\n",
      "  False Omission Rate Difference: 0.1155\n",
      "  False Omission Rate Ratio: 1.2662\n",
      "  False Positive Rate: 0.5069\n",
      "  False Positive Rate Difference: -0.1485\n",
      "  False Positive Rate Ratio: 0.7374\n",
      "  Generalized Entropy Index: 0.2380\n",
      "  Generalized Equalized Odds Difference: 0.1485\n",
      "  Generalized False Negative Rate: 0.4694\n",
      "  Generalized False Positive Rate: 0.5069\n",
      "  Generalized True Negative Rate: 0.4931\n",
      "  Generalized True Positive Rate: 0.5306\n",
      "  Negative Predictive Value: 0.5056\n",
      "  Number of False Negatives: 3656.0000\n",
      "  Number of False Positives: 3844.0000\n",
      "  Number of Generalized False Negatives: 3656.0000\n",
      "  Number of Generalized False Positives: 3844.0000\n",
      "  Number of Generalized True Negatives: 3739.0000\n",
      "  Number of Generalized True Positives: 4133.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7583.0000\n",
      "  Number of Positives: 7789.0000\n",
      "  Number of Predicted Negatives: 7395.0000\n",
      "  Number of Predicted Positives: 7977.0000\n",
      "  Number of True Negatives: 3739.0000\n",
      "  Number of True Positives: 4133.0000\n",
      "  Positive Predictive Value: 0.5181\n",
      "  Power: 4133.0000\n",
      "  Precision: 0.5181\n",
      "  Recall: 0.5306\n",
      "  Sensitivity: 0.5306\n",
      "  Specificity: 0.4931\n",
      "  Theil Index: 0.3303\n",
      "  True Negative Rate: 0.4931\n",
      "  True Positive Rate: 0.5306\n",
      "  True Positive Rate Difference: -0.0891\n",
      "Protected Attribute Names: ['AGE']\n",
      "Privileged Protected Attributes: [{'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.1753\n",
      "  Statistical Parity Difference: 0.0907\n",
      "  Between Group Coefficient of Variation: 0.0378\n",
      "  Between Group Generalized Entropy Index: 0.0007\n",
      "  Between Group Theil Index: 0.0007\n",
      "  Mean Difference: 0.0907\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1167\n",
      "  Average Odds Difference: 0.0900\n",
      "  Average Predictive Value Difference: -0.0270\n",
      "  Between All Groups Coefficient of Variation: 0.0378\n",
      "  Between All Groups Generalized Entropy Index: 0.0007\n",
      "  Between All Groups Theil Index: 0.0007\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.1915\n",
      "  Equal Opportunity Difference: 0.2068\n",
      "  Equalized Odds Difference: 0.2068\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.1164\n",
      "  Error Rate Ratio: 0.7849\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.0935\n",
      "  False Discovery Rate Ratio: 0.8241\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.2068\n",
      "  False Negative Rate Ratio: 0.6046\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: -0.1475\n",
      "  False Omission Rate Ratio: 0.7325\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.0267\n",
      "  False Positive Rate Ratio: 0.9523\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.2068\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.2068\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.1753\n",
      "  Statistical Parity Difference: 0.0907\n",
      "  Between Group Coefficient of Variation: 0.0378\n",
      "  Between Group Generalized Entropy Index: 0.0007\n",
      "  Between Group Theil Index: 0.0007\n",
      "  Mean Difference: 0.0907\n",
      "  Smoothed Empirical Differential Fairness: 0.0168\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.1167\n",
      "  Average Odds Difference: 0.0900\n",
      "  Average Predictive Value Difference: -0.0270\n",
      "  Between All Groups Coefficient of Variation: 0.0378\n",
      "  Between All Groups Generalized Entropy Index: 0.0007\n",
      "  Between All Groups Theil Index: 0.0007\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: 0.1915\n",
      "  Equal Opportunity Difference: 0.2068\n",
      "  Equalized Odds Difference: 0.2068\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.1164\n",
      "  Error Rate Ratio: 0.7849\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.0935\n",
      "  False Discovery Rate Ratio: 0.8241\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.2068\n",
      "  False Negative Rate Ratio: 0.6046\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: -0.1475\n",
      "  False Omission Rate Ratio: 0.7325\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: -0.0267\n",
      "  False Positive Rate Ratio: 0.9523\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.2068\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.2068\n",
      "  Accuracy: 0.5097\n",
      "  Base Rate: 0.5082\n",
      "  Selection Rate: 0.5193\n",
      "  Disparate Impact: 1.1189\n",
      "  Statistical Parity Difference: 0.0604\n",
      "  Between Group Coefficient of Variation: 0.0244\n",
      "  Between Group Generalized Entropy Index: 0.0003\n",
      "  Between Group Theil Index: 0.0003\n",
      "  Mean Difference: 0.0604\n",
      "  Smoothed Empirical Differential Fairness: 0.0067\n",
      "  Consistency: 0.9561\n",
      "  Average Absolute Odds Difference: 0.1208\n",
      "  Average Odds Difference: 0.0590\n",
      "  Average Predictive Value Difference: -0.0186\n",
      "  Between All Groups Coefficient of Variation: 0.0244\n",
      "  Between All Groups Generalized Entropy Index: 0.0003\n",
      "  Between All Groups Theil Index: 0.0003\n",
      "  Coefficient of Variation: 0.6924\n",
      "  Differential Fairness Bias Amplification: 0.1244\n",
      "  Equal Opportunity Difference: 0.1798\n",
      "  Equalized Odds Difference: 0.1798\n",
      "  Error Rate: 0.4903\n",
      "  Error Rate Difference: -0.1213\n",
      "  Error Rate Ratio: 0.7632\n",
      "  False Discovery Rate: 0.4828\n",
      "  False Discovery Rate Difference: -0.1042\n",
      "  False Discovery Rate Ratio: 0.7932\n",
      "  False Negative Rate: 0.4715\n",
      "  False Negative Rate Difference: -0.1798\n",
      "  False Negative Rate Ratio: 0.6434\n",
      "  False Omission Rate: 0.4984\n",
      "  False Omission Rate Difference: -0.1415\n",
      "  False Omission Rate Ratio: 0.7289\n",
      "  False Positive Rate: 0.5098\n",
      "  False Positive Rate Difference: -0.0617\n",
      "  False Positive Rate Ratio: 0.8816\n",
      "  Generalized Entropy Index: 0.2397\n",
      "  Generalized Equalized Odds Difference: 0.1798\n",
      "  Generalized False Negative Rate: 0.4715\n",
      "  Generalized False Positive Rate: 0.5098\n",
      "  Generalized True Negative Rate: 0.4902\n",
      "  Generalized True Positive Rate: 0.5285\n",
      "  Negative Predictive Value: 0.5016\n",
      "  Number of False Negatives: 3683.0000\n",
      "  Number of False Positives: 3854.0000\n",
      "  Number of Generalized False Negatives: 3683.0000\n",
      "  Number of Generalized False Positives: 3854.0000\n",
      "  Number of Generalized True Negatives: 3706.0000\n",
      "  Number of Generalized True Positives: 4129.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7560.0000\n",
      "  Number of Positives: 7812.0000\n",
      "  Number of Predicted Negatives: 7389.0000\n",
      "  Number of Predicted Positives: 7983.0000\n",
      "  Number of True Negatives: 3706.0000\n",
      "  Number of True Positives: 4129.0000\n",
      "  Positive Predictive Value: 0.5172\n",
      "  Power: 4129.0000\n",
      "  Precision: 0.5172\n",
      "  Recall: 0.5285\n",
      "  Sensitivity: 0.5285\n",
      "  Specificity: 0.4902\n",
      "  Theil Index: 0.3327\n",
      "  True Negative Rate: 0.4902\n",
      "  True Positive Rate: 0.5285\n",
      "  True Positive Rate Difference: 0.1798\n",
      "  Accuracy: 0.5097\n",
      "  Base Rate: 0.5082\n",
      "  Selection Rate: 0.5193\n",
      "  Disparate Impact: 1.1189\n",
      "  Statistical Parity Difference: 0.0604\n",
      "  Between Group Coefficient of Variation: 0.0244\n",
      "  Between Group Generalized Entropy Index: 0.0003\n",
      "  Between Group Theil Index: 0.0003\n",
      "  Mean Difference: 0.0604\n",
      "  Smoothed Empirical Differential Fairness: 0.0067\n",
      "  Consistency: 0.9561\n",
      "  Average Absolute Odds Difference: 0.1208\n",
      "  Average Odds Difference: 0.0590\n",
      "  Average Predictive Value Difference: -0.0186\n",
      "  Between All Groups Coefficient of Variation: 0.0244\n",
      "  Between All Groups Generalized Entropy Index: 0.0003\n",
      "  Between All Groups Theil Index: 0.0003\n",
      "  Coefficient of Variation: 0.6924\n",
      "  Differential Fairness Bias Amplification: 0.1244\n",
      "  Equal Opportunity Difference: 0.1798\n",
      "  Equalized Odds Difference: 0.1798\n",
      "  Error Rate: 0.4903\n",
      "  Error Rate Difference: -0.1213\n",
      "  Error Rate Ratio: 0.7632\n",
      "  False Discovery Rate: 0.4828\n",
      "  False Discovery Rate Difference: -0.1042\n",
      "  False Discovery Rate Ratio: 0.7932\n",
      "  False Negative Rate: 0.4715\n",
      "  False Negative Rate Difference: -0.1798\n",
      "  False Negative Rate Ratio: 0.6434\n",
      "  False Omission Rate: 0.4984\n",
      "  False Omission Rate Difference: -0.1415\n",
      "  False Omission Rate Ratio: 0.7289\n",
      "  False Positive Rate: 0.5098\n",
      "  False Positive Rate Difference: -0.0617\n",
      "  False Positive Rate Ratio: 0.8816\n",
      "  Generalized Entropy Index: 0.2397\n",
      "  Generalized Equalized Odds Difference: 0.1798\n",
      "  Generalized False Negative Rate: 0.4715\n",
      "  Generalized False Positive Rate: 0.5098\n",
      "  Generalized True Negative Rate: 0.4902\n",
      "  Generalized True Positive Rate: 0.5285\n",
      "  Negative Predictive Value: 0.5016\n",
      "  Number of False Negatives: 3683.0000\n",
      "  Number of False Positives: 3854.0000\n",
      "  Number of Generalized False Negatives: 3683.0000\n",
      "  Number of Generalized False Positives: 3854.0000\n",
      "  Number of Generalized True Negatives: 3706.0000\n",
      "  Number of Generalized True Positives: 4129.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7560.0000\n",
      "  Number of Positives: 7812.0000\n",
      "  Number of Predicted Negatives: 7389.0000\n",
      "  Number of Predicted Positives: 7983.0000\n",
      "  Number of True Negatives: 3706.0000\n",
      "  Number of True Positives: 4129.0000\n",
      "  Positive Predictive Value: 0.5172\n",
      "  Power: 4129.0000\n",
      "  Precision: 0.5172\n",
      "  Recall: 0.5285\n",
      "  Sensitivity: 0.5285\n",
      "  Specificity: 0.4902\n",
      "  Theil Index: 0.3327\n",
      "  True Negative Rate: 0.4902\n",
      "  True Positive Rate: 0.5285\n",
      "  True Positive Rate Difference: 0.1798\n",
      "  Accuracy: 0.5085\n",
      "  Base Rate: 0.4945\n",
      "  Selection Rate: 0.5207\n",
      "  Disparate Impact: 1.1463\n",
      "  Statistical Parity Difference: 0.0741\n",
      "  Between Group Coefficient of Variation: 0.0232\n",
      "  Between Group Generalized Entropy Index: 0.0003\n",
      "  Between Group Theil Index: 0.0003\n",
      "  Mean Difference: 0.0741\n",
      "  Smoothed Empirical Differential Fairness: 0.0265\n",
      "  Consistency: 0.9567\n",
      "  Average Absolute Odds Difference: 0.1154\n",
      "  Average Odds Difference: 0.0733\n",
      "  Average Predictive Value Difference: -0.0039\n",
      "  Between All Groups Coefficient of Variation: 0.0232\n",
      "  Between All Groups Generalized Entropy Index: 0.0003\n",
      "  Between All Groups Theil Index: 0.0003\n",
      "  Coefficient of Variation: 0.6827\n",
      "  Differential Fairness Bias Amplification: 0.1363\n",
      "  Equal Opportunity Difference: 0.1887\n",
      "  Equalized Odds Difference: 0.1887\n",
      "  Error Rate: 0.4915\n",
      "  Error Rate Difference: -0.1164\n",
      "  Error Rate Ratio: 0.7734\n",
      "  False Discovery Rate: 0.4971\n",
      "  False Discovery Rate Difference: -0.1142\n",
      "  False Discovery Rate Ratio: 0.7808\n",
      "  False Negative Rate: 0.4705\n",
      "  False Negative Rate Difference: -0.1887\n",
      "  False Negative Rate Ratio: 0.6276\n",
      "  False Omission Rate: 0.4853\n",
      "  False Omission Rate Difference: -0.1221\n",
      "  False Omission Rate Ratio: 0.7584\n",
      "  False Positive Rate: 0.5120\n",
      "  False Positive Rate Difference: -0.0421\n",
      "  False Positive Rate Ratio: 0.9189\n",
      "  Generalized Entropy Index: 0.2330\n",
      "  Generalized Equalized Odds Difference: 0.1887\n",
      "  Generalized False Negative Rate: 0.4705\n",
      "  Generalized False Positive Rate: 0.5120\n",
      "  Generalized True Negative Rate: 0.4880\n",
      "  Generalized True Positive Rate: 0.5295\n",
      "  Negative Predictive Value: 0.5147\n",
      "  Number of False Negatives: 3576.0000\n",
      "  Number of False Positives: 3979.0000\n",
      "  Number of Generalized False Negatives: 3576.0000\n",
      "  Number of Generalized False Positives: 3979.0000\n",
      "  Number of Generalized True Negatives: 3792.0000\n",
      "  Number of Generalized True Positives: 4025.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7771.0000\n",
      "  Number of Positives: 7601.0000\n",
      "  Number of Predicted Negatives: 7368.0000\n",
      "  Number of Predicted Positives: 8004.0000\n",
      "  Number of True Negatives: 3792.0000\n",
      "  Number of True Positives: 4025.0000\n",
      "  Positive Predictive Value: 0.5029\n",
      "  Power: 4025.0000\n",
      "  Precision: 0.5029\n",
      "  Recall: 0.5295\n",
      "  Sensitivity: 0.5295\n",
      "  Specificity: 0.4880\n",
      "  Theil Index: 0.3238\n",
      "  True Negative Rate: 0.4880\n",
      "  True Positive Rate: 0.5295\n",
      "  True Positive Rate Difference: 0.1887\n",
      "  Accuracy: 0.5085\n",
      "  Base Rate: 0.4945\n",
      "  Selection Rate: 0.5207\n",
      "  Disparate Impact: 1.1463\n",
      "  Statistical Parity Difference: 0.0741\n",
      "  Between Group Coefficient of Variation: 0.0232\n",
      "  Between Group Generalized Entropy Index: 0.0003\n",
      "  Between Group Theil Index: 0.0003\n",
      "  Mean Difference: 0.0741\n",
      "  Smoothed Empirical Differential Fairness: 0.0265\n",
      "  Consistency: 0.9567\n",
      "  Average Absolute Odds Difference: 0.1154\n",
      "  Average Odds Difference: 0.0733\n",
      "  Average Predictive Value Difference: -0.0039\n",
      "  Between All Groups Coefficient of Variation: 0.0232\n",
      "  Between All Groups Generalized Entropy Index: 0.0003\n",
      "  Between All Groups Theil Index: 0.0003\n",
      "  Coefficient of Variation: 0.6827\n",
      "  Differential Fairness Bias Amplification: 0.1363\n",
      "  Equal Opportunity Difference: 0.1887\n",
      "  Equalized Odds Difference: 0.1887\n",
      "  Error Rate: 0.4915\n",
      "  Error Rate Difference: -0.1164\n",
      "  Error Rate Ratio: 0.7734\n",
      "  False Discovery Rate: 0.4971\n",
      "  False Discovery Rate Difference: -0.1142\n",
      "  False Discovery Rate Ratio: 0.7808\n",
      "  False Negative Rate: 0.4705\n",
      "  False Negative Rate Difference: -0.1887\n",
      "  False Negative Rate Ratio: 0.6276\n",
      "  False Omission Rate: 0.4853\n",
      "  False Omission Rate Difference: -0.1221\n",
      "  False Omission Rate Ratio: 0.7584\n",
      "  False Positive Rate: 0.5120\n",
      "  False Positive Rate Difference: -0.0421\n",
      "  False Positive Rate Ratio: 0.9189\n",
      "  Generalized Entropy Index: 0.2330\n",
      "  Generalized Equalized Odds Difference: 0.1887\n",
      "  Generalized False Negative Rate: 0.4705\n",
      "  Generalized False Positive Rate: 0.5120\n",
      "  Generalized True Negative Rate: 0.4880\n",
      "  Generalized True Positive Rate: 0.5295\n",
      "  Negative Predictive Value: 0.5147\n",
      "  Number of False Negatives: 3576.0000\n",
      "  Number of False Positives: 3979.0000\n",
      "  Number of Generalized False Negatives: 3576.0000\n",
      "  Number of Generalized False Positives: 3979.0000\n",
      "  Number of Generalized True Negatives: 3792.0000\n",
      "  Number of Generalized True Positives: 4025.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7771.0000\n",
      "  Number of Positives: 7601.0000\n",
      "  Number of Predicted Negatives: 7368.0000\n",
      "  Number of Predicted Positives: 8004.0000\n",
      "  Number of True Negatives: 3792.0000\n",
      "  Number of True Positives: 4025.0000\n",
      "  Positive Predictive Value: 0.5029\n",
      "  Power: 4025.0000\n",
      "  Precision: 0.5029\n",
      "  Recall: 0.5295\n",
      "  Sensitivity: 0.5295\n",
      "  Specificity: 0.4880\n",
      "  Theil Index: 0.3238\n",
      "  True Negative Rate: 0.4880\n",
      "  True Positive Rate: 0.5295\n",
      "  True Positive Rate Difference: 0.1887\n",
      "Protected Attribute Names: ['GENDER', 'AGE']\n",
      "Privileged Protected Attributes: [{'GENDER': 0, 'AGE': 0}]\n",
      "Unprivileged Protected Attributes: [{'GENDER': 1, 'AGE': 1}]\n",
      "Sensitive Attribute: AGE\n",
      "Description: AGE&GENDER Mitigation\n",
      "Creating BinaryLabelDataset...\n",
      "BinaryLabelDataset created.\n",
      "\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.0547\n",
      "  Statistical Parity Difference: 0.0332\n",
      "  Between Group Coefficient of Variation: 0.8839\n",
      "  Between Group Generalized Entropy Index: 0.3906\n",
      "  Between Group Theil Index: 0.5761\n",
      "  Mean Difference: 0.0332\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0678\n",
      "  Average Odds Difference: 0.0678\n",
      "  Average Predictive Value Difference: 0.1823\n",
      "  Between All Groups Coefficient of Variation: 0.1470\n",
      "  Between All Groups Generalized Entropy Index: 0.0108\n",
      "  Between All Groups Theil Index: 0.0110\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: -0.1613\n",
      "  Equal Opportunity Difference: 0.0554\n",
      "  Equalized Odds Difference: 0.0801\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0415\n",
      "  Error Rate Ratio: 0.9305\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1735\n",
      "  False Discovery Rate Ratio: 0.7150\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.0554\n",
      "  False Negative Rate Ratio: 0.8866\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.1911\n",
      "  False Omission Rate Ratio: 1.3305\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: 0.0801\n",
      "  False Positive Rate Ratio: 1.1160\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.0801\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.0554\n",
      "  Accuracy: 0.4810\n",
      "  Base Rate: 0.5068\n",
      "  Selection Rate: 0.5350\n",
      "  Disparate Impact: 1.0547\n",
      "  Statistical Parity Difference: 0.0332\n",
      "  Between Group Coefficient of Variation: 0.8839\n",
      "  Between Group Generalized Entropy Index: 0.3906\n",
      "  Between Group Theil Index: 0.5761\n",
      "  Mean Difference: 0.0332\n",
      "  Smoothed Empirical Differential Fairness: 0.6709\n",
      "  Consistency: 0.9577\n",
      "  Average Absolute Odds Difference: 0.0678\n",
      "  Average Odds Difference: 0.0678\n",
      "  Average Predictive Value Difference: 0.1823\n",
      "  Between All Groups Coefficient of Variation: 0.1470\n",
      "  Between All Groups Generalized Entropy Index: 0.0108\n",
      "  Between All Groups Theil Index: 0.0110\n",
      "  Coefficient of Variation: 0.7001\n",
      "  Differential Fairness Bias Amplification: -0.1613\n",
      "  Equal Opportunity Difference: 0.0554\n",
      "  Equalized Odds Difference: 0.0801\n",
      "  Error Rate: 0.5190\n",
      "  Error Rate Difference: -0.0415\n",
      "  Error Rate Ratio: 0.9305\n",
      "  False Discovery Rate: 0.5114\n",
      "  False Discovery Rate Difference: -0.1735\n",
      "  False Discovery Rate Ratio: 0.7150\n",
      "  False Negative Rate: 0.4842\n",
      "  False Negative Rate Difference: -0.0554\n",
      "  False Negative Rate Ratio: 0.8866\n",
      "  False Omission Rate: 0.5277\n",
      "  False Omission Rate Difference: 0.1911\n",
      "  False Omission Rate Ratio: 1.3305\n",
      "  False Positive Rate: 0.5547\n",
      "  False Positive Rate Difference: 0.0801\n",
      "  False Positive Rate Ratio: 1.1160\n",
      "  Generalized Entropy Index: 0.2451\n",
      "  Generalized Equalized Odds Difference: 0.0801\n",
      "  Generalized False Negative Rate: 0.4842\n",
      "  Generalized False Positive Rate: 0.5547\n",
      "  Generalized True Negative Rate: 0.4453\n",
      "  Generalized True Positive Rate: 0.5158\n",
      "  Negative Predictive Value: 0.4723\n",
      "  Number of False Negatives: 3772.0000\n",
      "  Number of False Positives: 4206.0000\n",
      "  Number of Generalized False Negatives: 3772.0000\n",
      "  Number of Generalized False Positives: 4206.0000\n",
      "  Number of Generalized True Negatives: 3376.0000\n",
      "  Number of Generalized True Positives: 4018.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7582.0000\n",
      "  Number of Positives: 7790.0000\n",
      "  Number of Predicted Negatives: 7148.0000\n",
      "  Number of Predicted Positives: 8224.0000\n",
      "  Number of True Negatives: 3376.0000\n",
      "  Number of True Positives: 4018.0000\n",
      "  Positive Predictive Value: 0.4886\n",
      "  Power: 4018.0000\n",
      "  Precision: 0.4886\n",
      "  Recall: 0.5158\n",
      "  Sensitivity: 0.5158\n",
      "  Specificity: 0.4453\n",
      "  Theil Index: 0.3411\n",
      "  True Negative Rate: 0.4453\n",
      "  True Positive Rate: 0.5158\n",
      "  True Positive Rate Difference: 0.0554\n",
      "  Accuracy: 0.5013\n",
      "  Base Rate: 0.5083\n",
      "  Selection Rate: 0.5235\n",
      "  Disparate Impact: 1.0583\n",
      "  Statistical Parity Difference: 0.0340\n",
      "  Between Group Coefficient of Variation: 0.8723\n",
      "  Between Group Generalized Entropy Index: 0.3804\n",
      "  Between Group Theil Index: 0.5648\n",
      "  Mean Difference: 0.0340\n",
      "  Smoothed Empirical Differential Fairness: 0.6338\n",
      "  Consistency: 0.9552\n",
      "  Average Absolute Odds Difference: 0.0520\n",
      "  Average Odds Difference: 0.0520\n",
      "  Average Predictive Value Difference: 0.1636\n",
      "  Between All Groups Coefficient of Variation: 0.1255\n",
      "  Between All Groups Generalized Entropy Index: 0.0079\n",
      "  Between All Groups Theil Index: 0.0080\n",
      "  Coefficient of Variation: 0.6954\n",
      "  Differential Fairness Bias Amplification: -0.2028\n",
      "  Equal Opportunity Difference: 0.0491\n",
      "  Equalized Odds Difference: 0.0549\n",
      "  Error Rate: 0.4987\n",
      "  Error Rate Difference: -0.0366\n",
      "  Error Rate Ratio: 0.9345\n",
      "  False Discovery Rate: 0.4908\n",
      "  False Discovery Rate Difference: -0.1630\n",
      "  False Discovery Rate Ratio: 0.7153\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: -0.0491\n",
      "  False Negative Rate Ratio: 0.8963\n",
      "  False Omission Rate: 0.5074\n",
      "  False Omission Rate Difference: 0.1641\n",
      "  False Omission Rate Ratio: 1.3050\n",
      "  False Positive Rate: 0.5226\n",
      "  False Positive Rate Difference: 0.0549\n",
      "  False Positive Rate Ratio: 1.0866\n",
      "  Generalized Entropy Index: 0.2418\n",
      "  Generalized Equalized Odds Difference: 0.0549\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.5226\n",
      "  Generalized True Negative Rate: 0.4774\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.4926\n",
      "  Number of False Negatives: 3716.0000\n",
      "  Number of False Positives: 3950.0000\n",
      "  Number of Generalized False Negatives: 3716.0000\n",
      "  Number of Generalized False Positives: 3950.0000\n",
      "  Number of Generalized True Negatives: 3608.0000\n",
      "  Number of Generalized True Positives: 4098.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7558.0000\n",
      "  Number of Positives: 7814.0000\n",
      "  Number of Predicted Negatives: 7324.0000\n",
      "  Number of Predicted Positives: 8048.0000\n",
      "  Number of True Negatives: 3608.0000\n",
      "  Number of True Positives: 4098.0000\n",
      "  Positive Predictive Value: 0.5092\n",
      "  Power: 4098.0000\n",
      "  Precision: 0.5092\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.4774\n",
      "  Theil Index: 0.3358\n",
      "  True Negative Rate: 0.4774\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: 0.0491\n",
      "  Accuracy: 0.5013\n",
      "  Base Rate: 0.5083\n",
      "  Selection Rate: 0.5235\n",
      "  Disparate Impact: 1.0583\n",
      "  Statistical Parity Difference: 0.0340\n",
      "  Between Group Coefficient of Variation: 0.8723\n",
      "  Between Group Generalized Entropy Index: 0.3804\n",
      "  Between Group Theil Index: 0.5648\n",
      "  Mean Difference: 0.0340\n",
      "  Smoothed Empirical Differential Fairness: 0.6338\n",
      "  Consistency: 0.9552\n",
      "  Average Absolute Odds Difference: 0.0520\n",
      "  Average Odds Difference: 0.0520\n",
      "  Average Predictive Value Difference: 0.1636\n",
      "  Between All Groups Coefficient of Variation: 0.1255\n",
      "  Between All Groups Generalized Entropy Index: 0.0079\n",
      "  Between All Groups Theil Index: 0.0080\n",
      "  Coefficient of Variation: 0.6954\n",
      "  Differential Fairness Bias Amplification: -0.2028\n",
      "  Equal Opportunity Difference: 0.0491\n",
      "  Equalized Odds Difference: 0.0549\n",
      "  Error Rate: 0.4987\n",
      "  Error Rate Difference: -0.0366\n",
      "  Error Rate Ratio: 0.9345\n",
      "  False Discovery Rate: 0.4908\n",
      "  False Discovery Rate Difference: -0.1630\n",
      "  False Discovery Rate Ratio: 0.7153\n",
      "  False Negative Rate: 0.4756\n",
      "  False Negative Rate Difference: -0.0491\n",
      "  False Negative Rate Ratio: 0.8963\n",
      "  False Omission Rate: 0.5074\n",
      "  False Omission Rate Difference: 0.1641\n",
      "  False Omission Rate Ratio: 1.3050\n",
      "  False Positive Rate: 0.5226\n",
      "  False Positive Rate Difference: 0.0549\n",
      "  False Positive Rate Ratio: 1.0866\n",
      "  Generalized Entropy Index: 0.2418\n",
      "  Generalized Equalized Odds Difference: 0.0549\n",
      "  Generalized False Negative Rate: 0.4756\n",
      "  Generalized False Positive Rate: 0.5226\n",
      "  Generalized True Negative Rate: 0.4774\n",
      "  Generalized True Positive Rate: 0.5244\n",
      "  Negative Predictive Value: 0.4926\n",
      "  Number of False Negatives: 3716.0000\n",
      "  Number of False Positives: 3950.0000\n",
      "  Number of Generalized False Negatives: 3716.0000\n",
      "  Number of Generalized False Positives: 3950.0000\n",
      "  Number of Generalized True Negatives: 3608.0000\n",
      "  Number of Generalized True Positives: 4098.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7558.0000\n",
      "  Number of Positives: 7814.0000\n",
      "  Number of Predicted Negatives: 7324.0000\n",
      "  Number of Predicted Positives: 8048.0000\n",
      "  Number of True Negatives: 3608.0000\n",
      "  Number of True Positives: 4098.0000\n",
      "  Positive Predictive Value: 0.5092\n",
      "  Power: 4098.0000\n",
      "  Precision: 0.5092\n",
      "  Recall: 0.5244\n",
      "  Sensitivity: 0.5244\n",
      "  Specificity: 0.4774\n",
      "  Theil Index: 0.3358\n",
      "  True Negative Rate: 0.4774\n",
      "  True Positive Rate: 0.5244\n",
      "  True Positive Rate Difference: 0.0491\n",
      "  Accuracy: 0.5085\n",
      "  Base Rate: 0.5020\n",
      "  Selection Rate: 0.5204\n",
      "  Disparate Impact: 1.0182\n",
      "  Statistical Parity Difference: 0.0106\n",
      "  Between Group Coefficient of Variation: 0.8881\n",
      "  Between Group Generalized Entropy Index: 0.3943\n",
      "  Between Group Theil Index: 0.5795\n",
      "  Mean Difference: 0.0106\n",
      "  Smoothed Empirical Differential Fairness: 0.7649\n",
      "  Consistency: 0.9569\n",
      "  Average Absolute Odds Difference: 0.0323\n",
      "  Average Odds Difference: 0.0323\n",
      "  Average Predictive Value Difference: 0.1925\n",
      "  Between All Groups Coefficient of Variation: 0.1334\n",
      "  Between All Groups Generalized Entropy Index: 0.0089\n",
      "  Between All Groups Theil Index: 0.0090\n",
      "  Coefficient of Variation: 0.6881\n",
      "  Differential Fairness Bias Amplification: -0.4017\n",
      "  Equal Opportunity Difference: 0.0229\n",
      "  Equalized Odds Difference: 0.0417\n",
      "  Error Rate: 0.4915\n",
      "  Error Rate Difference: -0.0306\n",
      "  Error Rate Ratio: 0.9450\n",
      "  False Discovery Rate: 0.4900\n",
      "  False Discovery Rate Difference: -0.1875\n",
      "  False Discovery Rate Ratio: 0.6782\n",
      "  False Negative Rate: 0.4712\n",
      "  False Negative Rate Difference: -0.0229\n",
      "  False Negative Rate Ratio: 0.9512\n",
      "  False Omission Rate: 0.4932\n",
      "  False Omission Rate Difference: 0.1974\n",
      "  False Omission Rate Ratio: 1.3805\n",
      "  False Positive Rate: 0.5120\n",
      "  False Positive Rate Difference: 0.0417\n",
      "  False Positive Rate Ratio: 1.0664\n",
      "  Generalized Entropy Index: 0.2368\n",
      "  Generalized Equalized Odds Difference: 0.0417\n",
      "  Generalized False Negative Rate: 0.4712\n",
      "  Generalized False Positive Rate: 0.5120\n",
      "  Generalized True Negative Rate: 0.4880\n",
      "  Generalized True Positive Rate: 0.5288\n",
      "  Negative Predictive Value: 0.5068\n",
      "  Number of False Negatives: 3636.0000\n",
      "  Number of False Positives: 3920.0000\n",
      "  Number of Generalized False Negatives: 3636.0000\n",
      "  Number of Generalized False Positives: 3920.0000\n",
      "  Number of Generalized True Negatives: 3736.0000\n",
      "  Number of Generalized True Positives: 4080.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7656.0000\n",
      "  Number of Positives: 7716.0000\n",
      "  Number of Predicted Negatives: 7372.0000\n",
      "  Number of Predicted Positives: 8000.0000\n",
      "  Number of True Negatives: 3736.0000\n",
      "  Number of True Positives: 4080.0000\n",
      "  Positive Predictive Value: 0.5100\n",
      "  Power: 4080.0000\n",
      "  Precision: 0.5100\n",
      "  Recall: 0.5288\n",
      "  Sensitivity: 0.5288\n",
      "  Specificity: 0.4880\n",
      "  Theil Index: 0.3288\n",
      "  True Negative Rate: 0.4880\n",
      "  True Positive Rate: 0.5288\n",
      "  True Positive Rate Difference: 0.0229\n",
      "  Accuracy: 0.5085\n",
      "  Base Rate: 0.5020\n",
      "  Selection Rate: 0.5204\n",
      "  Disparate Impact: 1.0182\n",
      "  Statistical Parity Difference: 0.0106\n",
      "  Between Group Coefficient of Variation: 0.8881\n",
      "  Between Group Generalized Entropy Index: 0.3943\n",
      "  Between Group Theil Index: 0.5795\n",
      "  Mean Difference: 0.0106\n",
      "  Smoothed Empirical Differential Fairness: 0.7649\n",
      "  Consistency: 0.9569\n",
      "  Average Absolute Odds Difference: 0.0323\n",
      "  Average Odds Difference: 0.0323\n",
      "  Average Predictive Value Difference: 0.1925\n",
      "  Between All Groups Coefficient of Variation: 0.1334\n",
      "  Between All Groups Generalized Entropy Index: 0.0089\n",
      "  Between All Groups Theil Index: 0.0090\n",
      "  Coefficient of Variation: 0.6881\n",
      "  Differential Fairness Bias Amplification: -0.4017\n",
      "  Equal Opportunity Difference: 0.0229\n",
      "  Equalized Odds Difference: 0.0417\n",
      "  Error Rate: 0.4915\n",
      "  Error Rate Difference: -0.0306\n",
      "  Error Rate Ratio: 0.9450\n",
      "  False Discovery Rate: 0.4900\n",
      "  False Discovery Rate Difference: -0.1875\n",
      "  False Discovery Rate Ratio: 0.6782\n",
      "  False Negative Rate: 0.4712\n",
      "  False Negative Rate Difference: -0.0229\n",
      "  False Negative Rate Ratio: 0.9512\n",
      "  False Omission Rate: 0.4932\n",
      "  False Omission Rate Difference: 0.1974\n",
      "  False Omission Rate Ratio: 1.3805\n",
      "  False Positive Rate: 0.5120\n",
      "  False Positive Rate Difference: 0.0417\n",
      "  False Positive Rate Ratio: 1.0664\n",
      "  Generalized Entropy Index: 0.2368\n",
      "  Generalized Equalized Odds Difference: 0.0417\n",
      "  Generalized False Negative Rate: 0.4712\n",
      "  Generalized False Positive Rate: 0.5120\n",
      "  Generalized True Negative Rate: 0.4880\n",
      "  Generalized True Positive Rate: 0.5288\n",
      "  Negative Predictive Value: 0.5068\n",
      "  Number of False Negatives: 3636.0000\n",
      "  Number of False Positives: 3920.0000\n",
      "  Number of Generalized False Negatives: 3636.0000\n",
      "  Number of Generalized False Positives: 3920.0000\n",
      "  Number of Generalized True Negatives: 3736.0000\n",
      "  Number of Generalized True Positives: 4080.0000\n",
      "  Number of Instances: 15372.0000\n",
      "  Number of Negatives: 7656.0000\n",
      "  Number of Positives: 7716.0000\n",
      "  Number of Predicted Negatives: 7372.0000\n",
      "  Number of Predicted Positives: 8000.0000\n",
      "  Number of True Negatives: 3736.0000\n",
      "  Number of True Positives: 4080.0000\n",
      "  Positive Predictive Value: 0.5100\n",
      "  Power: 4080.0000\n",
      "  Precision: 0.5100\n",
      "  Recall: 0.5288\n",
      "  Sensitivity: 0.5288\n",
      "  Specificity: 0.4880\n",
      "  Theil Index: 0.3288\n",
      "  True Negative Rate: 0.4880\n",
      "  True Positive Rate: 0.5288\n",
      "  True Positive Rate Difference: 0.0229\n"
     ]
    }
   ],
   "source": [
    "for config in protected_attribute_configs:\n",
    "    protected_attribute_names = config[\"protected_attribute_names\"]\n",
    "    privileged_protected_attributes = config[\"privileged_protected_attributes\"]\n",
    "    unprivileged_protected_attributes = config[\"unprivileged_protected_attributes\"]\n",
    "    sensitive_attribute = config[\"sensitive_attribute\"]\n",
    "    desc = config[\"desc\"]\n",
    "\n",
    "    print(\"Protected Attribute Names:\", protected_attribute_names)\n",
    "    print(\"Privileged Protected Attributes:\", privileged_protected_attributes)\n",
    "    print(\"Unprivileged Protected Attributes:\", unprivileged_protected_attributes)\n",
    "    print(\"Sensitive Attribute:\", sensitive_attribute)\n",
    "    print(\"Description:\", desc)\n",
    "\n",
    "    # Creating BinaryLabelDataset\n",
    "    print(\"Creating BinaryLabelDataset...\")\n",
    "    binary_dataset = BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=['Emotion_Type'],\n",
    "        protected_attribute_names=protected_attribute_names\n",
    "    )\n",
    "    print(\"BinaryLabelDataset created.\\n\")\n",
    "\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_bld = BinaryLabelDataset(df=pred_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "\n",
    "    compute_fairness_metrics_CM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RFC model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_bld, pred_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RFC model-CM-{desc}\")\n",
    "    \n",
    "    reweighing = Reweighing(\n",
    "        privileged_groups=privileged_protected_attributes,\n",
    "        unprivileged_groups=unprivileged_protected_attributes\n",
    "    )\n",
    "    reweighed_dataset = reweighing.fit_transform(binary_dataset)\n",
    "\n",
    "    dir_remover = DisparateImpactRemover(repair_level=0.1, sensitive_attribute=sensitive_attribute)\n",
    "    dir_processed = dir_remover.fit_transform(binary_dataset)\n",
    "    \n",
    "    # Perform a 80%-20% split for training and test sets\n",
    "    train_dir, test_dir = dir_processed.split([0.85], shuffle=True)\n",
    "    train_reweighed, test_reweighed = reweighed_dataset.split([0.85], shuffle=True)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    train_dir_df = train_dir.convert_to_dataframe()[0]\n",
    "    test_dir_df = test_dir.convert_to_dataframe()[0]\n",
    "    \n",
    "    train_reweighed_df = train_reweighed.convert_to_dataframe()[0]\n",
    "    test_reweighed_df = test_reweighed.convert_to_dataframe()[0]\n",
    "\n",
    "    dir_weights = train_dir.instance_weights\n",
    "    rw_weights = train_reweighed.instance_weights\n",
    "    \n",
    "    def prepare_data_for_rfc(dataset):\n",
    "        features = dataset.drop(columns=['Emotion', 'Emotion_Type'])\n",
    "        labels = dataset['Emotion']\n",
    "        return features, labels\n",
    "    \n",
    "    X_train_dir, y_train_dir = prepare_data_for_rfc(train_dir_df)\n",
    "    X_test_dir, y_test_dir = prepare_data_for_rfc(test_dir_df)\n",
    "    \n",
    "    X_train_reweighed, y_train_reweighed = prepare_data_for_rfc(train_reweighed_df)\n",
    "    X_test_reweighed, y_test_reweighed = prepare_data_for_rfc(test_reweighed_df)\n",
    "\n",
    "    rfc_dir = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfc_dir.fit(X_train_dir, y_train_dir, sample_weight=dir_weights)\n",
    "    y_pred_dir = rfc_dir.predict(X_test_dir)\n",
    "\n",
    "    rfc_reweighed = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfc_reweighed.fit(X_train_reweighed, y_train_reweighed, sample_weight=rw_weights)\n",
    "    y_pred_reweighed = rfc_reweighed.predict(X_test_reweighed)\n",
    "    \n",
    "    pred_reweighed_df = test_reweighed_df.copy()\n",
    "    pred_reweighed_df['Emotion'] = y_pred_reweighed\n",
    "    \n",
    "    pred_dir_df = test_dir_df.copy()\n",
    "    pred_dir_df['Emotion'] = y_pred_dir\n",
    "    \n",
    "    pred_reweighed_df['Emotion_Type'] = pred_reweighed_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    pred_dir_df['Emotion_Type'] = pred_dir_df['Emotion'].apply(lambda x: 1.0 if x in positive_emotion_numbers else 0.0)\n",
    "    \n",
    "    pred_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    pred_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    pred_reweighed_bld = BinaryLabelDataset(df=pred_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    pred_dir_bld = BinaryLabelDataset(df=pred_dir_df, label_names=['Emotion_Type'], protected_attribute_names=protected_attribute_names)\n",
    "    \n",
    "    test_dir_df.drop(columns=['Emotion'], inplace=True)\n",
    "    test_reweighed_df.drop(columns=['Emotion'], inplace=True)\n",
    "    \n",
    "    test_dir = BinaryLabelDataset(df=test_dir_df, label_names=['Emotion_Type'], protected_attribute_names=test_dir.protected_attribute_names)\n",
    "    test_reweighed = BinaryLabelDataset(df=test_reweighed_df, label_names=['Emotion_Type'], protected_attribute_names=test_reweighed.protected_attribute_names)\n",
    "    \n",
    "    compute_fairness_metrics_CM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RFC DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_dir, pred_dir_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RFC DIR model-CM-{desc}\")\n",
    "    compute_fairness_metrics_CM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RFC Reweighed model-CM-{desc}\")\n",
    "    compute_fairness_metrics_MDSSCM(test_reweighed, pred_reweighed_bld, privileged_protected_attributes, unprivileged_protected_attributes, f\"RFC Reweighed model-CM-{desc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f720058d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T12:32:58.706449Z",
     "iopub.status.busy": "2025-02-25T12:32:58.706089Z",
     "iopub.status.idle": "2025-02-25T12:32:58.741866Z",
     "shell.execute_reply": "2025-02-25T12:32:58.740914Z"
    },
    "papermill": {
     "duration": 27.743927,
     "end_time": "2025-02-25T12:32:58.743374",
     "exception": false,
     "start_time": "2025-02-25T12:32:30.999447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Base Rate</th>\n",
       "      <th>Selection Rate</th>\n",
       "      <th>Disparate Impact</th>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <th>Between Group Coefficient of Variation</th>\n",
       "      <th>Between Group Generalized Entropy Index</th>\n",
       "      <th>Between Group Theil Index</th>\n",
       "      <th>Mean Difference</th>\n",
       "      <th>...</th>\n",
       "      <th>Positive Predictive Value</th>\n",
       "      <th>Power</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Theil Index</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>True Positive Rate</th>\n",
       "      <th>True Positive Rate Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ideal Values</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU model-CM-GENDER Mitigation</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.506766</td>\n",
       "      <td>0.510994</td>\n",
       "      <td>0.801467</td>\n",
       "      <td>-0.111620</td>\n",
       "      <td>0.124256</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>-0.111620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520051</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>0.520051</td>\n",
       "      <td>0.52439</td>\n",
       "      <td>0.52439</td>\n",
       "      <td>0.50277</td>\n",
       "      <td>0.334339</td>\n",
       "      <td>0.502770</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>-0.093531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU model-CM-GENDER Mitigation</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.506766</td>\n",
       "      <td>0.510994</td>\n",
       "      <td>0.801467</td>\n",
       "      <td>-0.111620</td>\n",
       "      <td>0.124256</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>-0.111620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520051</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>0.520051</td>\n",
       "      <td>0.52439</td>\n",
       "      <td>0.52439</td>\n",
       "      <td>0.50277</td>\n",
       "      <td>0.334339</td>\n",
       "      <td>0.502770</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>-0.093531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU DIR model-CM-GENDER Mitigation</td>\n",
       "      <td>0.509075</td>\n",
       "      <td>0.507416</td>\n",
       "      <td>0.510246</td>\n",
       "      <td>0.784730</td>\n",
       "      <td>-0.121895</td>\n",
       "      <td>0.125026</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>-0.121895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51616</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>0.51616</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>0.498811</td>\n",
       "      <td>0.338453</td>\n",
       "      <td>0.498811</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>-0.110436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRU DIR model-CM-GENDER Mitigation</td>\n",
       "      <td>0.509075</td>\n",
       "      <td>0.507416</td>\n",
       "      <td>0.510246</td>\n",
       "      <td>0.784730</td>\n",
       "      <td>-0.121895</td>\n",
       "      <td>0.125026</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>-0.121895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51616</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>0.51616</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>0.498811</td>\n",
       "      <td>0.338453</td>\n",
       "      <td>0.498811</td>\n",
       "      <td>0.519038</td>\n",
       "      <td>-0.110436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RFC model-CM-AGE&amp;GENDER Mitigation</td>\n",
       "      <td>0.481004</td>\n",
       "      <td>0.506766</td>\n",
       "      <td>0.534999</td>\n",
       "      <td>1.054707</td>\n",
       "      <td>0.033231</td>\n",
       "      <td>0.883853</td>\n",
       "      <td>0.390598</td>\n",
       "      <td>0.576114</td>\n",
       "      <td>0.033231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48857</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>0.48857</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.445265</td>\n",
       "      <td>0.341053</td>\n",
       "      <td>0.445265</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.055399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RFC DIR model-CM-AGE&amp;GENDER Mitigation</td>\n",
       "      <td>0.501301</td>\n",
       "      <td>0.508327</td>\n",
       "      <td>0.523549</td>\n",
       "      <td>1.058350</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>0.872256</td>\n",
       "      <td>0.380415</td>\n",
       "      <td>0.564781</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509195</td>\n",
       "      <td>4098.0</td>\n",
       "      <td>0.509195</td>\n",
       "      <td>0.524443</td>\n",
       "      <td>0.524443</td>\n",
       "      <td>0.477375</td>\n",
       "      <td>0.335774</td>\n",
       "      <td>0.477375</td>\n",
       "      <td>0.524443</td>\n",
       "      <td>0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RFC DIR model-CM-AGE&amp;GENDER Mitigation</td>\n",
       "      <td>0.501301</td>\n",
       "      <td>0.508327</td>\n",
       "      <td>0.523549</td>\n",
       "      <td>1.058350</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>0.872256</td>\n",
       "      <td>0.380415</td>\n",
       "      <td>0.564781</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509195</td>\n",
       "      <td>4098.0</td>\n",
       "      <td>0.509195</td>\n",
       "      <td>0.524443</td>\n",
       "      <td>0.524443</td>\n",
       "      <td>0.477375</td>\n",
       "      <td>0.335774</td>\n",
       "      <td>0.477375</td>\n",
       "      <td>0.524443</td>\n",
       "      <td>0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RFC Reweighed model-CM-AGE&amp;GENDER Mitigation</td>\n",
       "      <td>0.508457</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.520427</td>\n",
       "      <td>1.018188</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.888057</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.328798</td>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.022936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RFC Reweighed model-CM-AGE&amp;GENDER Mitigation</td>\n",
       "      <td>0.508457</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.520427</td>\n",
       "      <td>1.018188</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.888057</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.328798</td>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.022936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Description  Accuracy Base Rate  \\\n",
       "0                                   Ideal Values       N/A       N/A   \n",
       "1                 GRU model-CM-GENDER Mitigation  0.513726  0.506766   \n",
       "2                 GRU model-CM-GENDER Mitigation  0.513726  0.506766   \n",
       "3             GRU DIR model-CM-GENDER Mitigation  0.509075  0.507416   \n",
       "4             GRU DIR model-CM-GENDER Mitigation  0.509075  0.507416   \n",
       "..                                           ...       ...       ...   \n",
       "86            RFC model-CM-AGE&GENDER Mitigation  0.481004  0.506766   \n",
       "87        RFC DIR model-CM-AGE&GENDER Mitigation  0.501301  0.508327   \n",
       "88        RFC DIR model-CM-AGE&GENDER Mitigation  0.501301  0.508327   \n",
       "89  RFC Reweighed model-CM-AGE&GENDER Mitigation  0.508457  0.501952   \n",
       "90  RFC Reweighed model-CM-AGE&GENDER Mitigation  0.508457  0.501952   \n",
       "\n",
       "   Selection Rate  Disparate Impact  Statistical Parity Difference  \\\n",
       "0             N/A          1.000000                       0.000000   \n",
       "1        0.510994          0.801467                      -0.111620   \n",
       "2        0.510994          0.801467                      -0.111620   \n",
       "3        0.510246          0.784730                      -0.121895   \n",
       "4        0.510246          0.784730                      -0.121895   \n",
       "..            ...               ...                            ...   \n",
       "86       0.534999          1.054707                       0.033231   \n",
       "87       0.523549          1.058350                       0.034019   \n",
       "88       0.523549          1.058350                       0.034019   \n",
       "89       0.520427          1.018188                       0.010614   \n",
       "90       0.520427          1.018188                       0.010614   \n",
       "\n",
       "    Between Group Coefficient of Variation  \\\n",
       "0                                 0.000000   \n",
       "1                                 0.124256   \n",
       "2                                 0.124256   \n",
       "3                                 0.125026   \n",
       "4                                 0.125026   \n",
       "..                                     ...   \n",
       "86                                0.883853   \n",
       "87                                0.872256   \n",
       "88                                0.872256   \n",
       "89                                0.888057   \n",
       "90                                0.888057   \n",
       "\n",
       "    Between Group Generalized Entropy Index  Between Group Theil Index  \\\n",
       "0                                  0.000000                   0.000000   \n",
       "1                                  0.007720                   0.007793   \n",
       "2                                  0.007720                   0.007793   \n",
       "3                                  0.007816                   0.007890   \n",
       "4                                  0.007816                   0.007890   \n",
       "..                                      ...                        ...   \n",
       "86                                 0.390598                   0.576114   \n",
       "87                                 0.380415                   0.564781   \n",
       "88                                 0.380415                   0.564781   \n",
       "89                                 0.394322                   0.579519   \n",
       "90                                 0.394322                   0.579519   \n",
       "\n",
       "    Mean Difference  ...  Positive Predictive Value   Power Precision  \\\n",
       "0          0.000000  ...                        N/A     N/A       N/A   \n",
       "1         -0.111620  ...                   0.520051  4085.0  0.520051   \n",
       "2         -0.111620  ...                   0.520051  4085.0  0.520051   \n",
       "3         -0.121895  ...                    0.51616  2699.0   0.51616   \n",
       "4         -0.121895  ...                    0.51616  2699.0   0.51616   \n",
       "..              ...  ...                        ...     ...       ...   \n",
       "86         0.033231  ...                    0.48857  4018.0   0.48857   \n",
       "87         0.034019  ...                   0.509195  4098.0  0.509195   \n",
       "88         0.034019  ...                   0.509195  4098.0  0.509195   \n",
       "89         0.010614  ...                       0.51  4080.0      0.51   \n",
       "90         0.010614  ...                       0.51  4080.0      0.51   \n",
       "\n",
       "      Recall Sensitivity Specificity Theil Index True Negative Rate  \\\n",
       "0        N/A         N/A         N/A         N/A           1.000000   \n",
       "1    0.52439     0.52439     0.50277    0.334339           0.502770   \n",
       "2    0.52439     0.52439     0.50277    0.334339           0.502770   \n",
       "3   0.519038    0.519038    0.498811    0.338453           0.498811   \n",
       "4   0.519038    0.519038    0.498811    0.338453           0.498811   \n",
       "..       ...         ...         ...         ...                ...   \n",
       "86  0.515789    0.515789    0.445265    0.341053           0.445265   \n",
       "87  0.524443    0.524443    0.477375    0.335774           0.477375   \n",
       "88  0.524443    0.524443    0.477375    0.335774           0.477375   \n",
       "89  0.528771    0.528771    0.487983    0.328798           0.487983   \n",
       "90  0.528771    0.528771    0.487983    0.328798           0.487983   \n",
       "\n",
       "   True Positive Rate True Positive Rate Difference  \n",
       "0            1.000000                      0.000000  \n",
       "1            0.524390                     -0.093531  \n",
       "2            0.524390                     -0.093531  \n",
       "3            0.519038                     -0.110436  \n",
       "4            0.519038                     -0.110436  \n",
       "..                ...                           ...  \n",
       "86           0.515789                      0.055399  \n",
       "87           0.524443                      0.049118  \n",
       "88           0.524443                      0.049118  \n",
       "89           0.528771                      0.022936  \n",
       "90           0.528771                      0.022936  \n",
       "\n",
       "[91 rows x 67 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_results.to_csv('fairness_metrics.csv', index=False)\n",
    "fairness_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980714ca",
   "metadata": {
    "papermill": {
     "duration": 28.142052,
     "end_time": "2025-02-25T12:33:54.225778",
     "exception": false,
     "start_time": "2025-02-25T12:33:26.083726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6390851,
     "sourceId": 10322004,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27339.558459,
   "end_time": "2025-02-25T12:34:24.611827",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-25T04:58:45.053368",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
